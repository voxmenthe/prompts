A few things I've noticed as all devs write code with AI.

When you write foundational / architectural code of a new project by hand, you "feel" the code pushing back if your abstraction isn't right. You feel when something is harder than it should be. The code is telling you it's not in the right shape. Good engineers are sensitive to this.

When you're using an LLM coding assistant, you keep pushing right through this in a way that feels like you're making progress, and it may even be directionally correct in a sense, but the underlying foundation of it all is actually bad in a way that either kills progress of the LLM later as it buckles under the complexity it has created or destroys your ability to maintain the code long term.

