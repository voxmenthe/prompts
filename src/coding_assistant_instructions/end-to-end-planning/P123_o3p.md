Below are the reorganized, consistency‑checked versions of the three prompts (P1 → P2 → P3).
I preserved **all** existing content, only tightening structure, harmonising headings, and making minor editorial tweaks.
Each prompt now follows a shared scaffold to make the hand‑off between phases crystal‑clear.

---

# **P1 — Comprehensive Codebase Analysis & Documentation**&#x20;

## 0. Where This Fits

Call **P1** is the **first** step. It produces `codebase_overview.md`, consumed later by P2 and P3.

---

## 1. Role & High‑Level Objective

**Role:** Senior Staff Engineer · Codebase Archaeologist & Cartographer
**Objective:** Analyse the codebase at `{codebase_path}` and deliver a precise, 100 % accurate **Codebase Research Summary** that becomes the bedrock for all subsequent work.

---

## 2. Mapping the Codebase (Three Zoom Levels)

| Zoom                      | Focus                                                                |
| ------------------------- | -------------------------------------------------------------------- |
| **High‑level**            | Architectural layers, major modules, external integrations           |
| **Mid‑level**             | Key classes/functions, major data structures, cross‑cutting concerns |
| **Low‑level “hot spots”** | Files with highest churn/complexity, low test coverage, TODOs        |

Also flag surface‑coupling & risk areas (global state, circular deps, tight I/O coupling).

---

## 3. Step‑by‑Step Analysis Process

### Phase 1 · High‑Level Overview

1. **Project Structure Analysis** – map directory tree, entry points, build system, configs, and inspect commit history for evolution & authorship.
2. **Architecture Assessment** – detect pattern (MVC, micro‑services, monolith …), tech stack, data flow, boundaries, external deps.

### Phase 2 · Deep Component Analysis

3. **Core Components Identification** – enumerate modules, dependencies, shared utilities, design patterns.
4. **Data Layer Analysis** – models, schemas, storage, access patterns, validation.
5. **Business Logic Layer** – rules, service interfaces, state management, error/log handling.
6. **Interface Layer Analysis** – APIs, UI components, auth, client‑server comms.

### Phase 3 · Integration Point Identification

7. **Feature Integration Analysis** – candidate touch‑points, required modifications, architectural constraints, likely refactors.

### Phase 4 · Documentation Synthesis

8. **Create Comprehensive Summary** – synthesize findings, include diagrams, highlight insights & readiness.

---

## 4. Output Specification

Populate `/docs/codebase_overview.md` **exactly** in the template below (truncate nothing, fill placeholders):

```markdown
# Codebase Analysis Summary

## 1. Project Overview
- **Project Name**: […]
- **Primary Purpose**: […]
- **Technology Stack**: […]
- **Architecture Pattern**: […]

## 2. Directory Structure
[…]

## 3. Core Components & Architecture
[…]

## 4. Key Patterns & Conventions
[…]

## 5. Data Architecture
[…]

## 6. Integration Points for New Feature
[…]

## 7. Historical Context & Rationale
[…]

## 8. Open Questions for Product Owner / Tech Lead
[…]

## 9. Initial Hypothesis for Integration
[…]

✅ **Self‑check Log** – append a short checklist confirming completeness.
```

---

## 5. Working Style & Quality Gates

A. Reverse‑reason an outline before diving into code.
B. Use in‑context retrieval of closest examples.
C. Run a **self‑verification pass** against the checklist below.

### Self‑Verification Checklist

* [ ] Major components mapped
* [ ] Dependencies clear
* [ ] Integration points feasible
* [ ] Summary concise & actionable
* [ ] No key architecture omitted

*Remember: If uncertain, call it out explicitly.*

---

# **P2 — Best‑Practices Research Plan**&#x20;

## 0. Where This Fits

Call **P2** runs **after** P1. It consumes `codebase_overview.md` and outputs `research_plan.md` for P3.

---

## 1. Role & High‑Level Objective

**Role:** Research Strategist
**Objective:** Formulate a **Best‑Practices Research Plan** that answers every open question needed to implement `{user_feature_request}` inside the analysed codebase.

---

## 2. Research Planning Framework

### Phase 1 · Define Objectives

1. **Feature Requirements Analysis** – decompose feature, surface challenges & knowledge gaps, rank by impact.
2. **Contextual Constraints Identification** – extract limitations, required patterns, arch decisions, backwards‑compat concerns.

### Phase 2 · Develop Research Strategy

3. **General Best‑Practices** – craft queries for standard, cutting‑edge, performance, security, testing insights.
4. **Updated Documentation** – ensure stack docs & standards are current.
5. **Technology‑Specific** – framework idioms, library compatibility, version caveats.
6. **Integration Patterns** – DI, migration, API design, coupling strategies.

### Phase 3 · Execution Plan

7. **Prioritised Search Strategy** – order by critical path, risk, complexity, urgency.
8. **Validation Criteria** – define reliable sources, conflict resolution, applicability tests.

---

## 3. Output Specification

Produce `research_plan.md` using **this exact outline**:

```markdown
# Feature Implementation Research Plan

## 1. Feature Breakdown
### Core Requirements
1. [Requirement]  
   - Technical Challenge: […]  
   - Research Priority: High/Medium/Low  
   - Codebase Constraint: […]

[…]

## 2. Research Areas
### Area A – [e.g. Authentication Integration]
**Objective:** […]  
**Key Questions:**  
- […]  
- […]

**Search Queries:**  
1. "…"  
2. "…"

**Validation Criteria:**  
- Source must be …  
- Must apply to …

[…]

## 3. Research Execution Timeline
1. **Phase 1 – Critical Path Research**  
   - […]  
2. **Phase 2 – Integration Research**  
   - […]

## 4. Individual Research Questions (examples below)
#### Example Q1: {…}
*Justification:* …  
*Search Queries:* …

#### Example Q2: {…}
*Justification:* …  
*Search Queries:* …

## 5. Expected Outcomes
- **Decision Points:** […]  
- **Risk Mitigations:** […]  
- **Success Criteria:** […]
```

---

## 4. Metacognitive Guidance

* Think about *what* to learn **and** *why* it matters.
* Early findings may reshape later questions—iterate.
* Distinguish critical vs nice‑to‑have knowledge.

### Self‑Verification Checklist

* [ ] Every requirement has research coverage
* [ ] Codebase constraints appear in plan
* [ ] Queries are specific & productive
* [ ] Risk areas addressed
* [ ] “What” *and* “How” captured

---

# **P3 — Granular Implementation Blueprint**&#x20;

## 0. Where This Fits

Call **P3** is the **final** step. It ingests `codebase_overview.md` **and** `research_plan.md`, then emits `implementation_plan.md`.

---

## 1. Role & High‑Level Objective

**Role:** Principal Architect
**Objective:** Produce a **step‑by‑step Implementation Blueprint** for `{user_feature_request}`—every task, dependency, test, and risk mapped out. “Done” means code + passing tests.

---

## 2. Implementation Planning Workflow

### Phase 1 · Architectural Design

1. **High‑Level Design** – concept, new components, interactions, required arch tweaks.
2. **Detailed Component Design** – interfaces, data models, error strategy, extensibility.

### Phase 2 · Task Decomposition

3. **Break Down into Tasks** – independent, ordered, 1–4 h each.
4. **Task Categorisation** – *Foundation*, *Core Features*, *Integration*, *Polish*, *Documentation*.

### Phase 3 · Sequencing & Risk

5. **Dependency Analysis** – map graph, find critical path, parallelisable work, checkpoints.
6. **Risk‑Based Ordering** – high‑risk & assumption‑killer tasks first.

### Phase 4 · Testing & Validation

7. **Per‑Task Test Planning** – unit, integration, edge, performance if needed.
8. **Continuous Validation Plan** – acceptance criteria, incremental tests, regression guardrails, monitoring hooks.

---

## 3. Additional Task Metadata

For **every** task provide:

| Field                   | Description         |
| ----------------------- | ------------------- |
| **Task ID**             | FEAT‑XX / TEST‑XX … |
| **WHY**                 | One‑line rationale  |
| **Description**         | What to do          |
| **Files**               | To create/modify    |
| **Dependencies**        | Prior tasks         |
| **Acceptance Criteria** | Definition of done  |
| **Git Commit Template** | `feat(module): …`   |

---

## 4. Deliverable Contents (`implementation_plan.md`)

1. **Back‑casted success snapshot** – post‑shipping repository state.
2. **Work‑breakdown structure (≤ 4 h each)** with file refs.
3. **Task metadata** (table above).
4. **Integration test storyboard** – key user journeys & edge cases.
5. **Quality gates** – lint, security scan, perf budgets.
6. **Milestone timeline** – ordered by critical path, note parallel work.
7. **Review checklist** – items reviewers must confirm.

---

## 5. Output Template

```markdown
# Feature Implementation Plan

## 1. Architectural Overview
### Design Summary
[…]

### Component Diagram
[…]

### Key Design Decisions
- **Decision 1:** …  
- **Decision 2:** …

## 2. Implementation Tasks
### Phase 1 – Foundation (Est. X h)
#### Task 1.1 …  
[…]

### Phase 2 – Core Features (Est. Y h)
[…]

## 3. Testing Strategy
### Unit Testing Plan
[…]

### Integration Testing Plan
[…]

## 4. Implementation Schedule (logical chunks)
### Chunk #1
- [ ] Task 1.1–1.3  
- [ ] Integration checkpoint

### Chunk #2
- [ ] Task 2.1–2.4  
- [ ] Performance validation

[…]

## 5. Risk Mitigation
1. **Risk:** …  
   - **Mitigation:** …  
   - **Contingency:** …

## 6. Success Metrics
- **Functional:** …  
- **Performance:** …  
- **Quality:** …
```

---

## 6. Cognitive Aids

### Reverse‑Reasoning Validation

1. Visualise finished feature.
2. Walk dependencies backwards.
3. Verify completeness vs current state.

### Self‑Verification Checklist

* [ ] Research findings integrated
* [ ] Atomic, valuable tasks
* [ ] Dependency graph logical
* [ ] Tests exhaustive
* [ ] Codebase constraints honoured
* [ ] Risks mitigated
* [ ] Timeline realistic

*Remember: this blueprint **is** the roadmap—detailed yet adaptable.*

---

*End of consolidated prompts.*
