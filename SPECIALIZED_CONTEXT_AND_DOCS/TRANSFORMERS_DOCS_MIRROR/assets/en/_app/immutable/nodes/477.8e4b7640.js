import{s as El,o as Nl,n as Y}from"../chunks/scheduler.18a86fab.js";import{S as Vl,i as Al,g as m,s as n,r as u,A as ql,h as d,f as l,c as r,j as Rl,u as h,x as p,k as Xl,y as zl,a as s,v as M,d as y,t as $,w}from"../chunks/index.98837b22.js";import{T as St}from"../chunks/Tip.77304350.js";import{Y as Yl}from"../chunks/Youtube.14fb207c.js";import{C as k}from"../chunks/CodeBlock.8d0c2e8a.js";import{H as F,E as Ql}from"../chunks/getInferenceSnippets.06c2775f.js";import{H as Fl,a as Dt}from"../chunks/HfOption.6641485e.js";function Pl(J){let a,c='The <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method loads weights stored in the <a href="https://hf.co/docs/safetensors/index" rel="nofollow">safetensors</a> file format if they’re available. Traditionally, PyTorch model weights are serialized with the <a href="https://docs.python.org/3/library/pickle.html" rel="nofollow">pickle</a> utility which is known to be unsecure. Safetensor files are more secure and faster to load.';return{c(){a=m("p"),a.innerHTML=c},l(o){a=d(o,"P",{"data-svelte-h":!0}),p(a)!=="svelte-1303i5n"&&(a.innerHTML=c)},m(o,b){s(o,a,b)},p:Y,d(o){o&&l(a)}}}function Sl(J){let a,c='An <em>architecture</em> refers to the model’s skeleton and a <em>checkpoint</em> refers to the model’s weights for a given architecture. For example, <a href="./model_doc/bert">BERT</a> is an architecture while <a href="https://huggingface.co/google-bert/bert-base-uncased" rel="nofollow">google-bert/bert-base-uncased</a> is a checkpoint. You’ll see the term <em>model</em> used interchangeably with architecture and checkpoint.';return{c(){a=m("p"),a.innerHTML=c},l(o){a=d(o,"P",{"data-svelte-h":!0}),p(a)!=="svelte-1xaehye"&&(a.innerHTML=c)},m(o,b){s(o,a,b)},p:Y,d(o){o&&l(a)}}}function Dl(J){let a,c,o,b='The <a href="./model_doc/auto">AutoModel</a> class is a convenient way to load an architecture without needing to know the exact model class name because there are many models available. It automatically selects the correct model class based on the configuration file. You only need to know the task and checkpoint you want to use.',i,T,v="Easily switch between models or tasks, as long as the architecture is supported for a given task.",j,g,Z="For example, the same model can be used for separate tasks.",E,x,W,U,L="In other cases, you may want to quickly try out several different models for a task.",I,C,N;return a=new Yl({props:{id:"AhChOFRegn4"}}),x=new k({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTJDJTIwQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbiUyQyUyMEF1dG9Nb2RlbEZvclF1ZXN0aW9uQW5zd2VyaW5nJTBBJTBBJTIzJTIwdXNlJTIwdGhlJTIwc2FtZSUyMEFQSSUyMGZvciUyMDMlMjBkaWZmZXJlbnQlMjB0YXNrcyUwQW1vZGVsJTIwJTNEJTIwQXV0b01vZGVsRm9yQ2F1c2FsTE0uZnJvbV9wcmV0cmFpbmVkKCUyMm1ldGEtbGxhbWElMkZMbGFtYS0yLTdiLWhmJTIyKSUwQW1vZGVsJTIwJTNEJTIwQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbi5mcm9tX3ByZXRyYWluZWQoJTIybWV0YS1sbGFtYSUyRkxsYW1hLTItN2ItaGYlMjIpJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JRdWVzdGlvbkFuc3dlcmluZy5mcm9tX3ByZXRyYWluZWQoJTIybWV0YS1sbGFtYSUyRkxsYW1hLTItN2ItaGYlMjIp",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoModelForSequenceClassification, AutoModelForQuestionAnswering

<span class="hljs-comment"># use the same API for 3 different tasks</span>
model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;meta-llama/Llama-2-7b-hf&quot;</span>)
model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;meta-llama/Llama-2-7b-hf&quot;</span>)
model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;meta-llama/Llama-2-7b-hf&quot;</span>)`,wrap:!1}}),C=new k({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTBBJTBBJTIzJTIwdXNlJTIwdGhlJTIwc2FtZSUyMEFQSSUyMHRvJTIwbG9hZCUyMDMlMjBkaWZmZXJlbnQlMjBtb2RlbHMlMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNLmZyb21fcHJldHJhaW5lZCglMjJtZXRhLWxsYW1hJTJGTGxhbWEtMi03Yi1oZiUyMiklMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNLmZyb21fcHJldHJhaW5lZCglMjJtaXN0cmFsYWklMkZNaXN0cmFsLTdCLXYwLjElMjIpJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JDYXVzYWxMTS5mcm9tX3ByZXRyYWluZWQoJTIyZ29vZ2xlJTJGZ2VtbWEtN2IlMjIp",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM

<span class="hljs-comment"># use the same API to load 3 different models</span>
model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;meta-llama/Llama-2-7b-hf&quot;</span>)
model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;mistralai/Mistral-7B-v0.1&quot;</span>)
model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;google/gemma-7b&quot;</span>)`,wrap:!1}}),{c(){u(a.$$.fragment),c=n(),o=m("p"),o.innerHTML=b,i=n(),T=m("p"),T.textContent=v,j=n(),g=m("p"),g.textContent=Z,E=n(),u(x.$$.fragment),W=n(),U=m("p"),U.textContent=L,I=n(),u(C.$$.fragment)},l(f){h(a.$$.fragment,f),c=r(f),o=d(f,"P",{"data-svelte-h":!0}),p(o)!=="svelte-jbgeb6"&&(o.innerHTML=b),i=r(f),T=d(f,"P",{"data-svelte-h":!0}),p(T)!=="svelte-1ujsygc"&&(T.textContent=v),j=r(f),g=d(f,"P",{"data-svelte-h":!0}),p(g)!=="svelte-iecy5n"&&(g.textContent=Z),E=r(f),h(x.$$.fragment,f),W=r(f),U=d(f,"P",{"data-svelte-h":!0}),p(U)!=="svelte-1yrjcfs"&&(U.textContent=L),I=r(f),h(C.$$.fragment,f)},m(f,_){M(a,f,_),s(f,c,_),s(f,o,_),s(f,i,_),s(f,T,_),s(f,j,_),s(f,g,_),s(f,E,_),M(x,f,_),s(f,W,_),s(f,U,_),s(f,I,_),M(C,f,_),N=!0},p:Y,i(f){N||(y(a.$$.fragment,f),y(x.$$.fragment,f),y(C.$$.fragment,f),N=!0)},o(f){$(a.$$.fragment,f),$(x.$$.fragment,f),$(C.$$.fragment,f),N=!1},d(f){f&&(l(c),l(o),l(i),l(T),l(j),l(g),l(E),l(W),l(U),l(I)),w(a,f),w(x,f),w(C,f)}}}function Kl(J){let a,c='The <a href="./model_doc/auto">AutoModel</a> class builds on top of model-specific classes. All model classes that support a specific task are mapped to their respective <code>AutoModelFor</code> task class.',o,b,i="If you already know which model class you want to use, then you could use its model-specific class directly.",T,v,j;return v=new k({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMExsYW1hTW9kZWwlMkMlMjBMbGFtYUZvckNhdXNhbExNJTBBJTBBbW9kZWwlMjAlM0QlMjBMbGFtYUZvckNhdXNhbExNLmZyb21fcHJldHJhaW5lZCglMjJtZXRhLWxsYW1hJTJGTGxhbWEtMi03Yi1oZiUyMik=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> LlamaModel, LlamaForCausalLM

model = LlamaForCausalLM.from_pretrained(<span class="hljs-string">&quot;meta-llama/Llama-2-7b-hf&quot;</span>)`,wrap:!1}}),{c(){a=m("p"),a.innerHTML=c,o=n(),b=m("p"),b.textContent=i,T=n(),u(v.$$.fragment)},l(g){a=d(g,"P",{"data-svelte-h":!0}),p(a)!=="svelte-183gvra"&&(a.innerHTML=c),o=r(g),b=d(g,"P",{"data-svelte-h":!0}),p(b)!=="svelte-10soq8s"&&(b.textContent=i),T=r(g),h(v.$$.fragment,g)},m(g,Z){s(g,a,Z),s(g,o,Z),s(g,b,Z),s(g,T,Z),M(v,g,Z),j=!0},p:Y,i(g){j||(y(v.$$.fragment,g),j=!0)},o(g){$(v.$$.fragment,g),j=!1},d(g){g&&(l(a),l(o),l(b),l(T)),w(v,g)}}}function Ol(J){let a,c,o,b;return a=new Dt({props:{id:"model-classes",option:"AutoModel",$$slots:{default:[Dl]},$$scope:{ctx:J}}}),o=new Dt({props:{id:"model-classes",option:"model-specific class",$$slots:{default:[Kl]},$$scope:{ctx:J}}}),{c(){u(a.$$.fragment),c=n(),u(o.$$.fragment)},l(i){h(a.$$.fragment,i),c=r(i),h(o.$$.fragment,i)},m(i,T){M(a,i,T),s(i,c,T),M(o,i,T),b=!0},p(i,T){const v={};T&2&&(v.$$scope={dirty:T,ctx:i}),a.$set(v);const j={};T&2&&(j.$$scope={dirty:T,ctx:i}),o.$set(j)},i(i){b||(y(a.$$.fragment,i),y(o.$$.fragment,i),b=!0)},o(i){$(a.$$.fragment,i),$(o.$$.fragment,i),b=!1},d(i){i&&l(c),w(a,i),w(o,i)}}}function es(J){let a,c="Make sure you have Accelerate v0.9.0 and PyTorch v1.9.0 or later installed to use this feature!";return{c(){a=m("p"),a.textContent=c},l(o){a=d(o,"P",{"data-svelte-h":!0}),p(a)!=="svelte-qrtf3q"&&(a.textContent=c)},m(o,b){s(o,a,b)},p:Y,d(o){o&&l(a)}}}function ts(J){let a,c='Learn more about device placement in <a href="https://hf.co/docs/accelerate/v0.33.0/en/concept_guides/big_model_inference#designing-a-device-map" rel="nofollow">Designing a device map</a>.';return{c(){a=m("p"),a.innerHTML=c},l(o){a=d(o,"P",{"data-svelte-h":!0}),p(a)!=="svelte-i6ocir"&&(a.innerHTML=c)},m(o,b){s(o,a,b)},p:Y,d(o){o&&l(a)}}}function ls(J){let a,c;return a=new k({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwdHJhbnNmb3JtZXJzJTIwaW1wb3J0JTIwQXV0b01vZGVsRm9yQ2F1c2FsTE0lMEElMEFnZW1tYSUyMCUzRCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNLmZyb21fcHJldHJhaW5lZCglMjJnb29nbGUlMkZnZW1tYS03YiUyMiUyQyUyMGR0eXBlJTNEdG9yY2guZmxvYXQxNik=",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM

gemma = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;google/gemma-7b&quot;</span>, dtype=torch.float16)`,wrap:!1}}),{c(){u(a.$$.fragment)},l(o){h(a.$$.fragment,o)},m(o,b){M(a,o,b),c=!0},p:Y,i(o){c||(y(a.$$.fragment,o),c=!0)},o(o){$(a.$$.fragment,o),c=!1},d(o){w(a,o)}}}function ss(J){let a,c;return a=new k({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTBBJTBBZ2VtbWElMjAlM0QlMjBBdXRvTW9kZWxGb3JDYXVzYWxMTS5mcm9tX3ByZXRyYWluZWQoJTIyZ29vZ2xlJTJGZ2VtbWEtN2IlMjIlMkMlMjBkdHlwZSUzRCUyMmF1dG8lMjIp",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM

gemma = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;google/gemma-7b&quot;</span>, dtype=<span class="hljs-string">&quot;auto&quot;</span>)`,wrap:!1}}),{c(){u(a.$$.fragment)},l(o){h(a.$$.fragment,o)},m(o,b){M(a,o,b),c=!0},p:Y,i(o){c||(y(a.$$.fragment,o),c=!0)},o(o){$(a.$$.fragment,o),c=!1},d(o){w(a,o)}}}function as(J){let a,c,o,b;return a=new Dt({props:{id:"dtype",option:"specific dtype",$$slots:{default:[ls]},$$scope:{ctx:J}}}),o=new Dt({props:{id:"dtype",option:"auto dtype",$$slots:{default:[ss]},$$scope:{ctx:J}}}),{c(){u(a.$$.fragment),c=n(),u(o.$$.fragment)},l(i){h(a.$$.fragment,i),c=r(i),h(o.$$.fragment,i)},m(i,T){M(a,i,T),s(i,c,T),M(o,i,T),b=!0},p(i,T){const v={};T&2&&(v.$$scope={dirty:T,ctx:i}),a.$set(v);const j={};T&2&&(j.$$scope={dirty:T,ctx:i}),o.$set(j)},i(i){b||(y(a.$$.fragment,i),y(o.$$.fragment,i),b=!0)},o(i){$(a.$$.fragment,i),$(o.$$.fragment,i),b=!1},d(i){i&&l(c),w(a,i),w(o,i)}}}function os(J){let a,c,o,b,i,T,v,j='Transformers provides many pretrained models that are ready to use with a single line of code. It requires a model class and the <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method.',g,Z,E='Call <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> to download and load a model’s weights and configuration stored on the Hugging Face <a href="https://hf.co/models" rel="nofollow">Hub</a>.',x,W,U,L,I,C,N="This guide explains how models are loaded, the different ways you can load a model, how to overcome memory issues for really big models, and how to load custom models.",f,_,Ve,V,Kt="All models have a <code>configuration.py</code> file with specific attributes like the number of hidden layers, vocabulary size, activation function, and more. You’ll also find a <code>modeling.py</code> file that defines the layers and mathematical operations taking place inside each layer. The <code>modeling.py</code> file takes the model attributes in <code>configuration.py</code> and builds the model accordingly. At this point, you have a model with random weights that needs to be trained to output meaningful results.",Ae,B,qe,A,Ot="There are two general types of models you can load:",ze,q,el='<li>A barebones model, like <a href="/docs/transformers/v4.56.2/en/model_doc/auto#transformers.AutoModel">AutoModel</a> or <a href="/docs/transformers/v4.56.2/en/model_doc/llama#transformers.LlamaModel">LlamaModel</a>, that outputs hidden states.</li> <li>A model with a specific <em>head</em> attached, like <a href="/docs/transformers/v4.56.2/en/model_doc/auto#transformers.AutoModelForCausalLM">AutoModelForCausalLM</a> or <a href="/docs/transformers/v4.56.2/en/model_doc/llama#transformers.LlamaForCausalLM">LlamaForCausalLM</a>, for performing specific tasks.</li>',Qe,z,Pe,Q,tl='To get a pretrained model, you need to load the weights into the model. This is done by calling <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> which accepts weights from the Hugging Face Hub or a local directory.',Se,P,ll='There are two model classes, the <a href="./model_doc/auto">AutoModel</a> class and a model-specific class.',De,G,Ke,S,Oe,D,sl="Large pretrained models require a lot of memory to load. The loading process involves:",et,K,al="<li>creating a model with random weights</li> <li>loading the pretrained weights</li> <li>placing the pretrained weights on the model</li>",tt,O,ol="You need enough memory to hold two copies of the model weights (random and pretrained) which may not be possible depending on your hardware. In distributed training environments, this is even more challenging because each process loads a pretrained model.",lt,ee,nl='Transformers reduces some of these memory-related challenges with fast initialization, sharded checkpoints, Accelerate’s <a href="https://hf.co/docs/accelerate/usage_guides/big_modeling" rel="nofollow">Big Model Inference</a> feature, and supporting lower bit data types.',st,te,at,le,rl='The <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method automatically shards checkpoints larger than 10GB.',ot,se,il="Each shard is loaded sequentially after the previous shard is loaded, limiting memory usage to only the model size and the largest shard size.",nt,ae,ml="The <code>max_shard_size</code> parameter defaults to 5GB for each shard because it is easier to run on free-tier GPU instances without running out of memory.",rt,oe,dl='For example, create some shards checkpoints for <a href="https://hf.co/BioMistral/BioMistral-7B" rel="nofollow">BioMistral/BioMistral-7B</a> in <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>.',it,ne,mt,re,pl='Reload the sharded checkpoint with <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a>.',dt,ie,pt,me,fl='Sharded checkpoints can also be directly loaded with <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.modeling_utils.load_sharded_checkpoint">load_sharded_checkpoint()</a>.',ft,de,ct,pe,cl='The <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method creates an index file that maps parameter names to the files they’re stored in. The index file has two keys, <code>metadata</code> and <code>weight_map</code>.',ut,fe,ht,ce,ul="The <code>metadata</code> key provides the total model size.",Mt,ue,yt,he,hl="The <code>weight_map</code> key maps each parameter to the shard it’s stored in.",$t,Me,wt,ye,bt,H,Tt,$e,gt,we,Ml='<a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is supercharged with Accelerate’s <a href="https://hf.co/docs/accelerate/usage_guides/big_modeling" rel="nofollow">Big Model Inference</a> feature.',vt,be,yl='Big Model Inference creates a <em>model skeleton</em> on the PyTorch <a href="https://pytorch.org/docs/main/meta.html" rel="nofollow">meta</a> device. The meta device doesn’t store any real data, only the metadata.',Jt,Te,$l="Randomly initialized weights are only created when the pretrained weights are loaded to avoid maintaining two copies of the model in memory at the same time. The maximum memory usage is only the size of the model.",_t,R,jt,ge,wl="Big Model Inference’s second feature relates to how weights are loaded and dispatched in the model skeleton. Model weights are dispatched across all available devices, starting with the fastest device (usually the GPU) and then offloading any remaining weights to slower devices (CPU and hard drive).",kt,ve,bl="Both features combined reduces memory usage and loading times for big pretrained models.",Zt,Je,Tl='Set <a href="https://github.com/huggingface/transformers/blob/026a173a64372e9602a16523b8fae9de4b0ff428/src/transformers/modeling_utils.py#L3061" rel="nofollow">device_map</a> to <code>&quot;auto&quot;</code> to enable Big Model Inference.',Ct,_e,Wt,je,gl="You can also manually assign layers to a device in <code>device_map</code>. It should map all model parameters to a device, but you don’t have to detail where all the submodules of a layer go if the entire layer is on the same device.",xt,ke,vl="Access the <code>hf_device_map</code> attribute to see how a model is distributed across devices.",Ut,Ze,Lt,Ce,It,We,Jl="PyTorch model weights are initialized in <code>torch.float32</code> by default. Loading a model in a different data type, like <code>torch.float16</code>, requires additional memory because the model is loaded again in the desired data type.",Bt,xe,_l='Explicitly set the <a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" rel="nofollow">dtype</a> parameter to directly initialize the model in the desired data type instead of loading the weights twice (<code>torch.float32</code> then <code>torch.float16</code>). You could also set <code>dtype=&quot;auto&quot;</code> to automatically load the weights in the data type they are stored in.',Gt,X,Ht,Ue,jl='The <code>dtype</code> parameter can also be configured in <a href="/docs/transformers/v4.56.2/en/model_doc/auto#transformers.AutoConfig">AutoConfig</a> for models instantiated from scratch.',Rt,Le,Xt,Ie,Ft,Be,kl='Custom models builds on Transformers’ configuration and modeling classes, supports the <a href="#autoclass">AutoClass</a> API, and are loaded with <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a>. The difference is that the modeling code is <em>not</em> from Transformers.',Yt,Ge,Zl='Take extra precaution when loading a custom model. While the Hub includes <a href="https://hf.co/docs/hub/security-malware#malware-scanning" rel="nofollow">malware scanning</a> for every repository, you should still be careful to avoid inadvertently executing malicious code.',Et,He,Cl='Set <code>trust_remote_code=True</code> in <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> to load a custom model.',Nt,Re,Vt,Xe,Wl='As an extra layer of security, load a custom model from a specific revision to avoid loading model code that may have changed. The commit hash can be copied from the models <a href="https://hf.co/sgugger/custom-resnet50d/commits/main" rel="nofollow">commit history</a>.',At,Fe,qt,Ye,xl='Refer to the <a href="./custom_models">Customize models</a> guide for more information.',zt,Ee,Qt,Ne,Pt;return i=new F({props:{title:"Loading models",local:"loading-models",headingTag:"h1"}}),W=new St({props:{warning:!1,$$slots:{default:[Pl]},$$scope:{ctx:J}}}),L=new k({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JDYXVzYWxMTS5mcm9tX3ByZXRyYWluZWQoJTIybWV0YS1sbGFtYSUyRkxsYW1hLTItN2ItaGYlMjIlMkMlMjBkdHlwZSUzRCUyMmF1dG8lMjIlMkMlMjBkZXZpY2VfbWFwJTNEJTIyYXV0byUyMik=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM

model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;meta-llama/Llama-2-7b-hf&quot;</span>, dtype=<span class="hljs-string">&quot;auto&quot;</span>, device_map=<span class="hljs-string">&quot;auto&quot;</span>)`,wrap:!1}}),_=new F({props:{title:"Models and configurations",local:"models-and-configurations",headingTag:"h2"}}),B=new St({props:{warning:!1,$$slots:{default:[Sl]},$$scope:{ctx:J}}}),z=new F({props:{title:"Model classes",local:"model-classes",headingTag:"h2"}}),G=new Fl({props:{id:"model-classes",options:["AutoModel","model-specific class"],$$slots:{default:[Ol]},$$scope:{ctx:J}}}),S=new F({props:{title:"Large models",local:"large-models",headingTag:"h2"}}),te=new F({props:{title:"Sharded checkpoints",local:"sharded-checkpoints",headingTag:"h3"}}),ne=new k({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbCUwQWltcG9ydCUyMHRlbXBmaWxlJTBBaW1wb3J0JTIwb3MlMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbC5mcm9tX3ByZXRyYWluZWQoJTIyYmlvbWlzdHJhbCUyRmJpb21pc3RyYWwtN2IlMjIpJTBBd2l0aCUyMHRlbXBmaWxlLlRlbXBvcmFyeURpcmVjdG9yeSgpJTIwYXMlMjB0bXBfZGlyJTNBJTBBJTIwJTIwJTIwJTIwbW9kZWwuc2F2ZV9wcmV0cmFpbmVkKHRtcF9kaXIlMkMlMjBtYXhfc2hhcmRfc2l6ZSUzRCUyMjVHQiUyMiklMEElMjAlMjAlMjAlMjBwcmludChzb3J0ZWQob3MubGlzdGRpcih0bXBfZGlyKSkp",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel
<span class="hljs-keyword">import</span> tempfile
<span class="hljs-keyword">import</span> os

model = AutoModel.from_pretrained(<span class="hljs-string">&quot;biomistral/biomistral-7b&quot;</span>)
<span class="hljs-keyword">with</span> tempfile.TemporaryDirectory() <span class="hljs-keyword">as</span> tmp_dir:
    model.save_pretrained(tmp_dir, max_shard_size=<span class="hljs-string">&quot;5GB&quot;</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-built_in">sorted</span>(os.listdir(tmp_dir)))`,wrap:!1}}),ie=new k({props:{code:"d2l0aCUyMHRlbXBmaWxlLlRlbXBvcmFyeURpcmVjdG9yeSgpJTIwYXMlMjB0bXBfZGlyJTNBJTBBJTIwJTIwJTIwJTIwbW9kZWwuc2F2ZV9wcmV0cmFpbmVkKHRtcF9kaXIpJTBBJTIwJTIwJTIwJTIwbmV3X21vZGVsJTIwJTNEJTIwQXV0b01vZGVsLmZyb21fcHJldHJhaW5lZCh0bXBfZGlyKQ==",highlighted:`<span class="hljs-keyword">with</span> tempfile.TemporaryDirectory() <span class="hljs-keyword">as</span> tmp_dir:
    model.save_pretrained(tmp_dir)
    new_model = AutoModel.from_pretrained(tmp_dir)`,wrap:!1}}),de=new k({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycy5tb2RlbGluZ191dGlscyUyMGltcG9ydCUyMGxvYWRfc2hhcmRlZF9jaGVja3BvaW50JTBBJTBBd2l0aCUyMHRlbXBmaWxlLlRlbXBvcmFyeURpcmVjdG9yeSgpJTIwYXMlMjB0bXBfZGlyJTNBJTBBJTIwJTIwJTIwJTIwbW9kZWwuc2F2ZV9wcmV0cmFpbmVkKHRtcF9kaXIlMkMlMjBtYXhfc2hhcmRfc2l6ZSUzRCUyMjVHQiUyMiklMEElMjAlMjAlMjAlMjBsb2FkX3NoYXJkZWRfY2hlY2twb2ludChtb2RlbCUyQyUyMHRtcF9kaXIp",highlighted:`<span class="hljs-keyword">from</span> transformers.modeling_utils <span class="hljs-keyword">import</span> load_sharded_checkpoint

<span class="hljs-keyword">with</span> tempfile.TemporaryDirectory() <span class="hljs-keyword">as</span> tmp_dir:
    model.save_pretrained(tmp_dir, max_shard_size=<span class="hljs-string">&quot;5GB&quot;</span>)
    load_sharded_checkpoint(model, tmp_dir)`,wrap:!1}}),fe=new k({props:{code:"aW1wb3J0JTIwanNvbiUwQSUwQXdpdGglMjB0ZW1wZmlsZS5UZW1wb3JhcnlEaXJlY3RvcnkoKSUyMGFzJTIwdG1wX2RpciUzQSUwQSUyMCUyMCUyMCUyMG1vZGVsLnNhdmVfcHJldHJhaW5lZCh0bXBfZGlyJTJDJTIwbWF4X3NoYXJkX3NpemUlM0QlMjI1R0IlMjIpJTBBJTIwJTIwJTIwJTIwd2l0aCUyMG9wZW4ob3MucGF0aC5qb2luKHRtcF9kaXIlMkMlMjAlMjJtb2RlbC5zYWZldGVuc29ycy5pbmRleC5qc29uJTIyKSUyQyUyMCUyMnIlMjIpJTIwYXMlMjBmJTNBJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwaW5kZXglMjAlM0QlMjBqc29uLmxvYWQoZiklMEElMEFwcmludChpbmRleC5rZXlzKCkp",highlighted:`<span class="hljs-keyword">import</span> json

<span class="hljs-keyword">with</span> tempfile.TemporaryDirectory() <span class="hljs-keyword">as</span> tmp_dir:
    model.save_pretrained(tmp_dir, max_shard_size=<span class="hljs-string">&quot;5GB&quot;</span>)
    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(os.path.join(tmp_dir, <span class="hljs-string">&quot;model.safetensors.index.json&quot;</span>), <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:
        index = json.load(f)

<span class="hljs-built_in">print</span>(index.keys())`,wrap:!1}}),ue=new k({props:{code:"aW5kZXglNUIlMjJtZXRhZGF0YSUyMiU1RCUwQSU3Qid0b3RhbF9zaXplJyUzQSUyMDI4OTY2OTI4Mzg0JTdE",highlighted:`index[<span class="hljs-string">&quot;metadata&quot;</span>]
{<span class="hljs-string">&#x27;total_size&#x27;</span>: <span class="hljs-number">28966928384</span>}`,wrap:!1}}),Me=new k({props:{code:"aW5kZXglNUIlMjJ3ZWlnaHRfbWFwJTIyJTVEJTBBJTdCJ2xtX2hlYWQud2VpZ2h0JyUzQSUyMCdtb2RlbC0wMDAwNi1vZi0wMDAwNi5zYWZldGVuc29ycyclMkMlMEElMjAnbW9kZWwuZW1iZWRfdG9rZW5zLndlaWdodCclM0ElMjAnbW9kZWwtMDAwMDEtb2YtMDAwMDYuc2FmZXRlbnNvcnMnJTJDJTBBJTIwJ21vZGVsLmxheWVycy4wLmlucHV0X2xheWVybm9ybS53ZWlnaHQnJTNBJTIwJ21vZGVsLTAwMDAxLW9mLTAwMDA2LnNhZmV0ZW5zb3JzJyUyQyUwQSUyMCdtb2RlbC5sYXllcnMuMC5tbHAuZG93bl9wcm9qLndlaWdodCclM0ElMjAnbW9kZWwtMDAwMDEtb2YtMDAwMDYuc2FmZXRlbnNvcnMnJTJDJTBBJTIwLi4uJTBBJTdE",highlighted:`index[<span class="hljs-string">&quot;weight_map&quot;</span>]
{<span class="hljs-string">&#x27;lm_head.weight&#x27;</span>: <span class="hljs-string">&#x27;model-00006-of-00006.safetensors&#x27;</span>,
 <span class="hljs-string">&#x27;model.embed_tokens.weight&#x27;</span>: <span class="hljs-string">&#x27;model-00001-of-00006.safetensors&#x27;</span>,
 <span class="hljs-string">&#x27;model.layers.0.input_layernorm.weight&#x27;</span>: <span class="hljs-string">&#x27;model-00001-of-00006.safetensors&#x27;</span>,
 <span class="hljs-string">&#x27;model.layers.0.mlp.down_proj.weight&#x27;</span>: <span class="hljs-string">&#x27;model-00001-of-00006.safetensors&#x27;</span>,
 ...
}`,wrap:!1}}),ye=new F({props:{title:"Big Model Inference",local:"big-model-inference",headingTag:"h3"}}),H=new St({props:{warning:!1,$$slots:{default:[es]},$$scope:{ctx:J}}}),$e=new Yl({props:{id:"MWCSGj9jEAo"}}),R=new St({props:{warning:!1,$$slots:{default:[ts]},$$scope:{ctx:J}}}),_e=new k({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JDYXVzYWxMTS5mcm9tX3ByZXRyYWluZWQoJTIyZ29vZ2xlJTJGZ2VtbWEtN2IlMjIlMkMlMjBkZXZpY2VfbWFwJTNEJTIyYXV0byUyMik=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM

model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;google/gemma-7b&quot;</span>, device_map=<span class="hljs-string">&quot;auto&quot;</span>)`,wrap:!1}}),Ze=new k({props:{code:"ZGV2aWNlX21hcCUyMCUzRCUyMCU3QiUyMm1vZGVsLmxheWVycy4xJTIyJTNBJTIwMCUyQyUyMCUyMm1vZGVsLmxheWVycy4xNCUyMiUzQSUyMDElMkMlMjAlMjJtb2RlbC5sYXllcnMuMzElMjIlM0ElMjAlMjJjcHUlMjIlMkMlMjAlMjJsbV9oZWFkJTIyJTNBJTIwJTIyZGlzayUyMiU3RCUwQW1vZGVsLmhmX2RldmljZV9tYXA=",highlighted:`device_map = {<span class="hljs-string">&quot;model.layers.1&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;model.layers.14&quot;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&quot;model.layers.31&quot;</span>: <span class="hljs-string">&quot;cpu&quot;</span>, <span class="hljs-string">&quot;lm_head&quot;</span>: <span class="hljs-string">&quot;disk&quot;</span>}
model.hf_device_map`,wrap:!1}}),Ce=new F({props:{title:"Model data type",local:"model-data-type",headingTag:"h3"}}),X=new Fl({props:{id:"dtype",options:["specific dtype","auto dtype"],$$slots:{default:[as]},$$scope:{ctx:J}}}),Le=new k({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwdHJhbnNmb3JtZXJzJTIwaW1wb3J0JTIwQXV0b0NvbmZpZyUyQyUyMEF1dG9Nb2RlbCUwQSUwQW15X2NvbmZpZyUyMCUzRCUyMEF1dG9Db25maWcuZnJvbV9wcmV0cmFpbmVkKCUyMmdvb2dsZSUyRmdlbW1hLTJiJTIyJTJDJTIwZHR5cGUlM0R0b3JjaC5mbG9hdDE2KSUwQW1vZGVsJTIwJTNEJTIwQXV0b01vZGVsLmZyb21fY29uZmlnKG15X2NvbmZpZyk=",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

my_config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/gemma-2b&quot;</span>, dtype=torch.float16)
model = AutoModel.from_config(my_config)`,wrap:!1}}),Ie=new F({props:{title:"Custom models",local:"custom-models",headingTag:"h2"}}),Re=new k({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckltYWdlQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvckltYWdlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMnNndWdnZXIlMkZjdXN0b20tcmVzbmV0NTBkJTIyJTJDJTIwdHJ1c3RfcmVtb3RlX2NvZGUlM0RUcnVlKQ==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForImageClassification

model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;sgugger/custom-resnet50d&quot;</span>, trust_remote_code=<span class="hljs-literal">True</span>)`,wrap:!1}}),Fe=new k({props:{code:"Y29tbWl0X2hhc2glMjAlM0QlMjAlMjJlZDk0YTdjNjI0N2Q4YWVkY2U0NjQ3ZjAwZjIwZGU2ODc1YjViMjkyJTIyJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JJbWFnZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjAlMjJzZ3VnZ2VyJTJGY3VzdG9tLXJlc25ldDUwZCUyMiUyQyUyMHRydXN0X3JlbW90ZV9jb2RlJTNEVHJ1ZSUyQyUyMHJldmlzaW9uJTNEY29tbWl0X2hhc2glMEEp",highlighted:`commit_hash = <span class="hljs-string">&quot;ed94a7c6247d8aedce4647f00f20de6875b5b292&quot;</span>
model = AutoModelForImageClassification.from_pretrained(
    <span class="hljs-string">&quot;sgugger/custom-resnet50d&quot;</span>, trust_remote_code=<span class="hljs-literal">True</span>, revision=commit_hash
)`,wrap:!1}}),Ee=new Ql({props:{source:"https://github.com/huggingface/transformers/blob/main/docs/source/en/models.md"}}),{c(){a=m("meta"),c=n(),o=m("p"),b=n(),u(i.$$.fragment),T=n(),v=m("p"),v.innerHTML=j,g=n(),Z=m("p"),Z.innerHTML=E,x=n(),u(W.$$.fragment),U=n(),u(L.$$.fragment),I=n(),C=m("p"),C.textContent=N,f=n(),u(_.$$.fragment),Ve=n(),V=m("p"),V.innerHTML=Kt,Ae=n(),u(B.$$.fragment),qe=n(),A=m("p"),A.textContent=Ot,ze=n(),q=m("ol"),q.innerHTML=el,Qe=n(),u(z.$$.fragment),Pe=n(),Q=m("p"),Q.innerHTML=tl,Se=n(),P=m("p"),P.innerHTML=ll,De=n(),u(G.$$.fragment),Ke=n(),u(S.$$.fragment),Oe=n(),D=m("p"),D.textContent=sl,et=n(),K=m("ol"),K.innerHTML=al,tt=n(),O=m("p"),O.textContent=ol,lt=n(),ee=m("p"),ee.innerHTML=nl,st=n(),u(te.$$.fragment),at=n(),le=m("p"),le.innerHTML=rl,ot=n(),se=m("p"),se.textContent=il,nt=n(),ae=m("p"),ae.innerHTML=ml,rt=n(),oe=m("p"),oe.innerHTML=dl,it=n(),u(ne.$$.fragment),mt=n(),re=m("p"),re.innerHTML=pl,dt=n(),u(ie.$$.fragment),pt=n(),me=m("p"),me.innerHTML=fl,ft=n(),u(de.$$.fragment),ct=n(),pe=m("p"),pe.innerHTML=cl,ut=n(),u(fe.$$.fragment),ht=n(),ce=m("p"),ce.innerHTML=ul,Mt=n(),u(ue.$$.fragment),yt=n(),he=m("p"),he.innerHTML=hl,$t=n(),u(Me.$$.fragment),wt=n(),u(ye.$$.fragment),bt=n(),u(H.$$.fragment),Tt=n(),u($e.$$.fragment),gt=n(),we=m("p"),we.innerHTML=Ml,vt=n(),be=m("p"),be.innerHTML=yl,Jt=n(),Te=m("p"),Te.textContent=$l,_t=n(),u(R.$$.fragment),jt=n(),ge=m("p"),ge.textContent=wl,kt=n(),ve=m("p"),ve.textContent=bl,Zt=n(),Je=m("p"),Je.innerHTML=Tl,Ct=n(),u(_e.$$.fragment),Wt=n(),je=m("p"),je.innerHTML=gl,xt=n(),ke=m("p"),ke.innerHTML=vl,Ut=n(),u(Ze.$$.fragment),Lt=n(),u(Ce.$$.fragment),It=n(),We=m("p"),We.innerHTML=Jl,Bt=n(),xe=m("p"),xe.innerHTML=_l,Gt=n(),u(X.$$.fragment),Ht=n(),Ue=m("p"),Ue.innerHTML=jl,Rt=n(),u(Le.$$.fragment),Xt=n(),u(Ie.$$.fragment),Ft=n(),Be=m("p"),Be.innerHTML=kl,Yt=n(),Ge=m("p"),Ge.innerHTML=Zl,Et=n(),He=m("p"),He.innerHTML=Cl,Nt=n(),u(Re.$$.fragment),Vt=n(),Xe=m("p"),Xe.innerHTML=Wl,At=n(),u(Fe.$$.fragment),qt=n(),Ye=m("p"),Ye.innerHTML=xl,zt=n(),u(Ee.$$.fragment),Qt=n(),Ne=m("p"),this.h()},l(e){const t=ql("svelte-u9bgzb",document.head);a=d(t,"META",{name:!0,content:!0}),t.forEach(l),c=r(e),o=d(e,"P",{}),Rl(o).forEach(l),b=r(e),h(i.$$.fragment,e),T=r(e),v=d(e,"P",{"data-svelte-h":!0}),p(v)!=="svelte-1hv5b5u"&&(v.innerHTML=j),g=r(e),Z=d(e,"P",{"data-svelte-h":!0}),p(Z)!=="svelte-s251lt"&&(Z.innerHTML=E),x=r(e),h(W.$$.fragment,e),U=r(e),h(L.$$.fragment,e),I=r(e),C=d(e,"P",{"data-svelte-h":!0}),p(C)!=="svelte-9iq2wd"&&(C.textContent=N),f=r(e),h(_.$$.fragment,e),Ve=r(e),V=d(e,"P",{"data-svelte-h":!0}),p(V)!=="svelte-12kn5s6"&&(V.innerHTML=Kt),Ae=r(e),h(B.$$.fragment,e),qe=r(e),A=d(e,"P",{"data-svelte-h":!0}),p(A)!=="svelte-xokyhx"&&(A.textContent=Ot),ze=r(e),q=d(e,"OL",{"data-svelte-h":!0}),p(q)!=="svelte-1syqvfw"&&(q.innerHTML=el),Qe=r(e),h(z.$$.fragment,e),Pe=r(e),Q=d(e,"P",{"data-svelte-h":!0}),p(Q)!=="svelte-v665zx"&&(Q.innerHTML=tl),Se=r(e),P=d(e,"P",{"data-svelte-h":!0}),p(P)!=="svelte-1hac2gu"&&(P.innerHTML=ll),De=r(e),h(G.$$.fragment,e),Ke=r(e),h(S.$$.fragment,e),Oe=r(e),D=d(e,"P",{"data-svelte-h":!0}),p(D)!=="svelte-1tu6zwl"&&(D.textContent=sl),et=r(e),K=d(e,"OL",{"data-svelte-h":!0}),p(K)!=="svelte-yd1qun"&&(K.innerHTML=al),tt=r(e),O=d(e,"P",{"data-svelte-h":!0}),p(O)!=="svelte-1k996x1"&&(O.textContent=ol),lt=r(e),ee=d(e,"P",{"data-svelte-h":!0}),p(ee)!=="svelte-oz5rc7"&&(ee.innerHTML=nl),st=r(e),h(te.$$.fragment,e),at=r(e),le=d(e,"P",{"data-svelte-h":!0}),p(le)!=="svelte-16wwj7l"&&(le.innerHTML=rl),ot=r(e),se=d(e,"P",{"data-svelte-h":!0}),p(se)!=="svelte-zf1paz"&&(se.textContent=il),nt=r(e),ae=d(e,"P",{"data-svelte-h":!0}),p(ae)!=="svelte-188z5sm"&&(ae.innerHTML=ml),rt=r(e),oe=d(e,"P",{"data-svelte-h":!0}),p(oe)!=="svelte-3lih4w"&&(oe.innerHTML=dl),it=r(e),h(ne.$$.fragment,e),mt=r(e),re=d(e,"P",{"data-svelte-h":!0}),p(re)!=="svelte-cktsq9"&&(re.innerHTML=pl),dt=r(e),h(ie.$$.fragment,e),pt=r(e),me=d(e,"P",{"data-svelte-h":!0}),p(me)!=="svelte-swdmat"&&(me.innerHTML=fl),ft=r(e),h(de.$$.fragment,e),ct=r(e),pe=d(e,"P",{"data-svelte-h":!0}),p(pe)!=="svelte-10iejwi"&&(pe.innerHTML=cl),ut=r(e),h(fe.$$.fragment,e),ht=r(e),ce=d(e,"P",{"data-svelte-h":!0}),p(ce)!=="svelte-n8xk5n"&&(ce.innerHTML=ul),Mt=r(e),h(ue.$$.fragment,e),yt=r(e),he=d(e,"P",{"data-svelte-h":!0}),p(he)!=="svelte-1p559iq"&&(he.innerHTML=hl),$t=r(e),h(Me.$$.fragment,e),wt=r(e),h(ye.$$.fragment,e),bt=r(e),h(H.$$.fragment,e),Tt=r(e),h($e.$$.fragment,e),gt=r(e),we=d(e,"P",{"data-svelte-h":!0}),p(we)!=="svelte-l00kol"&&(we.innerHTML=Ml),vt=r(e),be=d(e,"P",{"data-svelte-h":!0}),p(be)!=="svelte-1vi9ins"&&(be.innerHTML=yl),Jt=r(e),Te=d(e,"P",{"data-svelte-h":!0}),p(Te)!=="svelte-pqkb96"&&(Te.textContent=$l),_t=r(e),h(R.$$.fragment,e),jt=r(e),ge=d(e,"P",{"data-svelte-h":!0}),p(ge)!=="svelte-ujc6pz"&&(ge.textContent=wl),kt=r(e),ve=d(e,"P",{"data-svelte-h":!0}),p(ve)!=="svelte-149juhs"&&(ve.textContent=bl),Zt=r(e),Je=d(e,"P",{"data-svelte-h":!0}),p(Je)!=="svelte-1s8o97y"&&(Je.innerHTML=Tl),Ct=r(e),h(_e.$$.fragment,e),Wt=r(e),je=d(e,"P",{"data-svelte-h":!0}),p(je)!=="svelte-xiaxyy"&&(je.innerHTML=gl),xt=r(e),ke=d(e,"P",{"data-svelte-h":!0}),p(ke)!=="svelte-y2h2jv"&&(ke.innerHTML=vl),Ut=r(e),h(Ze.$$.fragment,e),Lt=r(e),h(Ce.$$.fragment,e),It=r(e),We=d(e,"P",{"data-svelte-h":!0}),p(We)!=="svelte-7sq3ud"&&(We.innerHTML=Jl),Bt=r(e),xe=d(e,"P",{"data-svelte-h":!0}),p(xe)!=="svelte-1uq5vuk"&&(xe.innerHTML=_l),Gt=r(e),h(X.$$.fragment,e),Ht=r(e),Ue=d(e,"P",{"data-svelte-h":!0}),p(Ue)!=="svelte-1rs49wt"&&(Ue.innerHTML=jl),Rt=r(e),h(Le.$$.fragment,e),Xt=r(e),h(Ie.$$.fragment,e),Ft=r(e),Be=d(e,"P",{"data-svelte-h":!0}),p(Be)!=="svelte-e6qyk3"&&(Be.innerHTML=kl),Yt=r(e),Ge=d(e,"P",{"data-svelte-h":!0}),p(Ge)!=="svelte-dcgxoo"&&(Ge.innerHTML=Zl),Et=r(e),He=d(e,"P",{"data-svelte-h":!0}),p(He)!=="svelte-1faiqtq"&&(He.innerHTML=Cl),Nt=r(e),h(Re.$$.fragment,e),Vt=r(e),Xe=d(e,"P",{"data-svelte-h":!0}),p(Xe)!=="svelte-1u5do82"&&(Xe.innerHTML=Wl),At=r(e),h(Fe.$$.fragment,e),qt=r(e),Ye=d(e,"P",{"data-svelte-h":!0}),p(Ye)!=="svelte-12b0p8z"&&(Ye.innerHTML=xl),zt=r(e),h(Ee.$$.fragment,e),Qt=r(e),Ne=d(e,"P",{}),Rl(Ne).forEach(l),this.h()},h(){Xl(a,"name","hf:doc:metadata"),Xl(a,"content",ns)},m(e,t){zl(document.head,a),s(e,c,t),s(e,o,t),s(e,b,t),M(i,e,t),s(e,T,t),s(e,v,t),s(e,g,t),s(e,Z,t),s(e,x,t),M(W,e,t),s(e,U,t),M(L,e,t),s(e,I,t),s(e,C,t),s(e,f,t),M(_,e,t),s(e,Ve,t),s(e,V,t),s(e,Ae,t),M(B,e,t),s(e,qe,t),s(e,A,t),s(e,ze,t),s(e,q,t),s(e,Qe,t),M(z,e,t),s(e,Pe,t),s(e,Q,t),s(e,Se,t),s(e,P,t),s(e,De,t),M(G,e,t),s(e,Ke,t),M(S,e,t),s(e,Oe,t),s(e,D,t),s(e,et,t),s(e,K,t),s(e,tt,t),s(e,O,t),s(e,lt,t),s(e,ee,t),s(e,st,t),M(te,e,t),s(e,at,t),s(e,le,t),s(e,ot,t),s(e,se,t),s(e,nt,t),s(e,ae,t),s(e,rt,t),s(e,oe,t),s(e,it,t),M(ne,e,t),s(e,mt,t),s(e,re,t),s(e,dt,t),M(ie,e,t),s(e,pt,t),s(e,me,t),s(e,ft,t),M(de,e,t),s(e,ct,t),s(e,pe,t),s(e,ut,t),M(fe,e,t),s(e,ht,t),s(e,ce,t),s(e,Mt,t),M(ue,e,t),s(e,yt,t),s(e,he,t),s(e,$t,t),M(Me,e,t),s(e,wt,t),M(ye,e,t),s(e,bt,t),M(H,e,t),s(e,Tt,t),M($e,e,t),s(e,gt,t),s(e,we,t),s(e,vt,t),s(e,be,t),s(e,Jt,t),s(e,Te,t),s(e,_t,t),M(R,e,t),s(e,jt,t),s(e,ge,t),s(e,kt,t),s(e,ve,t),s(e,Zt,t),s(e,Je,t),s(e,Ct,t),M(_e,e,t),s(e,Wt,t),s(e,je,t),s(e,xt,t),s(e,ke,t),s(e,Ut,t),M(Ze,e,t),s(e,Lt,t),M(Ce,e,t),s(e,It,t),s(e,We,t),s(e,Bt,t),s(e,xe,t),s(e,Gt,t),M(X,e,t),s(e,Ht,t),s(e,Ue,t),s(e,Rt,t),M(Le,e,t),s(e,Xt,t),M(Ie,e,t),s(e,Ft,t),s(e,Be,t),s(e,Yt,t),s(e,Ge,t),s(e,Et,t),s(e,He,t),s(e,Nt,t),M(Re,e,t),s(e,Vt,t),s(e,Xe,t),s(e,At,t),M(Fe,e,t),s(e,qt,t),s(e,Ye,t),s(e,zt,t),M(Ee,e,t),s(e,Qt,t),s(e,Ne,t),Pt=!0},p(e,[t]){const Ul={};t&2&&(Ul.$$scope={dirty:t,ctx:e}),W.$set(Ul);const Ll={};t&2&&(Ll.$$scope={dirty:t,ctx:e}),B.$set(Ll);const Il={};t&2&&(Il.$$scope={dirty:t,ctx:e}),G.$set(Il);const Bl={};t&2&&(Bl.$$scope={dirty:t,ctx:e}),H.$set(Bl);const Gl={};t&2&&(Gl.$$scope={dirty:t,ctx:e}),R.$set(Gl);const Hl={};t&2&&(Hl.$$scope={dirty:t,ctx:e}),X.$set(Hl)},i(e){Pt||(y(i.$$.fragment,e),y(W.$$.fragment,e),y(L.$$.fragment,e),y(_.$$.fragment,e),y(B.$$.fragment,e),y(z.$$.fragment,e),y(G.$$.fragment,e),y(S.$$.fragment,e),y(te.$$.fragment,e),y(ne.$$.fragment,e),y(ie.$$.fragment,e),y(de.$$.fragment,e),y(fe.$$.fragment,e),y(ue.$$.fragment,e),y(Me.$$.fragment,e),y(ye.$$.fragment,e),y(H.$$.fragment,e),y($e.$$.fragment,e),y(R.$$.fragment,e),y(_e.$$.fragment,e),y(Ze.$$.fragment,e),y(Ce.$$.fragment,e),y(X.$$.fragment,e),y(Le.$$.fragment,e),y(Ie.$$.fragment,e),y(Re.$$.fragment,e),y(Fe.$$.fragment,e),y(Ee.$$.fragment,e),Pt=!0)},o(e){$(i.$$.fragment,e),$(W.$$.fragment,e),$(L.$$.fragment,e),$(_.$$.fragment,e),$(B.$$.fragment,e),$(z.$$.fragment,e),$(G.$$.fragment,e),$(S.$$.fragment,e),$(te.$$.fragment,e),$(ne.$$.fragment,e),$(ie.$$.fragment,e),$(de.$$.fragment,e),$(fe.$$.fragment,e),$(ue.$$.fragment,e),$(Me.$$.fragment,e),$(ye.$$.fragment,e),$(H.$$.fragment,e),$($e.$$.fragment,e),$(R.$$.fragment,e),$(_e.$$.fragment,e),$(Ze.$$.fragment,e),$(Ce.$$.fragment,e),$(X.$$.fragment,e),$(Le.$$.fragment,e),$(Ie.$$.fragment,e),$(Re.$$.fragment,e),$(Fe.$$.fragment,e),$(Ee.$$.fragment,e),Pt=!1},d(e){e&&(l(c),l(o),l(b),l(T),l(v),l(g),l(Z),l(x),l(U),l(I),l(C),l(f),l(Ve),l(V),l(Ae),l(qe),l(A),l(ze),l(q),l(Qe),l(Pe),l(Q),l(Se),l(P),l(De),l(Ke),l(Oe),l(D),l(et),l(K),l(tt),l(O),l(lt),l(ee),l(st),l(at),l(le),l(ot),l(se),l(nt),l(ae),l(rt),l(oe),l(it),l(mt),l(re),l(dt),l(pt),l(me),l(ft),l(ct),l(pe),l(ut),l(ht),l(ce),l(Mt),l(yt),l(he),l($t),l(wt),l(bt),l(Tt),l(gt),l(we),l(vt),l(be),l(Jt),l(Te),l(_t),l(jt),l(ge),l(kt),l(ve),l(Zt),l(Je),l(Ct),l(Wt),l(je),l(xt),l(ke),l(Ut),l(Lt),l(It),l(We),l(Bt),l(xe),l(Gt),l(Ht),l(Ue),l(Rt),l(Xt),l(Ft),l(Be),l(Yt),l(Ge),l(Et),l(He),l(Nt),l(Vt),l(Xe),l(At),l(qt),l(Ye),l(zt),l(Qt),l(Ne)),l(a),w(i,e),w(W,e),w(L,e),w(_,e),w(B,e),w(z,e),w(G,e),w(S,e),w(te,e),w(ne,e),w(ie,e),w(de,e),w(fe,e),w(ue,e),w(Me,e),w(ye,e),w(H,e),w($e,e),w(R,e),w(_e,e),w(Ze,e),w(Ce,e),w(X,e),w(Le,e),w(Ie,e),w(Re,e),w(Fe,e),w(Ee,e)}}}const ns='{"title":"Loading models","local":"loading-models","sections":[{"title":"Models and configurations","local":"models-and-configurations","sections":[],"depth":2},{"title":"Model classes","local":"model-classes","sections":[],"depth":2},{"title":"Large models","local":"large-models","sections":[{"title":"Sharded checkpoints","local":"sharded-checkpoints","sections":[],"depth":3},{"title":"Big Model Inference","local":"big-model-inference","sections":[],"depth":3},{"title":"Model data type","local":"model-data-type","sections":[],"depth":3}],"depth":2},{"title":"Custom models","local":"custom-models","sections":[],"depth":2}],"depth":1}';function rs(J){return Nl(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class hs extends Vl{constructor(a){super(),Al(this,a,rs,os,El,{})}}export{hs as component};
