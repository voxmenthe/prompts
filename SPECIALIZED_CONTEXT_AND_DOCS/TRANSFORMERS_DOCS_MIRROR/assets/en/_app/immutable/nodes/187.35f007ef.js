import{s as ae,o as oe,n as ie}from"../chunks/scheduler.18a86fab.js";import{S as re,i as pe,g as r,s as a,r as k,A as me,h as p,f as l,c as o,j as se,x as c,u as L,k as S,y as ue,a as n,v as J,d as Z,t as U,w as x}from"../chunks/index.98837b22.js";import{T as ce}from"../chunks/Tip.77304350.js";import{C as de}from"../chunks/CodeBlock.8d0c2e8a.js";import{H as Y,E as fe}from"../chunks/getInferenceSnippets.06c2775f.js";function he(H){let s,d='Refer to <a href="t5">T5’s documentation page</a> for API reference, tips, code examples and notebooks.';return{c(){s=r("p"),s.innerHTML=d},l(i){s=p(i,"P",{"data-svelte-h":!0}),c(s)!=="svelte-70j220"&&(s.innerHTML=d)},m(i,j){n(i,s,j)},p:ie,d(i){i&&l(s)}}}function ge(H){let s,d,i,j,f,Q="<em>This model was released on 2023-03-03 and added to Hugging Face Transformers on 2023-06-20.</em>",C,h,F,m,D='<img alt="PyTorch" src="https://img.shields.io/badge/PyTorch-DE3412?style=flat&amp;logo=pytorch&amp;logoColor=white"/>',G,g,q,w,O=`<a href="https://www.yitay.net/blog/flan-ul2-20b" rel="nofollow">Flan-UL2</a> is an encoder decoder model based on the T5 architecture. It uses the same configuration as the <a href="ul2">UL2</a> model released earlier last year.
It was fine tuned using the “Flan” prompt tuning and dataset collection. Similar to <code>Flan-T5</code>,  one can directly use FLAN-UL2 weights without finetuning the model:`,B,T,K="According to the original blog here are the notable improvements:",E,M,ee=`<li>The original UL2 model was only trained with receptive field of 512, which made it non-ideal for N-shot prompting where N is large.</li> <li>The Flan-UL2 checkpoint uses a receptive field of 2048 which makes it more usable for few-shot in-context learning.</li> <li>The original UL2 model also had mode switch tokens that was rather mandatory to get good performance. However, they were a little cumbersome as this requires often some changes during inference or finetuning. In this update/change, we continue training UL2 20B for an additional 100k steps (with small batch) to forget “mode tokens” before applying Flan instruction tuning. This Flan-UL2 checkpoint does not require mode tokens anymore.
Google has released the following variants:</li>`,z,$,te='The original checkpoints can be found <a href="https://github.com/google-research/google-research/tree/master/ul2" rel="nofollow">here</a>.',R,y,X,b,le="The model is pretty heavy (~40GB in half precision) so if you just want to run the model, make sure you load your model in 8bit, and use <code>device_map=&quot;auto&quot;</code> to make sure  you don’t have any OOM issue!",N,v,W,u,P,_,V,I,A;return h=new Y({props:{title:"FLAN-UL2",local:"flan-ul2",headingTag:"h1"}}),g=new Y({props:{title:"Overview",local:"overview",headingTag:"h2"}}),y=new Y({props:{title:"Running on low resource devices",local:"running-on-low-resource-devices",headingTag:"h2"}}),v=new de({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclNlcTJTZXFMTSUyQyUyMEF1dG9Ub2tlbml6ZXIlMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclNlcTJTZXFMTS5mcm9tX3ByZXRyYWluZWQoJTIyZ29vZ2xlJTJGZmxhbi11bDIlMjIlMkMlMjBsb2FkX2luXzhiaXQlM0RUcnVlJTJDJTIwZGV2aWNlX21hcCUzRCUyMmF1dG8lMjIpJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQoJTIyZ29vZ2xlJTJGZmxhbi11bDIlMjIpJTBBJTBBaW5wdXRzJTIwJTNEJTIwdG9rZW5pemVyKCUyMkElMjBzdGVwJTIwYnklMjBzdGVwJTIwcmVjaXBlJTIwdG8lMjBtYWtlJTIwYm9sb2duZXNlJTIwcGFzdGElM0ElMjIlMkMlMjByZXR1cm5fdGVuc29ycyUzRCUyMnB0JTIyKSUwQW91dHB1dHMlMjAlM0QlMjBtb2RlbC5nZW5lcmF0ZSgqKmlucHV0cyklMEFwcmludCh0b2tlbml6ZXIuYmF0Y2hfZGVjb2RlKG91dHB1dHMlMkMlMjBza2lwX3NwZWNpYWxfdG9rZW5zJTNEVHJ1ZSkp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSeq2SeqLM, AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;google/flan-ul2&quot;</span>, load_in_8bit=<span class="hljs-literal">True</span>, device_map=<span class="hljs-string">&quot;auto&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;google/flan-ul2&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;A step by step recipe to make bolognese pasta:&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model.generate(**inputs)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(tokenizer.batch_decode(outputs, skip_special_tokens=<span class="hljs-literal">True</span>))
[<span class="hljs-string">&#x27;In a large skillet, brown the ground beef and onion over medium heat. Add the garlic&#x27;</span>]`,wrap:!1}}),u=new ce({props:{$$slots:{default:[he]},$$scope:{ctx:H}}}),_=new fe({props:{source:"https://github.com/huggingface/transformers/blob/main/docs/source/en/model_doc/flan-ul2.md"}}),{c(){s=r("meta"),d=a(),i=r("p"),j=a(),f=r("p"),f.innerHTML=Q,C=a(),k(h.$$.fragment),F=a(),m=r("div"),m.innerHTML=D,G=a(),k(g.$$.fragment),q=a(),w=r("p"),w.innerHTML=O,B=a(),T=r("p"),T.textContent=K,E=a(),M=r("ul"),M.innerHTML=ee,z=a(),$=r("p"),$.innerHTML=te,R=a(),k(y.$$.fragment),X=a(),b=r("p"),b.innerHTML=le,N=a(),k(v.$$.fragment),W=a(),k(u.$$.fragment),P=a(),k(_.$$.fragment),V=a(),I=r("p"),this.h()},l(e){const t=me("svelte-u9bgzb",document.head);s=p(t,"META",{name:!0,content:!0}),t.forEach(l),d=o(e),i=p(e,"P",{}),se(i).forEach(l),j=o(e),f=p(e,"P",{"data-svelte-h":!0}),c(f)!=="svelte-w9v19a"&&(f.innerHTML=Q),C=o(e),L(h.$$.fragment,e),F=o(e),m=p(e,"DIV",{class:!0,"data-svelte-h":!0}),c(m)!=="svelte-13t8s2t"&&(m.innerHTML=D),G=o(e),L(g.$$.fragment,e),q=o(e),w=p(e,"P",{"data-svelte-h":!0}),c(w)!=="svelte-w3tmgg"&&(w.innerHTML=O),B=o(e),T=p(e,"P",{"data-svelte-h":!0}),c(T)!=="svelte-10cnwdi"&&(T.textContent=K),E=o(e),M=p(e,"UL",{"data-svelte-h":!0}),c(M)!=="svelte-145gzzg"&&(M.innerHTML=ee),z=o(e),$=p(e,"P",{"data-svelte-h":!0}),c($)!=="svelte-xyezra"&&($.innerHTML=te),R=o(e),L(y.$$.fragment,e),X=o(e),b=p(e,"P",{"data-svelte-h":!0}),c(b)!=="svelte-1qrqz37"&&(b.innerHTML=le),N=o(e),L(v.$$.fragment,e),W=o(e),L(u.$$.fragment,e),P=o(e),L(_.$$.fragment,e),V=o(e),I=p(e,"P",{}),se(I).forEach(l),this.h()},h(){S(s,"name","hf:doc:metadata"),S(s,"content",we),S(m,"class","flex flex-wrap space-x-1")},m(e,t){ue(document.head,s),n(e,d,t),n(e,i,t),n(e,j,t),n(e,f,t),n(e,C,t),J(h,e,t),n(e,F,t),n(e,m,t),n(e,G,t),J(g,e,t),n(e,q,t),n(e,w,t),n(e,B,t),n(e,T,t),n(e,E,t),n(e,M,t),n(e,z,t),n(e,$,t),n(e,R,t),J(y,e,t),n(e,X,t),n(e,b,t),n(e,N,t),J(v,e,t),n(e,W,t),J(u,e,t),n(e,P,t),J(_,e,t),n(e,V,t),n(e,I,t),A=!0},p(e,[t]){const ne={};t&2&&(ne.$$scope={dirty:t,ctx:e}),u.$set(ne)},i(e){A||(Z(h.$$.fragment,e),Z(g.$$.fragment,e),Z(y.$$.fragment,e),Z(v.$$.fragment,e),Z(u.$$.fragment,e),Z(_.$$.fragment,e),A=!0)},o(e){U(h.$$.fragment,e),U(g.$$.fragment,e),U(y.$$.fragment,e),U(v.$$.fragment,e),U(u.$$.fragment,e),U(_.$$.fragment,e),A=!1},d(e){e&&(l(d),l(i),l(j),l(f),l(C),l(F),l(m),l(G),l(q),l(w),l(B),l(T),l(E),l(M),l(z),l($),l(R),l(X),l(b),l(N),l(W),l(P),l(V),l(I)),l(s),x(h,e),x(g,e),x(y,e),x(v,e),x(u,e),x(_,e)}}}const we='{"title":"FLAN-UL2","local":"flan-ul2","sections":[{"title":"Overview","local":"overview","sections":[],"depth":2},{"title":"Running on low resource devices","local":"running-on-low-resource-devices","sections":[],"depth":2}],"depth":1}';function Te(H){return oe(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class _e extends re{constructor(s){super(),pe(this,s,Te,ge,ae,{})}}export{_e as component};
