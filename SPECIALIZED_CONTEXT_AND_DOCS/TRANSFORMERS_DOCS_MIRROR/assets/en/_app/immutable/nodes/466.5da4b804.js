import{s as oe,o as le,n as re}from"../chunks/scheduler.18a86fab.js";import{S as pe,i as me,g as l,s,r as S,A as fe,h as r,f as a,c as o,j as se,x as m,u as P,k as K,y as he,a as n,v as H,d as y,t as k,w as R}from"../chunks/index.98837b22.js";import{T as ue}from"../chunks/Tip.77304350.js";import{H as J,E as ce}from"../chunks/getInferenceSnippets.06c2775f.js";function ge(E){let i,u='XLS-R’s architecture is based on the Wav2Vec2 model, refer to <a href="wav2vec2">Wav2Vec2’s documentation page</a> for API reference.';return{c(){i=l("p"),i.innerHTML=u},l(p){i=r(p,"P",{"data-svelte-h":!0}),m(i)!=="svelte-bku3o"&&(i.innerHTML=u)},m(p,C){n(p,i,C)},p:re,d(p){p&&a(i)}}}function de(E){let i,u,p,C,c,N="<em>This model was released on 2021-11-17 and added to Hugging Face Transformers on 2023-06-20.</em>",X,g,A,f,Q='<img alt="PyTorch" src="https://img.shields.io/badge/PyTorch-DE3412?style=flat&amp;logo=pytorch&amp;logoColor=white"/>',V,d,W,v,Y=`The XLS-R model was proposed in <a href="https://huggingface.co/papers/2111.09296" rel="nofollow">XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale</a> by Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman
Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, Michael Auli.`,z,$,Z="The abstract from the paper is the following:",B,w,ee=`<em>This paper presents XLS-R, a large-scale model for cross-lingual speech representation learning based on wav2vec 2.0.
We train models with up to 2B parameters on nearly half a million hours of publicly available speech audio in 128
languages, an order of magnitude more public data than the largest known prior work. Our evaluation covers a wide range
of tasks, domains, data regimes and languages, both high and low-resource. On the CoVoST-2 speech translation
benchmark, we improve the previous state of the art by an average of 7.4 BLEU over 21 translation directions into
English. For speech recognition, XLS-R improves over the best known prior work on BABEL, MLS, CommonVoice as well as
VoxPopuli, lowering error rates by 14-34% relative on average. XLS-R also sets a new state of the art on VoxLingua107
language identification. Moreover, we show that with sufficient model size, cross-lingual pretraining can outperform
English-only pretraining when translating English speech into other languages, a setting which favors monolingual
pretraining. We hope XLS-R can help to improve speech processing tasks for many more languages of the world.</em>`,O,T,te='Relevant checkpoints can be found under <a href="https://huggingface.co/models?other=xls_r" rel="nofollow">https://huggingface.co/models?other=xls_r</a>.',U,L,ae='The original code can be found <a href="https://github.com/pytorch/fairseq/tree/master/fairseq/models/wav2vec" rel="nofollow">here</a>.',j,_,q,b,ne=`<li>XLS-R is a speech model that accepts a float array corresponding to the raw waveform of the speech signal.</li> <li>XLS-R model was trained using connectionist temporal classification (CTC) so the model output has to be decoded using
<a href="/docs/transformers/v4.56.2/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer">Wav2Vec2CTCTokenizer</a>.</li>`,D,h,F,x,G,M,I;return g=new J({props:{title:"XLS-R",local:"xls-r",headingTag:"h1"}}),d=new J({props:{title:"Overview",local:"overview",headingTag:"h2"}}),_=new J({props:{title:"Usage tips",local:"usage-tips",headingTag:"h2"}}),h=new ue({props:{$$slots:{default:[ge]},$$scope:{ctx:E}}}),x=new ce({props:{source:"https://github.com/huggingface/transformers/blob/main/docs/source/en/model_doc/xls_r.md"}}),{c(){i=l("meta"),u=s(),p=l("p"),C=s(),c=l("p"),c.innerHTML=N,X=s(),S(g.$$.fragment),A=s(),f=l("div"),f.innerHTML=Q,V=s(),S(d.$$.fragment),W=s(),v=l("p"),v.innerHTML=Y,z=s(),$=l("p"),$.textContent=Z,B=s(),w=l("p"),w.innerHTML=ee,O=s(),T=l("p"),T.innerHTML=te,U=s(),L=l("p"),L.innerHTML=ae,j=s(),S(_.$$.fragment),q=s(),b=l("ul"),b.innerHTML=ne,D=s(),S(h.$$.fragment),F=s(),S(x.$$.fragment),G=s(),M=l("p"),this.h()},l(e){const t=fe("svelte-u9bgzb",document.head);i=r(t,"META",{name:!0,content:!0}),t.forEach(a),u=o(e),p=r(e,"P",{}),se(p).forEach(a),C=o(e),c=r(e,"P",{"data-svelte-h":!0}),m(c)!=="svelte-jzetvc"&&(c.innerHTML=N),X=o(e),P(g.$$.fragment,e),A=o(e),f=r(e,"DIV",{class:!0,"data-svelte-h":!0}),m(f)!=="svelte-13t8s2t"&&(f.innerHTML=Q),V=o(e),P(d.$$.fragment,e),W=o(e),v=r(e,"P",{"data-svelte-h":!0}),m(v)!=="svelte-gajb60"&&(v.innerHTML=Y),z=o(e),$=r(e,"P",{"data-svelte-h":!0}),m($)!=="svelte-vfdo9a"&&($.textContent=Z),B=o(e),w=r(e,"P",{"data-svelte-h":!0}),m(w)!=="svelte-ul075o"&&(w.innerHTML=ee),O=o(e),T=r(e,"P",{"data-svelte-h":!0}),m(T)!=="svelte-p0mu8e"&&(T.innerHTML=te),U=o(e),L=r(e,"P",{"data-svelte-h":!0}),m(L)!=="svelte-12gzw10"&&(L.innerHTML=ae),j=o(e),P(_.$$.fragment,e),q=o(e),b=r(e,"UL",{"data-svelte-h":!0}),m(b)!=="svelte-153ioim"&&(b.innerHTML=ne),D=o(e),P(h.$$.fragment,e),F=o(e),P(x.$$.fragment,e),G=o(e),M=r(e,"P",{}),se(M).forEach(a),this.h()},h(){K(i,"name","hf:doc:metadata"),K(i,"content",ve),K(f,"class","flex flex-wrap space-x-1")},m(e,t){he(document.head,i),n(e,u,t),n(e,p,t),n(e,C,t),n(e,c,t),n(e,X,t),H(g,e,t),n(e,A,t),n(e,f,t),n(e,V,t),H(d,e,t),n(e,W,t),n(e,v,t),n(e,z,t),n(e,$,t),n(e,B,t),n(e,w,t),n(e,O,t),n(e,T,t),n(e,U,t),n(e,L,t),n(e,j,t),H(_,e,t),n(e,q,t),n(e,b,t),n(e,D,t),H(h,e,t),n(e,F,t),H(x,e,t),n(e,G,t),n(e,M,t),I=!0},p(e,[t]){const ie={};t&2&&(ie.$$scope={dirty:t,ctx:e}),h.$set(ie)},i(e){I||(y(g.$$.fragment,e),y(d.$$.fragment,e),y(_.$$.fragment,e),y(h.$$.fragment,e),y(x.$$.fragment,e),I=!0)},o(e){k(g.$$.fragment,e),k(d.$$.fragment,e),k(_.$$.fragment,e),k(h.$$.fragment,e),k(x.$$.fragment,e),I=!1},d(e){e&&(a(u),a(p),a(C),a(c),a(X),a(A),a(f),a(V),a(W),a(v),a(z),a($),a(B),a(w),a(O),a(T),a(U),a(L),a(j),a(q),a(b),a(D),a(F),a(G),a(M)),a(i),R(g,e),R(d,e),R(_,e),R(h,e),R(x,e)}}}const ve='{"title":"XLS-R","local":"xls-r","sections":[{"title":"Overview","local":"overview","sections":[],"depth":2},{"title":"Usage tips","local":"usage-tips","sections":[],"depth":2}],"depth":1}';function $e(E){return le(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class be extends pe{constructor(i){super(),me(this,i,$e,de,oe,{})}}export{be as component};
