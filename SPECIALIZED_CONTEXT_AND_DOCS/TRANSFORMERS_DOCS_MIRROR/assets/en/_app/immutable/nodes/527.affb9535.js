import{s as vt,o as It,n as Ct}from"../chunks/scheduler.18a86fab.js";import{S as Xt,i as xt,g as n,s as i,r as m,A as Wt,h as r,f as l,c as s,j as Ut,u as c,x as o,k as jt,y as At,a,v as u,d as f,t as d,w as M}from"../chunks/index.98837b22.js";import{T as Zt}from"../chunks/Tip.77304350.js";import{C as y}from"../chunks/CodeBlock.8d0c2e8a.js";import{H as me,E as Lt}from"../chunks/getInferenceSnippets.06c2775f.js";function Gt(ce){let h,$="Not all example scripts support the <code>max_predict_samples</code> parameter. Run the command below to check whether a script supports it or not.",_,w,T;return w=new y({props:{code:"ZXhhbXBsZXMlMkZweXRvcmNoJTJGc3VtbWFyaXphdGlvbiUyRnJ1bl9zdW1tYXJpemF0aW9uLnB5JTIwLWg=",highlighted:"examples/pytorch/summarization/run_summarization.py -h",wrap:!1}}),{c(){h=n("p"),h.innerHTML=$,_=i(),m(w.$$.fragment)},l(p){h=r(p,"P",{"data-svelte-h":!0}),o(h)!=="svelte-dama35"&&(h.innerHTML=$),_=s(p),c(w.$$.fragment,p)},m(p,J){a(p,h,J),a(p,_,J),u(w,p,J),T=!0},p:Ct,i(p){T||(f(w.$$.fragment,p),T=!0)},o(p){d(w.$$.fragment,p),T=!1},d(p){p&&(l(h),l(_)),M(w,p)}}}function Rt(ce){let h,$,_,w,T,p,J,et='Transformers provides many example training scripts for PyTorch and tasks in <a href="https://github.com/huggingface/transformers/tree/main/examples" rel="nofollow">transformers/examples</a>. There are additional scripts in <a href="https://github.com/huggingface/transformers-research-projects/" rel="nofollow">transformers/research projects</a> and <a href="https://github.com/huggingface/transformers/tree/main/examples/legacy" rel="nofollow">transformers/legacy</a>, but these aren’t actively maintained and requires a specific version of Transformers.',ue,g,tt="Example scripts are only examples and you may need to adapt the script to your use-case. To help you with this, most scripts are very transparent in how data is preprocessed, allowing you to edit it as necessary.",fe,U,lt='For any feature you’d like to implement in an example script, please discuss it on the <a href="https://discuss.huggingface.co/" rel="nofollow">forum</a> or in an <a href="https://github.com/huggingface/transformers/issues" rel="nofollow">issue</a> before submitting a pull request. While we welcome contributions, it is unlikely a pull request that adds more functionality is added at the cost of readability.',de,j,at='This guide will show you how to run an example summarization training script in <a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/summarization" rel="nofollow">PyTorch</a>.',Me,v,he,I,it="Install Transformers from source in a new virtual environment to run the latest version of the example script.",we,C,Te,X,st="Run the command below to checkout a script from a specific or older version of Transformers.",ye,x,Je,W,nt="After you’ve setup the correct version, navigate to the example folder of your choice and install the example specific requirements.",_e,A,be,Z,$e,L,rt="Start with a smaller dataset by including the <code>max_train_samples</code>, <code>max_eval_samples</code>, and <code>max_predict_samples</code> parameters to truncate the dataset to a maximum number of samples. This helps ensure training works as expected before committing to the entire dataset which can take hours to complete.",ge,b,Ue,G,ot='The example below fine-tunes <a href="https://huggingface.co/google-t5/t5-small" rel="nofollow">T5-small</a> on the <a href="https://huggingface.co/datasets/abisee/cnn_dailymail" rel="nofollow">CNN/DailyMail</a> dataset. T5 requires an additional <code>source_prefix</code> parameter to prompt it to summarize.',je,R,pt='The example script downloads and preprocesses a dataset, and then fine-tunes it with <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> with a supported model architecture.',ve,B,mt="Resuming training from a checkpoint is very useful if training is interrupted because you don’t have to start over again. There are two ways to resume training from a checkpoint.",Ie,V,ct="<li><code>--output dir previous_output_dir</code> resumes training from the latest checkpoint stored in <code>output_dir</code>. Remove the <code>--overwrite_output_dir</code> parameter if you’re using this method.</li> <li><code>--resume_from_checkpoint path_to_specific_checkpoint</code> resumes training from a specific checkpoint folder.</li>",Ce,Y,ut='Share your model on the <a href="https://huggingface.co/" rel="nofollow">Hub</a> with the <code>--push_to_hub</code> parameter. It creates a repository and uploads the model to the folder name specified in <code>--output_dir</code>. You could also use the <code>--push_to_hub_model_id</code> parameter to specify the repository name.',Xe,H,xe,z,ft='For mixed precision and distributed training, include the following parameters and launch training with <a href="https://pytorch.org/docs/stable/elastic/run.html" rel="nofollow">torchrun</a>.',We,N,dt="<li>Add the <code>fp16</code> or <code>bf16</code> parameters to enable mixed precision training. XPU devices only supports <code>bf16</code>.</li> <li>Add the <code>nproc_per_node</code> parameter to set number of GPUs to train with.</li>",Ae,k,Ze,F,Mt='PyTorch supports TPUs, hardware designed to accelerate performance, through the <a href="https://github.com/pytorch/xla/blob/master/README.md" rel="nofollow">PyTorch/XLA</a> package. Launch the <code>xla_spawn.py</code> script and use <code>num _cores</code> to set the number of TPU cores to train with.',Le,S,Ge,E,Re,P,ht='<a href="https://huggingface.co/docs/accelerate" rel="nofollow">Accelerate</a> is designed to simplify distributed training while offering complete visibility into the PyTorch training loop. If you’re planning on training with a script with Accelerate, use the <code>_no_trainer.py</code> version of the script.',Be,Q,wt="Install Accelerate from source to ensure you have the latest version.",Ve,D,Ye,q,Tt='Run the <a href="https://huggingface.co/docs/accelerate/package_reference/cli#accelerate-config" rel="nofollow">accelerate config</a> command to answer a few questions about your training setup. This creates and saves a config file about your system.',He,O,ze,K,yt='You can use <a href="https://huggingface.co/docs/accelerate/package_reference/cli#accelerate-test" rel="nofollow">accelerate test</a> to ensure your system is properly configured.',Ne,ee,ke,te,Jt='Run <a href="https://huggingface.co/docs/accelerate/package_reference/cli#accelerate-launch" rel="nofollow">accelerate launch</a> to start training.',Fe,le,Se,ae,Ee,ie,_t="The summarization scripts supports custom datasets as long as they are a CSV or JSONL file. When using your own dataset, you need to specify the following additional parameters.",Pe,se,bt="<li><code>train_file</code> and <code>validation_file</code> specify the path to your training and validation files.</li> <li><code>text_column</code> is the input text to summarize.</li> <li><code>summary_column</code> is the target text to output.</li>",Qe,ne,$t="An example command for summarizing a custom dataset is shown below.",De,re,qe,oe,Oe,pe,Ke;return T=new me({props:{title:"Training scripts",local:"training-scripts",headingTag:"h1"}}),v=new me({props:{title:"Setup",local:"setup",headingTag:"h2"}}),C=new y({props:{code:"Z2l0JTIwY2xvbmUlMjBodHRwcyUzQSUyRiUyRmdpdGh1Yi5jb20lMkZodWdnaW5nZmFjZSUyRnRyYW5zZm9ybWVycyUwQWNkJTIwdHJhbnNmb3JtZXJzJTBBcGlwJTIwaW5zdGFsbCUyMC4=",highlighted:`git <span class="hljs-built_in">clone</span> https://github.com/huggingface/transformers
<span class="hljs-built_in">cd</span> transformers
pip install .`,wrap:!1}}),x=new y({props:{code:"Z2l0JTIwY2hlY2tvdXQlMjB0YWdzJTJGdjMuNS4x",highlighted:"git checkout tags/v3.5.1",wrap:!1}}),A=new y({props:{code:"cGlwJTIwaW5zdGFsbCUyMC1yJTIwcmVxdWlyZW1lbnRzLnR4dA==",highlighted:"pip install -r requirements.txt",wrap:!1}}),Z=new me({props:{title:"Run a script",local:"run-a-script",headingTag:"h2"}}),b=new Zt({props:{warning:!0,$$slots:{default:[Gt]},$$scope:{ctx:ce}}}),H=new y({props:{code:"cHl0aG9uJTIwZXhhbXBsZXMlMkZweXRvcmNoJTJGc3VtbWFyaXphdGlvbiUyRnJ1bl9zdW1tYXJpemF0aW9uLnB5JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1tb2RlbF9uYW1lX29yX3BhdGglMjBnb29nbGUtdDUlMkZ0NS1zbWFsbCUyMCU1QyUwQSUyMCUyMCUyMCUyMCUyMyUyMHJlbW92ZSUyMHRoZSUyMCU2MG1heF90cmFpbl9zYW1wbGVzJTYwJTJDJTIwJTYwbWF4X2V2YWxfc2FtcGxlcyU2MCUyMGFuZCUyMCU2MG1heF9wcmVkaWN0X3NhbXBsZXMlNjAlMjBpZiUyMGV2ZXJ5dGhpbmclMjB3b3JrcyUwQSUyMCUyMCUyMCUyMC0tbWF4X3RyYWluX3NhbXBsZXMlMjA1MCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tbWF4X2V2YWxfc2FtcGxlcyUyMDUwJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1tYXhfcHJlZGljdF9zYW1wbGVzJTIwNTAlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRvX3RyYWluJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1kb19ldmFsJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1kYXRhc2V0X25hbWUlMjBjbm5fZGFpbHltYWlsJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1kYXRhc2V0X2NvbmZpZyUyMCUyMjMuMC4wJTIyJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1zb3VyY2VfcHJlZml4JTIwJTIyc3VtbWFyaXplJTNBJTIwJTIyJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1vdXRwdXRfZGlyJTIwJTJGdG1wJTJGdHN0LXN1bW1hcml6YXRpb24lMjAlNUMlMEElMjAlMjAlMjAlMjAtLXBlcl9kZXZpY2VfdHJhaW5fYmF0Y2hfc2l6ZSUzRDQlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXBlcl9kZXZpY2VfZXZhbF9iYXRjaF9zaXplJTNENCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcHVzaF90b19odWIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXB1c2hfdG9faHViX21vZGVsX2lkJTIwZmluZXR1bmVkLXQ1LWNubl9kYWlseW1haWwlMjAlNUMlMEElMjAlMjAlMjAlMjAlMjMlMjByZW1vdmUlMjBpZiUyMHVzaW5nJTIwJTYwb3V0cHV0X2RpciUyMHByZXZpb3VzX291dHB1dF9kaXIlNjAlMEElMjAlMjAlMjAlMjAlMjMlMjAtLW92ZXJ3cml0ZV9vdXRwdXRfZGlyJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1vdXRwdXRfZGlyJTIwcHJldmlvdXNfb3V0cHV0X2RpciUyMCU1QyUwQSUyMCUyMCUyMCUyMCUyMyUyMC0tcmVzdW1lX2Zyb21fY2hlY2twb2ludCUyMHBhdGhfdG9fc3BlY2lmaWNfY2hlY2twb2ludCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcHJlZGljdF93aXRoX2dlbmVyYXRlJTIwJTVD",highlighted:`python examples/pytorch/summarization/run_summarization.py \\
    --model_name_or_path google-t5/t5-small \\
    <span class="hljs-comment"># remove the \`max_train_samples\`, \`max_eval_samples\` and \`max_predict_samples\` if everything works</span>
    --max_train_samples 50 \\
    --max_eval_samples 50 \\
    --max_predict_samples 50 \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --push_to_hub \\
    --push_to_hub_model_id finetuned-t5-cnn_dailymail \\
    <span class="hljs-comment"># remove if using \`output_dir previous_output_dir\`</span>
    <span class="hljs-comment"># --overwrite_output_dir \\</span>
    --output_dir previous_output_dir \\
    <span class="hljs-comment"># --resume_from_checkpoint path_to_specific_checkpoint \\</span>
    --predict_with_generate \\`,wrap:!1}}),k=new y({props:{code:"dG9yY2hydW4lMjAlNUMlMEElMjAlMjAlMjAlMjAtLW5wcm9jX3Blcl9ub2RlJTIwOCUyMHB5dG9yY2glMkZzdW1tYXJpemF0aW9uJTJGcnVuX3N1bW1hcml6YXRpb24ucHklMjAlNUMlMEElMjAlMjAlMjAlMjAtLWZwMTYlMjAlNUMlMEElMjAlMjAlMjAlMjAuLi4lMEElMjAlMjAlMjAlMjAuLi4=",highlighted:`torchrun \\
    --nproc_per_node 8 pytorch/summarization/run_summarization.py \\
    --fp16 \\
    ...
    ...`,wrap:!1}}),S=new y({props:{code:"cHl0aG9uJTIweGxhX3NwYXduLnB5JTIwLS1udW1fY29yZXMlMjA4JTIwcHl0b3JjaCUyRnN1bW1hcml6YXRpb24lMkZydW5fc3VtbWFyaXphdGlvbi5weSUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tbW9kZWxfbmFtZV9vcl9wYXRoJTIwZ29vZ2xlLXQ1JTJGdDUtc21hbGwlMjAlNUMlMEElMjAlMjAlMjAlMjAuLi4lMEElMjAlMjAlMjAlMjAuLi4=",highlighted:`python xla_spawn.py --num_cores 8 pytorch/summarization/run_summarization.py \\
    --model_name_or_path google-t5/t5-small \\
    ...
    ...`,wrap:!1}}),E=new me({props:{title:"Accelerate",local:"accelerate",headingTag:"h2"}}),D=new y({props:{code:"cGlwJTIwaW5zdGFsbCUyMGdpdCUyQmh0dHBzJTNBJTJGJTJGZ2l0aHViLmNvbSUyRmh1Z2dpbmdmYWNlJTJGYWNjZWxlcmF0ZQ==",highlighted:"pip install git+https://github.com/huggingface/accelerate",wrap:!1}}),O=new y({props:{code:"YWNjZWxlcmF0ZSUyMGNvbmZpZw==",highlighted:"accelerate config",wrap:!1}}),ee=new y({props:{code:"YWNjZWxlcmF0ZSUyMHRlc3Q=",highlighted:'accelerate <span class="hljs-built_in">test</span>',wrap:!1}}),le=new y({props:{code:"YWNjZWxlcmF0ZSUyMGxhdW5jaCUyMHJ1bl9zdW1tYXJpemF0aW9uX25vX3RyYWluZXIucHklMjAlNUMlMEElMjAlMjAlMjAlMjAtLW1vZGVsX25hbWVfb3JfcGF0aCUyMGdvb2dsZS10NSUyRnQ1LXNtYWxsJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1kYXRhc2V0X25hbWUlMjBjbm5fZGFpbHltYWlsJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1kYXRhc2V0X2NvbmZpZyUyMCUyMjMuMC4wJTIyJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1zb3VyY2VfcHJlZml4JTIwJTIyc3VtbWFyaXplJTNBJTIwJTIyJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1vdXRwdXRfZGlyJTIwfiUyRnRtcCUyRnRzdC1zdW1tYXJpemF0aW9uJTIwJTVD",highlighted:`accelerate launch run_summarization_no_trainer.py \\
    --model_name_or_path google-t5/t5-small \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir ~/tmp/tst-summarization \\`,wrap:!1}}),ae=new me({props:{title:"Custom dataset",local:"custom-dataset",headingTag:"h2"}}),re=new y({props:{code:"cHl0aG9uJTIwZXhhbXBsZXMlMkZweXRvcmNoJTJGc3VtbWFyaXphdGlvbiUyRnJ1bl9zdW1tYXJpemF0aW9uLnB5JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1tb2RlbF9uYW1lX29yX3BhdGglMjBnb29nbGUtdDUlMkZ0NS1zbWFsbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZG9fdHJhaW4lMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRvX2V2YWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXRyYWluX2ZpbGUlMjBwYXRoX3RvX2Nzdl9vcl9qc29ubGluZXNfZmlsZSUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tdmFsaWRhdGlvbl9maWxlJTIwcGF0aF90b19jc3Zfb3JfanNvbmxpbmVzX2ZpbGUlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXRleHRfY29sdW1uJTIwdGV4dF9jb2x1bW5fbmFtZSUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tc3VtbWFyeV9jb2x1bW4lMjBzdW1tYXJ5X2NvbHVtbl9uYW1lJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1zb3VyY2VfcHJlZml4JTIwJTIyc3VtbWFyaXplJTNBJTIwJTIyJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1vdXRwdXRfZGlyJTIwJTJGdG1wJTJGdHN0LXN1bW1hcml6YXRpb24lMjAlNUMlMEElMjAlMjAlMjAlMjAtLW92ZXJ3cml0ZV9vdXRwdXRfZGlyJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1wZXJfZGV2aWNlX3RyYWluX2JhdGNoX3NpemUlM0Q0JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1wZXJfZGV2aWNlX2V2YWxfYmF0Y2hfc2l6ZSUzRDQlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXByZWRpY3Rfd2l0aF9nZW5lcmF0ZSUyMCU1Qw==",highlighted:`python examples/pytorch/summarization/run_summarization.py \\
    --model_name_or_path google-t5/t5-small \\
    --do_train \\
    --do_eval \\
    --train_file path_to_csv_or_jsonlines_file \\
    --validation_file path_to_csv_or_jsonlines_file \\
    --text_column text_column_name \\
    --summary_column summary_column_name \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --overwrite_output_dir \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --predict_with_generate \\`,wrap:!1}}),oe=new Lt({props:{source:"https://github.com/huggingface/transformers/blob/main/docs/source/en/run_scripts.md"}}),{c(){h=n("meta"),$=i(),_=n("p"),w=i(),m(T.$$.fragment),p=i(),J=n("p"),J.innerHTML=et,ue=i(),g=n("p"),g.textContent=tt,fe=i(),U=n("p"),U.innerHTML=lt,de=i(),j=n("p"),j.innerHTML=at,Me=i(),m(v.$$.fragment),he=i(),I=n("p"),I.textContent=it,we=i(),m(C.$$.fragment),Te=i(),X=n("p"),X.textContent=st,ye=i(),m(x.$$.fragment),Je=i(),W=n("p"),W.textContent=nt,_e=i(),m(A.$$.fragment),be=i(),m(Z.$$.fragment),$e=i(),L=n("p"),L.innerHTML=rt,ge=i(),m(b.$$.fragment),Ue=i(),G=n("p"),G.innerHTML=ot,je=i(),R=n("p"),R.innerHTML=pt,ve=i(),B=n("p"),B.textContent=mt,Ie=i(),V=n("ul"),V.innerHTML=ct,Ce=i(),Y=n("p"),Y.innerHTML=ut,Xe=i(),m(H.$$.fragment),xe=i(),z=n("p"),z.innerHTML=ft,We=i(),N=n("ul"),N.innerHTML=dt,Ae=i(),m(k.$$.fragment),Ze=i(),F=n("p"),F.innerHTML=Mt,Le=i(),m(S.$$.fragment),Ge=i(),m(E.$$.fragment),Re=i(),P=n("p"),P.innerHTML=ht,Be=i(),Q=n("p"),Q.textContent=wt,Ve=i(),m(D.$$.fragment),Ye=i(),q=n("p"),q.innerHTML=Tt,He=i(),m(O.$$.fragment),ze=i(),K=n("p"),K.innerHTML=yt,Ne=i(),m(ee.$$.fragment),ke=i(),te=n("p"),te.innerHTML=Jt,Fe=i(),m(le.$$.fragment),Se=i(),m(ae.$$.fragment),Ee=i(),ie=n("p"),ie.textContent=_t,Pe=i(),se=n("ul"),se.innerHTML=bt,Qe=i(),ne=n("p"),ne.textContent=$t,De=i(),m(re.$$.fragment),qe=i(),m(oe.$$.fragment),Oe=i(),pe=n("p"),this.h()},l(e){const t=Wt("svelte-u9bgzb",document.head);h=r(t,"META",{name:!0,content:!0}),t.forEach(l),$=s(e),_=r(e,"P",{}),Ut(_).forEach(l),w=s(e),c(T.$$.fragment,e),p=s(e),J=r(e,"P",{"data-svelte-h":!0}),o(J)!=="svelte-oefu67"&&(J.innerHTML=et),ue=s(e),g=r(e,"P",{"data-svelte-h":!0}),o(g)!=="svelte-17z6llo"&&(g.textContent=tt),fe=s(e),U=r(e,"P",{"data-svelte-h":!0}),o(U)!=="svelte-ktsq4f"&&(U.innerHTML=lt),de=s(e),j=r(e,"P",{"data-svelte-h":!0}),o(j)!=="svelte-mx2wto"&&(j.innerHTML=at),Me=s(e),c(v.$$.fragment,e),he=s(e),I=r(e,"P",{"data-svelte-h":!0}),o(I)!=="svelte-znqcxj"&&(I.textContent=it),we=s(e),c(C.$$.fragment,e),Te=s(e),X=r(e,"P",{"data-svelte-h":!0}),o(X)!=="svelte-1heqpxe"&&(X.textContent=st),ye=s(e),c(x.$$.fragment,e),Je=s(e),W=r(e,"P",{"data-svelte-h":!0}),o(W)!=="svelte-eoouts"&&(W.textContent=nt),_e=s(e),c(A.$$.fragment,e),be=s(e),c(Z.$$.fragment,e),$e=s(e),L=r(e,"P",{"data-svelte-h":!0}),o(L)!=="svelte-zd5fp"&&(L.innerHTML=rt),ge=s(e),c(b.$$.fragment,e),Ue=s(e),G=r(e,"P",{"data-svelte-h":!0}),o(G)!=="svelte-7oln71"&&(G.innerHTML=ot),je=s(e),R=r(e,"P",{"data-svelte-h":!0}),o(R)!=="svelte-lgod5z"&&(R.innerHTML=pt),ve=s(e),B=r(e,"P",{"data-svelte-h":!0}),o(B)!=="svelte-1ib51jx"&&(B.textContent=mt),Ie=s(e),V=r(e,"UL",{"data-svelte-h":!0}),o(V)!=="svelte-156tr31"&&(V.innerHTML=ct),Ce=s(e),Y=r(e,"P",{"data-svelte-h":!0}),o(Y)!=="svelte-3w6fs5"&&(Y.innerHTML=ut),Xe=s(e),c(H.$$.fragment,e),xe=s(e),z=r(e,"P",{"data-svelte-h":!0}),o(z)!=="svelte-g34bxd"&&(z.innerHTML=ft),We=s(e),N=r(e,"UL",{"data-svelte-h":!0}),o(N)!=="svelte-vvd6kc"&&(N.innerHTML=dt),Ae=s(e),c(k.$$.fragment,e),Ze=s(e),F=r(e,"P",{"data-svelte-h":!0}),o(F)!=="svelte-1vgd91y"&&(F.innerHTML=Mt),Le=s(e),c(S.$$.fragment,e),Ge=s(e),c(E.$$.fragment,e),Re=s(e),P=r(e,"P",{"data-svelte-h":!0}),o(P)!=="svelte-ovbb1b"&&(P.innerHTML=ht),Be=s(e),Q=r(e,"P",{"data-svelte-h":!0}),o(Q)!=="svelte-14nzkpr"&&(Q.textContent=wt),Ve=s(e),c(D.$$.fragment,e),Ye=s(e),q=r(e,"P",{"data-svelte-h":!0}),o(q)!=="svelte-qkqzs9"&&(q.innerHTML=Tt),He=s(e),c(O.$$.fragment,e),ze=s(e),K=r(e,"P",{"data-svelte-h":!0}),o(K)!=="svelte-e813qa"&&(K.innerHTML=yt),Ne=s(e),c(ee.$$.fragment,e),ke=s(e),te=r(e,"P",{"data-svelte-h":!0}),o(te)!=="svelte-2l6taw"&&(te.innerHTML=Jt),Fe=s(e),c(le.$$.fragment,e),Se=s(e),c(ae.$$.fragment,e),Ee=s(e),ie=r(e,"P",{"data-svelte-h":!0}),o(ie)!=="svelte-1ahosjn"&&(ie.textContent=_t),Pe=s(e),se=r(e,"UL",{"data-svelte-h":!0}),o(se)!=="svelte-1jtimg7"&&(se.innerHTML=bt),Qe=s(e),ne=r(e,"P",{"data-svelte-h":!0}),o(ne)!=="svelte-1qbczyv"&&(ne.textContent=$t),De=s(e),c(re.$$.fragment,e),qe=s(e),c(oe.$$.fragment,e),Oe=s(e),pe=r(e,"P",{}),Ut(pe).forEach(l),this.h()},h(){jt(h,"name","hf:doc:metadata"),jt(h,"content",Bt)},m(e,t){At(document.head,h),a(e,$,t),a(e,_,t),a(e,w,t),u(T,e,t),a(e,p,t),a(e,J,t),a(e,ue,t),a(e,g,t),a(e,fe,t),a(e,U,t),a(e,de,t),a(e,j,t),a(e,Me,t),u(v,e,t),a(e,he,t),a(e,I,t),a(e,we,t),u(C,e,t),a(e,Te,t),a(e,X,t),a(e,ye,t),u(x,e,t),a(e,Je,t),a(e,W,t),a(e,_e,t),u(A,e,t),a(e,be,t),u(Z,e,t),a(e,$e,t),a(e,L,t),a(e,ge,t),u(b,e,t),a(e,Ue,t),a(e,G,t),a(e,je,t),a(e,R,t),a(e,ve,t),a(e,B,t),a(e,Ie,t),a(e,V,t),a(e,Ce,t),a(e,Y,t),a(e,Xe,t),u(H,e,t),a(e,xe,t),a(e,z,t),a(e,We,t),a(e,N,t),a(e,Ae,t),u(k,e,t),a(e,Ze,t),a(e,F,t),a(e,Le,t),u(S,e,t),a(e,Ge,t),u(E,e,t),a(e,Re,t),a(e,P,t),a(e,Be,t),a(e,Q,t),a(e,Ve,t),u(D,e,t),a(e,Ye,t),a(e,q,t),a(e,He,t),u(O,e,t),a(e,ze,t),a(e,K,t),a(e,Ne,t),u(ee,e,t),a(e,ke,t),a(e,te,t),a(e,Fe,t),u(le,e,t),a(e,Se,t),u(ae,e,t),a(e,Ee,t),a(e,ie,t),a(e,Pe,t),a(e,se,t),a(e,Qe,t),a(e,ne,t),a(e,De,t),u(re,e,t),a(e,qe,t),u(oe,e,t),a(e,Oe,t),a(e,pe,t),Ke=!0},p(e,[t]){const gt={};t&2&&(gt.$$scope={dirty:t,ctx:e}),b.$set(gt)},i(e){Ke||(f(T.$$.fragment,e),f(v.$$.fragment,e),f(C.$$.fragment,e),f(x.$$.fragment,e),f(A.$$.fragment,e),f(Z.$$.fragment,e),f(b.$$.fragment,e),f(H.$$.fragment,e),f(k.$$.fragment,e),f(S.$$.fragment,e),f(E.$$.fragment,e),f(D.$$.fragment,e),f(O.$$.fragment,e),f(ee.$$.fragment,e),f(le.$$.fragment,e),f(ae.$$.fragment,e),f(re.$$.fragment,e),f(oe.$$.fragment,e),Ke=!0)},o(e){d(T.$$.fragment,e),d(v.$$.fragment,e),d(C.$$.fragment,e),d(x.$$.fragment,e),d(A.$$.fragment,e),d(Z.$$.fragment,e),d(b.$$.fragment,e),d(H.$$.fragment,e),d(k.$$.fragment,e),d(S.$$.fragment,e),d(E.$$.fragment,e),d(D.$$.fragment,e),d(O.$$.fragment,e),d(ee.$$.fragment,e),d(le.$$.fragment,e),d(ae.$$.fragment,e),d(re.$$.fragment,e),d(oe.$$.fragment,e),Ke=!1},d(e){e&&(l($),l(_),l(w),l(p),l(J),l(ue),l(g),l(fe),l(U),l(de),l(j),l(Me),l(he),l(I),l(we),l(Te),l(X),l(ye),l(Je),l(W),l(_e),l(be),l($e),l(L),l(ge),l(Ue),l(G),l(je),l(R),l(ve),l(B),l(Ie),l(V),l(Ce),l(Y),l(Xe),l(xe),l(z),l(We),l(N),l(Ae),l(Ze),l(F),l(Le),l(Ge),l(Re),l(P),l(Be),l(Q),l(Ve),l(Ye),l(q),l(He),l(ze),l(K),l(Ne),l(ke),l(te),l(Fe),l(Se),l(Ee),l(ie),l(Pe),l(se),l(Qe),l(ne),l(De),l(qe),l(Oe),l(pe)),l(h),M(T,e),M(v,e),M(C,e),M(x,e),M(A,e),M(Z,e),M(b,e),M(H,e),M(k,e),M(S,e),M(E,e),M(D,e),M(O,e),M(ee,e),M(le,e),M(ae,e),M(re,e),M(oe,e)}}}const Bt='{"title":"Training scripts","local":"training-scripts","sections":[{"title":"Setup","local":"setup","sections":[],"depth":2},{"title":"Run a script","local":"run-a-script","sections":[],"depth":2},{"title":"Accelerate","local":"accelerate","sections":[],"depth":2},{"title":"Custom dataset","local":"custom-dataset","sections":[],"depth":2}],"depth":1}';function Vt(ce){return It(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ft extends Xt{constructor(h){super(),xt(this,h,Vt,Rt,vt,{})}}export{Ft as component};
