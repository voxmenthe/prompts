import{s as Pe,o as Ke,n as It}from"../chunks/scheduler.18a86fab.js";import{S as Oe,i as tl,g as r,s as o,r as h,A as el,h as M,f as l,c as i,j as ie,u as J,x as y,k as Ae,y as c,a as s,v as w,d as U,t as T,w as b}from"../chunks/index.98837b22.js";import{T as ll}from"../chunks/Tip.77304350.js";import{C as x}from"../chunks/CodeBlock.8d0c2e8a.js";import{D as sl}from"../chunks/DocNotebookDropdown.a04a6b2a.js";import{H as mt,E as nl}from"../chunks/getInferenceSnippets.06c2775f.js";import{H as al,a as pe}from"../chunks/HfOption.6641485e.js";function ol(B){let a,u='Modern LLMs are typically decoder-only models, but there are some encoder-decoder LLMs like <a href="../model_doc/flan-t5">Flan-T5</a> or <a href="../model_doc/bart">BART</a> that may be used for prompting. For encoder-decoder models, make sure you set the pipeline task identifier to <code>text2text-generation</code> instead of <code>text-generation</code>.';return{c(){a=r("p"),a.innerHTML=u},l(n){a=M(n,"P",{"data-svelte-h":!0}),y(a)!=="svelte-b7pecs"&&(a.innerHTML=u)},m(n,f){s(n,a,f)},p:It,d(n){n&&l(a)}}}function il(B){let a,u;return a=new x({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBaW1wb3J0JTIwdG9yY2glMEElMEFwaXBlbGluZSUyMCUzRCUyMHBpcGVsaW5lKG1vZGVsJTNEJTIybWlzdHJhbGFpJTJGTWlzdHJhbC03Qi1JbnN0cnVjdC12MC4xJTIyJTJDJTIwZHR5cGUlM0R0b3JjaC5iZmxvYXQxNiUyQyUyMGRldmljZV9tYXAlM0QlMjJhdXRvJTIyKSUwQXByb21wdCUyMCUzRCUyMCUyMiUyMiUyMlJldHVybiUyMGElMjBsaXN0JTIwb2YlMjBuYW1lZCUyMGVudGl0aWVzJTIwaW4lMjB0aGUlMjB0ZXh0LiUwQVRleHQlM0ElMjBUaGUlMjBjb21wYW55JTIwd2FzJTIwZm91bmRlZCUyMGluJTIwMjAxNiUyMGJ5JTIwRnJlbmNoJTIwZW50cmVwcmVuZXVycyUyMENsJUMzJUE5bWVudCUyMERlbGFuZ3VlJTJDJTIwSnVsaWVuJTIwQ2hhdW1vbmQlMkMlMjBhbmQlMjBUaG9tYXMlMjBXb2xmJTIwaW4lMjBOZXclMjBZb3JrJTIwQ2l0eSUyQyUyMG9yaWdpbmFsbHklMjBhcyUyMGElMjBjb21wYW55JTIwdGhhdCUyMGRldmVsb3BlZCUyMGElMjBjaGF0Ym90JTIwYXBwJTIwdGFyZ2V0ZWQlMjBhdCUyMHRlZW5hZ2Vycy4lMEFOYW1lZCUyMGVudGl0aWVzJTNBJTBBJTIyJTIyJTIyJTBBJTBBb3V0cHV0cyUyMCUzRCUyMHBpcGVsaW5lKHByb21wdCUyQyUyMG1heF9uZXdfdG9rZW5zJTNENTAlMkMlMjByZXR1cm5fZnVsbF90ZXh0JTNERmFsc2UpJTBBZm9yJTIwb3V0cHV0JTIwaW4lMjBvdXRwdXRzJTNBJTBBJTIwJTIwJTIwJTIwcHJpbnQoZiUyMlJlc3VsdCUzQSUyMCU3Qm91dHB1dCU1QidnZW5lcmF0ZWRfdGV4dCclNUQlN0QlMjIpJTBBUmVzdWx0JTNBJTIwJTIwJTVCQ2wlQzMlQTltZW50JTIwRGVsYW5ndWUlMkMlMjBKdWxpZW4lMjBDaGF1bW9uZCUyQyUyMFRob21hcyUyMFdvbGYlMkMlMjBjb21wYW55JTJDJTIwTmV3JTIwWW9yayUyMENpdHklMkMlMjBjaGF0Ym90JTIwYXBwJTJDJTIwdGVlbmFnZXJzJTVE",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline
<span class="hljs-keyword">import</span> torch

pipeline = pipeline(model=<span class="hljs-string">&quot;mistralai/Mistral-7B-Instruct-v0.1&quot;</span>, dtype=torch.bfloat16, device_map=<span class="hljs-string">&quot;auto&quot;</span>)
prompt = <span class="hljs-string">&quot;&quot;&quot;Return a list of named entities in the text.
Text: The company was founded in 2016 by French entrepreneurs Clément Delangue, Julien Chaumond, and Thomas Wolf in New York City, originally as a company that developed a chatbot app targeted at teenagers.
Named entities:
&quot;&quot;&quot;</span>

outputs = pipeline(prompt, max_new_tokens=<span class="hljs-number">50</span>, return_full_text=<span class="hljs-literal">False</span>)
<span class="hljs-keyword">for</span> output <span class="hljs-keyword">in</span> outputs:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Result: <span class="hljs-subst">{output[<span class="hljs-string">&#x27;generated_text&#x27;</span>]}</span>&quot;</span>)
Result:  [Clément Delangue, Julien Chaumond, Thomas Wolf, company, New York City, chatbot app, teenagers]`,wrap:!1}}),{c(){h(a.$$.fragment)},l(n){J(a.$$.fragment,n)},m(n,f){w(a,n,f),u=!0},p:It,i(n){u||(U(a.$$.fragment,n),u=!0)},o(n){T(a.$$.fragment,n),u=!1},d(n){b(a,n)}}}function pl(B){let a,u;return a=new x({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBaW1wb3J0JTIwdG9yY2glMEElMEFwaXBlbGluZSUyMCUzRCUyMHBpcGVsaW5lKG1vZGVsJTNEJTIybWlzdHJhbGFpJTJGTWlzdHJhbC03Qi1JbnN0cnVjdC12MC4xJTIyJTJDJTIwZHR5cGUlM0R0b3JjaC5iZmxvYXQxNiUyQyUyMGRldmljZV9tYXAlM0QlMjJhdXRvJTIyKSUwQXByb21wdCUyMCUzRCUyMCUyMiUyMiUyMlRyYW5zbGF0ZSUyMHRoZSUyMEVuZ2xpc2glMjB0ZXh0JTIwdG8lMjBGcmVuY2guJTBBVGV4dCUzQSUyMFNvbWV0aW1lcyUyQyUyMEkndmUlMjBiZWxpZXZlZCUyMGFzJTIwbWFueSUyMGFzJTIwc2l4JTIwaW1wb3NzaWJsZSUyMHRoaW5ncyUyMGJlZm9yZSUyMGJyZWFrZmFzdC4lMEFUcmFuc2xhdGlvbiUzQSUwQSUyMiUyMiUyMiUwQSUwQW91dHB1dHMlMjAlM0QlMjBwaXBlbGluZShwcm9tcHQlMkMlMjBtYXhfbmV3X3Rva2VucyUzRDIwJTJDJTIwZG9fc2FtcGxlJTNEVHJ1ZSUyQyUyMHRvcF9rJTNEMTAlMkMlMjByZXR1cm5fZnVsbF90ZXh0JTNERmFsc2UpJTBBZm9yJTIwb3V0cHV0JTIwaW4lMjBvdXRwdXRzJTNBJTBBJTIwJTIwJTIwJTIwcHJpbnQoZiUyMlJlc3VsdCUzQSUyMCU3Qm91dHB1dCU1QidnZW5lcmF0ZWRfdGV4dCclNUQlN0QlMjIpJTBBUmVzdWx0JTNBJTIwJUMzJTgwJTIwbCdvY2Nhc2lvbiUyQyUyMGonYWklMjBjcm95dSUyMHBsdXMlMjBkZSUyMHNpeCUyMGNob3NlcyUyMGltcG9zc2libGVz",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline
<span class="hljs-keyword">import</span> torch

pipeline = pipeline(model=<span class="hljs-string">&quot;mistralai/Mistral-7B-Instruct-v0.1&quot;</span>, dtype=torch.bfloat16, device_map=<span class="hljs-string">&quot;auto&quot;</span>)
prompt = <span class="hljs-string">&quot;&quot;&quot;Translate the English text to French.
Text: Sometimes, I&#x27;ve believed as many as six impossible things before breakfast.
Translation:
&quot;&quot;&quot;</span>

outputs = pipeline(prompt, max_new_tokens=<span class="hljs-number">20</span>, do_sample=<span class="hljs-literal">True</span>, top_k=<span class="hljs-number">10</span>, return_full_text=<span class="hljs-literal">False</span>)
<span class="hljs-keyword">for</span> output <span class="hljs-keyword">in</span> outputs:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Result: <span class="hljs-subst">{output[<span class="hljs-string">&#x27;generated_text&#x27;</span>]}</span>&quot;</span>)
Result: À l<span class="hljs-string">&#x27;occasion, j&#x27;</span>ai croyu plus de six choses impossibles`,wrap:!1}}),{c(){h(a.$$.fragment)},l(n){J(a.$$.fragment,n)},m(n,f){w(a,n,f),u=!0},p:It,i(n){u||(U(a.$$.fragment,n),u=!0)},o(n){T(a.$$.fragment,n),u=!1},d(n){b(a,n)}}}function rl(B){let a,u;return a=new x({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBaW1wb3J0JTIwdG9yY2glMEElMEFwaXBlbGluZSUyMCUzRCUyMHBpcGVsaW5lKG1vZGVsJTNEJTIybWlzdHJhbGFpJTJGTWlzdHJhbC03Qi1JbnN0cnVjdC12MC4xJTIyJTJDJTIwZHR5cGUlM0R0b3JjaC5iZmxvYXQxNiUyQyUyMGRldmljZV9tYXAlM0QlMjJhdXRvJTIyKSUwQXByb21wdCUyMCUzRCUyMCUyMiUyMiUyMlBlcm1hY3VsdHVyZSUyMGlzJTIwYSUyMGRlc2lnbiUyMHByb2Nlc3MlMjBtaW1pY2tpbmclMjB0aGUlMjBkaXZlcnNpdHklMkMlMjBmdW5jdGlvbmFsaXR5JTIwYW5kJTIwcmVzaWxpZW5jZSUyMG9mJTIwbmF0dXJhbCUyMGVjb3N5c3RlbXMuJTIwVGhlJTIwcHJpbmNpcGxlcyUyMGFuZCUyMHByYWN0aWNlcyUyMGFyZSUyMGRyYXduJTIwZnJvbSUyMHRyYWRpdGlvbmFsJTIwZWNvbG9naWNhbCUyMGtub3dsZWRnZSUyMG9mJTIwaW5kaWdlbm91cyUyMGN1bHR1cmVzJTIwY29tYmluZWQlMjB3aXRoJTIwbW9kZXJuJTIwc2NpZW50aWZpYyUyMHVuZGVyc3RhbmRpbmclMjBhbmQlMjB0ZWNobm9sb2dpY2FsJTIwaW5ub3ZhdGlvbnMuJTIwUGVybWFjdWx0dXJlJTIwZGVzaWduJTIwcHJvdmlkZXMlMjBhJTIwZnJhbWV3b3JrJTIwaGVscGluZyUyMGluZGl2aWR1YWxzJTIwYW5kJTIwY29tbXVuaXRpZXMlMjBkZXZlbG9wJTIwaW5ub3ZhdGl2ZSUyQyUyMGNyZWF0aXZlJTIwYW5kJTIwZWZmZWN0aXZlJTIwc3RyYXRlZ2llcyUyMGZvciUyMG1lZXRpbmclMjBiYXNpYyUyMG5lZWRzJTIwd2hpbGUlMjBwcmVwYXJpbmclMjBmb3IlMjBhbmQlMjBtaXRpZ2F0aW5nJTIwdGhlJTIwcHJvamVjdGVkJTIwaW1wYWN0cyUyMG9mJTIwY2xpbWF0ZSUyMGNoYW5nZS4lMEFXcml0ZSUyMGElMjBzdW1tYXJ5JTIwb2YlMjB0aGUlMjBhYm92ZSUyMHRleHQuJTBBU3VtbWFyeSUzQSUwQSUyMiUyMiUyMiUwQSUwQW91dHB1dHMlMjAlM0QlMjBwaXBlbGluZShwcm9tcHQlMkMlMjBtYXhfbmV3X3Rva2VucyUzRDMwJTJDJTIwZG9fc2FtcGxlJTNEVHJ1ZSUyQyUyMHRvcF9rJTNEMTAlMkMlMjByZXR1cm5fZnVsbF90ZXh0JTNERmFsc2UpJTBBZm9yJTIwb3V0cHV0JTIwaW4lMjBvdXRwdXRzJTNBJTBBJTIwJTIwJTIwJTIwcHJpbnQoZiUyMlJlc3VsdCUzQSUyMCU3Qm91dHB1dCU1QidnZW5lcmF0ZWRfdGV4dCclNUQlN0QlMjIpJTBBUmVzdWx0JTNBJTIwUGVybWFjdWx0dXJlJTIwaXMlMjB0aGUlMjBkZXNpZ24lMjBwcm9jZXNzJTIwdGhhdCUyMGludm9sdmVzJTIwbWltaWNraW5nJTIwbmF0dXJhbCUyMGVjb3N5c3RlbXMlMjB0byUyMHByb3ZpZGUlMjBzdXN0YWluYWJsZSUyMHNvbHV0aW9ucyUyMHRvJTIwYmFzaWMlMjBuZWVkcy4lMjBJdCUyMGlzJTIwYSUyMGhvbGlzdGljJTIwYXBwcm9hY2glMjB0aGF0JTIwY29tYg==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline
<span class="hljs-keyword">import</span> torch

pipeline = pipeline(model=<span class="hljs-string">&quot;mistralai/Mistral-7B-Instruct-v0.1&quot;</span>, dtype=torch.bfloat16, device_map=<span class="hljs-string">&quot;auto&quot;</span>)
prompt = <span class="hljs-string">&quot;&quot;&quot;Permaculture is a design process mimicking the diversity, functionality and resilience of natural ecosystems. The principles and practices are drawn from traditional ecological knowledge of indigenous cultures combined with modern scientific understanding and technological innovations. Permaculture design provides a framework helping individuals and communities develop innovative, creative and effective strategies for meeting basic needs while preparing for and mitigating the projected impacts of climate change.
Write a summary of the above text.
Summary:
&quot;&quot;&quot;</span>

outputs = pipeline(prompt, max_new_tokens=<span class="hljs-number">30</span>, do_sample=<span class="hljs-literal">True</span>, top_k=<span class="hljs-number">10</span>, return_full_text=<span class="hljs-literal">False</span>)
<span class="hljs-keyword">for</span> output <span class="hljs-keyword">in</span> outputs:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Result: <span class="hljs-subst">{output[<span class="hljs-string">&#x27;generated_text&#x27;</span>]}</span>&quot;</span>)
Result: Permaculture <span class="hljs-keyword">is</span> the design process that involves mimicking natural ecosystems to provide sustainable solutions to basic needs. It <span class="hljs-keyword">is</span> a holistic approach that comb`,wrap:!1}}),{c(){h(a.$$.fragment)},l(n){J(a.$$.fragment,n)},m(n,f){w(a,n,f),u=!0},p:It,i(n){u||(U(a.$$.fragment,n),u=!0)},o(n){T(a.$$.fragment,n),u=!1},d(n){b(a,n)}}}function Ml(B){let a,u;return a=new x({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBaW1wb3J0JTIwdG9yY2glMEElMEFwaXBlbGluZSUyMCUzRCUyMHBpcGVsaW5lKG1vZGVsJTNEJTIybWlzdHJhbGFpJTJGTWlzdHJhbC03Qi1JbnN0cnVjdC12MC4xJTIyJTJDJTIwZHR5cGUlM0R0b3JjaC5iZmxvYXQxNiUyQyUyMGRldmljZV9tYXAlM0QlMjJhdXRvJTIyKSUwQXByb21wdCUyMCUzRCUyMCUyMiUyMiUyMkFuc3dlciUyMHRoZSUyMHF1ZXN0aW9uJTIwdXNpbmclMjB0aGUlMjBjb250ZXh0JTIwYmVsb3cuJTBBQ29udGV4dCUzQSUyMEdhenBhY2hvJTIwaXMlMjBhJTIwY29sZCUyMHNvdXAlMjBhbmQlMjBkcmluayUyMG1hZGUlMjBvZiUyMHJhdyUyQyUyMGJsZW5kZWQlMjB2ZWdldGFibGVzLiUyME1vc3QlMjBnYXpwYWNobyUyMGluY2x1ZGVzJTIwc3RhbGUlMjBicmVhZCUyQyUyMHRvbWF0byUyQyUyMGN1Y3VtYmVycyUyQyUyMG9uaW9uJTJDJTIwYmVsbCUyMHBlcHBlcnMlMkMlMjBnYXJsaWMlMkMlMjBvbGl2ZSUyMG9pbCUyQyUyMHdpbmUlMjB2aW5lZ2FyJTJDJTIwd2F0ZXIlMkMlMjBhbmQlMjBzYWx0LiUyME5vcnRoZXJuJTIwcmVjaXBlcyUyMG9mdGVuJTIwaW5jbHVkZSUyMGN1bWluJTIwYW5kJTJGb3IlMjBwaW1lbnQlQzMlQjNuJTIwKHNtb2tlZCUyMHN3ZWV0JTIwcGFwcmlrYSkuJTIwVHJhZGl0aW9uYWxseSUyQyUyMGdhenBhY2hvJTIwd2FzJTIwbWFkZSUyMGJ5JTIwcG91bmRpbmclMjB0aGUlMjB2ZWdldGFibGVzJTIwaW4lMjBhJTIwbW9ydGFyJTIwd2l0aCUyMGElMjBwZXN0bGUlM0IlMjB0aGlzJTIwbW9yZSUyMGxhYm9yaW91cyUyMG1ldGhvZCUyMGlzJTIwc3RpbGwlMjBzb21ldGltZXMlMjB1c2VkJTIwYXMlMjBpdCUyMGhlbHBzJTIwa2VlcCUyMHRoZSUyMGdhenBhY2hvJTIwY29vbCUyMGFuZCUyMGF2b2lkcyUyMHRoZSUyMGZvYW0lMjBhbmQlMjBzaWxreSUyMGNvbnNpc3RlbmN5JTIwb2YlMjBzbW9vdGhpZSUyMHZlcnNpb25zJTIwbWFkZSUyMGluJTIwYmxlbmRlcnMlMjBvciUyMGZvb2QlMjBwcm9jZXNzb3JzLiUwQVF1ZXN0aW9uJTNBJTIwV2hhdCUyMG1vZGVybiUyMHRvb2wlMjBpcyUyMHVzZWQlMjB0byUyMG1ha2UlMjBnYXpwYWNobyUzRiUwQUFuc3dlciUzQSUwQSUyMiUyMiUyMiUwQSUwQW91dHB1dHMlMjAlM0QlMjBwaXBlbGluZShwcm9tcHQlMkMlMjBtYXhfbmV3X3Rva2VucyUzRDEwJTJDJTIwZG9fc2FtcGxlJTNEVHJ1ZSUyQyUyMHRvcF9rJTNEMTAlMkMlMjByZXR1cm5fZnVsbF90ZXh0JTNERmFsc2UpJTBBZm9yJTIwb3V0cHV0JTIwaW4lMjBvdXRwdXRzJTNBJTBBJTIwJTIwJTIwJTIwcHJpbnQoZiUyMlJlc3VsdCUzQSUyMCU3Qm91dHB1dCU1QidnZW5lcmF0ZWRfdGV4dCclNUQlN0QlMjIpJTBBUmVzdWx0JTNBJTIwQSUyMGJsZW5kZXIlMjBvciUyMGZvb2QlMjBwcm9jZXNzb3IlMjBpcyUyMHRoZSUyMG1vZGVybiUyMHRvb2w=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline
<span class="hljs-keyword">import</span> torch

pipeline = pipeline(model=<span class="hljs-string">&quot;mistralai/Mistral-7B-Instruct-v0.1&quot;</span>, dtype=torch.bfloat16, device_map=<span class="hljs-string">&quot;auto&quot;</span>)
prompt = <span class="hljs-string">&quot;&quot;&quot;Answer the question using the context below.
Context: Gazpacho is a cold soup and drink made of raw, blended vegetables. Most gazpacho includes stale bread, tomato, cucumbers, onion, bell peppers, garlic, olive oil, wine vinegar, water, and salt. Northern recipes often include cumin and/or pimentón (smoked sweet paprika). Traditionally, gazpacho was made by pounding the vegetables in a mortar with a pestle; this more laborious method is still sometimes used as it helps keep the gazpacho cool and avoids the foam and silky consistency of smoothie versions made in blenders or food processors.
Question: What modern tool is used to make gazpacho?
Answer:
&quot;&quot;&quot;</span>

outputs = pipeline(prompt, max_new_tokens=<span class="hljs-number">10</span>, do_sample=<span class="hljs-literal">True</span>, top_k=<span class="hljs-number">10</span>, return_full_text=<span class="hljs-literal">False</span>)
<span class="hljs-keyword">for</span> output <span class="hljs-keyword">in</span> outputs:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Result: <span class="hljs-subst">{output[<span class="hljs-string">&#x27;generated_text&#x27;</span>]}</span>&quot;</span>)
Result: A blender <span class="hljs-keyword">or</span> food processor <span class="hljs-keyword">is</span> the modern tool`,wrap:!1}}),{c(){h(a.$$.fragment)},l(n){J(a.$$.fragment,n)},m(n,f){w(a,n,f),u=!0},p:It,i(n){u||(U(a.$$.fragment,n),u=!0)},o(n){T(a.$$.fragment,n),u=!1},d(n){b(a,n)}}}function yl(B){let a,u,n,f,G,g,Z,W;return a=new pe({props:{id:"tasks",option:"named entity recognition",$$slots:{default:[il]},$$scope:{ctx:B}}}),n=new pe({props:{id:"tasks",option:"translation",$$slots:{default:[pl]},$$scope:{ctx:B}}}),G=new pe({props:{id:"tasks",option:"summarization",$$slots:{default:[rl]},$$scope:{ctx:B}}}),Z=new pe({props:{id:"tasks",option:"question answering",$$slots:{default:[Ml]},$$scope:{ctx:B}}}),{c(){h(a.$$.fragment),u=o(),h(n.$$.fragment),f=o(),h(G.$$.fragment),g=o(),h(Z.$$.fragment)},l(p){J(a.$$.fragment,p),u=i(p),J(n.$$.fragment,p),f=i(p),J(G.$$.fragment,p),g=i(p),J(Z.$$.fragment,p)},m(p,j){w(a,p,j),s(p,u,j),w(n,p,j),s(p,f,j),w(G,p,j),s(p,g,j),w(Z,p,j),W=!0},p(p,j){const k={};j&2&&(k.$$scope={dirty:j,ctx:p}),a.$set(k);const I={};j&2&&(I.$$scope={dirty:j,ctx:p}),n.$set(I);const Zt={};j&2&&(Zt.$$scope={dirty:j,ctx:p}),G.$set(Zt);const X={};j&2&&(X.$$scope={dirty:j,ctx:p}),Z.$set(X)},i(p){W||(U(a.$$.fragment,p),U(n.$$.fragment,p),U(G.$$.fragment,p),U(Z.$$.fragment,p),W=!0)},o(p){T(a.$$.fragment,p),T(n.$$.fragment,p),T(G.$$.fragment,p),T(Z.$$.fragment,p),W=!1},d(p){p&&(l(u),l(f),l(g)),b(a,p),b(n,p),b(G,p),b(Z,p)}}}function ul(B){let a,u,n,f,G,g,Z,W,p,j='Prompt engineering or prompting, uses natural language to improve large language model (LLM) performance on a variety of tasks. A prompt can steer the model towards generating a desired output. In many cases, you don’t even need a <a href="#finetuning">fine-tuned</a> model for a task. You just need a good prompt.',k,I,Zt="Try prompting a LLM to classify some text. When you create a prompt, it’s important to provide very specific instructions about the task and what the result should look like.",X,H,gt,Q,Te="The challenge lies in designing prompts that produces the results you’re expecting because language is so incredibly nuanced and expressive.",Wt,$,be="This guide covers prompt engineering best practices, techniques, and examples for how to solve language and reasoning tasks.",vt,Y,Ct,m,v,ct,fe='Try to pick the latest models for the best performance. Keep in mind that LLMs can come in two variants, <a href="https://hf.co/mistralai/Mistral-7B-v0.1" rel="nofollow">base</a> and <a href="https://hf.co/mistralai/Mistral-7B-Instruct-v0.1" rel="nofollow">instruction-tuned</a> (or chat).',re,dt,je="Base models are excellent at completing text given an initial prompt, but they’re not as good at following instructions. Instruction-tuned models are specifically trained versions of the base models on instructional or conversational data. This makes instruction-tuned models a better fit for prompting.",Me,V,ye,ht,Ge="<p>Start with a short and simple prompt, and iterate on it to get better results.</p>",ue,Jt,Ze="<p>Put instructions at the beginning or end of a prompt. For longer prompts, models may apply optimizations to prevent attention from scaling quadratically, which places more emphasis at the beginning and end of a prompt.</p>",me,wt,Be="<p>Clearly separate instructions from the text of interest.</p>",ce,Ut,Ie="<p>Be specific and descriptive about the task and the desired output, including for example, its format, length, style, and language. Avoid ambiguous descriptions and instructions.</p>",de,Tt,ge="<p>Instructions should focus on “what to do” rather than “what not to do”.</p>",he,bt,We="<p>Lead the model to generate the correct output by writing the first word or even the first sentence.</p>",Je,ft,ve='<p>Try other techniques like <a href="#few-shot">few-shot</a> and <a href="#chain-of-thought">chain-of-thought</a> to improve results.</p>',we,jt,Ce="<p>Test your prompts with different models to assess their robustness.</p>",Ue,Gt,Ve="<p>Version and track your prompt performance.</p>",Vt,z,Rt,F,Re="Crafting a good prompt alone, also known as zero-shot prompting, may not be enough to get the results you want. You may need to try a few prompting techniques to get the best performance.",xt,N,xe="This section covers a few prompting techniques.",kt,S,Xt,E,ke="Few-shot prompting improves accuracy and performance by including specific examples of what a model should generate given an input. The explicit examples give the model a better understanding of the task and the output format you’re looking for. Try experimenting with different numbers of examples (2, 4, 8, etc.) to see how it affects performance. The example below provides the model with 1 example (1-shot) of the output format (a date in MM/DD/YYYY format) it should return.",Ht,_,Qt,q,Xe="The downside of few-shot prompting is that you need to create lengthier prompts which increases computation and latency. There is also a limit to prompt lengths. Finally, a model can learn unintended patterns from your examples, and it may not work well on complex reasoning tasks.",$t,L,He='To improve few-shot prompting for modern instruction-tuned LLMs, use a model’s specific <a href="../conversations">chat template</a>. These models are trained on datasets with turn-based conversations between a “user” and “assistant”. Structuring your prompt to align with this can improve performance.',Yt,D,Qe="Structure your prompt as a turn-based conversation and use the <code>apply_chat_template</code> method to tokenize and format it.",zt,A,Ft,P,$e="While the basic few-shot prompting approach embedded examples within a single text string, the chat template format offers the following benefits.",Nt,K,Ye="<li>The model may have a potentially improved understanding because it can better recognize the pattern and the expected roles of user input and assistant output.</li> <li>The model may more consistently output the desired output format because it is structured like its input during training.</li>",St,O,ze="Always consult a specific instruction-tuned model’s documentation to learn more about the format of their chat template so that you can structure your few-shot prompts accordingly.",Et,tt,_t,et,Fe="Chain-of-thought (CoT) is effective at generating more coherent and well-reasoned outputs by providing a series of prompts that help a model “think” more thoroughly about a topic.",qt,lt,Ne="The example below provides the model with several prompts to work through intermediate reasoning steps.",Lt,st,Dt,nt,Se='Like <a href="#few-shot">few-shot</a> prompting, the downside of CoT is that it requires more effort to design a series of prompts that help the model reason through a complex task and prompt length increases latency.',At,at,Pt,ot,Ee="While prompting is a powerful way to work with LLMs, there are scenarios where a fine-tuned model or even fine-tuning a model works better.",Kt,it,_e="Here are some examples scenarios where a fine-tuned model makes sense.",Ot,pt,qe="<li>Your domain is extremely different from what a LLM was pretrained on, and extensive prompting didn’t produce the results you want.</li> <li>Your model needs to work well in a low-resource language.</li> <li>Your model needs to be trained on sensitive data that have strict regulatory requirements.</li> <li>You’re using a small model due to cost, privacy, infrastructure, or other constraints.</li>",te,rt,Le="In all of these scenarios, ensure that you have a large enough domain-specific dataset to train your model with, have enough time and resources, and the cost of fine-tuning is worth it. Otherwise, you may be better off trying to optimize your prompt.",ee,Mt,le,yt,De="The examples below demonstrate prompting a LLM for different tasks.",se,R,ne,ut,ae,Bt,oe;return G=new mt({props:{title:"Prompt engineering",local:"prompt-engineering",headingTag:"h1"}}),Z=new sl({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/prompting.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/prompting.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/tensorflow/prompting.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/prompting.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/prompting.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/tensorflow/prompting.ipynb"}]}}),H=new x({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBaW1wb3J0JTIwdG9yY2glMEElMEFwaXBlbGluZSUyMCUzRCUyMHBpcGVsaW5lKHRhc2slM0QlMjJ0ZXh0LWdlbmVyYXRpb24lMjIlMkMlMjBtb2RlbCUzRCUyMm1pc3RyYWxhaSUyRk1pc3RhbC03Qi1JbnN0cnVjdC12MC4xJTIyJTJDJTIwZHR5cGUlM0R0b3JjaC5iZmxvYXQxNiUyQyUyMGRldmljZV9tYXAlM0QlMjJhdXRvJTIyKSUwQXByb21wdCUyMCUzRCUyMCUyMiUyMiUyMkNsYXNzaWZ5JTIwdGhlJTIwdGV4dCUyMGludG8lMjBuZXV0cmFsJTJDJTIwbmVnYXRpdmUlMjBvciUyMHBvc2l0aXZlLiUwQVRleHQlM0ElMjBUaGlzJTIwbW92aWUlMjBpcyUyMGRlZmluaXRlbHklMjBvbmUlMjBvZiUyMG15JTIwZmF2b3JpdGUlMjBtb3ZpZXMlMjBvZiUyMGl0cyUyMGtpbmQuJTIwVGhlJTIwaW50ZXJhY3Rpb24lMjBiZXR3ZWVuJTIwcmVzcGVjdGFibGUlMjBhbmQlMjBtb3JhbGx5JTIwc3Ryb25nJTIwY2hhcmFjdGVycyUyMGlzJTIwYW4lMjBvZGUlMjB0byUyMGNoaXZhbHJ5JTIwYW5kJTIwdGhlJTIwaG9ub3IlMjBjb2RlJTIwYW1vbmdzdCUyMHRoaWV2ZXMlMjBhbmQlMjBwb2xpY2VtZW4uJTBBU2VudGltZW50JTNBJTBBJTIyJTIyJTIyJTBBJTBBb3V0cHV0cyUyMCUzRCUyMHBpcGVsaW5lKHByb21wdCUyQyUyMG1heF9uZXdfdG9rZW5zJTNEMTApJTBBZm9yJTIwb3V0cHV0JTIwaW4lMjBvdXRwdXRzJTNBJTBBJTIwJTIwJTIwJTIwcHJpbnQoZiUyMlJlc3VsdCUzQSUyMCU3Qm91dHB1dCU1QidnZW5lcmF0ZWRfdGV4dCclNUQlN0QlMjIpJTBBUmVzdWx0JTNBJTIwQ2xhc3NpZnklMjB0aGUlMjB0ZXh0JTIwaW50byUyMG5ldXRyYWwlMkMlMjBuZWdhdGl2ZSUyMG9yJTIwcG9zaXRpdmUuJTIwJTBBVGV4dCUzQSUyMFRoaXMlMjBtb3ZpZSUyMGlzJTIwZGVmaW5pdGVseSUyMG9uZSUyMG9mJTIwbXklMjBmYXZvcml0ZSUyMG1vdmllcyUyMG9mJTIwaXRzJTIwa2luZC4lMjBUaGUlMjBpbnRlcmFjdGlvbiUyMGJldHdlZW4lMjByZXNwZWN0YWJsZSUyMGFuZCUyMG1vcmFsbHklMjBzdHJvbmclMjBjaGFyYWN0ZXJzJTIwaXMlMjBhbiUyMG9kZSUyMHRvJTIwY2hpdmFscnklMjBhbmQlMjB0aGUlMjBob25vciUyMGNvZGUlMjBhbW9uZ3N0JTIwdGhpZXZlcyUyMGFuZCUyMHBvbGljZW1lbi4lMEFTZW50aW1lbnQlM0ElMEFQb3NpdGl2ZQ==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline
<span class="hljs-keyword">import</span> torch

pipeline = pipeline(task=<span class="hljs-string">&quot;text-generation&quot;</span>, model=<span class="hljs-string">&quot;mistralai/Mistal-7B-Instruct-v0.1&quot;</span>, dtype=torch.bfloat16, device_map=<span class="hljs-string">&quot;auto&quot;</span>)
prompt = <span class="hljs-string">&quot;&quot;&quot;Classify the text into neutral, negative or positive.
Text: This movie is definitely one of my favorite movies of its kind. The interaction between respectable and morally strong characters is an ode to chivalry and the honor code amongst thieves and policemen.
Sentiment:
&quot;&quot;&quot;</span>

outputs = pipeline(prompt, max_new_tokens=<span class="hljs-number">10</span>)
<span class="hljs-keyword">for</span> output <span class="hljs-keyword">in</span> outputs:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Result: <span class="hljs-subst">{output[<span class="hljs-string">&#x27;generated_text&#x27;</span>]}</span>&quot;</span>)
Result: Classify the text into neutral, negative <span class="hljs-keyword">or</span> positive. 
Text: This movie <span class="hljs-keyword">is</span> definitely one of my favorite movies of its kind. The interaction between respectable <span class="hljs-keyword">and</span> morally strong characters <span class="hljs-keyword">is</span> an ode to chivalry <span class="hljs-keyword">and</span> the honor code amongst thieves <span class="hljs-keyword">and</span> policemen.
Sentiment:
Positive`,wrap:!1}}),Y=new mt({props:{title:"Best practices",local:"best-practices",headingTag:"h2"}}),V=new ll({props:{warning:!0,$$slots:{default:[ol]},$$scope:{ctx:B}}}),z=new mt({props:{title:"Techniques",local:"techniques",headingTag:"h2"}}),S=new mt({props:{title:"Few-shot prompting",local:"few-shot-prompting",headingTag:"h3"}}),_=new x({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBaW1wb3J0JTIwdG9yY2glMEElMEFwaXBlbGluZSUyMCUzRCUyMHBpcGVsaW5lKG1vZGVsJTNEJTIybWlzdHJhbGFpJTJGTWlzdHJhbC03Qi1JbnN0cnVjdC12MC4xJTIyJTJDJTIwZHR5cGUlM0R0b3JjaC5iZmxvYXQxNiUyQyUyMGRldmljZV9tYXAlM0QlMjJhdXRvJTIyKSUwQXByb21wdCUyMCUzRCUyMCUyMiUyMiUyMlRleHQlM0ElMjBUaGUlMjBmaXJzdCUyMGh1bWFuJTIwd2VudCUyMGludG8lMjBzcGFjZSUyMGFuZCUyMG9yYml0ZWQlMjB0aGUlMjBFYXJ0aCUyMG9uJTIwQXByaWwlMjAxMiUyQyUyMDE5NjEuJTBBRGF0ZSUzQSUyMDA0JTJGMTIlMkYxOTYxJTBBVGV4dCUzQSUyMFRoZSUyMGZpcnN0LWV2ZXIlMjB0ZWxldmlzZWQlMjBwcmVzaWRlbnRpYWwlMjBkZWJhdGUlMjBpbiUyMHRoZSUyMFVuaXRlZCUyMFN0YXRlcyUyMHRvb2slMjBwbGFjZSUyMG9uJTIwU2VwdGVtYmVyJTIwMjglMkMlMjAxOTYwJTJDJTIwYmV0d2VlbiUyMHByZXNpZGVudGlhbCUyMGNhbmRpZGF0ZXMlMjBKb2huJTIwRi4lMjBLZW5uZWR5JTIwYW5kJTIwUmljaGFyZCUyME5peG9uLiUwQURhdGUlM0ElMjIlMjIlMjIlMEElMEFvdXRwdXRzJTIwJTNEJTIwcGlwZWxpbmUocHJvbXB0JTJDJTIwbWF4X25ld190b2tlbnMlM0QxMiUyQyUyMGRvX3NhbXBsZSUzRFRydWUlMkMlMjB0b3BfayUzRDEwKSUwQWZvciUyMG91dHB1dCUyMGluJTIwb3V0cHV0cyUzQSUwQSUyMCUyMCUyMCUyMHByaW50KGYlMjJSZXN1bHQlM0ElMjAlN0JvdXRwdXQlNUInZ2VuZXJhdGVkX3RleHQnJTVEJTdEJTIyKSUwQSUyMyUyMFJlc3VsdCUzQSUyMFRleHQlM0ElMjBUaGUlMjBmaXJzdCUyMGh1bWFuJTIwd2VudCUyMGludG8lMjBzcGFjZSUyMGFuZCUyMG9yYml0ZWQlMjB0aGUlMjBFYXJ0aCUyMG9uJTIwQXByaWwlMjAxMiUyQyUyMDE5NjEuJTBBJTIzJTIwRGF0ZSUzQSUyMDA0JTJGMTIlMkYxOTYxJTBBJTIzJTIwVGV4dCUzQSUyMFRoZSUyMGZpcnN0LWV2ZXIlMjB0ZWxldmlzZWQlMjBwcmVzaWRlbnRpYWwlMjBkZWJhdGUlMjBpbiUyMHRoZSUyMFVuaXRlZCUyMFN0YXRlcyUyMHRvb2slMjBwbGFjZSUyMG9uJTIwU2VwdGVtYmVyJTIwMjglMkMlMjAxOTYwJTJDJTIwYmV0d2VlbiUyMHByZXNpZGVudGlhbCUyMGNhbmRpZGF0ZXMlMjBKb2huJTIwRi4lMjBLZW5uZWR5JTIwYW5kJTIwUmljaGFyZCUyME5peG9uLiUwQSUyMyUyMERhdGUlM0ElMjAwOSUyRjI4JTJGMTk2MA==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline
<span class="hljs-keyword">import</span> torch

pipeline = pipeline(model=<span class="hljs-string">&quot;mistralai/Mistral-7B-Instruct-v0.1&quot;</span>, dtype=torch.bfloat16, device_map=<span class="hljs-string">&quot;auto&quot;</span>)
prompt = <span class="hljs-string">&quot;&quot;&quot;Text: The first human went into space and orbited the Earth on April 12, 1961.
Date: 04/12/1961
Text: The first-ever televised presidential debate in the United States took place on September 28, 1960, between presidential candidates John F. Kennedy and Richard Nixon.
Date:&quot;&quot;&quot;</span>

outputs = pipeline(prompt, max_new_tokens=<span class="hljs-number">12</span>, do_sample=<span class="hljs-literal">True</span>, top_k=<span class="hljs-number">10</span>)
<span class="hljs-keyword">for</span> output <span class="hljs-keyword">in</span> outputs:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Result: <span class="hljs-subst">{output[<span class="hljs-string">&#x27;generated_text&#x27;</span>]}</span>&quot;</span>)
<span class="hljs-comment"># Result: Text: The first human went into space and orbited the Earth on April 12, 1961.</span>
<span class="hljs-comment"># Date: 04/12/1961</span>
<span class="hljs-comment"># Text: The first-ever televised presidential debate in the United States took place on September 28, 1960, between presidential candidates John F. Kennedy and Richard Nixon.</span>
<span class="hljs-comment"># Date: 09/28/1960</span>`,wrap:!1}}),A=new x({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBaW1wb3J0JTIwdG9yY2glMEElMEFwaXBlbGluZSUyMCUzRCUyMHBpcGVsaW5lKG1vZGVsJTNEJTIybWlzdHJhbGFpJTJGTWlzdHJhbC03Qi1JbnN0cnVjdC12MC4xJTIyJTJDJTIwZHR5cGUlM0R0b3JjaC5iZmxvYXQxNiUyQyUyMGRldmljZV9tYXAlM0QlMjJhdXRvJTIyKSUwQSUwQW1lc3NhZ2VzJTIwJTNEJTIwJTVCJTBBJTIwJTIwJTIwJTIwJTdCJTIycm9sZSUyMiUzQSUyMCUyMnVzZXIlMjIlMkMlMjAlMjJjb250ZW50JTIyJTNBJTIwJTIyVGV4dCUzQSUyMFRoZSUyMGZpcnN0JTIwaHVtYW4lMjB3ZW50JTIwaW50byUyMHNwYWNlJTIwYW5kJTIwb3JiaXRlZCUyMHRoZSUyMEVhcnRoJTIwb24lMjBBcHJpbCUyMDEyJTJDJTIwMTk2MS4lMjIlN0QlMkMlMEElMjAlMjAlMjAlMjAlN0IlMjJyb2xlJTIyJTNBJTIwJTIyYXNzaXN0YW50JTIyJTJDJTIwJTIyY29udGVudCUyMiUzQSUyMCUyMkRhdGUlM0ElMjAwNCUyRjEyJTJGMTk2MSUyMiU3RCUyQyUwQSUyMCUyMCUyMCUyMCU3QiUyMnJvbGUlMjIlM0ElMjAlMjJ1c2VyJTIyJTJDJTIwJTIyY29udGVudCUyMiUzQSUyMCUyMlRleHQlM0ElMjBUaGUlMjBmaXJzdC1ldmVyJTIwdGVsZXZpc2VkJTIwcHJlc2lkZW50aWFsJTIwZGViYXRlJTIwaW4lMjB0aGUlMjBVbml0ZWQlMjBTdGF0ZXMlMjB0b29rJTIwcGxhY2UlMjBvbiUyMFNlcHRlbWJlciUyMDI4JTJDJTIwMTk2MCUyQyUyMGJldHdlZW4lMjBwcmVzaWRlbnRpYWwlMjBjYW5kaWRhdGVzJTIwSm9obiUyMEYuJTIwS2VubmVkeSUyMGFuZCUyMFJpY2hhcmQlMjBOaXhvbi4lMjIlN0QlMEElNUQlMEElMEFwcm9tcHQlMjAlM0QlMjBwaXBlbGluZS50b2tlbml6ZXIuYXBwbHlfY2hhdF90ZW1wbGF0ZShtZXNzYWdlcyUyQyUyMHRva2VuaXplJTNERmFsc2UlMkMlMjBhZGRfZ2VuZXJhdGlvbl9wcm9tcHQlM0RUcnVlKSUwQSUwQW91dHB1dHMlMjAlM0QlMjBwaXBlbGluZShwcm9tcHQlMkMlMjBtYXhfbmV3X3Rva2VucyUzRDEyJTJDJTIwZG9fc2FtcGxlJTNEVHJ1ZSUyQyUyMHRvcF9rJTNEMTApJTBBJTBBZm9yJTIwb3V0cHV0JTIwaW4lMjBvdXRwdXRzJTNBJTBBJTIwJTIwJTIwJTIwcHJpbnQoZiUyMlJlc3VsdCUzQSUyMCU3Qm91dHB1dCU1QidnZW5lcmF0ZWRfdGV4dCclNUQlN0QlMjIp",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline
<span class="hljs-keyword">import</span> torch

pipeline = pipeline(model=<span class="hljs-string">&quot;mistralai/Mistral-7B-Instruct-v0.1&quot;</span>, dtype=torch.bfloat16, device_map=<span class="hljs-string">&quot;auto&quot;</span>)

messages = [
    {<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;Text: The first human went into space and orbited the Earth on April 12, 1961.&quot;</span>},
    {<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;assistant&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;Date: 04/12/1961&quot;</span>},
    {<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;Text: The first-ever televised presidential debate in the United States took place on September 28, 1960, between presidential candidates John F. Kennedy and Richard Nixon.&quot;</span>}
]

prompt = pipeline.tokenizer.apply_chat_template(messages, tokenize=<span class="hljs-literal">False</span>, add_generation_prompt=<span class="hljs-literal">True</span>)

outputs = pipeline(prompt, max_new_tokens=<span class="hljs-number">12</span>, do_sample=<span class="hljs-literal">True</span>, top_k=<span class="hljs-number">10</span>)

<span class="hljs-keyword">for</span> output <span class="hljs-keyword">in</span> outputs:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Result: <span class="hljs-subst">{output[<span class="hljs-string">&#x27;generated_text&#x27;</span>]}</span>&quot;</span>)`,wrap:!1}}),tt=new mt({props:{title:"Chain-of-thought",local:"chain-of-thought",headingTag:"h3"}}),st=new x({props:{code:"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",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline
<span class="hljs-keyword">import</span> torch

pipeline = pipeline(model=<span class="hljs-string">&quot;mistralai/Mistral-7B-Instruct-v0.1&quot;</span>, dtype=torch.bfloat16, device_map=<span class="hljs-string">&quot;auto&quot;</span>)
prompt = <span class="hljs-string">&quot;&quot;&quot;Let&#x27;s go through this step-by-step:
1. You start with 15 muffins.
2. You eat 2 muffins, leaving you with 13 muffins.
3. You give 5 muffins to your neighbor, leaving you with 8 muffins.
4. Your partner buys 6 more muffins, bringing the total number of muffins to 14.
5. Your partner eats 2 muffins, leaving you with 12 muffins.
If you eat 6 muffins, how many are left?&quot;&quot;&quot;</span>

outputs = pipeline(prompt, max_new_tokens=<span class="hljs-number">20</span>, do_sample=<span class="hljs-literal">True</span>, top_k=<span class="hljs-number">10</span>)
<span class="hljs-keyword">for</span> output <span class="hljs-keyword">in</span> outputs:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Result: <span class="hljs-subst">{output[<span class="hljs-string">&#x27;generated_text&#x27;</span>]}</span>&quot;</span>)
Result: Let<span class="hljs-string">&#x27;s go through this step-by-step:
1. You start with 15 muffins.
2. You eat 2 muffins, leaving you with 13 muffins.
3. You give 5 muffins to your neighbor, leaving you with 8 muffins.
4. Your partner buys 6 more muffins, bringing the total number of muffins to 14.
5. Your partner eats 2 muffins, leaving you with 12 muffins.
If you eat 6 muffins, how many are left?
Answer: 6</span>`,wrap:!1}}),at=new mt({props:{title:"Fine-tuning",local:"fine-tuning",headingTag:"h2"}}),Mt=new mt({props:{title:"Examples",local:"examples",headingTag:"h2"}}),R=new al({props:{id:"tasks",options:["named entity recognition","translation","summarization","question answering"],$$slots:{default:[yl]},$$scope:{ctx:B}}}),ut=new nl({props:{source:"https://github.com/huggingface/transformers/blob/main/docs/source/en/tasks/prompting.md"}}),{c(){a=r("meta"),u=o(),n=r("p"),f=o(),h(G.$$.fragment),g=o(),h(Z.$$.fragment),W=o(),p=r("p"),p.innerHTML=j,k=o(),I=r("p"),I.textContent=Zt,X=o(),h(H.$$.fragment),gt=o(),Q=r("p"),Q.textContent=Te,Wt=o(),$=r("p"),$.textContent=be,vt=o(),h(Y.$$.fragment),Ct=o(),m=r("ol"),v=r("li"),ct=r("p"),ct.innerHTML=fe,re=o(),dt=r("p"),dt.textContent=je,Me=o(),h(V.$$.fragment),ye=o(),ht=r("li"),ht.innerHTML=Ge,ue=o(),Jt=r("li"),Jt.innerHTML=Ze,me=o(),wt=r("li"),wt.innerHTML=Be,ce=o(),Ut=r("li"),Ut.innerHTML=Ie,de=o(),Tt=r("li"),Tt.innerHTML=ge,he=o(),bt=r("li"),bt.innerHTML=We,Je=o(),ft=r("li"),ft.innerHTML=ve,we=o(),jt=r("li"),jt.innerHTML=Ce,Ue=o(),Gt=r("li"),Gt.innerHTML=Ve,Vt=o(),h(z.$$.fragment),Rt=o(),F=r("p"),F.textContent=Re,xt=o(),N=r("p"),N.textContent=xe,kt=o(),h(S.$$.fragment),Xt=o(),E=r("p"),E.textContent=ke,Ht=o(),h(_.$$.fragment),Qt=o(),q=r("p"),q.textContent=Xe,$t=o(),L=r("p"),L.innerHTML=He,Yt=o(),D=r("p"),D.innerHTML=Qe,zt=o(),h(A.$$.fragment),Ft=o(),P=r("p"),P.textContent=$e,Nt=o(),K=r("ul"),K.innerHTML=Ye,St=o(),O=r("p"),O.textContent=ze,Et=o(),h(tt.$$.fragment),_t=o(),et=r("p"),et.textContent=Fe,qt=o(),lt=r("p"),lt.textContent=Ne,Lt=o(),h(st.$$.fragment),Dt=o(),nt=r("p"),nt.innerHTML=Se,At=o(),h(at.$$.fragment),Pt=o(),ot=r("p"),ot.textContent=Ee,Kt=o(),it=r("p"),it.textContent=_e,Ot=o(),pt=r("ul"),pt.innerHTML=qe,te=o(),rt=r("p"),rt.textContent=Le,ee=o(),h(Mt.$$.fragment),le=o(),yt=r("p"),yt.textContent=De,se=o(),h(R.$$.fragment),ne=o(),h(ut.$$.fragment),ae=o(),Bt=r("p"),this.h()},l(t){const e=el("svelte-u9bgzb",document.head);a=M(e,"META",{name:!0,content:!0}),e.forEach(l),u=i(t),n=M(t,"P",{}),ie(n).forEach(l),f=i(t),J(G.$$.fragment,t),g=i(t),J(Z.$$.fragment,t),W=i(t),p=M(t,"P",{"data-svelte-h":!0}),y(p)!=="svelte-1l36ky5"&&(p.innerHTML=j),k=i(t),I=M(t,"P",{"data-svelte-h":!0}),y(I)!=="svelte-ifrhpa"&&(I.textContent=Zt),X=i(t),J(H.$$.fragment,t),gt=i(t),Q=M(t,"P",{"data-svelte-h":!0}),y(Q)!=="svelte-1t9p3a6"&&(Q.textContent=Te),Wt=i(t),$=M(t,"P",{"data-svelte-h":!0}),y($)!=="svelte-13k67mk"&&($.textContent=be),vt=i(t),J(Y.$$.fragment,t),Ct=i(t),m=M(t,"OL",{});var d=ie(m);v=M(d,"LI",{});var C=ie(v);ct=M(C,"P",{"data-svelte-h":!0}),y(ct)!=="svelte-1pczpvf"&&(ct.innerHTML=fe),re=i(C),dt=M(C,"P",{"data-svelte-h":!0}),y(dt)!=="svelte-a4upz5"&&(dt.textContent=je),Me=i(C),J(V.$$.fragment,C),C.forEach(l),ye=i(d),ht=M(d,"LI",{"data-svelte-h":!0}),y(ht)!=="svelte-1xff5jr"&&(ht.innerHTML=Ge),ue=i(d),Jt=M(d,"LI",{"data-svelte-h":!0}),y(Jt)!=="svelte-gucgrn"&&(Jt.innerHTML=Ze),me=i(d),wt=M(d,"LI",{"data-svelte-h":!0}),y(wt)!=="svelte-7d64y8"&&(wt.innerHTML=Be),ce=i(d),Ut=M(d,"LI",{"data-svelte-h":!0}),y(Ut)!=="svelte-ta4x2u"&&(Ut.innerHTML=Ie),de=i(d),Tt=M(d,"LI",{"data-svelte-h":!0}),y(Tt)!=="svelte-1dba72e"&&(Tt.innerHTML=ge),he=i(d),bt=M(d,"LI",{"data-svelte-h":!0}),y(bt)!=="svelte-1ff859w"&&(bt.innerHTML=We),Je=i(d),ft=M(d,"LI",{"data-svelte-h":!0}),y(ft)!=="svelte-cf4264"&&(ft.innerHTML=ve),we=i(d),jt=M(d,"LI",{"data-svelte-h":!0}),y(jt)!=="svelte-3la2zv"&&(jt.innerHTML=Ce),Ue=i(d),Gt=M(d,"LI",{"data-svelte-h":!0}),y(Gt)!=="svelte-4t3fow"&&(Gt.innerHTML=Ve),d.forEach(l),Vt=i(t),J(z.$$.fragment,t),Rt=i(t),F=M(t,"P",{"data-svelte-h":!0}),y(F)!=="svelte-m5bobg"&&(F.textContent=Re),xt=i(t),N=M(t,"P",{"data-svelte-h":!0}),y(N)!=="svelte-xs9n05"&&(N.textContent=xe),kt=i(t),J(S.$$.fragment,t),Xt=i(t),E=M(t,"P",{"data-svelte-h":!0}),y(E)!=="svelte-1osuclx"&&(E.textContent=ke),Ht=i(t),J(_.$$.fragment,t),Qt=i(t),q=M(t,"P",{"data-svelte-h":!0}),y(q)!=="svelte-15zvrzz"&&(q.textContent=Xe),$t=i(t),L=M(t,"P",{"data-svelte-h":!0}),y(L)!=="svelte-cmca93"&&(L.innerHTML=He),Yt=i(t),D=M(t,"P",{"data-svelte-h":!0}),y(D)!=="svelte-18odvrx"&&(D.innerHTML=Qe),zt=i(t),J(A.$$.fragment,t),Ft=i(t),P=M(t,"P",{"data-svelte-h":!0}),y(P)!=="svelte-3kt6r9"&&(P.textContent=$e),Nt=i(t),K=M(t,"UL",{"data-svelte-h":!0}),y(K)!=="svelte-mtzqrn"&&(K.innerHTML=Ye),St=i(t),O=M(t,"P",{"data-svelte-h":!0}),y(O)!=="svelte-11gqod1"&&(O.textContent=ze),Et=i(t),J(tt.$$.fragment,t),_t=i(t),et=M(t,"P",{"data-svelte-h":!0}),y(et)!=="svelte-1va4f85"&&(et.textContent=Fe),qt=i(t),lt=M(t,"P",{"data-svelte-h":!0}),y(lt)!=="svelte-1314x5c"&&(lt.textContent=Ne),Lt=i(t),J(st.$$.fragment,t),Dt=i(t),nt=M(t,"P",{"data-svelte-h":!0}),y(nt)!=="svelte-1oqty7r"&&(nt.innerHTML=Se),At=i(t),J(at.$$.fragment,t),Pt=i(t),ot=M(t,"P",{"data-svelte-h":!0}),y(ot)!=="svelte-164c0yp"&&(ot.textContent=Ee),Kt=i(t),it=M(t,"P",{"data-svelte-h":!0}),y(it)!=="svelte-1vq8s8p"&&(it.textContent=_e),Ot=i(t),pt=M(t,"UL",{"data-svelte-h":!0}),y(pt)!=="svelte-16pui82"&&(pt.innerHTML=qe),te=i(t),rt=M(t,"P",{"data-svelte-h":!0}),y(rt)!=="svelte-1ms6wkd"&&(rt.textContent=Le),ee=i(t),J(Mt.$$.fragment,t),le=i(t),yt=M(t,"P",{"data-svelte-h":!0}),y(yt)!=="svelte-jdpxp7"&&(yt.textContent=De),se=i(t),J(R.$$.fragment,t),ne=i(t),J(ut.$$.fragment,t),ae=i(t),Bt=M(t,"P",{}),ie(Bt).forEach(l),this.h()},h(){Ae(a,"name","hf:doc:metadata"),Ae(a,"content",ml)},m(t,e){c(document.head,a),s(t,u,e),s(t,n,e),s(t,f,e),w(G,t,e),s(t,g,e),w(Z,t,e),s(t,W,e),s(t,p,e),s(t,k,e),s(t,I,e),s(t,X,e),w(H,t,e),s(t,gt,e),s(t,Q,e),s(t,Wt,e),s(t,$,e),s(t,vt,e),w(Y,t,e),s(t,Ct,e),s(t,m,e),c(m,v),c(v,ct),c(v,re),c(v,dt),c(v,Me),w(V,v,null),c(m,ye),c(m,ht),c(m,ue),c(m,Jt),c(m,me),c(m,wt),c(m,ce),c(m,Ut),c(m,de),c(m,Tt),c(m,he),c(m,bt),c(m,Je),c(m,ft),c(m,we),c(m,jt),c(m,Ue),c(m,Gt),s(t,Vt,e),w(z,t,e),s(t,Rt,e),s(t,F,e),s(t,xt,e),s(t,N,e),s(t,kt,e),w(S,t,e),s(t,Xt,e),s(t,E,e),s(t,Ht,e),w(_,t,e),s(t,Qt,e),s(t,q,e),s(t,$t,e),s(t,L,e),s(t,Yt,e),s(t,D,e),s(t,zt,e),w(A,t,e),s(t,Ft,e),s(t,P,e),s(t,Nt,e),s(t,K,e),s(t,St,e),s(t,O,e),s(t,Et,e),w(tt,t,e),s(t,_t,e),s(t,et,e),s(t,qt,e),s(t,lt,e),s(t,Lt,e),w(st,t,e),s(t,Dt,e),s(t,nt,e),s(t,At,e),w(at,t,e),s(t,Pt,e),s(t,ot,e),s(t,Kt,e),s(t,it,e),s(t,Ot,e),s(t,pt,e),s(t,te,e),s(t,rt,e),s(t,ee,e),w(Mt,t,e),s(t,le,e),s(t,yt,e),s(t,se,e),w(R,t,e),s(t,ne,e),w(ut,t,e),s(t,ae,e),s(t,Bt,e),oe=!0},p(t,[e]){const d={};e&2&&(d.$$scope={dirty:e,ctx:t}),V.$set(d);const C={};e&2&&(C.$$scope={dirty:e,ctx:t}),R.$set(C)},i(t){oe||(U(G.$$.fragment,t),U(Z.$$.fragment,t),U(H.$$.fragment,t),U(Y.$$.fragment,t),U(V.$$.fragment,t),U(z.$$.fragment,t),U(S.$$.fragment,t),U(_.$$.fragment,t),U(A.$$.fragment,t),U(tt.$$.fragment,t),U(st.$$.fragment,t),U(at.$$.fragment,t),U(Mt.$$.fragment,t),U(R.$$.fragment,t),U(ut.$$.fragment,t),oe=!0)},o(t){T(G.$$.fragment,t),T(Z.$$.fragment,t),T(H.$$.fragment,t),T(Y.$$.fragment,t),T(V.$$.fragment,t),T(z.$$.fragment,t),T(S.$$.fragment,t),T(_.$$.fragment,t),T(A.$$.fragment,t),T(tt.$$.fragment,t),T(st.$$.fragment,t),T(at.$$.fragment,t),T(Mt.$$.fragment,t),T(R.$$.fragment,t),T(ut.$$.fragment,t),oe=!1},d(t){t&&(l(u),l(n),l(f),l(g),l(W),l(p),l(k),l(I),l(X),l(gt),l(Q),l(Wt),l($),l(vt),l(Ct),l(m),l(Vt),l(Rt),l(F),l(xt),l(N),l(kt),l(Xt),l(E),l(Ht),l(Qt),l(q),l($t),l(L),l(Yt),l(D),l(zt),l(Ft),l(P),l(Nt),l(K),l(St),l(O),l(Et),l(_t),l(et),l(qt),l(lt),l(Lt),l(Dt),l(nt),l(At),l(Pt),l(ot),l(Kt),l(it),l(Ot),l(pt),l(te),l(rt),l(ee),l(le),l(yt),l(se),l(ne),l(ae),l(Bt)),l(a),b(G,t),b(Z,t),b(H,t),b(Y,t),b(V),b(z,t),b(S,t),b(_,t),b(A,t),b(tt,t),b(st,t),b(at,t),b(Mt,t),b(R,t),b(ut,t)}}}const ml='{"title":"Prompt engineering","local":"prompt-engineering","sections":[{"title":"Best practices","local":"best-practices","sections":[],"depth":2},{"title":"Techniques","local":"techniques","sections":[{"title":"Few-shot prompting","local":"few-shot-prompting","sections":[],"depth":3},{"title":"Chain-of-thought","local":"chain-of-thought","sections":[],"depth":3}],"depth":2},{"title":"Fine-tuning","local":"fine-tuning","sections":[],"depth":2},{"title":"Examples","local":"examples","sections":[],"depth":2}],"depth":1}';function cl(B){return Ke(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class fl extends Oe{constructor(a){super(),tl(this,a,cl,ul,Pe,{})}}export{fl as component};
