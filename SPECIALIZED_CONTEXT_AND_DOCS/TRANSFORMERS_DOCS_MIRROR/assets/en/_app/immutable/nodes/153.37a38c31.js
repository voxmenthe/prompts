import{s as me,o as pe,n as fe}from"../chunks/scheduler.18a86fab.js";import{S as ue,i as de,g as s,s as l,r as L,A as ge,h as r,f as n,c as o,j as re,x as p,u as H,k as X,y as ce,a,v as y,d as D,t as k,w as E}from"../chunks/index.98837b22.js";import{T as he}from"../chunks/Tip.77304350.js";import{H as Z,E as Te}from"../chunks/getInferenceSnippets.06c2775f.js";function ve(S){let i,d='DialoGPT’s architecture is based on the GPT2 model, refer to <a href="gpt2">GPT2’s documentation page</a> for API reference and examples.';return{c(){i=s("p"),i.innerHTML=d},l(m){i=r(m,"P",{"data-svelte-h":!0}),p(i)!=="svelte-c7ppar"&&(i.innerHTML=d)},m(m,M){a(m,i,M)},p:fe,d(m){m&&n(i)}}}function $e(S){let i,d,m,M,g,K="<em>This model was released on 2019-11-01 and added to Hugging Face Transformers on 2020-11-16.</em>",I,c,j,f,Q='<img alt="PyTorch" src="https://img.shields.io/badge/PyTorch-DE3412?style=flat&amp;logo=pytorch&amp;logoColor=white"/>',q,h,z,T,ee=`DialoGPT was proposed in <a href="https://huggingface.co/papers/1911.00536" rel="nofollow">DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation</a> by Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao,
Jianfeng Gao, Jingjing Liu, Bill Dolan. It’s a GPT2 Model trained on 147M conversation-like exchanges extracted from
Reddit.`,A,v,te="The abstract from the paper is the following:",O,$,ne=`<em>We present a large, tunable neural conversational response generation model, DialoGPT (dialogue generative pre-trained
transformer). Trained on 147M conversation-like exchanges extracted from Reddit comment chains over a period spanning
from 2005 through 2017, DialoGPT extends the Hugging Face PyTorch transformer to attain a performance close to human
both in terms of automatic and human evaluation in single-turn dialogue settings. We show that conversational systems
that leverage DialoGPT generate more relevant, contentful and context-consistent responses than strong baseline
systems. The pre-trained model and training pipeline are publicly released to facilitate research into neural response
generation and the development of more intelligent open-domain dialogue systems.</em>`,R,P,ae='The original code can be found <a href="https://github.com/microsoft/DialoGPT" rel="nofollow">here</a>.',U,x,W,_,ie=`<li>DialoGPT is a model with absolute position embeddings so it’s usually advised to pad the inputs on the right rather
than the left.</li> <li>DialoGPT was trained with a causal language modeling (CLM) objective on conversational data and is therefore powerful
at response generation in open-domain dialogue systems.</li> <li>DialoGPT enables the user to create a chat bot in just 10 lines of code as shown on <a href="https://huggingface.co/microsoft/DialoGPT-medium" rel="nofollow">DialoGPT’s model card</a>.</li>`,F,w,le="Training:",B,b,oe=`In order to train or fine-tune DialoGPT, one can use causal language modeling training. To cite the official paper: <em>We
follow the OpenAI GPT-2 to model a multiturn dialogue session as a long text and frame the generation task as language
modeling. We first concatenate all dialog turns within a dialogue session into a long text x_1,…, x_N (N is the
sequence length), ended by the end-of-text token.</em> For more information please confer to the original paper.`,J,u,N,G,Y,C,V;return c=new Z({props:{title:"DialoGPT",local:"dialogpt",headingTag:"h1"}}),h=new Z({props:{title:"Overview",local:"overview",headingTag:"h2"}}),x=new Z({props:{title:"Usage tips",local:"usage-tips",headingTag:"h2"}}),u=new he({props:{$$slots:{default:[ve]},$$scope:{ctx:S}}}),G=new Te({props:{source:"https://github.com/huggingface/transformers/blob/main/docs/source/en/model_doc/dialogpt.md"}}),{c(){i=s("meta"),d=l(),m=s("p"),M=l(),g=s("p"),g.innerHTML=K,I=l(),L(c.$$.fragment),j=l(),f=s("div"),f.innerHTML=Q,q=l(),L(h.$$.fragment),z=l(),T=s("p"),T.innerHTML=ee,A=l(),v=s("p"),v.textContent=te,O=l(),$=s("p"),$.innerHTML=ne,R=l(),P=s("p"),P.innerHTML=ae,U=l(),L(x.$$.fragment),W=l(),_=s("ul"),_.innerHTML=ie,F=l(),w=s("p"),w.textContent=le,B=l(),b=s("p"),b.innerHTML=oe,J=l(),L(u.$$.fragment),N=l(),L(G.$$.fragment),Y=l(),C=s("p"),this.h()},l(e){const t=ge("svelte-u9bgzb",document.head);i=r(t,"META",{name:!0,content:!0}),t.forEach(n),d=o(e),m=r(e,"P",{}),re(m).forEach(n),M=o(e),g=r(e,"P",{"data-svelte-h":!0}),p(g)!=="svelte-1b1bnzs"&&(g.innerHTML=K),I=o(e),H(c.$$.fragment,e),j=o(e),f=r(e,"DIV",{class:!0,"data-svelte-h":!0}),p(f)!=="svelte-13t8s2t"&&(f.innerHTML=Q),q=o(e),H(h.$$.fragment,e),z=o(e),T=r(e,"P",{"data-svelte-h":!0}),p(T)!=="svelte-1q5d397"&&(T.innerHTML=ee),A=o(e),v=r(e,"P",{"data-svelte-h":!0}),p(v)!=="svelte-vfdo9a"&&(v.textContent=te),O=o(e),$=r(e,"P",{"data-svelte-h":!0}),p($)!=="svelte-7bhez3"&&($.innerHTML=ne),R=o(e),P=r(e,"P",{"data-svelte-h":!0}),p(P)!=="svelte-17b2666"&&(P.innerHTML=ae),U=o(e),H(x.$$.fragment,e),W=o(e),_=r(e,"UL",{"data-svelte-h":!0}),p(_)!=="svelte-1kdkvca"&&(_.innerHTML=ie),F=o(e),w=r(e,"P",{"data-svelte-h":!0}),p(w)!=="svelte-1igpel8"&&(w.textContent=le),B=o(e),b=r(e,"P",{"data-svelte-h":!0}),p(b)!=="svelte-1yc28b0"&&(b.innerHTML=oe),J=o(e),H(u.$$.fragment,e),N=o(e),H(G.$$.fragment,e),Y=o(e),C=r(e,"P",{}),re(C).forEach(n),this.h()},h(){X(i,"name","hf:doc:metadata"),X(i,"content",Pe),X(f,"class","flex flex-wrap space-x-1")},m(e,t){ce(document.head,i),a(e,d,t),a(e,m,t),a(e,M,t),a(e,g,t),a(e,I,t),y(c,e,t),a(e,j,t),a(e,f,t),a(e,q,t),y(h,e,t),a(e,z,t),a(e,T,t),a(e,A,t),a(e,v,t),a(e,O,t),a(e,$,t),a(e,R,t),a(e,P,t),a(e,U,t),y(x,e,t),a(e,W,t),a(e,_,t),a(e,F,t),a(e,w,t),a(e,B,t),a(e,b,t),a(e,J,t),y(u,e,t),a(e,N,t),y(G,e,t),a(e,Y,t),a(e,C,t),V=!0},p(e,[t]){const se={};t&2&&(se.$$scope={dirty:t,ctx:e}),u.$set(se)},i(e){V||(D(c.$$.fragment,e),D(h.$$.fragment,e),D(x.$$.fragment,e),D(u.$$.fragment,e),D(G.$$.fragment,e),V=!0)},o(e){k(c.$$.fragment,e),k(h.$$.fragment,e),k(x.$$.fragment,e),k(u.$$.fragment,e),k(G.$$.fragment,e),V=!1},d(e){e&&(n(d),n(m),n(M),n(g),n(I),n(j),n(f),n(q),n(z),n(T),n(A),n(v),n(O),n($),n(R),n(P),n(U),n(W),n(_),n(F),n(w),n(B),n(b),n(J),n(N),n(Y),n(C)),n(i),E(c,e),E(h,e),E(x,e),E(u,e),E(G,e)}}}const Pe='{"title":"DialoGPT","local":"dialogpt","sections":[{"title":"Overview","local":"overview","sections":[],"depth":2},{"title":"Usage tips","local":"usage-tips","sections":[],"depth":2}],"depth":1}';function xe(S){return pe(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Me extends ue{constructor(i){super(),de(this,i,xe,$e,me,{})}}export{Me as component};
