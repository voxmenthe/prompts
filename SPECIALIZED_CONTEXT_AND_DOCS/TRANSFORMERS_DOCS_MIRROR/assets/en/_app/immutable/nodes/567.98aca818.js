import{s as Ta,o as ya,n as $}from"../chunks/scheduler.18a86fab.js";import{S as wa,i as Ja,g as y,s as p,r as M,A as ga,h as w,f as l,c as o,j as ha,u as f,x as J,k as ua,y as ja,a as n,v as d,d as h,t as u,w as T}from"../chunks/index.98837b22.js";import{T as De}from"../chunks/Tip.77304350.js";import{C as U}from"../chunks/CodeBlock.8d0c2e8a.js";import{H as I,E as _a}from"../chunks/getInferenceSnippets.06c2775f.js";import{H as Jt,a as B}from"../chunks/HfOption.6641485e.js";function ba(g){let t,r='The number of available parameters available in <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> may be intimidating at first. If there is a specific hyperparameter or feature you want to use, try searching for it directly. Otherwise, feel free to start with the default values and gradually customize them as you become more familiar with the training process.';return{c(){t=y("p"),t.innerHTML=r},l(a){t=w(a,"P",{"data-svelte-h":!0}),J(t)!=="svelte-16bhyp6"&&(t.innerHTML=r)},m(a,c){n(a,t,c)},p:$,d(a){a&&l(t)}}}function Ua(g){let t,r='Refer to the <a href="./training">Fine-tuning</a> guide for a more complete overview of the training process.';return{c(){t=y("p"),t.innerHTML=r},l(a){t=w(a,"P",{"data-svelte-h":!0}),J(t)!=="svelte-imgvnc"&&(t.innerHTML=r)},m(a,c){n(a,t,c)},p:$,d(a){a&&l(t)}}}function $a(g){let t,r;return t=new U({props:{code:"dHJhaW5lci50cmFpbihyZXN1bWVfZnJvbV9jaGVja3BvaW50JTNEVHJ1ZSk=",highlighted:'trainer.train(resume_from_checkpoint=<span class="hljs-literal">True</span>)',wrap:!1}}),{c(){M(t.$$.fragment)},l(a){f(t.$$.fragment,a)},m(a,c){d(t,a,c),r=!0},p:$,i(a){r||(h(t.$$.fragment,a),r=!0)},o(a){u(t.$$.fragment,a),r=!1},d(a){T(t,a)}}}function Za(g){let t,r;return t=new U({props:{code:"dHJhaW5lci50cmFpbihyZXN1bWVfZnJvbV9jaGVja3BvaW50JTNEJTIyeW91ci1tb2RlbCUyRmNoZWNrcG9pbnQtMTAwMCUyMik=",highlighted:'trainer.train(resume_from_checkpoint=<span class="hljs-string">&quot;your-model/checkpoint-1000&quot;</span>)',wrap:!1}}),{c(){M(t.$$.fragment)},l(a){f(t.$$.fragment,a)},m(a,c){d(t,a,c),r=!0},p:$,i(a){r||(h(t.$$.fragment,a),r=!0)},o(a){u(t.$$.fragment,a),r=!1},d(a){T(t,a)}}}function Ia(g){let t,r,a,c;return t=new B({props:{id:"ckpt",option:"latest checkpoint",$$slots:{default:[$a]},$$scope:{ctx:g}}}),a=new B({props:{id:"ckpt",option:"specific checkpoint",$$slots:{default:[Za]},$$scope:{ctx:g}}}),{c(){M(t.$$.fragment),r=p(),M(a.$$.fragment)},l(i){f(t.$$.fragment,i),r=o(i),f(a.$$.fragment,i)},m(i,m){d(t,i,m),n(i,r,m),d(a,i,m),c=!0},p(i,m){const _={};m&2&&(_.$$scope={dirty:m,ctx:i}),t.$set(_);const Z={};m&2&&(Z.$$scope={dirty:m,ctx:i}),a.$set(Z)},i(i){c||(h(t.$$.fragment,i),h(a.$$.fragment,i),c=!0)},o(i){u(t.$$.fragment,i),u(a.$$.fragment,i),c=!1},d(i){i&&l(r),T(t,i),T(a,i)}}}function va(g){let t,r;return t=new U({props:{code:"bXlfYXBwLnB5JTIwLi4uJTIwLS1sb2dfbGV2ZWwlMjB3YXJuaW5nJTIwLS1sb2dfbGV2ZWxfcmVwbGljYSUyMGVycm9y",highlighted:"my_app.py ... --log_level warning --log_level_replica error",wrap:!1}}),{c(){M(t.$$.fragment)},l(a){f(t.$$.fragment,a)},m(a,c){d(t,a,c),r=!0},p:$,i(a){r||(h(t.$$.fragment,a),r=!0)},o(a){u(t.$$.fragment,a),r=!1},d(a){T(t,a)}}}function Ba(g){let t,r="Add <code>log_on_each_node 0</code> for distributed environments.",a,c,i;return c=new U({props:{code:"bXlfYXBwLnB5JTIwLi4uJTIwLS1sb2dfbGV2ZWwlMjB3YXJuaW5nJTIwLS1sb2dfbGV2ZWxfcmVwbGljYSUyMGVycm9yJTIwLS1sb2dfb25fZWFjaF9ub2RlJTIwMCUwQSUwQSUyMyUyMHNldCUyMHRvJTIwb25seSUyMHJlcG9ydCUyMGVycm9ycyUwQW15X2FwcC5weSUyMC4uLiUyMC0tbG9nX2xldmVsJTIwZXJyb3IlMjAtLWxvZ19sZXZlbF9yZXBsaWNhJTIwZXJyb3IlMjAtLWxvZ19vbl9lYWNoX25vZGUlMjAw",highlighted:`my_app.py ... --log_level warning --log_level_replica error --log_on_each_node 0

<span class="hljs-comment"># set to only report errors</span>
my_app.py ... --log_level error --log_level_replica error --log_on_each_node 0`,wrap:!1}}),{c(){t=y("p"),t.innerHTML=r,a=p(),M(c.$$.fragment)},l(m){t=w(m,"P",{"data-svelte-h":!0}),J(t)!=="svelte-ggsz75"&&(t.innerHTML=r),a=o(m),f(c.$$.fragment,m)},m(m,_){n(m,t,_),n(m,a,_),d(c,m,_),i=!0},p:$,i(m){i||(h(c.$$.fragment,m),i=!0)},o(m){u(c.$$.fragment,m),i=!1},d(m){m&&(l(t),l(a)),T(c,m)}}}function Ca(g){let t,r,a,c;return t=new B({props:{id:"nodes",option:"single node",$$slots:{default:[va]},$$scope:{ctx:g}}}),a=new B({props:{id:"nodes",option:"multi-node",$$slots:{default:[Ba]},$$scope:{ctx:g}}}),{c(){M(t.$$.fragment),r=p(),M(a.$$.fragment)},l(i){f(t.$$.fragment,i),r=o(i),f(a.$$.fragment,i)},m(i,m){d(t,i,m),n(i,r,m),d(a,i,m),c=!0},p(i,m){const _={};m&2&&(_.$$scope={dirty:m,ctx:i}),t.$set(_);const Z={};m&2&&(Z.$$scope={dirty:m,ctx:i}),a.$set(Z)},i(i){c||(h(t.$$.fragment,i),h(a.$$.fragment,i),c=!0)},o(i){u(t.$$.fragment,i),u(a.$$.fragment,i),c=!1},d(i){i&&l(r),T(t,i),T(a,i)}}}function Xa(g){let t,r='The log level is separately set for each node in the <code>__init__()</code> method. Consider setting this sooner if you’re using other Transformers functionalities before creating the <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> instance.';return{c(){t=y("p"),t.innerHTML=r},l(a){t=w(a,"P",{"data-svelte-h":!0}),J(t)!=="svelte-1iyyye0"&&(t.innerHTML=r)},m(a,c){n(a,t,c)},p:$,d(a){a&&l(t)}}}function ka(g){let t,r='Learn more about FSDP sharding strategies, CPU offloading, and more with <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> in the <a href="./fsdp">Fully Sharded Data Parallel</a> guide.';return{c(){t=y("p"),t.innerHTML=r},l(a){t=w(a,"P",{"data-svelte-h":!0}),J(t)!=="svelte-1yognfy"&&(t.innerHTML=r)},m(a,c){n(a,t,c)},p:$,d(a){a&&l(t)}}}function Wa(g){let t,r;return t=new U({props:{code:"Y29tcHV0ZV9lbnZpcm9ubWVudCUzQSUyMExPQ0FMX01BQ0hJTkUlMEFkaXN0cmlidXRlZF90eXBlJTNBJTIwTVVMVElfR1BVJTBBZG93bmNhc3RfYmYxNiUzQSUyMCdubyclMEFncHVfaWRzJTNBJTIwYWxsJTBBbWFjaGluZV9yYW5rJTNBJTIwMCUyMCUyM2NoYW5nZSUyMHJhbmslMjBhcyUyMHBlciUyMHRoZSUyMG5vZGUlMEFtYWluX3Byb2Nlc3NfaXAlM0ElMjAxOTIuMTY4LjIwLjElMEFtYWluX3Byb2Nlc3NfcG9ydCUzQSUyMDk4OTglMEFtYWluX3RyYWluaW5nX2Z1bmN0aW9uJTNBJTIwbWFpbiUwQW1peGVkX3ByZWNpc2lvbiUzQSUyMGZwMTYlMEFudW1fbWFjaGluZXMlM0ElMjAyJTBBbnVtX3Byb2Nlc3NlcyUzQSUyMDglMEFyZHp2X2JhY2tlbmQlM0ElMjBzdGF0aWMlMEFzYW1lX25ldHdvcmslM0ElMjB0cnVlJTBBdHB1X2VudiUzQSUyMCU1QiU1RCUwQXRwdV91c2VfY2x1c3RlciUzQSUyMGZhbHNlJTBBdHB1X3VzZV9zdWRvJTNBJTIwZmFsc2UlMEF1c2VfY3B1JTNBJTIwZmFsc2U=",highlighted:`<span class="hljs-attr">compute_environment:</span> <span class="hljs-string">LOCAL_MACHINE</span>
<span class="hljs-attr">distributed_type:</span> <span class="hljs-string">MULTI_GPU</span>
<span class="hljs-attr">downcast_bf16:</span> <span class="hljs-string">&#x27;no&#x27;</span>
<span class="hljs-attr">gpu_ids:</span> <span class="hljs-string">all</span>
<span class="hljs-attr">machine_rank:</span> <span class="hljs-number">0</span> <span class="hljs-comment">#change rank as per the node</span>
<span class="hljs-attr">main_process_ip:</span> <span class="hljs-number">192.168</span><span class="hljs-number">.20</span><span class="hljs-number">.1</span>
<span class="hljs-attr">main_process_port:</span> <span class="hljs-number">9898</span>
<span class="hljs-attr">main_training_function:</span> <span class="hljs-string">main</span>
<span class="hljs-attr">mixed_precision:</span> <span class="hljs-string">fp16</span>
<span class="hljs-attr">num_machines:</span> <span class="hljs-number">2</span>
<span class="hljs-attr">num_processes:</span> <span class="hljs-number">8</span>
<span class="hljs-attr">rdzv_backend:</span> <span class="hljs-string">static</span>
<span class="hljs-attr">same_network:</span> <span class="hljs-literal">true</span>
<span class="hljs-attr">tpu_env:</span> []
<span class="hljs-attr">tpu_use_cluster:</span> <span class="hljs-literal">false</span>
<span class="hljs-attr">tpu_use_sudo:</span> <span class="hljs-literal">false</span>
<span class="hljs-attr">use_cpu:</span> <span class="hljs-literal">false</span>`,wrap:!1}}),{c(){M(t.$$.fragment)},l(a){f(t.$$.fragment,a)},m(a,c){d(t,a,c),r=!0},p:$,i(a){r||(h(t.$$.fragment,a),r=!0)},o(a){u(t.$$.fragment,a),r=!1},d(a){T(t,a)}}}function Aa(g){let t,r;return t=new U({props:{code:"Y29tcHV0ZV9lbnZpcm9ubWVudCUzQSUyMExPQ0FMX01BQ0hJTkUlMEFkaXN0cmlidXRlZF90eXBlJTNBJTIwRlNEUCUwQWRvd25jYXN0X2JmMTYlM0ElMjAnbm8nJTBBZnNkcF9jb25maWclM0ElMEElMjAlMjBmc2RwX2F1dG9fd3JhcF9wb2xpY3klM0ElMjBUUkFOU0ZPUk1FUl9CQVNFRF9XUkFQJTBBJTIwJTIwZnNkcF9iYWNrd2FyZF9wcmVmZXRjaF9wb2xpY3klM0ElMjBCQUNLV0FSRF9QUkUlMEElMjAlMjBmc2RwX2ZvcndhcmRfcHJlZmV0Y2glM0ElMjB0cnVlJTBBJTIwJTIwZnNkcF9vZmZsb2FkX3BhcmFtcyUzQSUyMGZhbHNlJTBBJTIwJTIwZnNkcF9zaGFyZGluZ19zdHJhdGVneSUzQSUyMDElMEElMjAlMjBmc2RwX3N0YXRlX2RpY3RfdHlwZSUzQSUyMEZVTExfU1RBVEVfRElDVCUwQSUyMCUyMGZzZHBfc3luY19tb2R1bGVfc3RhdGVzJTNBJTIwdHJ1ZSUwQSUyMCUyMGZzZHBfdHJhbnNmb3JtZXJfbGF5ZXJfY2xzX3RvX3dyYXAlM0ElMjBCZXJ0TGF5ZXIlMEElMjAlMjBmc2RwX3VzZV9vcmlnX3BhcmFtcyUzQSUyMHRydWUlMEFtYWNoaW5lX3JhbmslM0ElMjAwJTBBbWFpbl90cmFpbmluZ19mdW5jdGlvbiUzQSUyMG1haW4lMEFtaXhlZF9wcmVjaXNpb24lM0ElMjBiZjE2JTBBbnVtX21hY2hpbmVzJTNBJTIwMSUwQW51bV9wcm9jZXNzZXMlM0ElMjAyJTBBcmR6dl9iYWNrZW5kJTNBJTIwc3RhdGljJTBBc2FtZV9uZXR3b3JrJTNBJTIwdHJ1ZSUwQXRwdV9lbnYlM0ElMjAlNUIlNUQlMEF0cHVfdXNlX2NsdXN0ZXIlM0ElMjBmYWxzZSUwQXRwdV91c2Vfc3VkbyUzQSUyMGZhbHNlJTBBdXNlX2NwdSUzQSUyMGZhbHNl",highlighted:`<span class="hljs-attr">compute_environment:</span> <span class="hljs-string">LOCAL_MACHINE</span>
<span class="hljs-attr">distributed_type:</span> <span class="hljs-string">FSDP</span>
<span class="hljs-attr">downcast_bf16:</span> <span class="hljs-string">&#x27;no&#x27;</span>
<span class="hljs-attr">fsdp_config:</span>
  <span class="hljs-attr">fsdp_auto_wrap_policy:</span> <span class="hljs-string">TRANSFORMER_BASED_WRAP</span>
  <span class="hljs-attr">fsdp_backward_prefetch_policy:</span> <span class="hljs-string">BACKWARD_PRE</span>
  <span class="hljs-attr">fsdp_forward_prefetch:</span> <span class="hljs-literal">true</span>
  <span class="hljs-attr">fsdp_offload_params:</span> <span class="hljs-literal">false</span>
  <span class="hljs-attr">fsdp_sharding_strategy:</span> <span class="hljs-number">1</span>
  <span class="hljs-attr">fsdp_state_dict_type:</span> <span class="hljs-string">FULL_STATE_DICT</span>
  <span class="hljs-attr">fsdp_sync_module_states:</span> <span class="hljs-literal">true</span>
  <span class="hljs-attr">fsdp_transformer_layer_cls_to_wrap:</span> <span class="hljs-string">BertLayer</span>
  <span class="hljs-attr">fsdp_use_orig_params:</span> <span class="hljs-literal">true</span>
<span class="hljs-attr">machine_rank:</span> <span class="hljs-number">0</span>
<span class="hljs-attr">main_training_function:</span> <span class="hljs-string">main</span>
<span class="hljs-attr">mixed_precision:</span> <span class="hljs-string">bf16</span>
<span class="hljs-attr">num_machines:</span> <span class="hljs-number">1</span>
<span class="hljs-attr">num_processes:</span> <span class="hljs-number">2</span>
<span class="hljs-attr">rdzv_backend:</span> <span class="hljs-string">static</span>
<span class="hljs-attr">same_network:</span> <span class="hljs-literal">true</span>
<span class="hljs-attr">tpu_env:</span> []
<span class="hljs-attr">tpu_use_cluster:</span> <span class="hljs-literal">false</span>
<span class="hljs-attr">tpu_use_sudo:</span> <span class="hljs-literal">false</span>
<span class="hljs-attr">use_cpu:</span> <span class="hljs-literal">false</span>`,wrap:!1}}),{c(){M(t.$$.fragment)},l(a){f(t.$$.fragment,a)},m(a,c){d(t,a,c),r=!0},p:$,i(a){r||(h(t.$$.fragment,a),r=!0)},o(a){u(t.$$.fragment,a),r=!1},d(a){T(t,a)}}}function Na(g){let t,r;return t=new U({props:{code:"Y29tcHV0ZV9lbnZpcm9ubWVudCUzQSUyMExPQ0FMX01BQ0hJTkUlMEFkZWVwc3BlZWRfY29uZmlnJTNBJTBBJTIwJTIwZGVlcHNwZWVkX2NvbmZpZ19maWxlJTNBJTIwJTJGaG9tZSUyRnVzZXIlMkZjb25maWdzJTJGZHNfemVybzNfY29uZmlnLmpzb24lMEElMjAlMjB6ZXJvM19pbml0X2ZsYWclM0ElMjB0cnVlJTBBZGlzdHJpYnV0ZWRfdHlwZSUzQSUyMERFRVBTUEVFRCUwQWRvd25jYXN0X2JmMTYlM0ElMjAnbm8nJTBBbWFjaGluZV9yYW5rJTNBJTIwMCUwQW1haW5fdHJhaW5pbmdfZnVuY3Rpb24lM0ElMjBtYWluJTBBbnVtX21hY2hpbmVzJTNBJTIwMSUwQW51bV9wcm9jZXNzZXMlM0ElMjA0JTBBcmR6dl9iYWNrZW5kJTNBJTIwc3RhdGljJTBBc2FtZV9uZXR3b3JrJTNBJTIwdHJ1ZSUwQXRwdV9lbnYlM0ElMjAlNUIlNUQlMEF0cHVfdXNlX2NsdXN0ZXIlM0ElMjBmYWxzZSUwQXRwdV91c2Vfc3VkbyUzQSUyMGZhbHNlJTBBdXNlX2NwdSUzQSUyMGZhbHNl",highlighted:`<span class="hljs-attr">compute_environment:</span> <span class="hljs-string">LOCAL_MACHINE</span>
<span class="hljs-attr">deepspeed_config:</span>
  <span class="hljs-attr">deepspeed_config_file:</span> <span class="hljs-string">/home/user/configs/ds_zero3_config.json</span>
  <span class="hljs-attr">zero3_init_flag:</span> <span class="hljs-literal">true</span>
<span class="hljs-attr">distributed_type:</span> <span class="hljs-string">DEEPSPEED</span>
<span class="hljs-attr">downcast_bf16:</span> <span class="hljs-string">&#x27;no&#x27;</span>
<span class="hljs-attr">machine_rank:</span> <span class="hljs-number">0</span>
<span class="hljs-attr">main_training_function:</span> <span class="hljs-string">main</span>
<span class="hljs-attr">num_machines:</span> <span class="hljs-number">1</span>
<span class="hljs-attr">num_processes:</span> <span class="hljs-number">4</span>
<span class="hljs-attr">rdzv_backend:</span> <span class="hljs-string">static</span>
<span class="hljs-attr">same_network:</span> <span class="hljs-literal">true</span>
<span class="hljs-attr">tpu_env:</span> []
<span class="hljs-attr">tpu_use_cluster:</span> <span class="hljs-literal">false</span>
<span class="hljs-attr">tpu_use_sudo:</span> <span class="hljs-literal">false</span>
<span class="hljs-attr">use_cpu:</span> <span class="hljs-literal">false</span>`,wrap:!1}}),{c(){M(t.$$.fragment)},l(a){f(t.$$.fragment,a)},m(a,c){d(t,a,c),r=!0},p:$,i(a){r||(h(t.$$.fragment,a),r=!0)},o(a){u(t.$$.fragment,a),r=!1},d(a){T(t,a)}}}function Ra(g){let t,r;return t=new U({props:{code:"Y29tcHV0ZV9lbnZpcm9ubWVudCUzQSUyMExPQ0FMX01BQ0hJTkUlMEFkZWVwc3BlZWRfY29uZmlnJTNBJTBBJTIwJTIwZ3JhZGllbnRfYWNjdW11bGF0aW9uX3N0ZXBzJTNBJTIwMSUwQSUyMCUyMGdyYWRpZW50X2NsaXBwaW5nJTNBJTIwMC43JTBBJTIwJTIwb2ZmbG9hZF9vcHRpbWl6ZXJfZGV2aWNlJTNBJTIwY3B1JTBBJTIwJTIwb2ZmbG9hZF9wYXJhbV9kZXZpY2UlM0ElMjBjcHUlMEElMjAlMjB6ZXJvM19pbml0X2ZsYWclM0ElMjB0cnVlJTBBJTIwJTIwemVyb19zdGFnZSUzQSUyMDIlMEFkaXN0cmlidXRlZF90eXBlJTNBJTIwREVFUFNQRUVEJTBBZG93bmNhc3RfYmYxNiUzQSUyMCdubyclMEFtYWNoaW5lX3JhbmslM0ElMjAwJTBBbWFpbl90cmFpbmluZ19mdW5jdGlvbiUzQSUyMG1haW4lMEFtaXhlZF9wcmVjaXNpb24lM0ElMjBiZjE2JTBBbnVtX21hY2hpbmVzJTNBJTIwMSUwQW51bV9wcm9jZXNzZXMlM0ElMjA0JTBBcmR6dl9iYWNrZW5kJTNBJTIwc3RhdGljJTBBc2FtZV9uZXR3b3JrJTNBJTIwdHJ1ZSUwQXRwdV9lbnYlM0ElMjAlNUIlNUQlMEF0cHVfdXNlX2NsdXN0ZXIlM0ElMjBmYWxzZSUwQXRwdV91c2Vfc3VkbyUzQSUyMGZhbHNlJTBBdXNlX2NwdSUzQSUyMGZhbHNl",highlighted:`<span class="hljs-attr">compute_environment:</span> <span class="hljs-string">LOCAL_MACHINE</span>
<span class="hljs-attr">deepspeed_config:</span>
  <span class="hljs-attr">gradient_accumulation_steps:</span> <span class="hljs-number">1</span>
  <span class="hljs-attr">gradient_clipping:</span> <span class="hljs-number">0.7</span>
  <span class="hljs-attr">offload_optimizer_device:</span> <span class="hljs-string">cpu</span>
  <span class="hljs-attr">offload_param_device:</span> <span class="hljs-string">cpu</span>
  <span class="hljs-attr">zero3_init_flag:</span> <span class="hljs-literal">true</span>
  <span class="hljs-attr">zero_stage:</span> <span class="hljs-number">2</span>
<span class="hljs-attr">distributed_type:</span> <span class="hljs-string">DEEPSPEED</span>
<span class="hljs-attr">downcast_bf16:</span> <span class="hljs-string">&#x27;no&#x27;</span>
<span class="hljs-attr">machine_rank:</span> <span class="hljs-number">0</span>
<span class="hljs-attr">main_training_function:</span> <span class="hljs-string">main</span>
<span class="hljs-attr">mixed_precision:</span> <span class="hljs-string">bf16</span>
<span class="hljs-attr">num_machines:</span> <span class="hljs-number">1</span>
<span class="hljs-attr">num_processes:</span> <span class="hljs-number">4</span>
<span class="hljs-attr">rdzv_backend:</span> <span class="hljs-string">static</span>
<span class="hljs-attr">same_network:</span> <span class="hljs-literal">true</span>
<span class="hljs-attr">tpu_env:</span> []
<span class="hljs-attr">tpu_use_cluster:</span> <span class="hljs-literal">false</span>
<span class="hljs-attr">tpu_use_sudo:</span> <span class="hljs-literal">false</span>
<span class="hljs-attr">use_cpu:</span> <span class="hljs-literal">false</span>`,wrap:!1}}),{c(){M(t.$$.fragment)},l(a){f(t.$$.fragment,a)},m(a,c){d(t,a,c),r=!0},p:$,i(a){r||(h(t.$$.fragment,a),r=!0)},o(a){u(t.$$.fragment,a),r=!1},d(a){T(t,a)}}}function Ea(g){let t,r,a,c,i,m,_,Z;return t=new B({props:{id:"distributed-training",option:"DistributedDataParallel",$$slots:{default:[Wa]},$$scope:{ctx:g}}}),a=new B({props:{id:"distributed-training",option:"FullyShardedDataParallel",$$slots:{default:[Aa]},$$scope:{ctx:g}}}),i=new B({props:{id:"distributed-training",option:"DeepSpeed",$$slots:{default:[Na]},$$scope:{ctx:g}}}),_=new B({props:{id:"distributed-training",option:"DeepSpeed with Accelerate plugin",$$slots:{default:[Ra]},$$scope:{ctx:g}}}),{c(){M(t.$$.fragment),r=p(),M(a.$$.fragment),c=p(),M(i.$$.fragment),m=p(),M(_.$$.fragment)},l(j){f(t.$$.fragment,j),r=o(j),f(a.$$.fragment,j),c=o(j),f(i.$$.fragment,j),m=o(j),f(_.$$.fragment,j)},m(j,b){d(t,j,b),n(j,r,b),d(a,j,b),n(j,c,b),d(i,j,b),n(j,m,b),d(_,j,b),Z=!0},p(j,b){const Pe={};b&2&&(Pe.$$scope={dirty:b,ctx:j}),t.$set(Pe);const F={};b&2&&(F.$$scope={dirty:b,ctx:j}),a.$set(F);const v={};b&2&&(v.$$scope={dirty:b,ctx:j}),i.$set(v);const Ke={};b&2&&(Ke.$$scope={dirty:b,ctx:j}),_.$set(Ke)},i(j){Z||(h(t.$$.fragment,j),h(a.$$.fragment,j),h(i.$$.fragment,j),h(_.$$.fragment,j),Z=!0)},o(j){u(t.$$.fragment,j),u(a.$$.fragment,j),u(i.$$.fragment,j),u(_.$$.fragment,j),Z=!1},d(j){j&&(l(r),l(c),l(m)),T(t,j),T(a,j),T(i,j),T(_,j)}}}function Ga(g){let t,r='Refer to the <a href="https://hf.co/docs/accelerate/basic_tutorials/launch" rel="nofollow">Launching your Accelerate scripts</a> tutorial to learn more about <code>accelerate_launch</code> and custom configurations.';return{c(){t=y("p"),t.innerHTML=r},l(a){t=w(a,"P",{"data-svelte-h":!0}),J(t)!=="svelte-1ih0qfg"&&(t.innerHTML=r)},m(a,c){n(a,t,c)},p:$,d(a){a&&l(t)}}}function Va(g){let t,r="It can take some time before training starts (~3 minutes for a 2B model on a NVIDIA A100).";return{c(){t=y("p"),t.textContent=r},l(a){t=w(a,"P",{"data-svelte-h":!0}),J(t)!=="svelte-jkq35c"&&(t.textContent=r)},m(a,c){n(a,t,c)},p:$,d(a){a&&l(t)}}}function Ha(g){let t,r;return t=new U({props:{code:"aW1wb3J0JTIwZGF0YXNldHMlMEFmcm9tJTIwdHJsJTIwaW1wb3J0JTIwU0ZUQ29uZmlnJTJDJTIwU0ZUVHJhaW5lciUwQSUwQXRyYWluX2RhdGFzZXQlMjAlM0QlMjBkYXRhc2V0cy5sb2FkX2RhdGFzZXQoJ2ltZGInJTJDJTIwc3BsaXQlM0QndHJhaW4nKSUwQWFyZ3MlMjAlM0QlMjBTRlRDb25maWcoJTBBJTIwJTIwJTIwJTIwb3V0cHV0X2RpciUzRCUyMi4lMkZ0ZXN0LWdhbG9yZSUyMiUyQyUwQSUyMCUyMCUyMCUyMG1heF9zdGVwcyUzRDEwMCUyQyUwQSUyMCUyMCUyMCUyMG9wdGltJTNEJTIyZ2Fsb3JlX2FkYW13JTIyJTJDJTBBJTIwJTIwJTIwJTIwb3B0aW1fdGFyZ2V0X21vZHVsZXMlM0QlNUJyJTIyLiouYXR0bi4qJTIyJTJDJTIwciUyMi4qLm1scC4qJTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwb3B0aW1fYXJncyUzRCUyMnJhbmslM0Q2NCUyQyUyMHVwZGF0ZV9wcm9qX2dhcCUzRDEwMCUyQyUyMHNjYWxlJTNEMC4xMCUyMiUyQyUwQSUyMCUyMCUyMCUyMGdyYWRpZW50X2NoZWNrcG9pbnRpbmclM0RUcnVlJTJDJTBBKSUwQXRyYWluZXIlMjAlM0QlMjBTRlRUcmFpbmVyKCUwQSUyMCUyMCUyMCUyMG1vZGVsJTNEJTIyZ29vZ2xlJTJGZ2VtbWEtMmIlMjIlMkMlMEElMjAlMjAlMjAlMjBhcmdzJTNEYXJncyUyQyUwQSUyMCUyMCUyMCUyMHRyYWluX2RhdGFzZXQlM0R0cmFpbl9kYXRhc2V0JTJDJTBBKSUwQXRyYWluZXIudHJhaW4oKQ==",highlighted:`<span class="hljs-keyword">import</span> datasets
<span class="hljs-keyword">from</span> trl <span class="hljs-keyword">import</span> SFTConfig, SFTTrainer

train_dataset = datasets.load_dataset(<span class="hljs-string">&#x27;imdb&#x27;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)
args = SFTConfig(
    output_dir=<span class="hljs-string">&quot;./test-galore&quot;</span>,
    max_steps=<span class="hljs-number">100</span>,
    optim=<span class="hljs-string">&quot;galore_adamw&quot;</span>,
    optim_target_modules=[<span class="hljs-string">r&quot;.*.attn.*&quot;</span>, <span class="hljs-string">r&quot;.*.mlp.*&quot;</span>],
    optim_args=<span class="hljs-string">&quot;rank=64, update_proj_gap=100, scale=0.10&quot;</span>,
    gradient_checkpointing=<span class="hljs-literal">True</span>,
)
trainer = SFTTrainer(
    model=<span class="hljs-string">&quot;google/gemma-2b&quot;</span>,
    args=args,
    train_dataset=train_dataset,
)
trainer.train()`,wrap:!1}}),{c(){M(t.$$.fragment)},l(a){f(t.$$.fragment,a)},m(a,c){d(t,a,c),r=!0},p:$,i(a){r||(h(t.$$.fragment,a),r=!0)},o(a){u(t.$$.fragment,a),r=!1},d(a){T(t,a)}}}function Fa(g){let t,r='Append <code>layerwise</code> to the optimizer name to enable layerwise optimization. For example, <code>&quot;galore_adamw&quot;</code> becomes <code>&quot;galore_adamw_layerwise&quot;</code>. This feature is still experimental and does not support Distributed Data Parallel (DDP). The code below can only be run on a <a href="https://github.com/jiaweizzhao/GaLore?tab=readme-ov-file#train-7b-model-with-a-single-gpu-with-24gb-memory" rel="nofollow">single GPU</a>. Other features like gradient clipping and DeepSpeed may not be available out of the box. Feel free to open an <a href="https://github.com/huggingface/transformers/issues" rel="nofollow">issue</a> if you encounter any problems!',a,c,i;return c=new U({props:{code:"aW1wb3J0JTIwZGF0YXNldHMlMEFmcm9tJTIwdHJsJTIwaW1wb3J0JTIwU0ZUQ29uZmlnJTJDJTIwU0ZUVHJhaW5lciUwQSUwQXRyYWluX2RhdGFzZXQlMjAlM0QlMjBkYXRhc2V0cy5sb2FkX2RhdGFzZXQoJ2ltZGInJTJDJTIwc3BsaXQlM0QndHJhaW4nKSUwQWFyZ3MlMjAlM0QlMjBTRlRDb25maWcoJTBBJTIwJTIwJTIwJTIwb3V0cHV0X2RpciUzRCUyMi4lMkZ0ZXN0LWdhbG9yZSUyMiUyQyUwQSUyMCUyMCUyMCUyMG1heF9zdGVwcyUzRDEwMCUyQyUwQSUyMCUyMCUyMCUyMG9wdGltJTNEJTIyZ2Fsb3JlX2FkYW13X2xheWVyd2lzZSUyMiUyQyUwQSUyMCUyMCUyMCUyMG9wdGltX3RhcmdldF9tb2R1bGVzJTNEJTVCciUyMi4qLmF0dG4uKiUyMiUyQyUyMHIlMjIuKi5tbHAuKiUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMG9wdGltX2FyZ3MlM0QlMjJyYW5rJTNENjQlMkMlMjB1cGRhdGVfcHJval9nYXAlM0QxMDAlMkMlMjBzY2FsZSUzRDAuMTAlMjIlMkMlMEElMjAlMjAlMjAlMjBncmFkaWVudF9jaGVja3BvaW50aW5nJTNEVHJ1ZSUyQyUwQSklMEF0cmFpbmVyJTIwJTNEJTIwU0ZUVHJhaW5lciglMEElMjAlMjAlMjAlMjBtb2RlbCUzRCUyMmdvb2dsZSUyRmdlbW1hLTJiJTIyJTJDJTBBJTIwJTIwJTIwJTIwYXJncyUzRGFyZ3MlMkMlMEElMjAlMjAlMjAlMjB0cmFpbl9kYXRhc2V0JTNEdHJhaW5fZGF0YXNldCUyQyUwQSklMEF0cmFpbmVyLnRyYWluKCk=",highlighted:`<span class="hljs-keyword">import</span> datasets
<span class="hljs-keyword">from</span> trl <span class="hljs-keyword">import</span> SFTConfig, SFTTrainer

train_dataset = datasets.load_dataset(<span class="hljs-string">&#x27;imdb&#x27;</span>, split=<span class="hljs-string">&#x27;train&#x27;</span>)
args = SFTConfig(
    output_dir=<span class="hljs-string">&quot;./test-galore&quot;</span>,
    max_steps=<span class="hljs-number">100</span>,
    optim=<span class="hljs-string">&quot;galore_adamw_layerwise&quot;</span>,
    optim_target_modules=[<span class="hljs-string">r&quot;.*.attn.*&quot;</span>, <span class="hljs-string">r&quot;.*.mlp.*&quot;</span>],
    optim_args=<span class="hljs-string">&quot;rank=64, update_proj_gap=100, scale=0.10&quot;</span>,
    gradient_checkpointing=<span class="hljs-literal">True</span>,
)
trainer = SFTTrainer(
    model=<span class="hljs-string">&quot;google/gemma-2b&quot;</span>,
    args=args,
    train_dataset=train_dataset,
)
trainer.train()`,wrap:!1}}),{c(){t=y("p"),t.innerHTML=r,a=p(),M(c.$$.fragment)},l(m){t=w(m,"P",{"data-svelte-h":!0}),J(t)!=="svelte-1ex0hd8"&&(t.innerHTML=r),a=o(m),f(c.$$.fragment,m)},m(m,_){n(m,t,_),n(m,a,_),d(c,m,_),i=!0},p:$,i(m){i||(h(c.$$.fragment,m),i=!0)},o(m){u(c.$$.fragment,m),i=!1},d(m){m&&(l(t),l(a)),T(c,m)}}}function za(g){let t,r,a,c;return t=new B({props:{id:"galore",option:"GaLore optimizer",$$slots:{default:[Ha]},$$scope:{ctx:g}}}),a=new B({props:{id:"galore",option:"GaLore optimizer with layerwise optimization",$$slots:{default:[Fa]},$$scope:{ctx:g}}}),{c(){M(t.$$.fragment),r=p(),M(a.$$.fragment)},l(i){f(t.$$.fragment,i),r=o(i),f(a.$$.fragment,i)},m(i,m){d(t,i,m),n(i,r,m),d(a,i,m),c=!0},p(i,m){const _={};m&2&&(_.$$scope={dirty:m,ctx:i}),t.$set(_);const Z={};m&2&&(Z.$$scope={dirty:m,ctx:i}),a.$set(Z)},i(i){c||(h(t.$$.fragment,i),h(a.$$.fragment,i),c=!0)},o(i){u(t.$$.fragment,i),u(a.$$.fragment,i),c=!1},d(i){i&&l(r),T(t,i),T(a,i)}}}function Qa(g){let t,r='Liger Kernel supports Llama, Gemma, Mistral, and Mixtral models. Refer to the <a href="https://github.com/linkedin/Liger-Kernel#patching" rel="nofollow">patching</a> list for the latest list of supported models.';return{c(){t=y("p"),t.innerHTML=r},l(a){t=w(a,"P",{"data-svelte-h":!0}),J(t)!=="svelte-v7ceec"&&(t.innerHTML=r)},m(a,c){n(a,t,c)},p:$,d(a){a&&l(t)}}}function Ya(g){let t,r,a,c,i,m,_,Z='<a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> is a complete training and evaluation loop for Transformers’ PyTorch models. Plug a model, preprocessor, dataset, and training arguments into <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> and let it handle the rest to start training faster.',j,b,Pe='<a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> is also powered by <a href="https://hf.co/docs/accelerate/index" rel="nofollow">Accelerate</a>, a library for handling large models for distributed training.',F,v,Ke='This guide will show you how <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> works and how to customize it for your use case with a callback.',es,z,ss,Q,gt='<a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> contains all the necessary components of a training loop.',ts,Y,jt='<li>calculate the loss from a training step</li> <li>calculate the gradients with the <a href="https://huggingface.co/docs/accelerate/v1.10.1/en/package_reference/accelerator#accelerate.Accelerator.backward" rel="nofollow">backward</a> method</li> <li>update the weights based on the gradients</li> <li>repeat until the predetermined number of epochs is reached</li>',as,S,_t='Manually coding this training loop everytime can be inconvenient or a barrier if you’re just getting started with machine learning. <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> abstracts this process, allowing you to focus on the model, dataset, and training design choices.',ls,L,bt='Configure your training with hyperparameters and options from <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> which supports many features such as distributed training, torch.compile, mixed precision training, and saving the model to the Hub.',ns,C,rs,x,Ut='The example below demonstrates an example of <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> that evaluates and saves the model at the end of each epoch. It also loads the best model found during training and pushes it to the Hub.',is,q,ps,D,$t='Pass your model, dataset, preprocessor, and <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> to <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a>, and call <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer.train">train()</a> to start training.',os,X,cs,P,ms,K,Ms,O,Zt='<a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> saves checkpoints (the optimizer state is not saved by default) to the directory in <code>output_dir</code> in <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> to a subfolder named <code>checkpoint-000</code>. The number at the end is the training step at which the checkpoint was saved.',fs,ee,It='Saving checkpoints are useful for resuming training or recovering your training progress if you encounter an error. Set the <code>resume_from_checkpoint</code> parameter in <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer.train">train()</a> to resume training from the last checkpoint or a specific checkpoint.',ds,k,hs,se,vt='Checkpoints can be saved to the Hub by setting <code>push_to_hub=True</code> in <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>. The default method (<code>&quot;every_save&quot;</code>) saves a checkpoint to the Hub every time a model is saved, which is typically the final model at the end of training. Some other options for deciding how to save checkpoints to the Hub include the following.',us,te,Bt='<li><code>hub_strategy=&quot;end&quot;</code> only pushes a checkpoint when <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer.save_model">save_model()</a> is called</li> <li><code>hub_strategy=&quot;checkpoint&quot;</code> pushes the latest checkpoint to a subfolder named <em>last-checkpoint</em> from which training can be resumed</li> <li><code>hub_strategy=&quot;all_checkpoints&quot;</code> pushes all checkpoints to the Hub with one checkpoint per subfolder in your model repository</li>',Ts,ae,Ct='<a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> attempts to maintain the same Python, NumPy, and PyTorch RNG states when you resume training from a checkpoint. But PyTorch has various non-deterministic settings which can’t guarantee the RNG states are identical. To enable full determinism, refer to the <a href="https://pytorch.org/docs/stable/notes/randomness#controlling-sources-of-randomness" rel="nofollow">Controlling sources of randomness</a> guide to learn what settings to adjust to make training fully deterministic (some settings may result in slower training).',ys,le,ws,ne,Xt='<a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> is set to <code>logging.INFO</code> by default to report errors, warnings, and other basic information. Use <code>log_level()</code> to change the logging level and log verbosity.',Js,re,kt="The example below sets the main code and modules to use the same log level.",gs,ie,js,pe,Wt='In a distributed environment, <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> replicas are set to <code>logging.WARNING</code> to only report errors and warnings. Use <code>log_level_replica()</code> to change the logging level and log verbosity. To configure the log level for each node, use <code>log_on_each_node()</code> to determine whether to use a specific log level on each node or only the main node.',_s,oe,At="Use different combinations of <code>log_level</code> and <code>log_level_replica</code> to configure what gets logged on each node.",bs,W,Us,A,$s,ce,Zs,me,Nt='Tailor <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> to your use case by subclassing or overriding its methods to support the functionality you want to add or use, without rewriting the entire training loop from scratch. The table below lists some of the methods that can be customized.',Is,Me,Rt='<thead><tr><th>method</th> <th>description</th></tr></thead> <tbody><tr><td><a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer.get_train_dataloader">get_train_dataloader()</a></td> <td>create a training DataLoader</td></tr> <tr><td><a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer.get_eval_dataloader">get_eval_dataloader()</a></td> <td>create an evaluation DataLoader</td></tr> <tr><td><a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer.get_test_dataloader">get_test_dataloader()</a></td> <td>create a test DataLoader</td></tr> <tr><td><a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer.log">log()</a></td> <td>log information about the training process</td></tr> <tr><td><a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer.create_optimizer_and_scheduler">create_optimizer_and_scheduler()</a></td> <td>create an optimizer and learning rate scheduler (can also be separately customized with <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer.create_optimizer">create_optimizer()</a> and <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer.create_scheduler">create_scheduler()</a> if they weren’t passed in <code>__init__</code>)</td></tr> <tr><td><a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer.compute_loss">compute_loss()</a></td> <td>compute the loss of a batch of training inputs</td></tr> <tr><td><a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer.training_step">training_step()</a></td> <td>perform the training step</td></tr> <tr><td><a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer.prediction_step">prediction_step()</a></td> <td>perform the prediction and test step</td></tr> <tr><td><a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer.evaluate">evaluate()</a></td> <td>evaluate the model and return the evaluation metric</td></tr> <tr><td><a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer.predict">predict()</a></td> <td>make a prediction (with metrics if labels are available) on the test set</td></tr></tbody>',vs,fe,Et='For example, to use weighted loss, rewrite <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer.compute_loss">compute_loss()</a> inside <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a>.',Bs,de,Cs,he,Xs,ue,Gt='<a href="./main_classes/callback">Callbacks</a> are another way to customize <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a>, but they don’t change anything <em>inside the training loop</em>. Instead, a callback inspects the training loop state and executes some action (early stopping, logging, etc.) depending on the state. For example, you can’t implement a custom loss function with a callback because that requires overriding <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer.compute_loss">compute_loss()</a>.',ks,Te,Vt='To use a callback, create a class that inherits from <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> and implements the functionality you want. Then pass the callback to the <code>callback</code> parameter in <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a>. The example below implements an early stopping callback that stops training after 10 steps.',Ws,ye,As,we,Ns,Je,Ht='<a href="https://hf.co/docs/accelerate/index" rel="nofollow">Accelerate</a> is a library that simplifies training in distributed environments and across different hardware. Its integration with <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> means <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> supports distributed training frameworks like <a href="https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/" rel="nofollow">Fully Sharded Data Parallel (FSDP)</a> and <a href="https://www.deepspeed.ai/" rel="nofollow">DeepSpeed</a>.',Rs,N,Es,ge,Ft='To use Accelerate with <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a>, run the <a href="https://hf.co/docs/accelerate/package_reference/cli#accelerate-config" rel="nofollow">accelerate_config</a> command to configure your training environment. This command creates a <code>config_file.yaml</code> file that stores the configuration settings of your training environment and it’s used whenever you launch your training script. Some example distributed training configurations are shown below.',Gs,R,Vs,je,zt='Run <a href="https://hf.co/docs/accelerate/package_reference/cli#accelerate-launch" rel="nofollow">accelerate_launch</a> to start training with the configurations set in <code>config_file.yaml</code>. This file is saved to the Accelerate cache folder and automatically loaded when you run <code>accelerate_launch</code>.',Hs,_e,Qt='The example below launches the <a href="../../../examples/pytorch/text-classification/run_glue">run_glue.py</a> script with the FSDP configuration shown earlier. Parameters from the <code>config_file.yaml</code> file can also be directly set in the command line.',Fs,be,zs,E,Qs,Ue,Ys,$e,Yt='<a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> supports various optimizations to improve <em>training</em> performance - reduce memory and increase training speed - and <em>model</em> performance.',Ss,Ze,Ls,Ie,St='<a href="./perf_torch_compile">torch.compile</a> can significantly speed up training and reduce computational overhead. Configure your torch.compile settings in <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>. Set <code>torch_compile</code> to <code>True</code>, and select a backend and compile mode.',xs,ve,qs,Be,Ds,Ce,Lt='<a href="https://hf.co/papers/2403.03507" rel="nofollow">Gradient Low-Rank Projection (GaLore)</a> significantly reduces memory usage when training large language models (LLMs). One of GaLores key benefits is <em>full-parameter</em> learning, unlike low-rank adaptation methods like <a href="https://hf.co/papers/2106.09685" rel="nofollow">LoRA</a>, which produces better model performance.',Ps,Xe,xt='Install the <a href="https://github.com/jiaweizzhao/GaLore" rel="nofollow">GaLore</a> and <a href="https://hf.co/docs/trl/index" rel="nofollow">TRL</a> libraries.',Ks,ke,Os,We,qt='Pick a GaLore optimizer (<code>&quot;galore_adamw&quot;</code>, <code>&quot;galore_adafactor&quot;</code>, <code>&quot;galore_adamw_8bit</code>”) and pass it to the <code>optim</code> parameter in <a href="https://huggingface.co/docs/trl/v0.23.0/en/sft_trainer#trl.SFTConfig" rel="nofollow">trl.SFTConfig</a>. Use the <code>optim_target_modules</code> parameter to specify which modules to adapt (can be a list of strings, regex, or a full path).',et,Ae,Dt='Extra parameters supported by GaLore, <code>rank</code>, <code>update_proj_gap</code>, and <code>scale</code>, should be passed to the <code>optim_args</code> parameter in <a href="https://huggingface.co/docs/trl/v0.23.0/en/sft_trainer#trl.SFTConfig" rel="nofollow">trl.SFTConfig</a>.',st,Ne,Pt='The example below enables GaLore with <a href="https://huggingface.co/docs/trl/v0.23.0/en/sft_trainer#trl.SFTTrainer" rel="nofollow">SFTTrainer</a> that targets the <code>attn</code> and <code>mlp</code> layers with regex.',tt,G,at,V,lt,Re,Kt="Only linear layers that are considered GaLore layers can be trained with low-rank decomposition. The rest of the model layers are optimized in the usual way.",nt,Ee,rt,Ge,Ot='<a href="https://github.com/linkedin/Liger-Kernel" rel="nofollow">Liger Kernel</a> is a collection of layers such as RMSNorm, RoPE, SwiGLU, CrossEntropy, FusedLinearCrossEntropy, and more that have been fused into a single Triton kernel for training LLMs. These kernels are also compatible with FlashAttention, FSDP, and DeepSpeed. As a result, Liger Kernel can increase multi-GPU training throughput and reduce memory usage. This is useful for multi-head training and supporting larger vocabulary sizes, larger batch sizes, and longer context lengths.',it,Ve,pt,He,ea='Enable Liger Kernel for training by setting <code>use_liger_kernel=True</code> in <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>. This patches the corresponding layers in the model with Ligers kernels.',ot,H,ct,Fe,mt,ze,sa="You can also configure which specific kernels to apply using the <code>liger_kernel_config</code> parameter. This dict is passed as keyword arguments to the <code>_apply_liger_kernel_to_instance</code> function, allowing fine-grained control over kernel usage. Available options vary by model but typically include: <code>rope</code>, <code>swiglu</code>, <code>cross_entropy</code>, <code>fused_linear_cross_entropy</code>, <code>rms_norm</code>, etc.",Mt,Qe,ft,Ye,dt,Se,ta='<a href="https://hf.co/papers/2310.05914" rel="nofollow">NEFTune</a> adds noise to the embedding vectors during training to improve model performance. Enable it in <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> with the <code>neftune_noise_alpha</code> parameter in <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> to control how much noise is added.',ht,Le,ut,xe,aa="The original embedding layer is restored after training to avoid any unexpected behavior.",Tt,qe,yt,Oe,wt;return i=new I({props:{title:"Trainer",local:"trainer",headingTag:"h1"}}),z=new U({props:{code:"IXBpcCUyMGluc3RhbGwlMjBhY2NlbGVyYXRlJTIwLS11cGdyYWRl",highlighted:"!pip install accelerate --upgrade",wrap:!1}}),C=new De({props:{warning:!1,$$slots:{default:[ba]},$$scope:{ctx:g}}}),q=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRyYWluaW5nQXJndW1lbnRzJTBBJTBBdHJhaW5pbmdfYXJncyUyMCUzRCUyMFRyYWluaW5nQXJndW1lbnRzKCUwQSUyMCUyMCUyMCUyMG91dHB1dF9kaXIlM0QlMjJ5b3VyLW1vZGVsJTIyJTJDJTBBJTIwJTIwJTIwJTIwbGVhcm5pbmdfcmF0ZSUzRDJlLTUlMkMlMEElMjAlMjAlMjAlMjBwZXJfZGV2aWNlX3RyYWluX2JhdGNoX3NpemUlM0QxNiUyQyUwQSUyMCUyMCUyMCUyMHBlcl9kZXZpY2VfZXZhbF9iYXRjaF9zaXplJTNEMTYlMkMlMEElMjAlMjAlMjAlMjBudW1fdHJhaW5fZXBvY2hzJTNEMiUyQyUwQSUyMCUyMCUyMCUyMHdlaWdodF9kZWNheSUzRDAuMDElMkMlMEElMjAlMjAlMjAlMjBldmFsX3N0cmF0ZWd5JTNEJTIyZXBvY2glMjIlMkMlMEElMjAlMjAlMjAlMjBzYXZlX3N0cmF0ZWd5JTNEJTIyZXBvY2glMjIlMkMlMEElMjAlMjAlMjAlMjBsb2FkX2Jlc3RfbW9kZWxfYXRfZW5kJTNEVHJ1ZSUyQyUwQSUyMCUyMCUyMCUyMHB1c2hfdG9faHViJTNEVHJ1ZSUyQyUwQSk=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

training_args = TrainingArguments(
    output_dir=<span class="hljs-string">&quot;your-model&quot;</span>,
    learning_rate=<span class="hljs-number">2e-5</span>,
    per_device_train_batch_size=<span class="hljs-number">16</span>,
    per_device_eval_batch_size=<span class="hljs-number">16</span>,
    num_train_epochs=<span class="hljs-number">2</span>,
    weight_decay=<span class="hljs-number">0.01</span>,
    eval_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    load_best_model_at_end=<span class="hljs-literal">True</span>,
    push_to_hub=<span class="hljs-literal">True</span>,
)`,wrap:!1}}),X=new De({props:{warning:!1,$$slots:{default:[Ua]},$$scope:{ctx:g}}}),P=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRyYWluZXIlMEElMEF0cmFpbmVyJTIwJTNEJTIwVHJhaW5lciglMEElMjAlMjAlMjAlMjBtb2RlbCUzRG1vZGVsJTJDJTBBJTIwJTIwJTIwJTIwYXJncyUzRHRyYWluaW5nX2FyZ3MlMkMlMEElMjAlMjAlMjAlMjB0cmFpbl9kYXRhc2V0JTNEZGF0YXNldCU1QiUyMnRyYWluJTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwZXZhbF9kYXRhc2V0JTNEZGF0YXNldCU1QiUyMnRlc3QlMjIlNUQlMkMlMEElMjAlMjAlMjAlMjBwcm9jZXNzaW5nX2NsYXNzJTNEdG9rZW5pemVyJTJDJTBBJTIwJTIwJTIwJTIwZGF0YV9jb2xsYXRvciUzRGRhdGFfY29sbGF0b3IlMkMlMEElMjAlMjAlMjAlMjBjb21wdXRlX21ldHJpY3MlM0Rjb21wdXRlX21ldHJpY3MlMkMlMEEpJTBBJTBBdHJhaW5lci50cmFpbigp",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset[<span class="hljs-string">&quot;train&quot;</span>],
    eval_dataset=dataset[<span class="hljs-string">&quot;test&quot;</span>],
    processing_class=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics,
)

trainer.train()`,wrap:!1}}),K=new I({props:{title:"Checkpoints",local:"checkpoints",headingTag:"h2"}}),k=new Jt({props:{id:"ckpt",options:["latest checkpoint","specific checkpoint"],$$slots:{default:[Ia]},$$scope:{ctx:g}}}),le=new I({props:{title:"Logging",local:"logging",headingTag:"h2"}}),ie=new U({props:{code:"bG9nZ2VyJTIwJTNEJTIwbG9nZ2luZy5nZXRMb2dnZXIoX19uYW1lX18pJTBBJTBBbG9nZ2luZy5iYXNpY0NvbmZpZyglMEElMjAlMjAlMjAlMjBmb3JtYXQlM0QlMjIlMjUoYXNjdGltZSlzJTIwLSUyMCUyNShsZXZlbG5hbWUpcyUyMC0lMjAlMjUobmFtZSlzJTIwLSUyMCUyNShtZXNzYWdlKXMlMjIlMkMlMEElMjAlMjAlMjAlMjBkYXRlZm10JTNEJTIyJTI1bSUyRiUyNWQlMkYlMjVZJTIwJTI1SCUzQSUyNU0lM0ElMjVTJTIyJTJDJTBBJTIwJTIwJTIwJTIwaGFuZGxlcnMlM0QlNUJsb2dnaW5nLlN0cmVhbUhhbmRsZXIoc3lzLnN0ZG91dCklNUQlMkMlMEEpJTBBJTBBbG9nX2xldmVsJTIwJTNEJTIwdHJhaW5pbmdfYXJncy5nZXRfcHJvY2Vzc19sb2dfbGV2ZWwoKSUwQWxvZ2dlci5zZXRMZXZlbChsb2dfbGV2ZWwpJTBBZGF0YXNldHMudXRpbHMubG9nZ2luZy5zZXRfdmVyYm9zaXR5KGxvZ19sZXZlbCklMEF0cmFuc2Zvcm1lcnMudXRpbHMubG9nZ2luZy5zZXRfdmVyYm9zaXR5KGxvZ19sZXZlbCklMEElMEF0cmFpbmVyJTIwJTNEJTIwVHJhaW5lciguLi4p",highlighted:`logger = logging.getLogger(__name__)

logging.basicConfig(
    <span class="hljs-built_in">format</span>=<span class="hljs-string">&quot;%(asctime)s - %(levelname)s - %(name)s - %(message)s&quot;</span>,
    datefmt=<span class="hljs-string">&quot;%m/%d/%Y %H:%M:%S&quot;</span>,
    handlers=[logging.StreamHandler(sys.stdout)],
)

log_level = training_args.get_process_log_level()
logger.setLevel(log_level)
datasets.utils.logging.set_verbosity(log_level)
transformers.utils.logging.set_verbosity(log_level)

trainer = Trainer(...)`,wrap:!1}}),W=new Jt({props:{id:"nodes",options:["single node","multi-node"],$$slots:{default:[Ca]},$$scope:{ctx:g}}}),A=new De({props:{warning:!1,$$slots:{default:[Xa]},$$scope:{ctx:g}}}),ce=new I({props:{title:"Customize",local:"customize",headingTag:"h2"}}),de=new U({props:{code:"ZnJvbSUyMHRvcmNoJTIwaW1wb3J0JTIwbm4lMEFmcm9tJTIwdHJhbnNmb3JtZXJzJTIwaW1wb3J0JTIwVHJhaW5lciUwQSUwQWNsYXNzJTIwQ3VzdG9tVHJhaW5lcihUcmFpbmVyKSUzQSUwQSUyMCUyMCUyMCUyMGRlZiUyMGNvbXB1dGVfbG9zcyhzZWxmJTJDJTIwbW9kZWwlM0ElMjBubi5Nb2R1bGUlMkMlMjBpbnB1dHMlM0ElMjBkaWN0JTVCc3RyJTJDJTIwVW5pb24lNUJ0b3JjaC5UZW5zb3IlMkMlMjBBbnklNUQlNUQlMkMlMjByZXR1cm5fb3V0cHV0cyUzQSUyMGJvb2wlMjAlM0QlMjBGYWxzZSUyMG51bV9pdGVtc19pbl9iYXRjaCUzQSUyME9wdGlvbmFsJTVCdG9yY2guVGVuc29yJTVEJTIwJTNEJTIwTm9uZSklM0ElMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBsYWJlbHMlMjAlM0QlMjBpbnB1dHMucG9wKCUyMmxhYmVscyUyMiklMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjMlMjBmb3J3YXJkJTIwcGFzcyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMG91dHB1dHMlMjAlM0QlMjBtb2RlbCgqKmlucHV0cyklMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBsb2dpdHMlMjAlM0QlMjBvdXRwdXRzLmdldCglMjJsb2dpdHMlMjIpJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIzJTIwY29tcHV0ZSUyMGN1c3RvbSUyMGxvc3MlMjBmb3IlMjAzJTIwbGFiZWxzJTIwd2l0aCUyMGRpZmZlcmVudCUyMHdlaWdodHMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjByZWR1Y3Rpb24lMjAlM0QlMjAlMjJzdW0lMjIlMjBpZiUyMG51bV9pdGVtc19pbl9iYXRjaCUyMGlzJTIwbm90JTIwTm9uZSUyMGVsc2UlMjAlMjJtZWFuJTIyJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwbG9zc19mY3QlMjAlM0QlMjBubi5Dcm9zc0VudHJvcHlMb3NzKHdlaWdodCUzRHRvcmNoLnRlbnNvciglNUIxLjAlMkMlMjAyLjAlMkMlMjAzLjAlNUQlMkMlMjBkZXZpY2UlM0Rtb2RlbC5kZXZpY2UlMkMlMjByZWR1Y3Rpb24lM0RyZWR1Y3Rpb24pKSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMGxvc3MlMjAlM0QlMjBsb3NzX2ZjdChsb2dpdHMudmlldygtMSUyQyUyMHNlbGYubW9kZWwuY29uZmlnLm51bV9sYWJlbHMpJTJDJTIwbGFiZWxzLnZpZXcoLTEpKSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMGlmJTIwbnVtX2l0ZW1zX2luX2JhdGNoJTIwaXMlMjBub3QlMjBOb25lJTNBJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwbG9zcyUyMCUzRCUyMGxvc3MlMjAlMkYlMjBudW1faXRlbXNfaW5fYmF0Y2glMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjByZXR1cm4lMjAobG9zcyUyQyUyMG91dHB1dHMpJTIwaWYlMjByZXR1cm5fb3V0cHV0cyUyMGVsc2UlMjBsb3Nz",highlighted:`<span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer

<span class="hljs-keyword">class</span> <span class="hljs-title class_">CustomTrainer</span>(<span class="hljs-title class_ inherited__">Trainer</span>):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_loss</span>(<span class="hljs-params">self, model: nn.Module, inputs: <span class="hljs-built_in">dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-type">Union</span>[torch.Tensor, <span class="hljs-type">Any</span>]], return_outputs: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span> num_items_in_batch: <span class="hljs-type">Optional</span>[torch.Tensor] = <span class="hljs-literal">None</span></span>):
        labels = inputs.pop(<span class="hljs-string">&quot;labels&quot;</span>)
        <span class="hljs-comment"># forward pass</span>
        outputs = model(**inputs)
        logits = outputs.get(<span class="hljs-string">&quot;logits&quot;</span>)
        <span class="hljs-comment"># compute custom loss for 3 labels with different weights</span>
        reduction = <span class="hljs-string">&quot;sum&quot;</span> <span class="hljs-keyword">if</span> num_items_in_batch <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;mean&quot;</span>
        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>], device=model.device, reduction=reduction))
        loss = loss_fct(logits.view(-<span class="hljs-number">1</span>, self.model.config.num_labels), labels.view(-<span class="hljs-number">1</span>))
        <span class="hljs-keyword">if</span> num_items_in_batch <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:
            loss = loss / num_items_in_batch
        <span class="hljs-keyword">return</span> (loss, outputs) <span class="hljs-keyword">if</span> return_outputs <span class="hljs-keyword">else</span> loss`,wrap:!1}}),he=new I({props:{title:"Callbacks",local:"callbacks",headingTag:"h3"}}),ye=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRyYWluZXJDYWxsYmFjayUyQyUyMFRyYWluZXIlMEElMEFjbGFzcyUyMEVhcmx5U3RvcHBpbmdDYWxsYmFjayhUcmFpbmVyQ2FsbGJhY2spJTNBJTBBJTIwJTIwJTIwJTIwZGVmJTIwX19pbml0X18oc2VsZiUyQyUyMG51bV9zdGVwcyUzRDEwKSUzQSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMHNlbGYubnVtX3N0ZXBzJTIwJTNEJTIwbnVtX3N0ZXBzJTBBJTBBJTIwJTIwJTIwJTIwZGVmJTIwb25fc3RlcF9lbmQoc2VsZiUyQyUyMGFyZ3MlMkMlMjBzdGF0ZSUyQyUyMGNvbnRyb2wlMkMlMjAqKmt3YXJncyklM0ElMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBpZiUyMHN0YXRlLmdsb2JhbF9zdGVwJTIwJTNFJTNEJTIwc2VsZi5udW1fc3RlcHMlM0ElMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjByZXR1cm4lMjAlN0IlMjJzaG91bGRfdHJhaW5pbmdfc3RvcCUyMiUzQSUyMFRydWUlN0QlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBlbHNlJTNBJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwcmV0dXJuJTIwJTdCJTdEJTBBJTBBdHJhaW5lciUyMCUzRCUyMFRyYWluZXIoJTBBJTIwJTIwJTIwJTIwbW9kZWwlM0Rtb2RlbCUyQyUwQSUyMCUyMCUyMCUyMGFyZ3MlM0R0cmFpbmluZ19hcmdzJTJDJTBBJTIwJTIwJTIwJTIwdHJhaW5fZGF0YXNldCUzRGRhdGFzZXQlNUIlMjJ0cmFpbiUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMGV2YWxfZGF0YXNldCUzRGRhdGFzZXQlNUIlMjJ0ZXN0JTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwcHJvY2Vzc2luZ19jbGFzcyUzRHRva2VuaXplciUyQyUwQSUyMCUyMCUyMCUyMGRhdGFfY29sbGF0b3IlM0RkYXRhX2NvbGxhdG9yJTJDJTBBJTIwJTIwJTIwJTIwY29tcHV0ZV9tZXRyaWNzJTNEY29tcHV0ZV9tZXRyaWNzJTJDJTBBJTIwJTIwJTIwJTIwY2FsbGJhY2tzJTNEJTVCRWFybHlTdG9wcGluZ0NhbGxiYWNrKCklNUQlMkMlMEEp",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainerCallback, Trainer

<span class="hljs-keyword">class</span> <span class="hljs-title class_">EarlyStoppingCallback</span>(<span class="hljs-title class_ inherited__">TrainerCallback</span>):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_steps=<span class="hljs-number">10</span></span>):
        self.num_steps = num_steps

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">on_step_end</span>(<span class="hljs-params">self, args, state, control, **kwargs</span>):
        <span class="hljs-keyword">if</span> state.global_step &gt;= self.num_steps:
            <span class="hljs-keyword">return</span> {<span class="hljs-string">&quot;should_training_stop&quot;</span>: <span class="hljs-literal">True</span>}
        <span class="hljs-keyword">else</span>:
            <span class="hljs-keyword">return</span> {}

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset[<span class="hljs-string">&quot;train&quot;</span>],
    eval_dataset=dataset[<span class="hljs-string">&quot;test&quot;</span>],
    processing_class=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback()],
)`,wrap:!1}}),we=new I({props:{title:"Accelerate",local:"accelerate",headingTag:"h2"}}),N=new De({props:{warning:!1,$$slots:{default:[ka]},$$scope:{ctx:g}}}),R=new Jt({props:{id:"distributed-training",options:["DistributedDataParallel","FullyShardedDataParallel","DeepSpeed","DeepSpeed with Accelerate plugin"],$$slots:{default:[Ea]},$$scope:{ctx:g}}}),be=new U({props:{code:"YWNjZWxlcmF0ZSUyMGxhdW5jaCUyMCU1QyUwQSUyMCUyMCUyMCUyMC4lMkZleGFtcGxlcyUyRnB5dG9yY2glMkZ0ZXh0LWNsYXNzaWZpY2F0aW9uJTJGcnVuX2dsdWUucHklMjAlNUMlMEElMjAlMjAlMjAlMjAtLW1vZGVsX25hbWVfb3JfcGF0aCUyMGdvb2dsZS1iZXJ0JTJGYmVydC1iYXNlLWNhc2VkJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS10YXNrX25hbWUlMjAlMjRUQVNLX05BTUUlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRvX3RyYWluJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1kb19ldmFsJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1tYXhfc2VxX2xlbmd0aCUyMDEyOCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcGVyX2RldmljZV90cmFpbl9iYXRjaF9zaXplJTIwMTYlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWxlYXJuaW5nX3JhdGUlMjA1ZS01JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1udW1fdHJhaW5fZXBvY2hzJTIwMyUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tb3V0cHV0X2RpciUyMCUyRnRtcCUyRiUyNFRBU0tfTkFNRSUyRiUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tb3ZlcndyaXRlX291dHB1dF9kaXI=",highlighted:`accelerate launch \\
    ./examples/pytorch/text-classification/run_glue.py \\
    --model_name_or_path google-bert/bert-base-cased \\
    --task_name <span class="hljs-variable">$TASK_NAME</span> \\
    --do_train \\
    --do_eval \\
    --max_seq_length 128 \\
    --per_device_train_batch_size 16 \\
    --learning_rate 5e-5 \\
    --num_train_epochs 3 \\
    --output_dir /tmp/<span class="hljs-variable">$TASK_NAME</span>/ \\
    --overwrite_output_dir`,wrap:!1}}),E=new De({props:{warning:!1,$$slots:{default:[Ga]},$$scope:{ctx:g}}}),Ue=new I({props:{title:"Optimizations",local:"optimizations",headingTag:"h2"}}),Ze=new I({props:{title:"torch.compile",local:"torchcompile",headingTag:"h3"}}),ve=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRyYWluaW5nQXJndW1lbnRzJTBBJTBBdHJhaW5pbmdfYXJncyUyMCUzRCUyMFRyYWluaW5nQXJndW1lbnRzKCUwQSUyMCUyMCUyMCUyMHRvcmNoX2NvbXBpbGUlM0RUcnVlJTJDJTBBJTIwJTIwJTIwJTIwdG9yY2hfY29tcGlsZV9iYWNrZW5kJTNEJTIyaW5kdWN0b3IlMjIlMkMlMEElMjAlMjAlMjAlMjB0b3JjaF9jb21waWxlX21vZGUlM0QlMjJkZWZhdWx0JTIyJTJDJTBBJTIwJTIwJTIwJTIwLi4uJTJDJTBBKQ==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

training_args = TrainingArguments(
    torch_compile=<span class="hljs-literal">True</span>,
    torch_compile_backend=<span class="hljs-string">&quot;inductor&quot;</span>,
    torch_compile_mode=<span class="hljs-string">&quot;default&quot;</span>,
    ...,
)`,wrap:!1}}),Be=new I({props:{title:"GaLore",local:"galore",headingTag:"h3"}}),ke=new U({props:{code:"cGlwJTIwaW5zdGFsbCUyMGdhbG9yZS10b3JjaCUyMHRybA==",highlighted:"pip install galore-torch trl",wrap:!1}}),G=new De({props:{warning:!1,$$slots:{default:[Va]},$$scope:{ctx:g}}}),V=new Jt({props:{id:"galore",options:["GaLore optimizer","GaLore optimizer with layerwise optimization"],$$slots:{default:[za]},$$scope:{ctx:g}}}),Ee=new I({props:{title:"Liger",local:"liger",headingTag:"h3"}}),Ve=new U({props:{code:"cGlwJTIwaW5zdGFsbCUyMGxpZ2VyLWtlcm5lbA==",highlighted:"pip install liger-kernel",wrap:!1}}),H=new De({props:{warning:!1,$$slots:{default:[Qa]},$$scope:{ctx:g}}}),Fe=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRyYWluaW5nQXJndW1lbnRzJTBBJTBBdHJhaW5pbmdfYXJncyUyMCUzRCUyMFRyYWluaW5nQXJndW1lbnRzKCUwQSUyMCUyMCUyMCUyMG91dHB1dF9kaXIlM0QlMjJ5b3VyLW1vZGVsJTIyJTJDJTBBJTIwJTIwJTIwJTIwbGVhcm5pbmdfcmF0ZSUzRDJlLTUlMkMlMEElMjAlMjAlMjAlMjBwZXJfZGV2aWNlX3RyYWluX2JhdGNoX3NpemUlM0QxNiUyQyUwQSUyMCUyMCUyMCUyMHBlcl9kZXZpY2VfZXZhbF9iYXRjaF9zaXplJTNEMTYlMkMlMEElMjAlMjAlMjAlMjBudW1fdHJhaW5fZXBvY2hzJTNEMiUyQyUwQSUyMCUyMCUyMCUyMHdlaWdodF9kZWNheSUzRDAuMDElMkMlMEElMjAlMjAlMjAlMjBldmFsX3N0cmF0ZWd5JTNEJTIyZXBvY2glMjIlMkMlMEElMjAlMjAlMjAlMjBzYXZlX3N0cmF0ZWd5JTNEJTIyZXBvY2glMjIlMkMlMEElMjAlMjAlMjAlMjBsb2FkX2Jlc3RfbW9kZWxfYXRfZW5kJTNEVHJ1ZSUyQyUwQSUyMCUyMCUyMCUyMHB1c2hfdG9faHViJTNEVHJ1ZSUyQyUwQSUyMCUyMCUyMCUyMHVzZV9saWdlcl9rZXJuZWwlM0RUcnVlJTBBKQ==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

training_args = TrainingArguments(
    output_dir=<span class="hljs-string">&quot;your-model&quot;</span>,
    learning_rate=<span class="hljs-number">2e-5</span>,
    per_device_train_batch_size=<span class="hljs-number">16</span>,
    per_device_eval_batch_size=<span class="hljs-number">16</span>,
    num_train_epochs=<span class="hljs-number">2</span>,
    weight_decay=<span class="hljs-number">0.01</span>,
    eval_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    load_best_model_at_end=<span class="hljs-literal">True</span>,
    push_to_hub=<span class="hljs-literal">True</span>,
    use_liger_kernel=<span class="hljs-literal">True</span>
)`,wrap:!1}}),Qe=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRyYWluaW5nQXJndW1lbnRzJTBBJTBBJTIzJTIwQXBwbHklMjBvbmx5JTIwc3BlY2lmaWMlMjBrZXJuZWxzJTBBdHJhaW5pbmdfYXJncyUyMCUzRCUyMFRyYWluaW5nQXJndW1lbnRzKCUwQSUyMCUyMCUyMCUyMG91dHB1dF9kaXIlM0QlMjJ5b3VyLW1vZGVsJTIyJTJDJTBBJTIwJTIwJTIwJTIwbGVhcm5pbmdfcmF0ZSUzRDJlLTUlMkMlMEElMjAlMjAlMjAlMjBwZXJfZGV2aWNlX3RyYWluX2JhdGNoX3NpemUlM0QxNiUyQyUwQSUyMCUyMCUyMCUyMHBlcl9kZXZpY2VfZXZhbF9iYXRjaF9zaXplJTNEMTYlMkMlMEElMjAlMjAlMjAlMjBudW1fdHJhaW5fZXBvY2hzJTNEMiUyQyUwQSUyMCUyMCUyMCUyMHdlaWdodF9kZWNheSUzRDAuMDElMkMlMEElMjAlMjAlMjAlMjBldmFsX3N0cmF0ZWd5JTNEJTIyZXBvY2glMjIlMkMlMEElMjAlMjAlMjAlMjBzYXZlX3N0cmF0ZWd5JTNEJTIyZXBvY2glMjIlMkMlMEElMjAlMjAlMjAlMjBsb2FkX2Jlc3RfbW9kZWxfYXRfZW5kJTNEVHJ1ZSUyQyUwQSUyMCUyMCUyMCUyMHB1c2hfdG9faHViJTNEVHJ1ZSUyQyUwQSUyMCUyMCUyMCUyMHVzZV9saWdlcl9rZXJuZWwlM0RUcnVlJTJDJTBBJTIwJTIwJTIwJTIwbGlnZXJfa2VybmVsX2NvbmZpZyUzRCU3QiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMnJvcGUlMjIlM0ElMjBUcnVlJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIyY3Jvc3NfZW50cm9weSUyMiUzQSUyMFRydWUlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJybXNfbm9ybSUyMiUzQSUyMEZhbHNlJTJDJTIwJTIwJTIzJTIwRG9uJ3QlMjBhcHBseSUyMExpZ2VyJ3MlMjBSTVNOb3JtJTIwa2VybmVsJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIyc3dpZ2x1JTIyJTNBJTIwVHJ1ZSUyQyUwQSUyMCUyMCUyMCUyMCU3RCUwQSk=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

<span class="hljs-comment"># Apply only specific kernels</span>
training_args = TrainingArguments(
    output_dir=<span class="hljs-string">&quot;your-model&quot;</span>,
    learning_rate=<span class="hljs-number">2e-5</span>,
    per_device_train_batch_size=<span class="hljs-number">16</span>,
    per_device_eval_batch_size=<span class="hljs-number">16</span>,
    num_train_epochs=<span class="hljs-number">2</span>,
    weight_decay=<span class="hljs-number">0.01</span>,
    eval_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    load_best_model_at_end=<span class="hljs-literal">True</span>,
    push_to_hub=<span class="hljs-literal">True</span>,
    use_liger_kernel=<span class="hljs-literal">True</span>,
    liger_kernel_config={
        <span class="hljs-string">&quot;rope&quot;</span>: <span class="hljs-literal">True</span>,
        <span class="hljs-string">&quot;cross_entropy&quot;</span>: <span class="hljs-literal">True</span>,
        <span class="hljs-string">&quot;rms_norm&quot;</span>: <span class="hljs-literal">False</span>,  <span class="hljs-comment"># Don&#x27;t apply Liger&#x27;s RMSNorm kernel</span>
        <span class="hljs-string">&quot;swiglu&quot;</span>: <span class="hljs-literal">True</span>,
    }
)`,wrap:!1}}),Ye=new I({props:{title:"NEFTune",local:"neftune",headingTag:"h3"}}),Le=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRyYWluaW5nQXJndW1lbnRzJTJDJTIwVHJhaW5lciUwQSUwQXRyYWluaW5nX2FyZ3MlMjAlM0QlMjBUcmFpbmluZ0FyZ3VtZW50cyguLi4lMkMlMjBuZWZ0dW5lX25vaXNlX2FscGhhJTNEMC4xKSUwQXRyYWluZXIlMjAlM0QlMjBUcmFpbmVyKC4uLiUyQyUyMGFyZ3MlM0R0cmFpbmluZ19hcmdzKQ==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments, Trainer

training_args = TrainingArguments(..., neftune_noise_alpha=<span class="hljs-number">0.1</span>)
trainer = Trainer(..., args=training_args)`,wrap:!1}}),qe=new _a({props:{source:"https://github.com/huggingface/transformers/blob/main/docs/source/en/trainer.md"}}),{c(){t=y("meta"),r=p(),a=y("p"),c=p(),M(i.$$.fragment),m=p(),_=y("p"),_.innerHTML=Z,j=p(),b=y("p"),b.innerHTML=Pe,F=p(),v=y("p"),v.innerHTML=Ke,es=p(),M(z.$$.fragment),ss=p(),Q=y("p"),Q.innerHTML=gt,ts=p(),Y=y("ol"),Y.innerHTML=jt,as=p(),S=y("p"),S.innerHTML=_t,ls=p(),L=y("p"),L.innerHTML=bt,ns=p(),M(C.$$.fragment),rs=p(),x=y("p"),x.innerHTML=Ut,is=p(),M(q.$$.fragment),ps=p(),D=y("p"),D.innerHTML=$t,os=p(),M(X.$$.fragment),cs=p(),M(P.$$.fragment),ms=p(),M(K.$$.fragment),Ms=p(),O=y("p"),O.innerHTML=Zt,fs=p(),ee=y("p"),ee.innerHTML=It,ds=p(),M(k.$$.fragment),hs=p(),se=y("p"),se.innerHTML=vt,us=p(),te=y("ul"),te.innerHTML=Bt,Ts=p(),ae=y("p"),ae.innerHTML=Ct,ys=p(),M(le.$$.fragment),ws=p(),ne=y("p"),ne.innerHTML=Xt,Js=p(),re=y("p"),re.textContent=kt,gs=p(),M(ie.$$.fragment),js=p(),pe=y("p"),pe.innerHTML=Wt,_s=p(),oe=y("p"),oe.innerHTML=At,bs=p(),M(W.$$.fragment),Us=p(),M(A.$$.fragment),$s=p(),M(ce.$$.fragment),Zs=p(),me=y("p"),me.innerHTML=Nt,Is=p(),Me=y("table"),Me.innerHTML=Rt,vs=p(),fe=y("p"),fe.innerHTML=Et,Bs=p(),M(de.$$.fragment),Cs=p(),M(he.$$.fragment),Xs=p(),ue=y("p"),ue.innerHTML=Gt,ks=p(),Te=y("p"),Te.innerHTML=Vt,Ws=p(),M(ye.$$.fragment),As=p(),M(we.$$.fragment),Ns=p(),Je=y("p"),Je.innerHTML=Ht,Rs=p(),M(N.$$.fragment),Es=p(),ge=y("p"),ge.innerHTML=Ft,Gs=p(),M(R.$$.fragment),Vs=p(),je=y("p"),je.innerHTML=zt,Hs=p(),_e=y("p"),_e.innerHTML=Qt,Fs=p(),M(be.$$.fragment),zs=p(),M(E.$$.fragment),Qs=p(),M(Ue.$$.fragment),Ys=p(),$e=y("p"),$e.innerHTML=Yt,Ss=p(),M(Ze.$$.fragment),Ls=p(),Ie=y("p"),Ie.innerHTML=St,xs=p(),M(ve.$$.fragment),qs=p(),M(Be.$$.fragment),Ds=p(),Ce=y("p"),Ce.innerHTML=Lt,Ps=p(),Xe=y("p"),Xe.innerHTML=xt,Ks=p(),M(ke.$$.fragment),Os=p(),We=y("p"),We.innerHTML=qt,et=p(),Ae=y("p"),Ae.innerHTML=Dt,st=p(),Ne=y("p"),Ne.innerHTML=Pt,tt=p(),M(G.$$.fragment),at=p(),M(V.$$.fragment),lt=p(),Re=y("p"),Re.textContent=Kt,nt=p(),M(Ee.$$.fragment),rt=p(),Ge=y("p"),Ge.innerHTML=Ot,it=p(),M(Ve.$$.fragment),pt=p(),He=y("p"),He.innerHTML=ea,ot=p(),M(H.$$.fragment),ct=p(),M(Fe.$$.fragment),mt=p(),ze=y("p"),ze.innerHTML=sa,Mt=p(),M(Qe.$$.fragment),ft=p(),M(Ye.$$.fragment),dt=p(),Se=y("p"),Se.innerHTML=ta,ht=p(),M(Le.$$.fragment),ut=p(),xe=y("p"),xe.textContent=aa,Tt=p(),M(qe.$$.fragment),yt=p(),Oe=y("p"),this.h()},l(e){const s=ga("svelte-u9bgzb",document.head);t=w(s,"META",{name:!0,content:!0}),s.forEach(l),r=o(e),a=w(e,"P",{}),ha(a).forEach(l),c=o(e),f(i.$$.fragment,e),m=o(e),_=w(e,"P",{"data-svelte-h":!0}),J(_)!=="svelte-1v5u15y"&&(_.innerHTML=Z),j=o(e),b=w(e,"P",{"data-svelte-h":!0}),J(b)!=="svelte-1ww6cgz"&&(b.innerHTML=Pe),F=o(e),v=w(e,"P",{"data-svelte-h":!0}),J(v)!=="svelte-1q7y8zt"&&(v.innerHTML=Ke),es=o(e),f(z.$$.fragment,e),ss=o(e),Q=w(e,"P",{"data-svelte-h":!0}),J(Q)!=="svelte-1alji4a"&&(Q.innerHTML=gt),ts=o(e),Y=w(e,"OL",{"data-svelte-h":!0}),J(Y)!=="svelte-1ssqzhc"&&(Y.innerHTML=jt),as=o(e),S=w(e,"P",{"data-svelte-h":!0}),J(S)!=="svelte-19o6oc2"&&(S.innerHTML=_t),ls=o(e),L=w(e,"P",{"data-svelte-h":!0}),J(L)!=="svelte-l1xjdn"&&(L.innerHTML=bt),ns=o(e),f(C.$$.fragment,e),rs=o(e),x=w(e,"P",{"data-svelte-h":!0}),J(x)!=="svelte-1pxed0w"&&(x.innerHTML=Ut),is=o(e),f(q.$$.fragment,e),ps=o(e),D=w(e,"P",{"data-svelte-h":!0}),J(D)!=="svelte-9cighu"&&(D.innerHTML=$t),os=o(e),f(X.$$.fragment,e),cs=o(e),f(P.$$.fragment,e),ms=o(e),f(K.$$.fragment,e),Ms=o(e),O=w(e,"P",{"data-svelte-h":!0}),J(O)!=="svelte-qw1b7q"&&(O.innerHTML=Zt),fs=o(e),ee=w(e,"P",{"data-svelte-h":!0}),J(ee)!=="svelte-omvjgf"&&(ee.innerHTML=It),ds=o(e),f(k.$$.fragment,e),hs=o(e),se=w(e,"P",{"data-svelte-h":!0}),J(se)!=="svelte-3r1u1f"&&(se.innerHTML=vt),us=o(e),te=w(e,"UL",{"data-svelte-h":!0}),J(te)!=="svelte-7e9i8d"&&(te.innerHTML=Bt),Ts=o(e),ae=w(e,"P",{"data-svelte-h":!0}),J(ae)!=="svelte-mtjeix"&&(ae.innerHTML=Ct),ys=o(e),f(le.$$.fragment,e),ws=o(e),ne=w(e,"P",{"data-svelte-h":!0}),J(ne)!=="svelte-civq6u"&&(ne.innerHTML=Xt),Js=o(e),re=w(e,"P",{"data-svelte-h":!0}),J(re)!=="svelte-13ujenl"&&(re.textContent=kt),gs=o(e),f(ie.$$.fragment,e),js=o(e),pe=w(e,"P",{"data-svelte-h":!0}),J(pe)!=="svelte-1feaoud"&&(pe.innerHTML=Wt),_s=o(e),oe=w(e,"P",{"data-svelte-h":!0}),J(oe)!=="svelte-iuct8l"&&(oe.innerHTML=At),bs=o(e),f(W.$$.fragment,e),Us=o(e),f(A.$$.fragment,e),$s=o(e),f(ce.$$.fragment,e),Zs=o(e),me=w(e,"P",{"data-svelte-h":!0}),J(me)!=="svelte-iafayv"&&(me.innerHTML=Nt),Is=o(e),Me=w(e,"TABLE",{"data-svelte-h":!0}),J(Me)!=="svelte-14rkmec"&&(Me.innerHTML=Rt),vs=o(e),fe=w(e,"P",{"data-svelte-h":!0}),J(fe)!=="svelte-12pze9j"&&(fe.innerHTML=Et),Bs=o(e),f(de.$$.fragment,e),Cs=o(e),f(he.$$.fragment,e),Xs=o(e),ue=w(e,"P",{"data-svelte-h":!0}),J(ue)!=="svelte-1eklbj0"&&(ue.innerHTML=Gt),ks=o(e),Te=w(e,"P",{"data-svelte-h":!0}),J(Te)!=="svelte-ix3yq7"&&(Te.innerHTML=Vt),Ws=o(e),f(ye.$$.fragment,e),As=o(e),f(we.$$.fragment,e),Ns=o(e),Je=w(e,"P",{"data-svelte-h":!0}),J(Je)!=="svelte-1svcyua"&&(Je.innerHTML=Ht),Rs=o(e),f(N.$$.fragment,e),Es=o(e),ge=w(e,"P",{"data-svelte-h":!0}),J(ge)!=="svelte-1n9jedh"&&(ge.innerHTML=Ft),Gs=o(e),f(R.$$.fragment,e),Vs=o(e),je=w(e,"P",{"data-svelte-h":!0}),J(je)!=="svelte-g8vtta"&&(je.innerHTML=zt),Hs=o(e),_e=w(e,"P",{"data-svelte-h":!0}),J(_e)!=="svelte-1w2ffu3"&&(_e.innerHTML=Qt),Fs=o(e),f(be.$$.fragment,e),zs=o(e),f(E.$$.fragment,e),Qs=o(e),f(Ue.$$.fragment,e),Ys=o(e),$e=w(e,"P",{"data-svelte-h":!0}),J($e)!=="svelte-1ls6tfp"&&($e.innerHTML=Yt),Ss=o(e),f(Ze.$$.fragment,e),Ls=o(e),Ie=w(e,"P",{"data-svelte-h":!0}),J(Ie)!=="svelte-1f569s2"&&(Ie.innerHTML=St),xs=o(e),f(ve.$$.fragment,e),qs=o(e),f(Be.$$.fragment,e),Ds=o(e),Ce=w(e,"P",{"data-svelte-h":!0}),J(Ce)!=="svelte-1vgfgwy"&&(Ce.innerHTML=Lt),Ps=o(e),Xe=w(e,"P",{"data-svelte-h":!0}),J(Xe)!=="svelte-1ey6jfv"&&(Xe.innerHTML=xt),Ks=o(e),f(ke.$$.fragment,e),Os=o(e),We=w(e,"P",{"data-svelte-h":!0}),J(We)!=="svelte-1t37z06"&&(We.innerHTML=qt),et=o(e),Ae=w(e,"P",{"data-svelte-h":!0}),J(Ae)!=="svelte-18gvocp"&&(Ae.innerHTML=Dt),st=o(e),Ne=w(e,"P",{"data-svelte-h":!0}),J(Ne)!=="svelte-1mtv13c"&&(Ne.innerHTML=Pt),tt=o(e),f(G.$$.fragment,e),at=o(e),f(V.$$.fragment,e),lt=o(e),Re=w(e,"P",{"data-svelte-h":!0}),J(Re)!=="svelte-193bcdy"&&(Re.textContent=Kt),nt=o(e),f(Ee.$$.fragment,e),rt=o(e),Ge=w(e,"P",{"data-svelte-h":!0}),J(Ge)!=="svelte-1hqueez"&&(Ge.innerHTML=Ot),it=o(e),f(Ve.$$.fragment,e),pt=o(e),He=w(e,"P",{"data-svelte-h":!0}),J(He)!=="svelte-1nj60oe"&&(He.innerHTML=ea),ot=o(e),f(H.$$.fragment,e),ct=o(e),f(Fe.$$.fragment,e),mt=o(e),ze=w(e,"P",{"data-svelte-h":!0}),J(ze)!=="svelte-ho8xjh"&&(ze.innerHTML=sa),Mt=o(e),f(Qe.$$.fragment,e),ft=o(e),f(Ye.$$.fragment,e),dt=o(e),Se=w(e,"P",{"data-svelte-h":!0}),J(Se)!=="svelte-1c0v71w"&&(Se.innerHTML=ta),ht=o(e),f(Le.$$.fragment,e),ut=o(e),xe=w(e,"P",{"data-svelte-h":!0}),J(xe)!=="svelte-1dfz8sx"&&(xe.textContent=aa),Tt=o(e),f(qe.$$.fragment,e),yt=o(e),Oe=w(e,"P",{}),ha(Oe).forEach(l),this.h()},h(){ua(t,"name","hf:doc:metadata"),ua(t,"content",Sa)},m(e,s){ja(document.head,t),n(e,r,s),n(e,a,s),n(e,c,s),d(i,e,s),n(e,m,s),n(e,_,s),n(e,j,s),n(e,b,s),n(e,F,s),n(e,v,s),n(e,es,s),d(z,e,s),n(e,ss,s),n(e,Q,s),n(e,ts,s),n(e,Y,s),n(e,as,s),n(e,S,s),n(e,ls,s),n(e,L,s),n(e,ns,s),d(C,e,s),n(e,rs,s),n(e,x,s),n(e,is,s),d(q,e,s),n(e,ps,s),n(e,D,s),n(e,os,s),d(X,e,s),n(e,cs,s),d(P,e,s),n(e,ms,s),d(K,e,s),n(e,Ms,s),n(e,O,s),n(e,fs,s),n(e,ee,s),n(e,ds,s),d(k,e,s),n(e,hs,s),n(e,se,s),n(e,us,s),n(e,te,s),n(e,Ts,s),n(e,ae,s),n(e,ys,s),d(le,e,s),n(e,ws,s),n(e,ne,s),n(e,Js,s),n(e,re,s),n(e,gs,s),d(ie,e,s),n(e,js,s),n(e,pe,s),n(e,_s,s),n(e,oe,s),n(e,bs,s),d(W,e,s),n(e,Us,s),d(A,e,s),n(e,$s,s),d(ce,e,s),n(e,Zs,s),n(e,me,s),n(e,Is,s),n(e,Me,s),n(e,vs,s),n(e,fe,s),n(e,Bs,s),d(de,e,s),n(e,Cs,s),d(he,e,s),n(e,Xs,s),n(e,ue,s),n(e,ks,s),n(e,Te,s),n(e,Ws,s),d(ye,e,s),n(e,As,s),d(we,e,s),n(e,Ns,s),n(e,Je,s),n(e,Rs,s),d(N,e,s),n(e,Es,s),n(e,ge,s),n(e,Gs,s),d(R,e,s),n(e,Vs,s),n(e,je,s),n(e,Hs,s),n(e,_e,s),n(e,Fs,s),d(be,e,s),n(e,zs,s),d(E,e,s),n(e,Qs,s),d(Ue,e,s),n(e,Ys,s),n(e,$e,s),n(e,Ss,s),d(Ze,e,s),n(e,Ls,s),n(e,Ie,s),n(e,xs,s),d(ve,e,s),n(e,qs,s),d(Be,e,s),n(e,Ds,s),n(e,Ce,s),n(e,Ps,s),n(e,Xe,s),n(e,Ks,s),d(ke,e,s),n(e,Os,s),n(e,We,s),n(e,et,s),n(e,Ae,s),n(e,st,s),n(e,Ne,s),n(e,tt,s),d(G,e,s),n(e,at,s),d(V,e,s),n(e,lt,s),n(e,Re,s),n(e,nt,s),d(Ee,e,s),n(e,rt,s),n(e,Ge,s),n(e,it,s),d(Ve,e,s),n(e,pt,s),n(e,He,s),n(e,ot,s),d(H,e,s),n(e,ct,s),d(Fe,e,s),n(e,mt,s),n(e,ze,s),n(e,Mt,s),d(Qe,e,s),n(e,ft,s),d(Ye,e,s),n(e,dt,s),n(e,Se,s),n(e,ht,s),d(Le,e,s),n(e,ut,s),n(e,xe,s),n(e,Tt,s),d(qe,e,s),n(e,yt,s),n(e,Oe,s),wt=!0},p(e,[s]){const la={};s&2&&(la.$$scope={dirty:s,ctx:e}),C.$set(la);const na={};s&2&&(na.$$scope={dirty:s,ctx:e}),X.$set(na);const ra={};s&2&&(ra.$$scope={dirty:s,ctx:e}),k.$set(ra);const ia={};s&2&&(ia.$$scope={dirty:s,ctx:e}),W.$set(ia);const pa={};s&2&&(pa.$$scope={dirty:s,ctx:e}),A.$set(pa);const oa={};s&2&&(oa.$$scope={dirty:s,ctx:e}),N.$set(oa);const ca={};s&2&&(ca.$$scope={dirty:s,ctx:e}),R.$set(ca);const ma={};s&2&&(ma.$$scope={dirty:s,ctx:e}),E.$set(ma);const Ma={};s&2&&(Ma.$$scope={dirty:s,ctx:e}),G.$set(Ma);const fa={};s&2&&(fa.$$scope={dirty:s,ctx:e}),V.$set(fa);const da={};s&2&&(da.$$scope={dirty:s,ctx:e}),H.$set(da)},i(e){wt||(h(i.$$.fragment,e),h(z.$$.fragment,e),h(C.$$.fragment,e),h(q.$$.fragment,e),h(X.$$.fragment,e),h(P.$$.fragment,e),h(K.$$.fragment,e),h(k.$$.fragment,e),h(le.$$.fragment,e),h(ie.$$.fragment,e),h(W.$$.fragment,e),h(A.$$.fragment,e),h(ce.$$.fragment,e),h(de.$$.fragment,e),h(he.$$.fragment,e),h(ye.$$.fragment,e),h(we.$$.fragment,e),h(N.$$.fragment,e),h(R.$$.fragment,e),h(be.$$.fragment,e),h(E.$$.fragment,e),h(Ue.$$.fragment,e),h(Ze.$$.fragment,e),h(ve.$$.fragment,e),h(Be.$$.fragment,e),h(ke.$$.fragment,e),h(G.$$.fragment,e),h(V.$$.fragment,e),h(Ee.$$.fragment,e),h(Ve.$$.fragment,e),h(H.$$.fragment,e),h(Fe.$$.fragment,e),h(Qe.$$.fragment,e),h(Ye.$$.fragment,e),h(Le.$$.fragment,e),h(qe.$$.fragment,e),wt=!0)},o(e){u(i.$$.fragment,e),u(z.$$.fragment,e),u(C.$$.fragment,e),u(q.$$.fragment,e),u(X.$$.fragment,e),u(P.$$.fragment,e),u(K.$$.fragment,e),u(k.$$.fragment,e),u(le.$$.fragment,e),u(ie.$$.fragment,e),u(W.$$.fragment,e),u(A.$$.fragment,e),u(ce.$$.fragment,e),u(de.$$.fragment,e),u(he.$$.fragment,e),u(ye.$$.fragment,e),u(we.$$.fragment,e),u(N.$$.fragment,e),u(R.$$.fragment,e),u(be.$$.fragment,e),u(E.$$.fragment,e),u(Ue.$$.fragment,e),u(Ze.$$.fragment,e),u(ve.$$.fragment,e),u(Be.$$.fragment,e),u(ke.$$.fragment,e),u(G.$$.fragment,e),u(V.$$.fragment,e),u(Ee.$$.fragment,e),u(Ve.$$.fragment,e),u(H.$$.fragment,e),u(Fe.$$.fragment,e),u(Qe.$$.fragment,e),u(Ye.$$.fragment,e),u(Le.$$.fragment,e),u(qe.$$.fragment,e),wt=!1},d(e){e&&(l(r),l(a),l(c),l(m),l(_),l(j),l(b),l(F),l(v),l(es),l(ss),l(Q),l(ts),l(Y),l(as),l(S),l(ls),l(L),l(ns),l(rs),l(x),l(is),l(ps),l(D),l(os),l(cs),l(ms),l(Ms),l(O),l(fs),l(ee),l(ds),l(hs),l(se),l(us),l(te),l(Ts),l(ae),l(ys),l(ws),l(ne),l(Js),l(re),l(gs),l(js),l(pe),l(_s),l(oe),l(bs),l(Us),l($s),l(Zs),l(me),l(Is),l(Me),l(vs),l(fe),l(Bs),l(Cs),l(Xs),l(ue),l(ks),l(Te),l(Ws),l(As),l(Ns),l(Je),l(Rs),l(Es),l(ge),l(Gs),l(Vs),l(je),l(Hs),l(_e),l(Fs),l(zs),l(Qs),l(Ys),l($e),l(Ss),l(Ls),l(Ie),l(xs),l(qs),l(Ds),l(Ce),l(Ps),l(Xe),l(Ks),l(Os),l(We),l(et),l(Ae),l(st),l(Ne),l(tt),l(at),l(lt),l(Re),l(nt),l(rt),l(Ge),l(it),l(pt),l(He),l(ot),l(ct),l(mt),l(ze),l(Mt),l(ft),l(dt),l(Se),l(ht),l(ut),l(xe),l(Tt),l(yt),l(Oe)),l(t),T(i,e),T(z,e),T(C,e),T(q,e),T(X,e),T(P,e),T(K,e),T(k,e),T(le,e),T(ie,e),T(W,e),T(A,e),T(ce,e),T(de,e),T(he,e),T(ye,e),T(we,e),T(N,e),T(R,e),T(be,e),T(E,e),T(Ue,e),T(Ze,e),T(ve,e),T(Be,e),T(ke,e),T(G,e),T(V,e),T(Ee,e),T(Ve,e),T(H,e),T(Fe,e),T(Qe,e),T(Ye,e),T(Le,e),T(qe,e)}}}const Sa='{"title":"Trainer","local":"trainer","sections":[{"title":"Checkpoints","local":"checkpoints","sections":[],"depth":2},{"title":"Logging","local":"logging","sections":[],"depth":2},{"title":"Customize","local":"customize","sections":[{"title":"Callbacks","local":"callbacks","sections":[],"depth":3}],"depth":2},{"title":"Accelerate","local":"accelerate","sections":[],"depth":2},{"title":"Optimizations","local":"optimizations","sections":[{"title":"torch.compile","local":"torchcompile","sections":[],"depth":3},{"title":"GaLore","local":"galore","sections":[],"depth":3},{"title":"Liger","local":"liger","sections":[],"depth":3},{"title":"NEFTune","local":"neftune","sections":[],"depth":3}],"depth":2}],"depth":1}';function La(g){return ya(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class el extends wa{constructor(t){super(),Ja(this,t,La,Ya,Ta,{})}}export{el as component};
