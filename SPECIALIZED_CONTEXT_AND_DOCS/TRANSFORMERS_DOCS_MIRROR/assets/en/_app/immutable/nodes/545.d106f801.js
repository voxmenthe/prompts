import{s as et,o as st,n as Os}from"../chunks/scheduler.18a86fab.js";import{S as tt,i as at,g as p,s as l,r,A as lt,h as i,f as t,c as n,j as Ds,u as c,x as o,k as Ps,y as nt,a,v as m,d as h,t as u,w as d}from"../chunks/index.98837b22.js";import{T as Ks}from"../chunks/Tip.77304350.js";import{C as f}from"../chunks/CodeBlock.8d0c2e8a.js";import{D as pt}from"../chunks/DocNotebookDropdown.a04a6b2a.js";import{H as we,E as it}from"../chunks/getInferenceSnippets.06c2775f.js";function ot(be){let y,M='If you arenâ€™t familiar with finetuning a model with the <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a>, take a look at the basic tutorial <a href="../training#train-with-pytorch-trainer">here</a>!';return{c(){y=p("p"),y.innerHTML=M},l(g){y=i(g,"P",{"data-svelte-h":!0}),o(y)!=="svelte-p303g8"&&(y.innerHTML=M)},m(g,b){a(g,y,b)},p:Os,d(g){g&&t(y)}}}function rt(be){let y,M=`For a more in-depth example of how to finetune a model for multiple choice, take a look at the corresponding
<a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb" rel="nofollow">PyTorch notebook</a>.`;return{c(){y=p("p"),y.innerHTML=M},l(g){y=i(g,"P",{"data-svelte-h":!0}),o(y)!=="svelte-t46659"&&(y.innerHTML=M)},m(g,b){a(g,y,b)},p:Os,d(g){g&&t(y)}}}function ct(be){let y,M,g,b,T,Te,J,Je,U,Ts="A multiple choice task is similar to question answering, except several candidate answers are provided along with a context and the model is trained to select the correct answer.",Ue,$,Js="This guide will show you how to:",$e,C,Us='<li>Finetune <a href="https://huggingface.co/google-bert/bert-base-uncased" rel="nofollow">BERT</a> on the <code>regular</code> configuration of the <a href="https://huggingface.co/datasets/swag" rel="nofollow">SWAG</a> dataset to select the best answer given multiple options and some context.</li> <li>Use your finetuned model for inference.</li>',Ce,k,$s="Before you begin, make sure you have all the necessary libraries installed:",ke,Z,Ze,v,Cs="We encourage you to login to your Hugging Face account so you can upload and share your model with the community. When prompted, enter your token to login:",ve,_,_e,W,We,x,ks="Start by loading the <code>regular</code> configuration of the SWAG dataset from the ðŸ¤— Datasets library:",xe,I,Ie,G,Zs="Then take a look at an example:",Ge,B,Be,R,vs="While it looks like there are a lot of fields here, it is actually pretty straightforward:",Re,X,_s="<li><code>sent1</code> and <code>sent2</code>: these fields show how a sentence starts, and if you put the two together, you get the <code>startphrase</code> field.</li> <li><code>ending</code>: suggests a possible ending for how a sentence can end, but only one of them is correct.</li> <li><code>label</code>: identifies the correct sentence ending.</li>",Xe,V,Ve,z,Ws="The next step is to load a BERT tokenizer to process the sentence starts and the four possible endings:",ze,Y,Ye,F,xs="The preprocessing function you want to create needs to:",Fe,H,Is="<li>Make four copies of the <code>sent1</code> field and combine each of them with <code>sent2</code> to recreate how a sentence starts.</li> <li>Combine <code>sent2</code> with each of the four possible sentence endings.</li> <li>Flatten these two lists so you can tokenize them, and then unflatten them afterward so each example has a corresponding <code>input_ids</code>, <code>attention_mask</code>, and <code>labels</code> field.</li>",He,N,Ne,Q,Gs='To apply the preprocessing function over the entire dataset, use ðŸ¤— Datasets <a href="https://huggingface.co/docs/datasets/v4.1.0/en/package_reference/main_classes#datasets.Dataset.map" rel="nofollow">map</a> method. You can speed up the <code>map</code> function by setting <code>batched=True</code> to process multiple elements of the dataset at once:',Qe,E,Ee,A,Bs='To create a batch of examples, itâ€™s more efficient to <em>dynamically pad</em> the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length. <a href="/docs/transformers/v4.56.2/en/main_classes/data_collator#transformers.DataCollatorForMultipleChoice">DataCollatorForMultipleChoice</a> flattens all the model inputs, applies padding, and then unflattens the results.',Ae,q,qe,S,Se,L,Rs='Including a metric during training is often helpful for evaluating your modelâ€™s performance. You can quickly load a evaluation method with the ðŸ¤— <a href="https://huggingface.co/docs/evaluate/index" rel="nofollow">Evaluate</a> library. For this task, load the <a href="https://huggingface.co/spaces/evaluate-metric/accuracy" rel="nofollow">accuracy</a> metric (see the ðŸ¤— Evaluate <a href="https://huggingface.co/docs/evaluate/a_quick_tour" rel="nofollow">quick tour</a> to learn more about how to load and compute a metric):',Le,D,De,P,Xs='Then create a function that passes your predictions and labels to <a href="https://huggingface.co/docs/evaluate/v0.4.5/en/package_reference/main_classes#evaluate.EvaluationModule.compute" rel="nofollow">compute</a> to calculate the accuracy:',Pe,K,Ke,O,Vs="Your <code>compute_metrics</code> function is ready to go now, and youâ€™ll return to it when you setup your training.",Oe,ee,es,w,ss,se,zs='Youâ€™re ready to start training your model now! Load BERT with <a href="/docs/transformers/v4.56.2/en/model_doc/auto#transformers.AutoModelForMultipleChoice">AutoModelForMultipleChoice</a>:',ts,te,as,ae,Ys="At this point, only three steps remain:",ls,le,Fs='<li>Define your training hyperparameters in <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>. The only required parameter is <code>output_dir</code> which specifies where to save your model. Youâ€™ll push this model to the Hub by setting <code>push_to_hub=True</code> (you need to be signed in to Hugging Face to upload your model). At the end of each epoch, the <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> will evaluate the accuracy and save the training checkpoint.</li> <li>Pass the training arguments to <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> along with the model, dataset, tokenizer, data collator, and <code>compute_metrics</code> function.</li> <li>Call <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer.train">train()</a> to finetune your model.</li>',ns,ne,ps,pe,Hs='Once training is completed, share your model to the Hub with the <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer.push_to_hub">push_to_hub()</a> method so everyone can use your model:',is,ie,os,j,rs,oe,cs,re,Ns="Great, now that youâ€™ve finetuned a model, you can use it for inference!",ms,ce,Qs="Come up with some text and two candidate answers:",hs,me,us,he,Es="Tokenize each prompt and candidate answer pair and return PyTorch tensors. You should also create some <code>labels</code>:",ds,ue,ys,de,As="Pass your inputs and labels to the model and return the <code>logits</code>:",gs,ye,fs,ge,qs="Get the class with the highest probability:",Ms,fe,bs,Me,ws,je,js;return T=new we({props:{title:"Multiple choice",local:"multiple-choice",headingTag:"h1"}}),J=new pt({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/multiple_choice.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/multiple_choice.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/tensorflow/multiple_choice.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/multiple_choice.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/multiple_choice.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/tensorflow/multiple_choice.ipynb"}]}}),Z=new f({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRyYW5zZm9ybWVycyUyMGRhdGFzZXRzJTIwZXZhbHVhdGU=",highlighted:"pip install transformers datasets evaluate",wrap:!1}}),_=new f({props:{code:"ZnJvbSUyMGh1Z2dpbmdmYWNlX2h1YiUyMGltcG9ydCUyMG5vdGVib29rX2xvZ2luJTBBJTBBbm90ZWJvb2tfbG9naW4oKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

<span class="hljs-meta">&gt;&gt;&gt; </span>notebook_login()`,wrap:!1}}),W=new we({props:{title:"Load SWAG dataset",local:"load-swag-dataset",headingTag:"h2"}}),I=new f({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBJTBBc3dhZyUyMCUzRCUyMGxvYWRfZGF0YXNldCglMjJzd2FnJTIyJTJDJTIwJTIycmVndWxhciUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>swag = load_dataset(<span class="hljs-string">&quot;swag&quot;</span>, <span class="hljs-string">&quot;regular&quot;</span>)`,wrap:!1}}),B=new f({props:{code:"c3dhZyU1QiUyMnRyYWluJTIyJTVEJTVCMCU1RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>swag[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;ending0&#x27;</span>: <span class="hljs-string">&#x27;passes by walking down the street playing their instruments.&#x27;</span>,
 <span class="hljs-string">&#x27;ending1&#x27;</span>: <span class="hljs-string">&#x27;has heard approaching them.&#x27;</span>,
 <span class="hljs-string">&#x27;ending2&#x27;</span>: <span class="hljs-string">&quot;arrives and they&#x27;re outside dancing and asleep.&quot;</span>,
 <span class="hljs-string">&#x27;ending3&#x27;</span>: <span class="hljs-string">&#x27;turns the lead singer watches the performance.&#x27;</span>,
 <span class="hljs-string">&#x27;fold-ind&#x27;</span>: <span class="hljs-string">&#x27;3416&#x27;</span>,
 <span class="hljs-string">&#x27;gold-source&#x27;</span>: <span class="hljs-string">&#x27;gold&#x27;</span>,
 <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;sent1&#x27;</span>: <span class="hljs-string">&#x27;Members of the procession walk down the street holding small horn brass instruments.&#x27;</span>,
 <span class="hljs-string">&#x27;sent2&#x27;</span>: <span class="hljs-string">&#x27;A drum line&#x27;</span>,
 <span class="hljs-string">&#x27;startphrase&#x27;</span>: <span class="hljs-string">&#x27;Members of the procession walk down the street holding small horn brass instruments. A drum line&#x27;</span>,
 <span class="hljs-string">&#x27;video-id&#x27;</span>: <span class="hljs-string">&#x27;anetv_jkn6uvmqwh4&#x27;</span>}`,wrap:!1}}),V=new we({props:{title:"Preprocess",local:"preprocess",headingTag:"h2"}}),Y=new f({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJnb29nbGUtYmVydCUyRmJlcnQtYmFzZS11bmNhc2VkJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-uncased&quot;</span>)`,wrap:!1}}),N=new f({props:{code:"ZW5kaW5nX25hbWVzJTIwJTNEJTIwJTVCJTIyZW5kaW5nMCUyMiUyQyUyMCUyMmVuZGluZzElMjIlMkMlMjAlMjJlbmRpbmcyJTIyJTJDJTIwJTIyZW5kaW5nMyUyMiU1RCUwQSUwQSUwQWRlZiUyMHByZXByb2Nlc3NfZnVuY3Rpb24oZXhhbXBsZXMpJTNBJTBBJTIwJTIwJTIwJTIwZmlyc3Rfc2VudGVuY2VzJTIwJTNEJTIwJTVCJTVCY29udGV4dCU1RCUyMColMjA0JTIwZm9yJTIwY29udGV4dCUyMGluJTIwZXhhbXBsZXMlNUIlMjJzZW50MSUyMiU1RCU1RCUwQSUyMCUyMCUyMCUyMHF1ZXN0aW9uX2hlYWRlcnMlMjAlM0QlMjBleGFtcGxlcyU1QiUyMnNlbnQyJTIyJTVEJTBBJTIwJTIwJTIwJTIwc2Vjb25kX3NlbnRlbmNlcyUyMCUzRCUyMCU1QiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCU1QmYlMjIlN0JoZWFkZXIlN0QlMjAlN0JleGFtcGxlcyU1QmVuZCU1RCU1QmklNUQlN0QlMjIlMjBmb3IlMjBlbmQlMjBpbiUyMGVuZGluZ19uYW1lcyU1RCUyMGZvciUyMGklMkMlMjBoZWFkZXIlMjBpbiUyMGVudW1lcmF0ZShxdWVzdGlvbl9oZWFkZXJzKSUwQSUyMCUyMCUyMCUyMCU1RCUwQSUwQSUyMCUyMCUyMCUyMGZpcnN0X3NlbnRlbmNlcyUyMCUzRCUyMHN1bShmaXJzdF9zZW50ZW5jZXMlMkMlMjAlNUIlNUQpJTBBJTIwJTIwJTIwJTIwc2Vjb25kX3NlbnRlbmNlcyUyMCUzRCUyMHN1bShzZWNvbmRfc2VudGVuY2VzJTJDJTIwJTVCJTVEKSUwQSUwQSUyMCUyMCUyMCUyMHRva2VuaXplZF9leGFtcGxlcyUyMCUzRCUyMHRva2VuaXplcihmaXJzdF9zZW50ZW5jZXMlMkMlMjBzZWNvbmRfc2VudGVuY2VzJTJDJTIwdHJ1bmNhdGlvbiUzRFRydWUpJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwJTdCayUzQSUyMCU1QnYlNUJpJTIwJTNBJTIwaSUyMCUyQiUyMDQlNUQlMjBmb3IlMjBpJTIwaW4lMjByYW5nZSgwJTJDJTIwbGVuKHYpJTJDJTIwNCklNUQlMjBmb3IlMjBrJTJDJTIwdiUyMGluJTIwdG9rZW5pemVkX2V4YW1wbGVzLml0ZW1zKCklN0Q=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>ending_names = [<span class="hljs-string">&quot;ending0&quot;</span>, <span class="hljs-string">&quot;ending1&quot;</span>, <span class="hljs-string">&quot;ending2&quot;</span>, <span class="hljs-string">&quot;ending3&quot;</span>]


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    first_sentences = [[context] * <span class="hljs-number">4</span> <span class="hljs-keyword">for</span> context <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;sent1&quot;</span>]]
<span class="hljs-meta">... </span>    question_headers = examples[<span class="hljs-string">&quot;sent2&quot;</span>]
<span class="hljs-meta">... </span>    second_sentences = [
<span class="hljs-meta">... </span>        [<span class="hljs-string">f&quot;<span class="hljs-subst">{header}</span> <span class="hljs-subst">{examples[end][i]}</span>&quot;</span> <span class="hljs-keyword">for</span> end <span class="hljs-keyword">in</span> ending_names] <span class="hljs-keyword">for</span> i, header <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(question_headers)
<span class="hljs-meta">... </span>    ]

<span class="hljs-meta">... </span>    first_sentences = <span class="hljs-built_in">sum</span>(first_sentences, [])
<span class="hljs-meta">... </span>    second_sentences = <span class="hljs-built_in">sum</span>(second_sentences, [])

<span class="hljs-meta">... </span>    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=<span class="hljs-literal">True</span>)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> {k: [v[i : i + <span class="hljs-number">4</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(v), <span class="hljs-number">4</span>)] <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> tokenized_examples.items()}`,wrap:!1}}),E=new f({props:{code:"dG9rZW5pemVkX3N3YWclMjAlM0QlMjBzd2FnLm1hcChwcmVwcm9jZXNzX2Z1bmN0aW9uJTJDJTIwYmF0Y2hlZCUzRFRydWUp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_swag = swag.<span class="hljs-built_in">map</span>(preprocess_function, batched=<span class="hljs-literal">True</span>)',wrap:!1}}),q=new f({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMERhdGFDb2xsYXRvckZvck11bHRpcGxlQ2hvaWNlJTBBY29sbGF0b3IlMjAlM0QlMjBEYXRhQ29sbGF0b3JGb3JNdWx0aXBsZUNob2ljZSh0b2tlbml6ZXIlM0R0b2tlbml6ZXIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForMultipleChoice
<span class="hljs-meta">&gt;&gt;&gt; </span>collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)`,wrap:!1}}),S=new we({props:{title:"Evaluate",local:"evaluate",headingTag:"h2"}}),D=new f({props:{code:"aW1wb3J0JTIwZXZhbHVhdGUlMEElMEFhY2N1cmFjeSUyMCUzRCUyMGV2YWx1YXRlLmxvYWQoJTIyYWNjdXJhY3klMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> evaluate

<span class="hljs-meta">&gt;&gt;&gt; </span>accuracy = evaluate.load(<span class="hljs-string">&quot;accuracy&quot;</span>)`,wrap:!1}}),K=new f({props:{code:"aW1wb3J0JTIwbnVtcHklMjBhcyUyMG5wJTBBJTBBJTBBZGVmJTIwY29tcHV0ZV9tZXRyaWNzKGV2YWxfcHJlZCklM0ElMEElMjAlMjAlMjAlMjBwcmVkaWN0aW9ucyUyQyUyMGxhYmVscyUyMCUzRCUyMGV2YWxfcHJlZCUwQSUyMCUyMCUyMCUyMHByZWRpY3Rpb25zJTIwJTNEJTIwbnAuYXJnbWF4KHByZWRpY3Rpb25zJTJDJTIwYXhpcyUzRDEpJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwYWNjdXJhY3kuY29tcHV0ZShwcmVkaWN0aW9ucyUzRHByZWRpY3Rpb25zJTJDJTIwcmVmZXJlbmNlcyUzRGxhYmVscyk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):
<span class="hljs-meta">... </span>    predictions, labels = eval_pred
<span class="hljs-meta">... </span>    predictions = np.argmax(predictions, axis=<span class="hljs-number">1</span>)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> accuracy.compute(predictions=predictions, references=labels)`,wrap:!1}}),ee=new we({props:{title:"Train",local:"train",headingTag:"h2"}}),w=new Ks({props:{$$slots:{default:[ot]},$$scope:{ctx:be}}}),te=new f({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvck11bHRpcGxlQ2hvaWNlJTJDJTIwVHJhaW5pbmdBcmd1bWVudHMlMkMlMjBUcmFpbmVyJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JNdWx0aXBsZUNob2ljZS5mcm9tX3ByZXRyYWluZWQoJTIyZ29vZ2xlLWJlcnQlMkZiZXJ0LWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForMultipleChoice, TrainingArguments, Trainer

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-uncased&quot;</span>)`,wrap:!1}}),ne=new f({props:{code:"dHJhaW5pbmdfYXJncyUyMCUzRCUyMFRyYWluaW5nQXJndW1lbnRzKCUwQSUyMCUyMCUyMCUyMG91dHB1dF9kaXIlM0QlMjJteV9hd2Vzb21lX3N3YWdfbW9kZWwlMjIlMkMlMEElMjAlMjAlMjAlMjBldmFsX3N0cmF0ZWd5JTNEJTIyZXBvY2glMjIlMkMlMEElMjAlMjAlMjAlMjBzYXZlX3N0cmF0ZWd5JTNEJTIyZXBvY2glMjIlMkMlMEElMjAlMjAlMjAlMjBsb2FkX2Jlc3RfbW9kZWxfYXRfZW5kJTNEVHJ1ZSUyQyUwQSUyMCUyMCUyMCUyMGxlYXJuaW5nX3JhdGUlM0Q1ZS01JTJDJTBBJTIwJTIwJTIwJTIwcGVyX2RldmljZV90cmFpbl9iYXRjaF9zaXplJTNEMTYlMkMlMEElMjAlMjAlMjAlMjBwZXJfZGV2aWNlX2V2YWxfYmF0Y2hfc2l6ZSUzRDE2JTJDJTBBJTIwJTIwJTIwJTIwbnVtX3RyYWluX2Vwb2NocyUzRDMlMkMlMEElMjAlMjAlMjAlMjB3ZWlnaHRfZGVjYXklM0QwLjAxJTJDJTBBJTIwJTIwJTIwJTIwcHVzaF90b19odWIlM0RUcnVlJTJDJTBBKSUwQSUwQXRyYWluZXIlMjAlM0QlMjBUcmFpbmVyKCUwQSUyMCUyMCUyMCUyMG1vZGVsJTNEbW9kZWwlMkMlMEElMjAlMjAlMjAlMjBhcmdzJTNEdHJhaW5pbmdfYXJncyUyQyUwQSUyMCUyMCUyMCUyMHRyYWluX2RhdGFzZXQlM0R0b2tlbml6ZWRfc3dhZyU1QiUyMnRyYWluJTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwZXZhbF9kYXRhc2V0JTNEdG9rZW5pemVkX3N3YWclNUIlMjJ2YWxpZGF0aW9uJTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwcHJvY2Vzc2luZ19jbGFzcyUzRHRva2VuaXplciUyQyUwQSUyMCUyMCUyMCUyMGRhdGFfY29sbGF0b3IlM0Rjb2xsYXRvciUyQyUwQSUyMCUyMCUyMCUyMGNvbXB1dGVfbWV0cmljcyUzRGNvbXB1dGVfbWV0cmljcyUyQyUwQSklMEElMEF0cmFpbmVyLnRyYWluKCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;my_awesome_swag_model&quot;</span>,
<span class="hljs-meta">... </span>    eval_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
<span class="hljs-meta">... </span>    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
<span class="hljs-meta">... </span>    load_best_model_at_end=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    learning_rate=<span class="hljs-number">5e-5</span>,
<span class="hljs-meta">... </span>    per_device_train_batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    per_device_eval_batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    num_train_epochs=<span class="hljs-number">3</span>,
<span class="hljs-meta">... </span>    weight_decay=<span class="hljs-number">0.01</span>,
<span class="hljs-meta">... </span>    push_to_hub=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=tokenized_swag[<span class="hljs-string">&quot;train&quot;</span>],
<span class="hljs-meta">... </span>    eval_dataset=tokenized_swag[<span class="hljs-string">&quot;validation&quot;</span>],
<span class="hljs-meta">... </span>    processing_class=tokenizer,
<span class="hljs-meta">... </span>    data_collator=collator,
<span class="hljs-meta">... </span>    compute_metrics=compute_metrics,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()`,wrap:!1}}),ie=new f({props:{code:"dHJhaW5lci5wdXNoX3RvX2h1Yigp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.push_to_hub()',wrap:!1}}),j=new Ks({props:{$$slots:{default:[rt]},$$scope:{ctx:be}}}),oe=new we({props:{title:"Inference",local:"inference",headingTag:"h2"}}),me=new f({props:{code:"cHJvbXB0JTIwJTNEJTIwJTIyRnJhbmNlJTIwaGFzJTIwYSUyMGJyZWFkJTIwbGF3JTJDJTIwTGUlMjBEJUMzJUE5Y3JldCUyMFBhaW4lMkMlMjB3aXRoJTIwc3RyaWN0JTIwcnVsZXMlMjBvbiUyMHdoYXQlMjBpcyUyMGFsbG93ZWQlMjBpbiUyMGElMjB0cmFkaXRpb25hbCUyMGJhZ3VldHRlLiUyMiUwQWNhbmRpZGF0ZTElMjAlM0QlMjAlMjJUaGUlMjBsYXclMjBkb2VzJTIwbm90JTIwYXBwbHklMjB0byUyMGNyb2lzc2FudHMlMjBhbmQlMjBicmlvY2hlLiUyMiUwQWNhbmRpZGF0ZTIlMjAlM0QlMjAlMjJUaGUlMjBsYXclMjBhcHBsaWVzJTIwdG8lMjBiYWd1ZXR0ZXMuJTIy",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>prompt = <span class="hljs-string">&quot;France has a bread law, Le DÃ©cret Pain, with strict rules on what is allowed in a traditional baguette.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>candidate1 = <span class="hljs-string">&quot;The law does not apply to croissants and brioche.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>candidate2 = <span class="hljs-string">&quot;The law applies to baguettes.&quot;</span>`,wrap:!1}}),ue=new f({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJ1c2VybmFtZSUyRm15X2F3ZXNvbWVfc3dhZ19tb2RlbCUyMiklMEFpbnB1dHMlMjAlM0QlMjB0b2tlbml6ZXIoJTVCJTVCcHJvbXB0JTJDJTIwY2FuZGlkYXRlMSU1RCUyQyUyMCU1QnByb21wdCUyQyUyMGNhbmRpZGF0ZTIlNUQlNUQlMkMlMjByZXR1cm5fdGVuc29ycyUzRCUyMnB0JTIyJTJDJTIwcGFkZGluZyUzRFRydWUpJTBBbGFiZWxzJTIwJTNEJTIwdG9yY2gudGVuc29yKDApLnVuc3F1ZWV6ZSgwKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;username/my_awesome_swag_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer([[prompt, candidate1], [prompt, candidate2]], return_tensors=<span class="hljs-string">&quot;pt&quot;</span>, padding=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>labels = torch.tensor(<span class="hljs-number">0</span>).unsqueeze(<span class="hljs-number">0</span>)`,wrap:!1}}),ye=new f({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvck11bHRpcGxlQ2hvaWNlJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JNdWx0aXBsZUNob2ljZS5mcm9tX3ByZXRyYWluZWQoJTIydXNlcm5hbWUlMkZteV9hd2Vzb21lX3N3YWdfbW9kZWwlMjIpJTBBb3V0cHV0cyUyMCUzRCUyMG1vZGVsKCoqJTdCayUzQSUyMHYudW5zcXVlZXplKDApJTIwZm9yJTIwayUyQyUyMHYlMjBpbiUyMGlucHV0cy5pdGVtcygpJTdEJTJDJTIwbGFiZWxzJTNEbGFiZWxzKSUwQWxvZ2l0cyUyMCUzRCUyMG91dHB1dHMubG9naXRz",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;username/my_awesome_swag_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**{k: v.unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> inputs.items()}, labels=labels)
<span class="hljs-meta">&gt;&gt;&gt; </span>logits = outputs.logits`,wrap:!1}}),fe=new f({props:{code:"cHJlZGljdGVkX2NsYXNzJTIwJTNEJTIwbG9naXRzLmFyZ21heCgpLml0ZW0oKSUwQXByZWRpY3RlZF9jbGFzcw==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_class = logits.argmax().item()
<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_class
<span class="hljs-number">0</span>`,wrap:!1}}),Me=new it({props:{source:"https://github.com/huggingface/transformers/blob/main/docs/source/en/tasks/multiple_choice.md"}}),{c(){y=p("meta"),M=l(),g=p("p"),b=l(),r(T.$$.fragment),Te=l(),r(J.$$.fragment),Je=l(),U=p("p"),U.textContent=Ts,Ue=l(),$=p("p"),$.textContent=Js,$e=l(),C=p("ol"),C.innerHTML=Us,Ce=l(),k=p("p"),k.textContent=$s,ke=l(),r(Z.$$.fragment),Ze=l(),v=p("p"),v.textContent=Cs,ve=l(),r(_.$$.fragment),_e=l(),r(W.$$.fragment),We=l(),x=p("p"),x.innerHTML=ks,xe=l(),r(I.$$.fragment),Ie=l(),G=p("p"),G.textContent=Zs,Ge=l(),r(B.$$.fragment),Be=l(),R=p("p"),R.textContent=vs,Re=l(),X=p("ul"),X.innerHTML=_s,Xe=l(),r(V.$$.fragment),Ve=l(),z=p("p"),z.textContent=Ws,ze=l(),r(Y.$$.fragment),Ye=l(),F=p("p"),F.textContent=xs,Fe=l(),H=p("ol"),H.innerHTML=Is,He=l(),r(N.$$.fragment),Ne=l(),Q=p("p"),Q.innerHTML=Gs,Qe=l(),r(E.$$.fragment),Ee=l(),A=p("p"),A.innerHTML=Bs,Ae=l(),r(q.$$.fragment),qe=l(),r(S.$$.fragment),Se=l(),L=p("p"),L.innerHTML=Rs,Le=l(),r(D.$$.fragment),De=l(),P=p("p"),P.innerHTML=Xs,Pe=l(),r(K.$$.fragment),Ke=l(),O=p("p"),O.innerHTML=Vs,Oe=l(),r(ee.$$.fragment),es=l(),r(w.$$.fragment),ss=l(),se=p("p"),se.innerHTML=zs,ts=l(),r(te.$$.fragment),as=l(),ae=p("p"),ae.textContent=Ys,ls=l(),le=p("ol"),le.innerHTML=Fs,ns=l(),r(ne.$$.fragment),ps=l(),pe=p("p"),pe.innerHTML=Hs,is=l(),r(ie.$$.fragment),os=l(),r(j.$$.fragment),rs=l(),r(oe.$$.fragment),cs=l(),re=p("p"),re.textContent=Ns,ms=l(),ce=p("p"),ce.textContent=Qs,hs=l(),r(me.$$.fragment),us=l(),he=p("p"),he.innerHTML=Es,ds=l(),r(ue.$$.fragment),ys=l(),de=p("p"),de.innerHTML=As,gs=l(),r(ye.$$.fragment),fs=l(),ge=p("p"),ge.textContent=qs,Ms=l(),r(fe.$$.fragment),bs=l(),r(Me.$$.fragment),ws=l(),je=p("p"),this.h()},l(e){const s=lt("svelte-u9bgzb",document.head);y=i(s,"META",{name:!0,content:!0}),s.forEach(t),M=n(e),g=i(e,"P",{}),Ds(g).forEach(t),b=n(e),c(T.$$.fragment,e),Te=n(e),c(J.$$.fragment,e),Je=n(e),U=i(e,"P",{"data-svelte-h":!0}),o(U)!=="svelte-gcifhg"&&(U.textContent=Ts),Ue=n(e),$=i(e,"P",{"data-svelte-h":!0}),o($)!=="svelte-1aff4p7"&&($.textContent=Js),$e=n(e),C=i(e,"OL",{"data-svelte-h":!0}),o(C)!=="svelte-1iw2sa5"&&(C.innerHTML=Us),Ce=n(e),k=i(e,"P",{"data-svelte-h":!0}),o(k)!=="svelte-1c9nexd"&&(k.textContent=$s),ke=n(e),c(Z.$$.fragment,e),Ze=n(e),v=i(e,"P",{"data-svelte-h":!0}),o(v)!=="svelte-k76o1m"&&(v.textContent=Cs),ve=n(e),c(_.$$.fragment,e),_e=n(e),c(W.$$.fragment,e),We=n(e),x=i(e,"P",{"data-svelte-h":!0}),o(x)!=="svelte-ndvump"&&(x.innerHTML=ks),xe=n(e),c(I.$$.fragment,e),Ie=n(e),G=i(e,"P",{"data-svelte-h":!0}),o(G)!=="svelte-1m91ua0"&&(G.textContent=Zs),Ge=n(e),c(B.$$.fragment,e),Be=n(e),R=i(e,"P",{"data-svelte-h":!0}),o(R)!=="svelte-1dgdrcg"&&(R.textContent=vs),Re=n(e),X=i(e,"UL",{"data-svelte-h":!0}),o(X)!=="svelte-vj0noe"&&(X.innerHTML=_s),Xe=n(e),c(V.$$.fragment,e),Ve=n(e),z=i(e,"P",{"data-svelte-h":!0}),o(z)!=="svelte-j3i2fe"&&(z.textContent=Ws),ze=n(e),c(Y.$$.fragment,e),Ye=n(e),F=i(e,"P",{"data-svelte-h":!0}),o(F)!=="svelte-pduvot"&&(F.textContent=xs),Fe=n(e),H=i(e,"OL",{"data-svelte-h":!0}),o(H)!=="svelte-tso4vc"&&(H.innerHTML=Is),He=n(e),c(N.$$.fragment,e),Ne=n(e),Q=i(e,"P",{"data-svelte-h":!0}),o(Q)!=="svelte-1hylcv0"&&(Q.innerHTML=Gs),Qe=n(e),c(E.$$.fragment,e),Ee=n(e),A=i(e,"P",{"data-svelte-h":!0}),o(A)!=="svelte-1pf19in"&&(A.innerHTML=Bs),Ae=n(e),c(q.$$.fragment,e),qe=n(e),c(S.$$.fragment,e),Se=n(e),L=i(e,"P",{"data-svelte-h":!0}),o(L)!=="svelte-j1ipe9"&&(L.innerHTML=Rs),Le=n(e),c(D.$$.fragment,e),De=n(e),P=i(e,"P",{"data-svelte-h":!0}),o(P)!=="svelte-16da6d3"&&(P.innerHTML=Xs),Pe=n(e),c(K.$$.fragment,e),Ke=n(e),O=i(e,"P",{"data-svelte-h":!0}),o(O)!=="svelte-183aynn"&&(O.innerHTML=Vs),Oe=n(e),c(ee.$$.fragment,e),es=n(e),c(w.$$.fragment,e),ss=n(e),se=i(e,"P",{"data-svelte-h":!0}),o(se)!=="svelte-1k2vxq5"&&(se.innerHTML=zs),ts=n(e),c(te.$$.fragment,e),as=n(e),ae=i(e,"P",{"data-svelte-h":!0}),o(ae)!=="svelte-l42k0i"&&(ae.textContent=Ys),ls=n(e),le=i(e,"OL",{"data-svelte-h":!0}),o(le)!=="svelte-swqbmp"&&(le.innerHTML=Fs),ns=n(e),c(ne.$$.fragment,e),ps=n(e),pe=i(e,"P",{"data-svelte-h":!0}),o(pe)!=="svelte-yclg6q"&&(pe.innerHTML=Hs),is=n(e),c(ie.$$.fragment,e),os=n(e),c(j.$$.fragment,e),rs=n(e),c(oe.$$.fragment,e),cs=n(e),re=i(e,"P",{"data-svelte-h":!0}),o(re)!=="svelte-633ppb"&&(re.textContent=Ns),ms=n(e),ce=i(e,"P",{"data-svelte-h":!0}),o(ce)!=="svelte-nni2mt"&&(ce.textContent=Qs),hs=n(e),c(me.$$.fragment,e),us=n(e),he=i(e,"P",{"data-svelte-h":!0}),o(he)!=="svelte-1qxmddt"&&(he.innerHTML=Es),ds=n(e),c(ue.$$.fragment,e),ys=n(e),de=i(e,"P",{"data-svelte-h":!0}),o(de)!=="svelte-10twm8n"&&(de.innerHTML=As),gs=n(e),c(ye.$$.fragment,e),fs=n(e),ge=i(e,"P",{"data-svelte-h":!0}),o(ge)!=="svelte-18e4iwl"&&(ge.textContent=qs),Ms=n(e),c(fe.$$.fragment,e),bs=n(e),c(Me.$$.fragment,e),ws=n(e),je=i(e,"P",{}),Ds(je).forEach(t),this.h()},h(){Ps(y,"name","hf:doc:metadata"),Ps(y,"content",mt)},m(e,s){nt(document.head,y),a(e,M,s),a(e,g,s),a(e,b,s),m(T,e,s),a(e,Te,s),m(J,e,s),a(e,Je,s),a(e,U,s),a(e,Ue,s),a(e,$,s),a(e,$e,s),a(e,C,s),a(e,Ce,s),a(e,k,s),a(e,ke,s),m(Z,e,s),a(e,Ze,s),a(e,v,s),a(e,ve,s),m(_,e,s),a(e,_e,s),m(W,e,s),a(e,We,s),a(e,x,s),a(e,xe,s),m(I,e,s),a(e,Ie,s),a(e,G,s),a(e,Ge,s),m(B,e,s),a(e,Be,s),a(e,R,s),a(e,Re,s),a(e,X,s),a(e,Xe,s),m(V,e,s),a(e,Ve,s),a(e,z,s),a(e,ze,s),m(Y,e,s),a(e,Ye,s),a(e,F,s),a(e,Fe,s),a(e,H,s),a(e,He,s),m(N,e,s),a(e,Ne,s),a(e,Q,s),a(e,Qe,s),m(E,e,s),a(e,Ee,s),a(e,A,s),a(e,Ae,s),m(q,e,s),a(e,qe,s),m(S,e,s),a(e,Se,s),a(e,L,s),a(e,Le,s),m(D,e,s),a(e,De,s),a(e,P,s),a(e,Pe,s),m(K,e,s),a(e,Ke,s),a(e,O,s),a(e,Oe,s),m(ee,e,s),a(e,es,s),m(w,e,s),a(e,ss,s),a(e,se,s),a(e,ts,s),m(te,e,s),a(e,as,s),a(e,ae,s),a(e,ls,s),a(e,le,s),a(e,ns,s),m(ne,e,s),a(e,ps,s),a(e,pe,s),a(e,is,s),m(ie,e,s),a(e,os,s),m(j,e,s),a(e,rs,s),m(oe,e,s),a(e,cs,s),a(e,re,s),a(e,ms,s),a(e,ce,s),a(e,hs,s),m(me,e,s),a(e,us,s),a(e,he,s),a(e,ds,s),m(ue,e,s),a(e,ys,s),a(e,de,s),a(e,gs,s),m(ye,e,s),a(e,fs,s),a(e,ge,s),a(e,Ms,s),m(fe,e,s),a(e,bs,s),m(Me,e,s),a(e,ws,s),a(e,je,s),js=!0},p(e,[s]){const Ss={};s&2&&(Ss.$$scope={dirty:s,ctx:e}),w.$set(Ss);const Ls={};s&2&&(Ls.$$scope={dirty:s,ctx:e}),j.$set(Ls)},i(e){js||(h(T.$$.fragment,e),h(J.$$.fragment,e),h(Z.$$.fragment,e),h(_.$$.fragment,e),h(W.$$.fragment,e),h(I.$$.fragment,e),h(B.$$.fragment,e),h(V.$$.fragment,e),h(Y.$$.fragment,e),h(N.$$.fragment,e),h(E.$$.fragment,e),h(q.$$.fragment,e),h(S.$$.fragment,e),h(D.$$.fragment,e),h(K.$$.fragment,e),h(ee.$$.fragment,e),h(w.$$.fragment,e),h(te.$$.fragment,e),h(ne.$$.fragment,e),h(ie.$$.fragment,e),h(j.$$.fragment,e),h(oe.$$.fragment,e),h(me.$$.fragment,e),h(ue.$$.fragment,e),h(ye.$$.fragment,e),h(fe.$$.fragment,e),h(Me.$$.fragment,e),js=!0)},o(e){u(T.$$.fragment,e),u(J.$$.fragment,e),u(Z.$$.fragment,e),u(_.$$.fragment,e),u(W.$$.fragment,e),u(I.$$.fragment,e),u(B.$$.fragment,e),u(V.$$.fragment,e),u(Y.$$.fragment,e),u(N.$$.fragment,e),u(E.$$.fragment,e),u(q.$$.fragment,e),u(S.$$.fragment,e),u(D.$$.fragment,e),u(K.$$.fragment,e),u(ee.$$.fragment,e),u(w.$$.fragment,e),u(te.$$.fragment,e),u(ne.$$.fragment,e),u(ie.$$.fragment,e),u(j.$$.fragment,e),u(oe.$$.fragment,e),u(me.$$.fragment,e),u(ue.$$.fragment,e),u(ye.$$.fragment,e),u(fe.$$.fragment,e),u(Me.$$.fragment,e),js=!1},d(e){e&&(t(M),t(g),t(b),t(Te),t(Je),t(U),t(Ue),t($),t($e),t(C),t(Ce),t(k),t(ke),t(Ze),t(v),t(ve),t(_e),t(We),t(x),t(xe),t(Ie),t(G),t(Ge),t(Be),t(R),t(Re),t(X),t(Xe),t(Ve),t(z),t(ze),t(Ye),t(F),t(Fe),t(H),t(He),t(Ne),t(Q),t(Qe),t(Ee),t(A),t(Ae),t(qe),t(Se),t(L),t(Le),t(De),t(P),t(Pe),t(Ke),t(O),t(Oe),t(es),t(ss),t(se),t(ts),t(as),t(ae),t(ls),t(le),t(ns),t(ps),t(pe),t(is),t(os),t(rs),t(cs),t(re),t(ms),t(ce),t(hs),t(us),t(he),t(ds),t(ys),t(de),t(gs),t(fs),t(ge),t(Ms),t(bs),t(ws),t(je)),t(y),d(T,e),d(J,e),d(Z,e),d(_,e),d(W,e),d(I,e),d(B,e),d(V,e),d(Y,e),d(N,e),d(E,e),d(q,e),d(S,e),d(D,e),d(K,e),d(ee,e),d(w,e),d(te,e),d(ne,e),d(ie,e),d(j,e),d(oe,e),d(me,e),d(ue,e),d(ye,e),d(fe,e),d(Me,e)}}}const mt='{"title":"Multiple choice","local":"multiple-choice","sections":[{"title":"Load SWAG dataset","local":"load-swag-dataset","sections":[],"depth":2},{"title":"Preprocess","local":"preprocess","sections":[],"depth":2},{"title":"Evaluate","local":"evaluate","sections":[],"depth":2},{"title":"Train","local":"train","sections":[],"depth":2},{"title":"Inference","local":"inference","sections":[],"depth":2}],"depth":1}';function ht(be){return st(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class bt extends tt{constructor(y){super(),at(this,y,ht,ct,et,{})}}export{bt as component};
