import{s as _e,n as be,o as Te}from"../chunks/scheduler.18a86fab.js";import{S as ve,i as ye,g as i,s as r,r as H,A as $e,h as c,f as t,c as n,j as A,u as S,x as m,k as j,y as s,a,v as N,d as D,t as k,w as W}from"../chunks/index.98837b22.js";import{D as ie}from"../chunks/Docstring.a1ef7999.js";import{H as xe,E as we}from"../chunks/getInferenceSnippets.06c2775f.js";function Ee(ce){let l,V,I,q,g,F,x,se='<a href="https://github.com/pytorch/executorch" rel="nofollow"><code>ExecuTorch</code></a> is an end-to-end solution for enabling on-device inference capabilities across mobile and edge devices including wearables, embedded devices and microcontrollers. It is part of the PyTorch ecosystem and supports the deployment of PyTorch models with a focus on portability, productivity, and performance.',G,_,de='ExecuTorch introduces well defined entry points to perform model, device, and/or use-case specific optimizations such as backend delegation, user-defined compiler transformations, memory planning, and more. The first step in preparing a PyTorch model for execution on an edge device using ExecuTorch is to export the model. This is achieved through the use of a PyTorch API called <a href="https://pytorch.org/docs/stable/export.html" rel="nofollow"><code>torch.export</code></a>.',R,b,U,T,pe="An integration point is being developed to ensure that ðŸ¤— Transformers can be exported using <code>torch.export</code>. The goal of this integration is not only to enable export but also to ensure that the exported artifact can be further lowered and optimized to run efficiently in <code>ExecuTorch</code>, particularly for mobile and edge use cases.",B,d,v,Z,E,le=`A recipe module designed to make a <code>PreTrainedModel</code> exportable with <code>torch.export</code>,
specifically for decoder-only LM to <code>StaticCache</code>. This module ensures that the
exported model is compatible with further lowering and execution in <code>ExecuTorch</code>.`,ee,M,he=`Note:
This class is specifically designed to support export process using <code>torch.export</code>
in a way that ensures the model can be further lowered and run efficiently in <code>ExecuTorch</code>.`,te,p,y,oe,C,me="Forward pass of the module, which is compatible with the ExecuTorch runtime.",re,P,ue="This forward adapter serves two primary purposes:",ne,L,fe=`<li><p><strong>Making the Model <code>torch.export</code>-Compatible</strong>:
The adapter hides unsupported objects, such as the <code>Cache</code>, from the graph inputs and outputs,
enabling the model to be exportable using <code>torch.export</code> without encountering issues.</p></li> <li><p><strong>Ensuring Compatibility with <code>ExecuTorch</code> runtime</strong>:
The adapter matches the modelâ€™s forward signature with that in <code>executorch/extension/llm/runner</code>,
ensuring that the exported model can be executed in <code>ExecuTorch</code> out-of-the-box.</p></li>`,J,h,$,ae,O,ge=`Convert a <code>PreTrainedModel</code> into an exportable module and export it using <code>torch.export</code>,
ensuring the exported model is compatible with <code>ExecuTorch</code>.`,K,w,Q,z,X;return g=new xe({props:{title:"ExecuTorch",local:"executorch",headingTag:"h1"}}),b=new xe({props:{title:"ExecuTorch Integration",local:"transformers.TorchExportableModuleWithStaticCache",headingTag:"h2"}}),v=new ie({props:{name:"class transformers.TorchExportableModuleWithStaticCache",anchor:"transformers.TorchExportableModuleWithStaticCache",parameters:[{name:"model",val:": PreTrainedModel"},{name:"batch_size",val:": typing.Optional[int] = None"},{name:"max_cache_len",val:": typing.Optional[int] = None"},{name:"device",val:": typing.Optional[torch.device] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/executorch.py#L462"}}),y=new ie({props:{name:"forward",anchor:"transformers.TorchExportableModuleWithStaticCache.forward",parameters:[{name:"input_ids",val:": typing.Optional[torch.LongTensor] = None"},{name:"inputs_embeds",val:": typing.Optional[torch.Tensor] = None"},{name:"cache_position",val:": typing.Optional[torch.Tensor] = None"}],parametersDescription:[{anchor:"transformers.TorchExportableModuleWithStaticCache.forward.input_ids",description:"<strong>input_ids</strong> (<code>torch.Tensor</code>) &#x2014; Tensor representing current input token id to the module.",name:"input_ids"},{anchor:"transformers.TorchExportableModuleWithStaticCache.forward.inputs_embeds",description:"<strong>inputs_embeds</strong> (<code>torch.Tensor</code>) &#x2014; Tensor representing current input embeddings to the module.",name:"inputs_embeds"},{anchor:"transformers.TorchExportableModuleWithStaticCache.forward.cache_position",description:"<strong>cache_position</strong> (<code>torch.Tensor</code>) &#x2014; Tensor representing current input position in the cache.",name:"cache_position"}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/executorch.py#L547",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>Logits output from the model.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p>torch.Tensor</p>
`}}),$=new ie({props:{name:"transformers.convert_and_export_with_cache",anchor:"transformers.convert_and_export_with_cache",parameters:[{name:"model",val:": PreTrainedModel"},{name:"example_input_ids",val:": typing.Optional[torch.Tensor] = None"},{name:"example_cache_position",val:": typing.Optional[torch.Tensor] = None"},{name:"dynamic_shapes",val:": typing.Optional[dict] = None"},{name:"strict",val:": typing.Optional[bool] = None"}],parametersDescription:[{anchor:"transformers.convert_and_export_with_cache.model",description:"<strong>model</strong> (<code>PreTrainedModel</code>) &#x2014; The pretrained model to be exported.",name:"model"},{anchor:"transformers.convert_and_export_with_cache.example_input_ids",description:"<strong>example_input_ids</strong> (<code>Optional[torch.Tensor]</code>) &#x2014; Example input token id used by <code>torch.export</code>.",name:"example_input_ids"},{anchor:"transformers.convert_and_export_with_cache.example_cache_position",description:"<strong>example_cache_position</strong> (<code>Optional[torch.Tensor]</code>) &#x2014; Example current cache position used by <code>torch.export</code>.",name:"example_cache_position"},{anchor:"transformers.convert_and_export_with_cache.dynamic_shapes(Optional[dict])",description:"<strong>dynamic_shapes(<code>Optional[dict]</code>)</strong> &#x2014; Dynamic shapes used by <code>torch.export</code>.",name:"dynamic_shapes(Optional[dict])"},{anchor:"transformers.convert_and_export_with_cache.strict(Optional[bool])",description:"<strong>strict(<code>Optional[bool]</code>)</strong> &#x2014; Flag to instruct <code>torch.export</code> to use <code>torchdynamo</code>.",name:"strict(Optional[bool])"}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/executorch.py#L746",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The exported program generated via <code>torch.export</code>.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p>Exported program (<code>torch.export.ExportedProgram</code>)</p>
`}}),w=new we({props:{source:"https://github.com/huggingface/transformers/blob/main/docs/source/en/main_classes/executorch.md"}}),{c(){l=i("meta"),V=r(),I=i("p"),q=r(),H(g.$$.fragment),F=r(),x=i("p"),x.innerHTML=se,G=r(),_=i("p"),_.innerHTML=de,R=r(),H(b.$$.fragment),U=r(),T=i("p"),T.innerHTML=pe,B=r(),d=i("div"),H(v.$$.fragment),Z=r(),E=i("p"),E.innerHTML=le,ee=r(),M=i("p"),M.innerHTML=he,te=r(),p=i("div"),H(y.$$.fragment),oe=r(),C=i("p"),C.textContent=me,re=r(),P=i("p"),P.textContent=ue,ne=r(),L=i("ol"),L.innerHTML=fe,J=r(),h=i("div"),H($.$$.fragment),ae=r(),O=i("p"),O.innerHTML=ge,K=r(),H(w.$$.fragment),Q=r(),z=i("p"),this.h()},l(e){const o=$e("svelte-u9bgzb",document.head);l=c(o,"META",{name:!0,content:!0}),o.forEach(t),V=n(e),I=c(e,"P",{}),A(I).forEach(t),q=n(e),S(g.$$.fragment,e),F=n(e),x=c(e,"P",{"data-svelte-h":!0}),m(x)!=="svelte-s52zyj"&&(x.innerHTML=se),G=n(e),_=c(e,"P",{"data-svelte-h":!0}),m(_)!=="svelte-krphnt"&&(_.innerHTML=de),R=n(e),S(b.$$.fragment,e),U=n(e),T=c(e,"P",{"data-svelte-h":!0}),m(T)!=="svelte-rak2iw"&&(T.innerHTML=pe),B=n(e),d=c(e,"DIV",{class:!0});var u=A(d);S(v.$$.fragment,u),Z=n(u),E=c(u,"P",{"data-svelte-h":!0}),m(E)!=="svelte-qvv9u7"&&(E.innerHTML=le),ee=n(u),M=c(u,"P",{"data-svelte-h":!0}),m(M)!=="svelte-sxfggh"&&(M.innerHTML=he),te=n(u),p=c(u,"DIV",{class:!0});var f=A(p);S(y.$$.fragment,f),oe=n(f),C=c(f,"P",{"data-svelte-h":!0}),m(C)!=="svelte-1b4e8fi"&&(C.textContent=me),re=n(f),P=c(f,"P",{"data-svelte-h":!0}),m(P)!=="svelte-15fkaet"&&(P.textContent=ue),ne=n(f),L=c(f,"OL",{"data-svelte-h":!0}),m(L)!=="svelte-ezgyom"&&(L.innerHTML=fe),f.forEach(t),u.forEach(t),J=n(e),h=c(e,"DIV",{class:!0});var Y=A(h);S($.$$.fragment,Y),ae=n(Y),O=c(Y,"P",{"data-svelte-h":!0}),m(O)!=="svelte-2axmlh"&&(O.innerHTML=ge),Y.forEach(t),K=n(e),S(w.$$.fragment,e),Q=n(e),z=c(e,"P",{}),A(z).forEach(t),this.h()},h(){j(l,"name","hf:doc:metadata"),j(l,"content",Me),j(p,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),j(d,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),j(h,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,o){s(document.head,l),a(e,V,o),a(e,I,o),a(e,q,o),N(g,e,o),a(e,F,o),a(e,x,o),a(e,G,o),a(e,_,o),a(e,R,o),N(b,e,o),a(e,U,o),a(e,T,o),a(e,B,o),a(e,d,o),N(v,d,null),s(d,Z),s(d,E),s(d,ee),s(d,M),s(d,te),s(d,p),N(y,p,null),s(p,oe),s(p,C),s(p,re),s(p,P),s(p,ne),s(p,L),a(e,J,o),a(e,h,o),N($,h,null),s(h,ae),s(h,O),a(e,K,o),N(w,e,o),a(e,Q,o),a(e,z,o),X=!0},p:be,i(e){X||(D(g.$$.fragment,e),D(b.$$.fragment,e),D(v.$$.fragment,e),D(y.$$.fragment,e),D($.$$.fragment,e),D(w.$$.fragment,e),X=!0)},o(e){k(g.$$.fragment,e),k(b.$$.fragment,e),k(v.$$.fragment,e),k(y.$$.fragment,e),k($.$$.fragment,e),k(w.$$.fragment,e),X=!1},d(e){e&&(t(V),t(I),t(q),t(F),t(x),t(G),t(_),t(R),t(U),t(T),t(B),t(d),t(J),t(h),t(K),t(Q),t(z)),t(l),W(g,e),W(b,e),W(v),W(y),W($),W(w,e)}}}const Me='{"title":"ExecuTorch","local":"executorch","sections":[{"title":"ExecuTorch Integration","local":"transformers.TorchExportableModuleWithStaticCache","sections":[],"depth":2}],"depth":1}';function Ce(ce){return Te(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Se extends ve{constructor(l){super(),ye(this,l,Ce,Ee,_e,{})}}export{Se as component};
