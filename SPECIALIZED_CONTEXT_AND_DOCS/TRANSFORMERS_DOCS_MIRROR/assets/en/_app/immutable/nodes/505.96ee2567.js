import{s as le,n as se,o as re}from"../chunks/scheduler.18a86fab.js";import{S as oe,i as me,g as s,s as a,r as x,A as ue,h as r,f as n,c as l,j as ie,u as L,x as u,k as ae,l as fe,y as pe,a as i,v as q,d as C,t as z,w as B}from"../chunks/index.98837b22.js";import{C as he}from"../chunks/CodeBlock.8d0c2e8a.js";import{H as S,E as ce}from"../chunks/getInferenceSnippets.06c2775f.js";function de(Y){let o,H,_,R,f,k,p,I='<a href="https://huggingface.co/papers/2402.17764" rel="nofollow">BitNet</a> replaces traditional linear layers in Multi-Head Attention and feed-forward networks with specialized BitLinear layers. The BitLinear layers quantize the weights using ternary precision (with values of -1, 0, and 1) and quantize the activations to 8-bit precision.',P,m,V='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/1.58llm_extreme_quantization/bitlinear.png" alt="Alt Text"/> <figcaption>The architecture of BitNet with BitLinear layers.</figcaption>',N,h,D="BitNet models can’t be quantized on the fly. They need to be quantized during pretraining or fine-tuning because it is a Quantization-Aware Training (QAT) technique. During training, the weights are quantized to ternary values with symmetric per tensor quantization.",U,c,K='<li>Compute the average of the absolute values of the weight matrix and use as a scale.</li> <li>Divide the weights by the scale, round the values, constrain them between -1 and 1, and rescale them to continue in full precision.</li> <li>Activations are quantized to a specified bit-width (8-bit) using <a href="https://huggingface.co/papers/2208.07339" rel="nofollow">absmax</a> quantization (symmetric per channel quantization). This involves scaling the activations into a range of [−128,127].</li>',A,d,O='Refer to this <a href="https://github.com/huggingface/nanotron/pull/180" rel="nofollow">PR</a> to pretrain or fine-tune a 1.58-bit model with <a href="https://github.com/huggingface/nanotron" rel="nofollow">Nanotron</a>. For fine-tuning, convert a model from the Hugging Face to Nanotron format. Find the conversion steps in this <a href="https://github.com/huggingface/nanotron/pull/174" rel="nofollow">PR</a>.',j,g,ee='Load a BitNet quantized model with <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a>.',G,v,E,y,F,$,te="<code>@torch.compile</code> is used to unpack the weights and perform the forward pass. It’s very straightforward to implement and delivers significant speed improvements. Additional optimized kernels will be integrated in future versions.",Z,w,W,b,ne='Read <a href="https://huggingface.co/blog/1_58_llm_extreme_quantization" rel="nofollow">Fine-tuning LLMs to 1.58bit: extreme quantization made easy</a> to learn more about how BitNet models are trained and fine-tuned.',J,M,Q,T,X;return f=new S({props:{title:"BitNet",local:"bitnet",headingTag:"h1"}}),v=new he({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTBBcGF0aCUyMCUzRCUyMCUyMiUyRnBhdGglMkZ0byUyRm1vZGVsJTIyJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JDYXVzYWxMTS5mcm9tX3ByZXRyYWluZWQocGF0aCUyQyUyMGRldmljZV9tYXAlM0QlMjJhdXRvJTIyKQ==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM
path = <span class="hljs-string">&quot;/path/to/model&quot;</span>
model = AutoModelForCausalLM.from_pretrained(path, device_map=<span class="hljs-string">&quot;auto&quot;</span>)`,wrap:!1}}),y=new S({props:{title:"Kernels",local:"kernels",headingTag:"h2"}}),w=new S({props:{title:"Resources",local:"resources",headingTag:"h2"}}),M=new ce({props:{source:"https://github.com/huggingface/transformers/blob/main/docs/source/en/quantization/bitnet.md"}}),{c(){o=s("meta"),H=a(),_=s("p"),R=a(),x(f.$$.fragment),k=a(),p=s("p"),p.innerHTML=I,P=a(),m=s("figure"),m.innerHTML=V,N=a(),h=s("p"),h.textContent=D,U=a(),c=s("ol"),c.innerHTML=K,A=a(),d=s("p"),d.innerHTML=O,j=a(),g=s("p"),g.innerHTML=ee,G=a(),x(v.$$.fragment),E=a(),x(y.$$.fragment),F=a(),$=s("p"),$.innerHTML=te,Z=a(),x(w.$$.fragment),W=a(),b=s("p"),b.innerHTML=ne,J=a(),x(M.$$.fragment),Q=a(),T=s("p"),this.h()},l(e){const t=ue("svelte-u9bgzb",document.head);o=r(t,"META",{name:!0,content:!0}),t.forEach(n),H=l(e),_=r(e,"P",{}),ie(_).forEach(n),R=l(e),L(f.$$.fragment,e),k=l(e),p=r(e,"P",{"data-svelte-h":!0}),u(p)!=="svelte-1fq2u7x"&&(p.innerHTML=I),P=l(e),m=r(e,"FIGURE",{style:!0,"data-svelte-h":!0}),u(m)!=="svelte-4royag"&&(m.innerHTML=V),N=l(e),h=r(e,"P",{"data-svelte-h":!0}),u(h)!=="svelte-jn7uej"&&(h.textContent=D),U=l(e),c=r(e,"OL",{"data-svelte-h":!0}),u(c)!=="svelte-e2tn8t"&&(c.innerHTML=K),A=l(e),d=r(e,"P",{"data-svelte-h":!0}),u(d)!=="svelte-1qo8lxi"&&(d.innerHTML=O),j=l(e),g=r(e,"P",{"data-svelte-h":!0}),u(g)!=="svelte-1mshwqh"&&(g.innerHTML=ee),G=l(e),L(v.$$.fragment,e),E=l(e),L(y.$$.fragment,e),F=l(e),$=r(e,"P",{"data-svelte-h":!0}),u($)!=="svelte-1kkxyro"&&($.innerHTML=te),Z=l(e),L(w.$$.fragment,e),W=l(e),b=r(e,"P",{"data-svelte-h":!0}),u(b)!=="svelte-d588cy"&&(b.innerHTML=ne),J=l(e),L(M.$$.fragment,e),Q=l(e),T=r(e,"P",{}),ie(T).forEach(n),this.h()},h(){ae(o,"name","hf:doc:metadata"),ae(o,"content",ge),fe(m,"text-align","center")},m(e,t){pe(document.head,o),i(e,H,t),i(e,_,t),i(e,R,t),q(f,e,t),i(e,k,t),i(e,p,t),i(e,P,t),i(e,m,t),i(e,N,t),i(e,h,t),i(e,U,t),i(e,c,t),i(e,A,t),i(e,d,t),i(e,j,t),i(e,g,t),i(e,G,t),q(v,e,t),i(e,E,t),q(y,e,t),i(e,F,t),i(e,$,t),i(e,Z,t),q(w,e,t),i(e,W,t),i(e,b,t),i(e,J,t),q(M,e,t),i(e,Q,t),i(e,T,t),X=!0},p:se,i(e){X||(C(f.$$.fragment,e),C(v.$$.fragment,e),C(y.$$.fragment,e),C(w.$$.fragment,e),C(M.$$.fragment,e),X=!0)},o(e){z(f.$$.fragment,e),z(v.$$.fragment,e),z(y.$$.fragment,e),z(w.$$.fragment,e),z(M.$$.fragment,e),X=!1},d(e){e&&(n(H),n(_),n(R),n(k),n(p),n(P),n(m),n(N),n(h),n(U),n(c),n(A),n(d),n(j),n(g),n(G),n(E),n(F),n($),n(Z),n(W),n(b),n(J),n(Q),n(T)),n(o),B(f,e),B(v,e),B(y,e),B(w,e),B(M,e)}}}const ge='{"title":"BitNet","local":"bitnet","sections":[{"title":"Kernels","local":"kernels","sections":[],"depth":2},{"title":"Resources","local":"resources","sections":[],"depth":2}],"depth":1}';function ve(Y){return re(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Me extends oe{constructor(o){super(),me(this,o,ve,de,le,{})}}export{Me as component};
