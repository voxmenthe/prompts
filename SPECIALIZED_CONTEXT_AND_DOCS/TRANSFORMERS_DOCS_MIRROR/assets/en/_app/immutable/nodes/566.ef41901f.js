import{s as lt,o as st,n as xe}from"../chunks/scheduler.18a86fab.js";import{S as rt,i as at,g as m,s as a,r as d,A as ot,h as c,f as n,c as o,j as et,u as h,x as b,k as tt,y as it,a as l,v as f,d as u,t as M,w as $}from"../chunks/index.98837b22.js";import{T as pt}from"../chunks/Tip.77304350.js";import{C as _}from"../chunks/CodeBlock.8d0c2e8a.js";import{H as ee,E as mt}from"../chunks/getInferenceSnippets.06c2775f.js";import{H as ct,a as nt}from"../chunks/HfOption.6641485e.js";function dt(T){let s,p;return s=new _({props:{code:"Y29uZmlnJTIwJTNEJTIwQmVydENvbmZpZyglMEElMjAlMjAlMjAlMjB2b2NhYl9zaXplX29yX2NvbmZpZ19qc29uX2ZpbGUlM0QzMjAwMCUyQyUwQSUyMCUyMCUyMCUyMGhpZGRlbl9zaXplJTNENzY4JTJDJTBBJTIwJTIwJTIwJTIwbnVtX2hpZGRlbl9sYXllcnMlM0QxMiUyQyUwQSUyMCUyMCUyMCUyMG51bV9hdHRlbnRpb25faGVhZHMlM0QxMiUyQyUwQSUyMCUyMCUyMCUyMGludGVybWVkaWF0ZV9zaXplJTNEMzA3MiUyQyUwQSUyMCUyMCUyMCUyMHRvcmNoc2NyaXB0JTNEVHJ1ZSUyQyUwQSklMEElMEFtb2RlbCUyMCUzRCUyMEJlcnRNb2RlbChjb25maWcpJTBBbW9kZWwuZXZhbCgp",highlighted:`config = BertConfig(
    vocab_size_or_config_json_file=<span class="hljs-number">32000</span>,
    hidden_size=<span class="hljs-number">768</span>,
    num_hidden_layers=<span class="hljs-number">12</span>,
    num_attention_heads=<span class="hljs-number">12</span>,
    intermediate_size=<span class="hljs-number">3072</span>,
    torchscript=<span class="hljs-literal">True</span>,
)

model = BertModel(config)
model.<span class="hljs-built_in">eval</span>()`,wrap:!1}}),{c(){d(s.$$.fragment)},l(r){h(s.$$.fragment,r)},m(r,y){f(s,r,y),p=!0},p:xe,i(r){p||(u(s.$$.fragment,r),p=!0)},o(r){M(s.$$.fragment,r),p=!1},d(r){$(s,r)}}}function ht(T){let s,p;return s=new _({props:{code:"bW9kZWwlMjAlM0QlMjBCZXJ0TW9kZWwuZnJvbV9wcmV0cmFpbmVkKCUyMmdvb2dsZS1iZXJ0JTJGYmVydC1iYXNlLXVuY2FzZWQlMjIlMkMlMjB0b3JjaHNjcmlwdCUzRFRydWUpJTBBbW9kZWwuZXZhbCgp",highlighted:`model = BertModel.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-uncased&quot;</span>, torchscript=<span class="hljs-literal">True</span>)
model.<span class="hljs-built_in">eval</span>()`,wrap:!1}}),{c(){d(s.$$.fragment)},l(r){h(s.$$.fragment,r)},m(r,y){f(s,r,y),p=!0},p:xe,i(r){p||(u(s.$$.fragment,r),p=!0)},o(r){M(s.$$.fragment,r),p=!1},d(r){$(s,r)}}}function ft(T){let s,p,r,y;return s=new nt({props:{id:"torchscript",option:"randomly initialized model",$$slots:{default:[dt]},$$scope:{ctx:T}}}),r=new nt({props:{id:"torchscript",option:"pretrained model",$$slots:{default:[ht]},$$scope:{ctx:T}}}),{c(){d(s.$$.fragment),p=a(),d(r.$$.fragment)},l(i){h(s.$$.fragment,i),p=o(i),h(r.$$.fragment,i)},m(i,w){f(s,i,w),l(i,p,w),f(r,i,w),y=!0},p(i,w){const g={};w&2&&(g.$$scope={dirty:w,ctx:i}),s.$set(g);const te={};w&2&&(te.$$scope={dirty:w,ctx:i}),r.$set(te)},i(i){y||(u(s.$$.fragment,i),u(r.$$.fragment,i),y=!0)},o(i){M(s.$$.fragment,i),M(r.$$.fragment,i),y=!1},d(i){i&&n(p),$(s,i),$(r,i)}}}function ut(T){let s,p='AWS Neuron requires a <a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/inference-torch-neuron.html#inference-torch-neuron" rel="nofollow">Neuron SDK environment</a> which is preconfigured on <a href="https://docs.aws.amazon.com/dlami/latest/devguide/tutorial-inferentia-launching.html" rel="nofollow">AWS DLAMI</a>.';return{c(){s=m("p"),s.innerHTML=p},l(r){s=c(r,"P",{"data-svelte-h":!0}),b(s)!=="svelte-1ln4va2"&&(s.innerHTML=p)},m(r,y){l(r,s,y)},p:xe,d(r){r&&n(s)}}}function Mt(T){let s,p,r,y,i,w,g,te='<a href="https://pytorch.org/docs/stable/jit.html" rel="nofollow">TorchScript</a> serializes PyTorch models into programs that can be executed in non-Python processes. This is especially advantageous in production environments where Python may not be the most performant choice.',le,v,ze="Transformers can export a model to TorchScript by:",se,U,Qe='<li>creating dummy inputs to create a <em>trace</em> of the model to serialize to TorchScript</li> <li>enabling the <code>torchscript</code> parameter in either <code>~PretrainedConfig.torchscript</code> for a randomly initialized model or <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> for a pretrained model</li>',re,Z,ae,k,Ie="The dummy inputs are used in the forward pass, and as the input values are propagated through each layer, PyTorch tracks the different operations executed on each tensor. The recorded operations are used to create the model trace. Once it is recorded, it is serialized into a TorchScript program.",oe,C,ie,B,Xe="The trace is created based on the provided inputs dimensions and it can only handle inputs with the same shape as the provided input during tracing. An input with a different size raises the error message shown below.",pe,W,me,V,Ne="Try to create a trace with a dummy input size at least as large as the largest expected input during inference. Padding can help fill missing values for larger inputs. It may be slower though since a larger input size requires more calculations. Be mindful of the total number of operations performed on each input and track the model performance when exporting models with variable sequence lengths.",ce,H,de,x,Ge="Weights between the <code>Embedding</code> and <code>Decoding</code> layers are tied in Transformers and TorchScript can’t export models with tied weights. Instantiating a model with <code>torchscript=True</code>, separates the <code>Embedding</code> and <code>Decoding</code> layers and they aren’t trained any further because it would throw the two layers out of sync which can lead to unexpected results.",he,z,Re="Models <em>without</em> a language model head don’t have tied weights and can be safely exported without the <code>torchscript</code> parameter.",fe,j,ue,Q,Me,I,Ae='Create the Torchscript program with <a href="https://pytorch.org/docs/stable/generated/torch.jit.trace.html" rel="nofollow">torch.jit.trace</a>, and save with <a href="https://pytorch.org/docs/stable/generated/torch.jit.save.html" rel="nofollow">torch.jit.save</a>.',$e,X,be,N,Ee='Use <a href="https://pytorch.org/docs/stable/generated/torch.jit.load.html" rel="nofollow">torch.jit.load</a> to load the traced model.',ye,G,we,R,Le="To use the traced model for inference, use the <code>__call__</code> dunder method.",Te,A,ge,E,je,L,Se='TorchScript programs serialized from Transformers can be deployed on <a href="https://aws.amazon.com/ec2/instance-types/inf1/" rel="nofollow">Amazon EC2 Inf1</a> instances. The instance is powered by AWS Inferentia chips, a custom hardware accelerator designed for deep learning inference workloads. <a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/#" rel="nofollow">AWS Neuron</a> supports tracing Transformers models for deployment on Inf1 instances.',Je,J,_e,S,Ye='Instead of <a href="https://pytorch.org/docs/stable/generated/torch.jit.trace.html" rel="nofollow">torch.jit.trace</a>, use <a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuron/api-compilation-python-api.html" rel="nofollow">torch.neuron.trace</a> to trace a model and optimize it for Inf1 instances.',ve,Y,Ue,P,Pe='Refer to the <a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/index.html" rel="nofollow">AWS Neuron</a> documentation for more information.',Ze,D,ke,q,De='BERT-based models - like <a href="./model_doc/distilbert">DistilBERT</a> or <a href="./model_doc/roberta">RoBERTa</a> - run best on Inf1 instances for non-generative tasks such as extractive question answering, and sequence or token classification.',Ce,F,qe='Text generation can be adapted to run on an Inf1 instance as shown in the <a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/src/examples/pytorch/transformers-marianmt.html" rel="nofollow">Transformers MarianMT</a> tutorial.',Be,K,Fe='Refer to the <a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/general/models/inference-inf1-samples.html#model-samples-inference-inf1" rel="nofollow">Inference Samples/Tutorials (Inf1)</a> guide for more information about which models can be converted out of the box to run on Inf1 instances.',We,O,Ve,ne,He;return i=new ee({props:{title:"TorchScript",local:"torchscript",headingTag:"h1"}}),Z=new ee({props:{title:"Dummy inputs",local:"dummy-inputs",headingTag:"h2"}}),C=new _({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEJlcnRNb2RlbCUyQyUyMEJlcnRUb2tlbml6ZXIlMkMlMjBCZXJ0Q29uZmlnJTBBaW1wb3J0JTIwdG9yY2glMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBCZXJ0VG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJnb29nbGUtYmVydCUyRmJlcnQtYmFzZS11bmNhc2VkJTIyKSUwQXRleHQlMjAlM0QlMjAlMjIlNUJDTFMlNUQlMjBXaG8lMjB3YXMlMjBKaW0lMjBIZW5zb24lMjAlM0YlMjAlNUJTRVAlNUQlMjBKaW0lMjBIZW5zb24lMjB3YXMlMjBhJTIwcHVwcGV0ZWVyJTIwJTVCU0VQJTVEJTIyJTBBdG9rZW5pemVkX3RleHQlMjAlM0QlMjB0b2tlbml6ZXIudG9rZW5pemUodGV4dCklMEElMEFtYXNrZWRfaW5kZXglMjAlM0QlMjA4JTBBdG9rZW5pemVkX3RleHQlNUJtYXNrZWRfaW5kZXglNUQlMjAlM0QlMjAlMjIlNUJNQVNLJTVEJTIyJTBBaW5kZXhlZF90b2tlbnMlMjAlM0QlMjB0b2tlbml6ZXIuY29udmVydF90b2tlbnNfdG9faWRzKHRva2VuaXplZF90ZXh0KSUwQXNlZ21lbnRzX2lkcyUyMCUzRCUyMCU1QjAlMkMlMjAwJTJDJTIwMCUyQyUyMDAlMkMlMjAwJTJDJTIwMCUyQyUyMDAlMkMlMjAxJTJDJTIwMSUyQyUyMDElMkMlMjAxJTJDJTIwMSUyQyUyMDElMkMlMjAxJTVEJTBBJTBBJTIzJTIwY3JlYXRpbmclMjBhJTIwZHVtbXklMjBpbnB1dCUwQXRva2Vuc190ZW5zb3IlMjAlM0QlMjB0b3JjaC50ZW5zb3IoJTVCaW5kZXhlZF90b2tlbnMlNUQpJTBBc2VnbWVudHNfdGVuc29ycyUyMCUzRCUyMHRvcmNoLnRlbnNvciglNUJzZWdtZW50c19pZHMlNUQpJTBBZHVtbXlfaW5wdXQlMjAlM0QlMjAlNUJ0b2tlbnNfdGVuc29yJTJDJTIwc2VnbWVudHNfdGVuc29ycyU1RA==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertModel, BertTokenizer, BertConfig
<span class="hljs-keyword">import</span> torch

tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-uncased&quot;</span>)
text = <span class="hljs-string">&quot;[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]&quot;</span>
tokenized_text = tokenizer.tokenize(text)

masked_index = <span class="hljs-number">8</span>
tokenized_text[masked_index] = <span class="hljs-string">&quot;[MASK]&quot;</span>
indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)
segments_ids = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]

<span class="hljs-comment"># creating a dummy input</span>
tokens_tensor = torch.tensor([indexed_tokens])
segments_tensors = torch.tensor([segments_ids])
dummy_input = [tokens_tensor, segments_tensors]`,wrap:!1}}),W=new _({props:{code:"JTYwVGhlJTIwZXhwYW5kZWQlMjBzaXplJTIwb2YlMjB0aGUlMjB0ZW5zb3IlMjAoMyklMjBtdXN0JTIwbWF0Y2glMjB0aGUlMjBleGlzdGluZyUyMHNpemUlMjAoNyklMjBhdCUyMG5vbi1zaW5nbGV0b24lMjBkaW1lbnNpb24lMjAyJTYwLg==",highlighted:"`The expanded size of the tensor (3) must match the existing size (7) at non-singleton dimension 2`.",wrap:!1}}),H=new ee({props:{title:"Tied weights",local:"tied-weights",headingTag:"h2"}}),j=new ct({props:{id:"torchscript",options:["randomly initialized model","pretrained model"],$$slots:{default:[ft]},$$scope:{ctx:T}}}),Q=new ee({props:{title:"Export to TorchScript",local:"export-to-torchscript",headingTag:"h2"}}),X=new _({props:{code:"dHJhY2VkX21vZGVsJTIwJTNEJTIwdG9yY2guaml0LnRyYWNlKG1vZGVsJTJDJTIwJTVCdG9rZW5zX3RlbnNvciUyQyUyMHNlZ21lbnRzX3RlbnNvcnMlNUQpJTBBdG9yY2guaml0LnNhdmUodHJhY2VkX21vZGVsJTJDJTIwJTIydHJhY2VkX2JlcnQucHQlMjIp",highlighted:`traced_model = torch.jit.trace(model, [tokens_tensor, segments_tensors])
torch.jit.save(traced_model, <span class="hljs-string">&quot;traced_bert.pt&quot;</span>)`,wrap:!1}}),G=new _({props:{code:"bG9hZGVkX21vZGVsJTIwJTNEJTIwdG9yY2guaml0LmxvYWQoJTIydHJhY2VkX2JlcnQucHQlMjIpJTBBbG9hZGVkX21vZGVsLmV2YWwoKSUwQSUwQWFsbF9lbmNvZGVyX2xheWVycyUyQyUyMHBvb2xlZF9vdXRwdXQlMjAlM0QlMjBsb2FkZWRfbW9kZWwoKmR1bW15X2lucHV0KQ==",highlighted:`loaded_model = torch.jit.load(<span class="hljs-string">&quot;traced_bert.pt&quot;</span>)
loaded_model.<span class="hljs-built_in">eval</span>()

all_encoder_layers, pooled_output = loaded_model(*dummy_input)`,wrap:!1}}),A=new _({props:{code:"dHJhY2VkX21vZGVsKHRva2Vuc190ZW5zb3IlMkMlMjBzZWdtZW50c190ZW5zb3JzKQ==",highlighted:"traced_model(tokens_tensor, segments_tensors)",wrap:!1}}),E=new ee({props:{title:"Deploy to AWS",local:"deploy-to-aws",headingTag:"h2"}}),J=new pt({props:{warning:!1,$$slots:{default:[ut]},$$scope:{ctx:T}}}),Y=new _({props:{code:"aW1wb3J0JTIwdG9yY2gubmV1cm9uJTBBJTBBdG9yY2gubmV1cm9uLnRyYWNlKG1vZGVsJTJDJTIwJTVCdG9rZW5zX3RlbnNvciUyQyUyMHNlZ21lbnRzX3RlbnNvcnMlNUQp",highlighted:`<span class="hljs-keyword">import</span> torch.neuron

torch.neuron.trace(model, [tokens_tensor, segments_tensors])`,wrap:!1}}),D=new ee({props:{title:"Model architectures",local:"model-architectures",headingTag:"h3"}}),O=new mt({props:{source:"https://github.com/huggingface/transformers/blob/main/docs/source/en/torchscript.md"}}),{c(){s=m("meta"),p=a(),r=m("p"),y=a(),d(i.$$.fragment),w=a(),g=m("p"),g.innerHTML=te,le=a(),v=m("p"),v.textContent=ze,se=a(),U=m("ol"),U.innerHTML=Qe,re=a(),d(Z.$$.fragment),ae=a(),k=m("p"),k.textContent=Ie,oe=a(),d(C.$$.fragment),ie=a(),B=m("p"),B.textContent=Xe,pe=a(),d(W.$$.fragment),me=a(),V=m("p"),V.textContent=Ne,ce=a(),d(H.$$.fragment),de=a(),x=m("p"),x.innerHTML=Ge,he=a(),z=m("p"),z.innerHTML=Re,fe=a(),d(j.$$.fragment),ue=a(),d(Q.$$.fragment),Me=a(),I=m("p"),I.innerHTML=Ae,$e=a(),d(X.$$.fragment),be=a(),N=m("p"),N.innerHTML=Ee,ye=a(),d(G.$$.fragment),we=a(),R=m("p"),R.innerHTML=Le,Te=a(),d(A.$$.fragment),ge=a(),d(E.$$.fragment),je=a(),L=m("p"),L.innerHTML=Se,Je=a(),d(J.$$.fragment),_e=a(),S=m("p"),S.innerHTML=Ye,ve=a(),d(Y.$$.fragment),Ue=a(),P=m("p"),P.innerHTML=Pe,Ze=a(),d(D.$$.fragment),ke=a(),q=m("p"),q.innerHTML=De,Ce=a(),F=m("p"),F.innerHTML=qe,Be=a(),K=m("p"),K.innerHTML=Fe,We=a(),d(O.$$.fragment),Ve=a(),ne=m("p"),this.h()},l(e){const t=ot("svelte-u9bgzb",document.head);s=c(t,"META",{name:!0,content:!0}),t.forEach(n),p=o(e),r=c(e,"P",{}),et(r).forEach(n),y=o(e),h(i.$$.fragment,e),w=o(e),g=c(e,"P",{"data-svelte-h":!0}),b(g)!=="svelte-1p2jp9h"&&(g.innerHTML=te),le=o(e),v=c(e,"P",{"data-svelte-h":!0}),b(v)!=="svelte-19vr8o1"&&(v.textContent=ze),se=o(e),U=c(e,"OL",{"data-svelte-h":!0}),b(U)!=="svelte-cpv1c7"&&(U.innerHTML=Qe),re=o(e),h(Z.$$.fragment,e),ae=o(e),k=c(e,"P",{"data-svelte-h":!0}),b(k)!=="svelte-1a6x1rv"&&(k.textContent=Ie),oe=o(e),h(C.$$.fragment,e),ie=o(e),B=c(e,"P",{"data-svelte-h":!0}),b(B)!=="svelte-iry9lj"&&(B.textContent=Xe),pe=o(e),h(W.$$.fragment,e),me=o(e),V=c(e,"P",{"data-svelte-h":!0}),b(V)!=="svelte-pqz47w"&&(V.textContent=Ne),ce=o(e),h(H.$$.fragment,e),de=o(e),x=c(e,"P",{"data-svelte-h":!0}),b(x)!=="svelte-1c7f96d"&&(x.innerHTML=Ge),he=o(e),z=c(e,"P",{"data-svelte-h":!0}),b(z)!=="svelte-d9cbzb"&&(z.innerHTML=Re),fe=o(e),h(j.$$.fragment,e),ue=o(e),h(Q.$$.fragment,e),Me=o(e),I=c(e,"P",{"data-svelte-h":!0}),b(I)!=="svelte-1gfw7kg"&&(I.innerHTML=Ae),$e=o(e),h(X.$$.fragment,e),be=o(e),N=c(e,"P",{"data-svelte-h":!0}),b(N)!=="svelte-h0kse6"&&(N.innerHTML=Ee),ye=o(e),h(G.$$.fragment,e),we=o(e),R=c(e,"P",{"data-svelte-h":!0}),b(R)!=="svelte-1re42a5"&&(R.innerHTML=Le),Te=o(e),h(A.$$.fragment,e),ge=o(e),h(E.$$.fragment,e),je=o(e),L=c(e,"P",{"data-svelte-h":!0}),b(L)!=="svelte-48ajy7"&&(L.innerHTML=Se),Je=o(e),h(J.$$.fragment,e),_e=o(e),S=c(e,"P",{"data-svelte-h":!0}),b(S)!=="svelte-19l8duq"&&(S.innerHTML=Ye),ve=o(e),h(Y.$$.fragment,e),Ue=o(e),P=c(e,"P",{"data-svelte-h":!0}),b(P)!=="svelte-182uj63"&&(P.innerHTML=Pe),Ze=o(e),h(D.$$.fragment,e),ke=o(e),q=c(e,"P",{"data-svelte-h":!0}),b(q)!=="svelte-1gu0sly"&&(q.innerHTML=De),Ce=o(e),F=c(e,"P",{"data-svelte-h":!0}),b(F)!=="svelte-ndwcam"&&(F.innerHTML=qe),Be=o(e),K=c(e,"P",{"data-svelte-h":!0}),b(K)!=="svelte-e14za4"&&(K.innerHTML=Fe),We=o(e),h(O.$$.fragment,e),Ve=o(e),ne=c(e,"P",{}),et(ne).forEach(n),this.h()},h(){tt(s,"name","hf:doc:metadata"),tt(s,"content",$t)},m(e,t){it(document.head,s),l(e,p,t),l(e,r,t),l(e,y,t),f(i,e,t),l(e,w,t),l(e,g,t),l(e,le,t),l(e,v,t),l(e,se,t),l(e,U,t),l(e,re,t),f(Z,e,t),l(e,ae,t),l(e,k,t),l(e,oe,t),f(C,e,t),l(e,ie,t),l(e,B,t),l(e,pe,t),f(W,e,t),l(e,me,t),l(e,V,t),l(e,ce,t),f(H,e,t),l(e,de,t),l(e,x,t),l(e,he,t),l(e,z,t),l(e,fe,t),f(j,e,t),l(e,ue,t),f(Q,e,t),l(e,Me,t),l(e,I,t),l(e,$e,t),f(X,e,t),l(e,be,t),l(e,N,t),l(e,ye,t),f(G,e,t),l(e,we,t),l(e,R,t),l(e,Te,t),f(A,e,t),l(e,ge,t),f(E,e,t),l(e,je,t),l(e,L,t),l(e,Je,t),f(J,e,t),l(e,_e,t),l(e,S,t),l(e,ve,t),f(Y,e,t),l(e,Ue,t),l(e,P,t),l(e,Ze,t),f(D,e,t),l(e,ke,t),l(e,q,t),l(e,Ce,t),l(e,F,t),l(e,Be,t),l(e,K,t),l(e,We,t),f(O,e,t),l(e,Ve,t),l(e,ne,t),He=!0},p(e,[t]){const Ke={};t&2&&(Ke.$$scope={dirty:t,ctx:e}),j.$set(Ke);const Oe={};t&2&&(Oe.$$scope={dirty:t,ctx:e}),J.$set(Oe)},i(e){He||(u(i.$$.fragment,e),u(Z.$$.fragment,e),u(C.$$.fragment,e),u(W.$$.fragment,e),u(H.$$.fragment,e),u(j.$$.fragment,e),u(Q.$$.fragment,e),u(X.$$.fragment,e),u(G.$$.fragment,e),u(A.$$.fragment,e),u(E.$$.fragment,e),u(J.$$.fragment,e),u(Y.$$.fragment,e),u(D.$$.fragment,e),u(O.$$.fragment,e),He=!0)},o(e){M(i.$$.fragment,e),M(Z.$$.fragment,e),M(C.$$.fragment,e),M(W.$$.fragment,e),M(H.$$.fragment,e),M(j.$$.fragment,e),M(Q.$$.fragment,e),M(X.$$.fragment,e),M(G.$$.fragment,e),M(A.$$.fragment,e),M(E.$$.fragment,e),M(J.$$.fragment,e),M(Y.$$.fragment,e),M(D.$$.fragment,e),M(O.$$.fragment,e),He=!1},d(e){e&&(n(p),n(r),n(y),n(w),n(g),n(le),n(v),n(se),n(U),n(re),n(ae),n(k),n(oe),n(ie),n(B),n(pe),n(me),n(V),n(ce),n(de),n(x),n(he),n(z),n(fe),n(ue),n(Me),n(I),n($e),n(be),n(N),n(ye),n(we),n(R),n(Te),n(ge),n(je),n(L),n(Je),n(_e),n(S),n(ve),n(Ue),n(P),n(Ze),n(ke),n(q),n(Ce),n(F),n(Be),n(K),n(We),n(Ve),n(ne)),n(s),$(i,e),$(Z,e),$(C,e),$(W,e),$(H,e),$(j,e),$(Q,e),$(X,e),$(G,e),$(A,e),$(E,e),$(J,e),$(Y,e),$(D,e),$(O,e)}}}const $t='{"title":"TorchScript","local":"torchscript","sections":[{"title":"Dummy inputs","local":"dummy-inputs","sections":[],"depth":2},{"title":"Tied weights","local":"tied-weights","sections":[],"depth":2},{"title":"Export to TorchScript","local":"export-to-torchscript","sections":[],"depth":2},{"title":"Deploy to AWS","local":"deploy-to-aws","sections":[{"title":"Model architectures","local":"model-architectures","sections":[],"depth":3}],"depth":2}],"depth":1}';function bt(T){return st(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class _t extends rt{constructor(s){super(),at(this,s,bt,Mt,lt,{})}}export{_t as component};
