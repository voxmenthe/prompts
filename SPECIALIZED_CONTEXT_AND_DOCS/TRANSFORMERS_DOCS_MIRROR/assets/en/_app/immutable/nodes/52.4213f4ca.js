import{s as bi,c as $i,u as Ci,g as ki,d as wi,o as yi,n as Ea}from"../chunks/scheduler.18a86fab.js";import{S as vi,i as _i,r as g,u as f,v as h,d as m,t as p,w as u,g as n,m as hi,s as r,h as s,j as _,n as ui,f as o,c as a,k as T,a as c,y as t,o as xi,A as Mi,x as i}from"../chunks/index.98837b22.js";import{T as Ti}from"../chunks/Tip.77304350.js";import{D as $}from"../chunks/Docstring.a1ef7999.js";import{C as Ia}from"../chunks/CodeBlock.8d0c2e8a.js";import{E as Uo}from"../chunks/ExampleCodeBlock.8c3ee1f9.js";import{H as La,E as Li}from"../chunks/getInferenceSnippets.06c2775f.js";function Ii(L){let d,M,v,C,y;const b=L[1].default,x=$i(b,L,L[2],null);return{c(){d=n("p"),M=hi("Deprecated in "),v=hi(L[0]),C=r(),x&&x.c(),this.h()},l(I){d=s(I,"P",{class:!0});var H=_(d);M=ui(H,"Deprecated in "),v=ui(H,L[0]),H.forEach(o),C=a(I),x&&x.l(I),this.h()},h(){T(d,"class","font-medium")},m(I,H){c(I,d,H),t(d,M),t(d,v),c(I,C,H),x&&x.m(I,H),y=!0},p(I,H){(!y||H&1)&&xi(v,I[0]),x&&x.p&&(!y||H&4)&&Ci(x,b,I,I[2],y?wi(b,I[2],H,null):ki(I[2]),null)},i(I){y||(m(x,I),y=!0)},o(I){p(x,I),y=!1},d(I){I&&(o(d),o(C)),x&&x.d(I)}}}function Ei(L){let d,M;return d=new Ti({props:{warning:!0,$$slots:{default:[Ii]},$$scope:{ctx:L}}}),{c(){g(d.$$.fragment)},l(v){f(d.$$.fragment,v)},m(v,C){h(d,v,C),M=!0},p(v,[C]){const y={};C&5&&(y.$$scope={dirty:C,ctx:v}),d.$set(y)},i(v){M||(m(d.$$.fragment,v),M=!0)},o(v){p(d.$$.fragment,v),M=!1},d(v){u(d,v)}}}function Hi(L,d,M){let{$$slots:v={},$$scope:C}=d,{version:y}=d;return L.$$set=b=>{"version"in b&&M(0,y=b.version),"$$scope"in b&&M(2,C=b.$$scope)},[y,v,C]}class Ai extends vi{constructor(d){super(),_i(this,d,Hi,Ei,bi,{version:0})}}function ji(L){let d,M="<strong>Requires</strong>:",v,C,y;return C=new Ia({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRyYWNraW8=",highlighted:"pip install trackio",wrap:!1}}),{c(){d=n("p"),d.innerHTML=M,v=r(),g(C.$$.fragment)},l(b){d=s(b,"P",{"data-svelte-h":!0}),i(d)!=="svelte-1da90m7"&&(d.innerHTML=M),v=a(b),f(C.$$.fragment,b)},m(b,x){c(b,d,x),c(b,v,x),h(C,b,x),y=!0},p:Ea,i(b){y||(m(C.$$.fragment,b),y=!0)},o(b){p(C.$$.fragment,b),y=!1},d(b){b&&(o(d),o(v)),u(C,b)}}}function Si(L){let d,M="Setting <code>WANDB_LOG_MODEL</code> as <code>bool</code> will be deprecated in version 5 of ü§ó Transformers.";return{c(){d=n("p"),d.innerHTML=M},l(v){d=s(v,"P",{"data-svelte-h":!0}),i(d)!=="svelte-fxlq1n"&&(d.innerHTML=M)},m(v,C){c(v,d,C)},p:Ea,d(v){v&&o(d)}}}function Ni(L){let d,M="Example:",v,C,y;return C=new Ia({props:{code:"JTIzJTIwTm90ZSUzQSUyMFRoaXMlMjBleGFtcGxlJTIwc2tpcHMlMjBvdmVyJTIwc29tZSUyMHNldHVwJTIwc3RlcHMlMjBmb3IlMjBicmV2aXR5LiUwQWZyb20lMjBmbHl0ZWtpdCUyMGltcG9ydCUyMGN1cnJlbnRfY29udGV4dCUyQyUyMHRhc2slMEElMEElMEElNDB0YXNrJTBBZGVmJTIwdHJhaW5faGZfdHJhbnNmb3JtZXIoKSUzQSUwQSUyMCUyMCUyMCUyMGNwJTIwJTNEJTIwY3VycmVudF9jb250ZXh0KCkuY2hlY2twb2ludCUwQSUyMCUyMCUyMCUyMHRyYWluZXIlMjAlM0QlMjBUcmFpbmVyKC4uLiUyQyUyMGNhbGxiYWNrcyUzRCU1QkZseXRlQ2FsbGJhY2soKSU1RCklMEElMjAlMjAlMjAlMjBvdXRwdXQlMjAlM0QlMjB0cmFpbmVyLnRyYWluKHJlc3VtZV9mcm9tX2NoZWNrcG9pbnQlM0RjcC5yZXN0b3JlKCkp",highlighted:`<span class="hljs-comment"># Note: This example skips over some setup steps for brevity.</span>
<span class="hljs-keyword">from</span> flytekit <span class="hljs-keyword">import</span> current_context, task


<span class="hljs-meta">@task</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">train_hf_transformer</span>():
    cp = current_context().checkpoint
    trainer = Trainer(..., callbacks=[FlyteCallback()])
    output = trainer.train(resume_from_checkpoint=cp.restore())`,wrap:!1}}),{c(){d=n("p"),d.textContent=M,v=r(),g(C.$$.fragment)},l(b){d=s(b,"P",{"data-svelte-h":!0}),i(d)!=="svelte-11lpom8"&&(d.textContent=M),v=a(b),f(C.$$.fragment,b)},m(b,x){c(b,d,x),c(b,v,x),h(C,b,x),y=!0},p:Ea,i(b){y||(m(C.$$.fragment,b),y=!0)},o(b){p(C.$$.fragment,b),y=!1},d(b){b&&(o(d),o(v)),u(C,b)}}}function Pi(L){let d,M="Example:",v,C,y;return C=new Ia({props:{code:"Y2xhc3MlMjBQcmludGVyQ2FsbGJhY2soVHJhaW5lckNhbGxiYWNrKSUzQSUwQSUyMCUyMCUyMCUyMGRlZiUyMG9uX2xvZyhzZWxmJTJDJTIwYXJncyUyQyUyMHN0YXRlJTJDJTIwY29udHJvbCUyQyUyMGxvZ3MlM0ROb25lJTJDJTIwKiprd2FyZ3MpJTNBJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwXyUyMCUzRCUyMGxvZ3MucG9wKCUyMnRvdGFsX2Zsb3MlMjIlMkMlMjBOb25lKSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMGlmJTIwc3RhdGUuaXNfbG9jYWxfcHJvY2Vzc196ZXJvJTNBJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwcHJpbnQobG9ncyk=",highlighted:`<span class="hljs-keyword">class</span> <span class="hljs-title class_">PrinterCallback</span>(<span class="hljs-title class_ inherited__">TrainerCallback</span>):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">on_log</span>(<span class="hljs-params">self, args, state, control, logs=<span class="hljs-literal">None</span>, **kwargs</span>):
        _ = logs.pop(<span class="hljs-string">&quot;total_flos&quot;</span>, <span class="hljs-literal">None</span>)
        <span class="hljs-keyword">if</span> state.is_local_process_zero:
            <span class="hljs-built_in">print</span>(logs)`,wrap:!1}}),{c(){d=n("p"),d.textContent=M,v=r(),g(C.$$.fragment)},l(b){d=s(b,"P",{"data-svelte-h":!0}),i(d)!=="svelte-11lpom8"&&(d.textContent=M),v=a(b),f(C.$$.fragment,b)},m(b,x){c(b,d,x),c(b,v,x),h(C,b,x),y=!0},p:Ea,i(b){y||(m(C.$$.fragment,b),y=!0)},o(b){p(C.$$.fragment,b),y=!1},d(b){b&&(o(d),o(v)),u(C,b)}}}function Di(L){let d,M=`In all this class, one step is to be understood as one update step. When using gradient accumulation, one update
step may require several forward and backward passes: if you use <code>gradient_accumulation_steps=n</code>, then one update
step requires going through <em>n</em> batches.`;return{c(){d=n("p"),d.innerHTML=M},l(v){d=s(v,"P",{"data-svelte-h":!0}),i(d)!=="svelte-rhwh6p"&&(d.innerHTML=M)},m(v,C){c(v,d,C)},p:Ea,d(v){v&&o(d)}}}function Ui(L){let d,M,v,C,y,b,x,I=`Callbacks are objects that can customize the behavior of the training loop in the PyTorch
<a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> that can inspect the training loop state (for progress reporting, logging on TensorBoard or other ML
platforms‚Ä¶) and take decisions (like early stopping).`,H,Fe,Jo=`Callbacks are ‚Äúread only‚Äù pieces of code, apart from the <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerControl">TrainerControl</a> object they return, they
cannot change anything in the training loop. For customizations that require changes in the training loop, you should
subclass <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> and override the methods you need (see <a href="trainer">trainer</a> for examples).`,Ha,ze,Wo='By default, <code>TrainingArguments.report_to</code> is set to <code>&quot;all&quot;</code>, so a <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> will use the following callbacks.',Aa,Be,Fo=`<li><a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.DefaultFlowCallback">DefaultFlowCallback</a> which handles the default behavior for logging, saving and evaluation.</li> <li><a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.PrinterCallback">PrinterCallback</a> or <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.ProgressCallback">ProgressCallback</a> to display progress and print the
logs (the first one is used if you deactivate tqdm through the <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>, otherwise
it‚Äôs the second one).</li> <li><a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.integrations.TensorBoardCallback">TensorBoardCallback</a> if tensorboard is accessible (either through PyTorch &gt;= 1.4
or tensorboardX).</li> <li><a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.integrations.TrackioCallback">TrackioCallback</a> if <a href="https://github.com/gradio-app/trackio" rel="nofollow">trackio</a> is installed.</li> <li><a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.integrations.WandbCallback">WandbCallback</a> if <a href="https://www.wandb.com/" rel="nofollow">wandb</a> is installed.</li> <li><a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.integrations.CometCallback">CometCallback</a> if <a href="https://www.comet.com/site/" rel="nofollow">comet_ml</a> is installed.</li> <li><a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.integrations.MLflowCallback">MLflowCallback</a> if <a href="https://www.mlflow.org/" rel="nofollow">mlflow</a> is installed.</li> <li><a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.integrations.NeptuneCallback">NeptuneCallback</a> if <a href="https://neptune.ai/" rel="nofollow">neptune</a> is installed.</li> <li><a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.integrations.AzureMLCallback">AzureMLCallback</a> if <a href="https://pypi.org/project/azureml-sdk/" rel="nofollow">azureml-sdk</a> is
installed.</li> <li><a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.integrations.CodeCarbonCallback">CodeCarbonCallback</a> if <a href="https://pypi.org/project/codecarbon/" rel="nofollow">codecarbon</a> is
installed.</li> <li><a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.integrations.ClearMLCallback">ClearMLCallback</a> if <a href="https://github.com/allegroai/clearml" rel="nofollow">clearml</a> is installed.</li> <li><a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.integrations.DagsHubCallback">DagsHubCallback</a> if <a href="https://dagshub.com/" rel="nofollow">dagshub</a> is installed.</li> <li><a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.integrations.FlyteCallback">FlyteCallback</a> if <a href="https://flyte.org/" rel="nofollow">flyte</a> is installed.</li> <li><a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.integrations.DVCLiveCallback">DVCLiveCallback</a> if <a href="https://dvc.org/doc/dvclive" rel="nofollow">dvclive</a> is installed.</li> <li><a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.integrations.SwanLabCallback">SwanLabCallback</a> if <a href="http://swanlab.cn/" rel="nofollow">swanlab</a> is installed.</li>`,ja,qe,zo="If a package is installed but you don‚Äôt wish to use the accompanying integration, you can change <code>TrainingArguments.report_to</code> to a list of just those integrations you want to use (e.g. <code>[&quot;azure_ml&quot;, &quot;wandb&quot;]</code>).",Sa,Re,Bo=`The main class that implements callbacks is <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a>. It gets the
<a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> used to instantiate the <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a>, can access that
Trainer‚Äôs internal state via <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerState">TrainerState</a>, and can take some actions on the training loop via
<a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerControl">TrainerControl</a>.`,Na,Oe,Pa,Ve,qo='Here is the list of the available <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> in the library:',Da,R,Ge,Un,Qt,Ro='A <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that sends the logs to <a href="https://www.comet.com/site/" rel="nofollow">Comet ML</a>.',Jn,S,Ye,Wn,Kt,Oo="Setup the optional Comet integration.",Fn,er,Vo="Environment:",zn,tr,Go=`<li><strong>COMET_MODE</strong> (<code>str</code>, <em>optional</em>, default to <code>get_or_create</code>):
Control whether to create and log to a new Comet experiment or append to an existing experiment.
It accepts the following values:<ul><li><code>get_or_create</code>: Decides automatically depending if
<code>COMET_EXPERIMENT_KEY</code> is set and whether an Experiment
with that key already exists or not.</li> <li><code>create</code>: Always create a new Comet Experiment.</li> <li><code>get</code>: Always try to append to an Existing Comet Experiment.
Requires <code>COMET_EXPERIMENT_KEY</code> to be set.</li> <li><code>ONLINE</code>: <strong>deprecated</strong>, used to create an online
Experiment. Use <code>COMET_START_ONLINE=1</code> instead.</li> <li><code>OFFLINE</code>: <strong>deprecated</strong>, used to created an offline
Experiment. Use <code>COMET_START_ONLINE=0</code> instead.</li> <li><code>DISABLED</code>: <strong>deprecated</strong>, used to disable Comet logging.
Use the <code>--report_to</code> flag to control the integrations used
for logging result instead.</li></ul></li> <li><strong>COMET_PROJECT_NAME</strong> (<code>str</code>, <em>optional</em>):
Comet project name for experiments.</li> <li><strong>COMET_LOG_ASSETS</strong> (<code>str</code>, <em>optional</em>, defaults to <code>TRUE</code>):
Whether or not to log training assets (tf event logs, checkpoints, etc), to Comet. Can be <code>TRUE</code>, or
<code>FALSE</code>.</li>`,Bn,rr,Yo=`For a number of configurable items in the environment, see
<a href="https://www.comet.com/docs/v2/guides/experiment-management/configure-sdk/#explore-comet-configuration-options" rel="nofollow">here</a>.`,Ua,ae,Xe,qn,ar,Xo='A <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that handles the default flow of the training loop for logs, evaluation and checkpoints.',Ja,ne,Ze,Rn,nr,Zo='A bare <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that just prints the logs.',Wa,se,Qe,On,sr,Qo=`A <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that displays the progress of training or evaluation.
You can modify <code>max_str_len</code> to control how long strings are truncated when logging.`,Fa,O,Ke,Vn,or,Ko='A <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that handles early stopping.',Gn,lr,el=`This callback depends on <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> argument <em>load_best_model_at_end</em> functionality to set best_metric
in <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerState">TrainerState</a>. Note that if the <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> argument <em>save_steps</em> differs from <em>eval_steps</em>, the
early stopping will not occur until the next save step.`,za,oe,et,Yn,ir,tl='A <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that sends the logs to <a href="https://www.tensorflow.org/tensorboard" rel="nofollow">TensorBoard</a>.',Ba,j,tt,Xn,cr,rl='A <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that logs metrics to Trackio.',Zn,dr,al=`It records training metrics, model (and PEFT) configuration, and GPU memory usage.
If <code>nvidia-ml-py</code> is installed, GPU power consumption is also tracked.`,Qn,me,Kn,N,rt,es,mr,nl="Setup the optional Trackio integration.",ts,pr,sl="To customize the setup you can also override the following environment variables:",rs,gr,ol="Environment:",as,fr,ll=`<li><strong>TRACKIO_PROJECT</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;huggingface&quot;</code>):
The name of the project (can be an existing project to continue tracking or a new project to start tracking
from scratch).</li> <li><strong>TRACKIO_SPACE_ID</strong> (<code>str</code>, <em>optional</em>, defaults to <code>None</code>):
If set, the project will be logged to a Hugging Face Space instead of a local directory. Should be a
complete Space name like <code>&quot;username/reponame&quot;</code> or <code>&quot;orgname/reponame&quot;</code>, or just \`‚Äúreponame‚Äù in which case
the Space will be created in the currently-logged-in Hugging Face user‚Äôs namespace. If the Space does not
exist, it will be created. If the Space already exists, the project will be logged to it.</li>`,qa,V,at,ns,hr,il='A <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that logs metrics, media, model checkpoints to <a href="https://www.wandb.com/" rel="nofollow">Weight and Biases</a>.',ss,P,nt,os,ur,cl="Setup the optional Weights &amp; Biases (<em>wandb</em>) integration.",ls,br,dl=`One can subclass and override this method to customize the setup if needed. Find more information
<a href="https://docs.wandb.ai/guides/integrations/huggingface" rel="nofollow">here</a>. You can also override the following environment
variables:`,is,vr,ml="Environment:",cs,G,st,_r,pl=`<strong>WANDB_LOG_MODEL</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;false&quot;</code>):
Whether to log model and checkpoints during training. Can be <code>&quot;end&quot;</code>, <code>&quot;checkpoint&quot;</code> or <code>&quot;false&quot;</code>. If set
to <code>&quot;end&quot;</code>, the model will be uploaded at the end of training. If set to <code>&quot;checkpoint&quot;</code>, the checkpoint
will be uploaded every <code>args.save_steps</code> . If set to <code>&quot;false&quot;</code>, the model will not be uploaded. Use along
with <code>load_best_model_at_end()</code> to upload best model.`,ds,pe,ms,Tr,gl=`<p><strong>WANDB_WATCH</strong> (<code>str</code>, <em>optional</em> defaults to <code>&quot;false&quot;</code>):
Can be <code>&quot;gradients&quot;</code>, <code>&quot;all&quot;</code>, <code>&quot;parameters&quot;</code>, or <code>&quot;false&quot;</code>. Set to <code>&quot;all&quot;</code> to log gradients and
parameters.</p>`,ps,$r,fl=`<p><strong>WANDB_PROJECT</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;huggingface&quot;</code>):
Set this to a custom string to store results in a different project.</p>`,gs,Cr,hl=`<p><strong>WANDB_DISABLED</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):
Whether to disable wandb entirely. Set <code>WANDB_DISABLED=true</code> to disable.</p>`,Ra,Y,ot,fs,kr,ul=`A <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that sends the logs to <a href="https://www.mlflow.org/" rel="nofollow">MLflow</a>. Can be disabled by setting
environment variable <code>DISABLE_MLFLOW_INTEGRATION = TRUE</code>.`,hs,F,lt,us,wr,bl="Setup the optional MLflow integration.",bs,yr,vl="Environment:",vs,xr,_l=`<li><strong>HF_MLFLOW_LOG_ARTIFACTS</strong> (<code>str</code>, <em>optional</em>):
Whether to use MLflow <code>.log_artifact()</code> facility to log artifacts. This only makes sense if logging to a
remote server, e.g. s3 or GCS. If set to <code>True</code> or <em>1</em>, will copy each saved checkpoint on each save in
<a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>‚Äôs <code>output_dir</code> to the local or remote artifact storage. Using it without a remote
storage will just copy the files to your artifact location.</li> <li><strong>MLFLOW_TRACKING_URI</strong> (<code>str</code>, <em>optional</em>):
Whether to store runs at a specific path or remote server. Unset by default, which skips setting the
tracking URI entirely.</li> <li><strong>MLFLOW_EXPERIMENT_NAME</strong> (<code>str</code>, <em>optional</em>, defaults to <code>None</code>):
Whether to use an MLflow experiment_name under which to launch the run. Default to <code>None</code> which will point
to the <code>Default</code> experiment in MLflow. Otherwise, it is a case sensitive name of the experiment to be
activated. If an experiment with this name does not exist, a new experiment with this name is created.</li> <li><strong>MLFLOW_TAGS</strong> (<code>str</code>, <em>optional</em>):
A string dump of a dictionary of key/value pair to be added to the MLflow run as tags. Example:
<code>os.environ[&#39;MLFLOW_TAGS&#39;]=&#39;{&quot;release.candidate&quot;: &quot;RC1&quot;, &quot;release.version&quot;: &quot;2.2.0&quot;}&#39;</code>.</li> <li><strong>MLFLOW_NESTED_RUN</strong> (<code>str</code>, <em>optional</em>):
Whether to use MLflow nested runs. If set to <code>True</code> or <em>1</em>, will create a nested run inside the current
run.</li> <li><strong>MLFLOW_RUN_ID</strong> (<code>str</code>, <em>optional</em>):
Allow to reattach to an existing run which can be useful when resuming training from a checkpoint. When
<code>MLFLOW_RUN_ID</code> environment variable is set, <code>start_run</code> attempts to resume a run with the specified run ID
and other parameters are ignored.</li> <li><strong>MLFLOW_FLATTEN_PARAMS</strong> (<code>str</code>, <em>optional</em>, defaults to <code>False</code>):
Whether to flatten the parameters dictionary before logging.</li> <li><strong>MLFLOW_MAX_LOG_PARAMS</strong> (<code>int</code>, <em>optional</em>):
Set the maximum number of parameters to log in the run.</li>`,Oa,le,it,_s,Mr,Tl='A <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that sends the logs to <a href="https://pypi.org/project/azureml-sdk/" rel="nofollow">AzureML</a>.',Va,ie,ct,Ts,Lr,$l='A <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that tracks the CO2 emission of training.',Ga,X,dt,$s,Ir,Cl='TrainerCallback that sends the logs to <a href="https://app.neptune.ai" rel="nofollow">Neptune</a>.',Cs,Er,kl=`For instructions and examples, see the <a href="https://docs.neptune.ai/integrations/transformers" rel="nofollow">Transformers integration
guide</a> in the Neptune documentation.`,Ya,U,mt,ks,Hr,wl='A <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that sends the logs to <a href="https://clear.ml/" rel="nofollow">ClearML</a>.',ws,Ar,yl="Environment:",ys,jr,xl=`<li><strong>CLEARML_PROJECT</strong> (<code>str</code>, <em>optional</em>, defaults to <code>HuggingFace Transformers</code>):
ClearML project name.</li> <li><strong>CLEARML_TASK</strong> (<code>str</code>, <em>optional</em>, defaults to <code>Trainer</code>):
ClearML task name.</li> <li><strong>CLEARML_LOG_MODEL</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):
Whether to log models as artifacts during training.</li>`,Xa,Z,pt,xs,Sr,Ml='A <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that logs to <a href="https://dagshub.com/" rel="nofollow">DagsHub</a>. Extends <code>MLflowCallback</code>',Ms,z,gt,Ls,Nr,Ll="Setup the DagsHub‚Äôs Logging integration.",Is,Pr,Il="Environment:",Es,Dr,El=`<li><strong>HF_DAGSHUB_LOG_ARTIFACTS</strong> (<code>str</code>, <em>optional</em>):
Whether to save the data and model artifacts for the experiment. Default to <code>False</code>.</li>`,Za,Q,ft,Hs,Ur,Hl=`A <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that sends the logs to <a href="https://flyte.org/" rel="nofollow">Flyte</a>.
NOTE: This callback only works within a Flyte task.`,As,ge,Qa,J,ht,js,Jr,Al='A <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that sends the logs to <a href="https://www.dvc.org/doc/dvclive" rel="nofollow">DVCLive</a>.',Ss,Wr,jl=`Use the environment variables below in <code>setup</code> to configure the integration. To customize this callback beyond
those environment variables, see <a href="https://dvc.org/doc/dvclive/ml-frameworks/huggingface" rel="nofollow">here</a>.`,Ns,B,ut,Ps,Fr,Sl=`Setup the optional DVCLive integration. To customize this callback beyond the environment variables below, see
<a href="https://dvc.org/doc/dvclive/ml-frameworks/huggingface" rel="nofollow">here</a>.`,Ds,zr,Nl="Environment:",Us,Br,Pl=`<li><strong>HF_DVCLIVE_LOG_MODEL</strong> (<code>str</code>, <em>optional</em>):
Whether to use <code>dvclive.Live.log_artifact()</code> to log checkpoints created by <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a>. If set to <code>True</code> or
<em>1</em>, the final checkpoint is logged at the end of training. If set to <code>all</code>, the entire
<a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>‚Äôs <code>output_dir</code> is logged at each checkpoint.</li>`,Ka,K,bt,Js,qr,Dl='A <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that logs metrics, media, model checkpoints to <a href="https://swanlab.cn/" rel="nofollow">SwanLab</a>.',Ws,A,vt,Fs,Rr,Ul="Setup the optional SwanLab (<em>swanlab</em>) integration.",zs,Or,Jl=`One can subclass and override this method to customize the setup if needed. Find more information
<a href="https://docs.swanlab.cn/guide_cloud/integration/integration-huggingface-transformers.html" rel="nofollow">here</a>.`,Bs,Vr,Wl=`You can also override the following environment variables. Find more information about environment
variables <a href="https://docs.swanlab.cn/en/api/environment-variable.html#environment-variables" rel="nofollow">here</a>`,qs,Gr,Fl="Environment:",Rs,Yr,zl=`<li><p><strong>SWANLAB_API_KEY</strong> (<code>str</code>, <em>optional</em>, defaults to <code>None</code>):
Cloud API Key. During login, this environment variable is checked first. If it doesn‚Äôt exist, the system
checks if the user is already logged in. If not, the login process is initiated.</p> <ul><li>If a string is passed to the login interface, this environment variable is ignored.</li> <li>If the user is already logged in, this environment variable takes precedence over locally stored
login information.</li></ul></li> <li><p><strong>SWANLAB_PROJECT</strong> (<code>str</code>, <em>optional</em>, defaults to <code>None</code>):
Set this to a custom string to store results in a different project. If not specified, the name of the current
running directory is used.</p></li> <li><p><strong>SWANLAB_LOG_DIR</strong> (<code>str</code>, <em>optional</em>, defaults to <code>swanlog</code>):
This environment variable specifies the storage path for log files when running in local mode.
By default, logs are saved in a folder named swanlog under the working directory.</p></li> <li><p><strong>SWANLAB_MODE</strong> (<code>Literal[&quot;local&quot;, &quot;cloud&quot;, &quot;disabled&quot;]</code>, <em>optional</em>, defaults to <code>cloud</code>):
SwanLab‚Äôs parsing mode, which involves callbacks registered by the operator. Currently, there are three modes:
local, cloud, and disabled. Note: Case-sensitive. Find more information
<a href="https://docs.swanlab.cn/en/api/py-init.html#swanlab-init" rel="nofollow">here</a></p></li> <li><p><strong>SWANLAB_LOG_MODEL</strong> (<code>str</code>, <em>optional</em>, defaults to <code>None</code>):
SwanLab does not currently support the save mode functionality.This feature will be available in a future
release</p></li> <li><p><strong>SWANLAB_WEB_HOST</strong> (<code>str</code>, <em>optional</em>, defaults to <code>None</code>):
Web address for the SwanLab cloud environment for private version (its free)</p></li> <li><p><strong>SWANLAB_API_HOST</strong> (<code>str</code>, <em>optional</em>, defaults to <code>None</code>):
API address for the SwanLab cloud environment for private version (its free)</p></li>`,en,_t,tn,k,Tt,Os,Xr,Bl=`A class for objects that will inspect the state of the training loop at some events and take some decisions. At
each of those events the following arguments are available:`,Vs,Zr,ql=`The <code>control</code> object is the only one that can be changed by the callback, in which case the event that changes it
should return the modified version.`,Gs,Qr,Rl=`The argument <code>args</code>, <code>state</code> and <code>control</code> are positionals for all events, all the others are grouped in <code>kwargs</code>.
You can unpack the ones you need in the signature of the event using them. As an example, see the code of the
simple <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.PrinterCallback">PrinterCallback</a>.`,Ys,fe,Xs,he,$t,Zs,Kr,Ol="Event called at the beginning of an epoch.",Qs,ue,Ct,Ks,ea,Vl="Event called at the end of an epoch.",eo,be,kt,to,ta,Gl="Event called after an evaluation phase.",ro,ve,wt,ao,ra,Yl='Event called at the end of the initialization of the <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a>.',no,_e,yt,so,aa,Xl="Event called after logging the last logs.",oo,Te,xt,lo,na,Zl="Event called after the optimizer step but before gradients are zeroed out. Useful for monitoring gradients.",io,$e,Mt,co,sa,Ql="Event called before the optimizer step but after gradient clipping. Useful for monitoring gradients.",mo,Ce,Lt,po,oa,Kl="Event called after a successful prediction.",go,ke,It,fo,la,ei="Event called after a prediction step.",ho,we,Et,uo,ia,ti="Event called after a checkpoint save.",bo,ye,Ht,vo,ca,ri=`Event called at the beginning of a training step. If using gradient accumulation, one training step might take
several inputs.`,_o,xe,At,To,da,ai=`Event called at the end of a training step. If using gradient accumulation, one training step might take
several inputs.`,$o,Me,jt,Co,ma,ni="Event called at the end of an substep during gradient accumulation.",ko,Le,St,wo,pa,si="Event called at the beginning of training.",yo,Ie,Nt,xo,ga,oi="Event called at the end of training.",rn,Pt,li='Here is an example of how to register a custom callback with the PyTorch <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a>:',an,Dt,nn,Ut,ii="Another way to register a callback is to call <code>trainer.add_callback()</code> as follows:",sn,Jt,on,Wt,ln,E,Ft,Mo,fa,ci=`A class containing the <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> inner state that will be saved along the model and optimizer when checkpointing
and passed to the <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a>.`,Lo,Ee,Io,He,zt,Eo,ha,di=`Calculates and stores the absolute value for logging,
eval, and save steps based on if it was a proportion
or not.`,Ho,Ae,Bt,Ao,ua,mi="Stores the initial training references needed in <code>self</code>",jo,je,qt,So,ba,pi="Create an instance from the content of <code>json_path</code>.",No,Se,Rt,Po,va,gi="Save the content of this instance in JSON format inside <code>json_path</code>.",cn,Ot,dn,ce,Vt,Do,_a,fi=`A class that handles the <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> control flow. This class is used by the <a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> to activate some
switches in the training loop.`,mn,Gt,pn,Ma,gn;return y=new La({props:{title:"Callbacks",local:"callbacks",headingTag:"h1"}}),Oe=new La({props:{title:"Available Callbacks",local:"transformers.integrations.CometCallback",headingTag:"h2"}}),Ge=new $({props:{name:"class transformers.integrations.CometCallback",anchor:"transformers.integrations.CometCallback",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/integration_utils.py#L1190"}}),Ye=new $({props:{name:"setup",anchor:"transformers.integrations.CometCallback.setup",parameters:[{name:"args",val:""},{name:"state",val:""},{name:"model",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/integration_utils.py#L1204"}}),Xe=new $({props:{name:"class transformers.DefaultFlowCallback",anchor:"transformers.DefaultFlowCallback",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L574"}}),Ze=new $({props:{name:"class transformers.PrinterCallback",anchor:"transformers.PrinterCallback",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L701"}}),Qe=new $({props:{name:"class transformers.ProgressCallback",anchor:"transformers.ProgressCallback",parameters:[{name:"max_str_len",val:": int = 100"}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L627"}}),Ke=new $({props:{name:"class transformers.EarlyStoppingCallback",anchor:"transformers.EarlyStoppingCallback",parameters:[{name:"early_stopping_patience",val:": int = 1"},{name:"early_stopping_threshold",val:": typing.Optional[float] = 0.0"}],parametersDescription:[{anchor:"transformers.EarlyStoppingCallback.early_stopping_patience",description:`<strong>early_stopping_patience</strong> (<code>int</code>) &#x2014;
Use with <code>metric_for_best_model</code> to stop training when the specified metric worsens for
<code>early_stopping_patience</code> evaluation calls.`,name:"early_stopping_patience"},{anchor:"transformers.EarlyStoppingCallback.early_stopping_threshold(float,",description:`<strong>early_stopping_threshold(<code>float</code>,</strong> <em>optional</em>) &#x2014;
Use with TrainingArguments <code>metric_for_best_model</code> and <code>early_stopping_patience</code> to denote how much the
specified metric must improve to satisfy early stopping conditions. \``,name:"early_stopping_threshold(float,"}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L712"}}),et=new $({props:{name:"class transformers.integrations.TensorBoardCallback",anchor:"transformers.integrations.TensorBoardCallback",parameters:[{name:"tb_writer",val:" = None"}],parametersDescription:[{anchor:"transformers.integrations.TensorBoardCallback.tb_writer",description:`<strong>tb_writer</strong> (<code>SummaryWriter</code>, <em>optional</em>) &#x2014;
The writer to use. Will instantiate one if not set.`,name:"tb_writer"}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/integration_utils.py#L671"}}),tt=new $({props:{name:"class transformers.integrations.TrackioCallback",anchor:"transformers.integrations.TrackioCallback",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/integration_utils.py#L1068"}}),me=new Uo({props:{anchor:"transformers.integrations.TrackioCallback.example",$$slots:{default:[ji]},$$scope:{ctx:L}}}),rt=new $({props:{name:"setup",anchor:"transformers.integrations.TrackioCallback.setup",parameters:[{name:"args",val:""},{name:"state",val:""},{name:"model",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/integration_utils.py#L1091"}}),at=new $({props:{name:"class transformers.integrations.WandbCallback",anchor:"transformers.integrations.WandbCallback",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/integration_utils.py#L804"}}),nt=new $({props:{name:"setup",anchor:"transformers.integrations.WandbCallback.setup",parameters:[{name:"args",val:""},{name:"state",val:""},{name:"model",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/integration_utils.py#L833"}}),pe=new Ai({props:{version:"5.0",$$slots:{default:[Si]},$$scope:{ctx:L}}}),ot=new $({props:{name:"class transformers.integrations.MLflowCallback",anchor:"transformers.integrations.MLflowCallback",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/integration_utils.py#L1353"}}),lt=new $({props:{name:"setup",anchor:"transformers.integrations.MLflowCallback.setup",parameters:[{name:"args",val:""},{name:"state",val:""},{name:"model",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/integration_utils.py#L1372"}}),it=new $({props:{name:"class transformers.integrations.AzureMLCallback",anchor:"transformers.integrations.AzureMLCallback",parameters:[{name:"azureml_run",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/integration_utils.py#L1330"}}),ct=new $({props:{name:"class transformers.integrations.CodeCarbonCallback",anchor:"transformers.integrations.CodeCarbonCallback",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/integration_utils.py#L1867"}}),dt=new $({props:{name:"class transformers.integrations.NeptuneCallback",anchor:"transformers.integrations.NeptuneCallback",parameters:[{name:"api_token",val:": typing.Optional[str] = None"},{name:"project",val:": typing.Optional[str] = None"},{name:"name",val:": typing.Optional[str] = None"},{name:"base_namespace",val:": str = 'finetuning'"},{name:"run",val:" = None"},{name:"log_parameters",val:": bool = True"},{name:"log_checkpoints",val:": typing.Optional[str] = None"},{name:"**neptune_run_kwargs",val:""}],parametersDescription:[{anchor:"transformers.integrations.NeptuneCallback.api_token",description:`<strong>api_token</strong> (<code>str</code>, <em>optional</em>) &#x2014; Neptune API token obtained upon registration.
You can leave this argument out if you have saved your token to the <code>NEPTUNE_API_TOKEN</code> environment
variable (strongly recommended). See full setup instructions in the
<a href="https://docs.neptune.ai/setup/installation" rel="nofollow">docs</a>.`,name:"api_token"},{anchor:"transformers.integrations.NeptuneCallback.project",description:`<strong>project</strong> (<code>str</code>, <em>optional</em>) &#x2014; Name of an existing Neptune project, in the form &#x201C;workspace-name/project-name&#x201D;.
You can find and copy the name in Neptune from the project settings -&gt; Properties. If None (default), the
value of the <code>NEPTUNE_PROJECT</code> environment variable is used.`,name:"project"},{anchor:"transformers.integrations.NeptuneCallback.name",description:"<strong>name</strong> (<code>str</code>, <em>optional</em>) &#x2014; Custom name for the run.",name:"name"},{anchor:"transformers.integrations.NeptuneCallback.base_namespace",description:`<strong>base_namespace</strong> (<code>str</code>, <em>optional</em>, defaults to &#x201C;finetuning&#x201D;) &#x2014; In the Neptune run, the root namespace
that will contain all of the metadata logged by the callback.`,name:"base_namespace"},{anchor:"transformers.integrations.NeptuneCallback.log_parameters",description:`<strong>log_parameters</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
If True, logs all Trainer arguments and model parameters provided by the Trainer.`,name:"log_parameters"},{anchor:"transformers.integrations.NeptuneCallback.log_checkpoints",description:`<strong>log_checkpoints</strong> (<code>str</code>, <em>optional</em>) &#x2014; If &#x201C;same&#x201D;, uploads checkpoints whenever they are saved by the Trainer.
If &#x201C;last&#x201D;, uploads only the most recently saved checkpoint. If &#x201C;best&#x201D;, uploads the best checkpoint (among
the ones saved by the Trainer). If <code>None</code>, does not upload checkpoints.`,name:"log_checkpoints"},{anchor:"transformers.integrations.NeptuneCallback.run",description:`<strong>run</strong> (<code>Run</code>, <em>optional</em>) &#x2014; Pass a Neptune run object if you want to continue logging to an existing run.
Read more about resuming runs in the <a href="https://docs.neptune.ai/logging/to_existing_object" rel="nofollow">docs</a>.`,name:"run"},{anchor:"transformers.integrations.NeptuneCallback.*neptune_run_kwargs",description:`*<strong>*neptune_run_kwargs</strong> (<em>optional</em>) &#x2014;
Additional keyword arguments to be passed directly to the
<a href="https://docs.neptune.ai/api/neptune#init_run" rel="nofollow"><code>neptune.init_run()</code></a> function when a new run is created.`,name:"*neptune_run_kwargs"}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/integration_utils.py#L1594"}}),mt=new $({props:{name:"class transformers.integrations.ClearMLCallback",anchor:"transformers.integrations.ClearMLCallback",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/integration_utils.py#L1901"}}),pt=new $({props:{name:"class transformers.integrations.DagsHubCallback",anchor:"transformers.integrations.DagsHubCallback",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/integration_utils.py#L1534"}}),gt=new $({props:{name:"setup",anchor:"transformers.integrations.DagsHubCallback.setup",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/integration_utils.py#L1548"}}),ft=new $({props:{name:"class transformers.integrations.FlyteCallback",anchor:"transformers.integrations.FlyteCallback",parameters:[{name:"save_log_history",val:": bool = True"},{name:"sync_checkpoints",val:": bool = True"}],parametersDescription:[{anchor:"transformers.integrations.FlyteCallback.save_log_history",description:`<strong>save_log_history</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
When set to True, the training logs are saved as a Flyte Deck.`,name:"save_log_history"},{anchor:"transformers.integrations.FlyteCallback.sync_checkpoints",description:`<strong>sync_checkpoints</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
When set to True, checkpoints are synced with Flyte and can be used to resume training in the case of an
interruption.`,name:"sync_checkpoints"}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/integration_utils.py#L2152"}}),ge=new Uo({props:{anchor:"transformers.integrations.FlyteCallback.example",$$slots:{default:[Ni]},$$scope:{ctx:L}}}),ht=new $({props:{name:"class transformers.integrations.DVCLiveCallback",anchor:"transformers.integrations.DVCLiveCallback",parameters:[{name:"live",val:": typing.Optional[typing.Any] = None"},{name:"log_model",val:": typing.Union[typing.Literal['all'], bool, NoneType] = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.integrations.DVCLiveCallback.live",description:`<strong>live</strong> (<code>dvclive.Live</code>, <em>optional</em>, defaults to <code>None</code>) &#x2014;
Optional Live instance. If None, a new instance will be created using **kwargs.`,name:"live"},{anchor:"transformers.integrations.DVCLiveCallback.log_model",description:`<strong>log_model</strong> (Union[Literal[&#x201C;all&#x201D;], bool], <em>optional</em>, defaults to <code>None</code>) &#x2014;
Whether to use <code>dvclive.Live.log_artifact()</code> to log checkpoints created by <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a>. If set to <code>True</code>,
the final checkpoint is logged at the end of training. If set to <code>&quot;all&quot;</code>, the entire
<a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>&#x2019;s <code>output_dir</code> is logged at each checkpoint.`,name:"log_model"}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/integration_utils.py#L2215"}}),ut=new $({props:{name:"setup",anchor:"transformers.integrations.DVCLiveCallback.setup",parameters:[{name:"args",val:""},{name:"state",val:""},{name:"model",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/integration_utils.py#L2256"}}),bt=new $({props:{name:"class transformers.integrations.SwanLabCallback",anchor:"transformers.integrations.SwanLabCallback",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/integration_utils.py#L2320"}}),vt=new $({props:{name:"setup",anchor:"transformers.integrations.SwanLabCallback.setup",parameters:[{name:"args",val:""},{name:"state",val:""},{name:"model",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/integrations/integration_utils.py#L2334"}}),_t=new La({props:{title:"TrainerCallback",local:"transformers.TrainerCallback",headingTag:"h2"}}),Tt=new $({props:{name:"class transformers.TrainerCallback",anchor:"transformers.TrainerCallback",parameters:[],parametersDescription:[{anchor:"transformers.TrainerCallback.args",description:`<strong>args</strong> (<a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>) &#x2014;
The training arguments used to instantiate the <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a>.`,name:"args"},{anchor:"transformers.TrainerCallback.state",description:`<strong>state</strong> (<a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerState">TrainerState</a>) &#x2014;
The current state of the <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a>.`,name:"state"},{anchor:"transformers.TrainerCallback.control",description:`<strong>control</strong> (<a href="/docs/transformers/v4.56.2/en/main_classes/callback#transformers.TrainerControl">TrainerControl</a>) &#x2014;
The object that is returned to the <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> and can be used to make some decisions.`,name:"control"},{anchor:"transformers.TrainerCallback.model",description:`<strong>model</strong> (<a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel">PreTrainedModel</a> or <code>torch.nn.Module</code>) &#x2014;
The model being trained.`,name:"model"},{anchor:"transformers.TrainerCallback.tokenizer",description:`<strong>tokenizer</strong> (<a href="/docs/transformers/v4.56.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer">PreTrainedTokenizer</a>) &#x2014;
The tokenizer used for encoding the data. This is deprecated in favour of <code>processing_class</code>.`,name:"tokenizer"},{anchor:"transformers.TrainerCallback.processing_class",description:`<strong>processing_class</strong> ([<code>PreTrainedTokenizer</code> or <code>BaseImageProcessor</code> or <code>ProcessorMixin</code> or <code>FeatureExtractionMixin</code>]) &#x2014;
The processing class used for encoding the data. Can be a tokenizer, a processor, an image processor or a feature extractor.`,name:"processing_class"},{anchor:"transformers.TrainerCallback.optimizer",description:`<strong>optimizer</strong> (<code>torch.optim.Optimizer</code>) &#x2014;
The optimizer used for the training steps.`,name:"optimizer"},{anchor:"transformers.TrainerCallback.lr_scheduler",description:`<strong>lr_scheduler</strong> (<code>torch.optim.lr_scheduler.LambdaLR</code>) &#x2014;
The scheduler used for setting the learning rate.`,name:"lr_scheduler"},{anchor:"transformers.TrainerCallback.train_dataloader",description:`<strong>train_dataloader</strong> (<code>torch.utils.data.DataLoader</code>, <em>optional</em>) &#x2014;
The current dataloader used for training.`,name:"train_dataloader"},{anchor:"transformers.TrainerCallback.eval_dataloader",description:`<strong>eval_dataloader</strong> (<code>torch.utils.data.DataLoader</code>, <em>optional</em>) &#x2014;
The current dataloader used for evaluation.`,name:"eval_dataloader"},{anchor:"transformers.TrainerCallback.metrics",description:`<strong>metrics</strong> (<code>dict[str, float]</code>) &#x2014;
The metrics computed by the last evaluation phase.</p>
<p>Those are only accessible in the event <code>on_evaluate</code>.`,name:"metrics"},{anchor:"transformers.TrainerCallback.logs",description:`<strong>logs</strong>  (<code>dict[str, float]</code>) &#x2014;
The values to log.</p>
<p>Those are only accessible in the event <code>on_log</code>.`,name:"logs"}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L297"}}),fe=new Uo({props:{anchor:"transformers.TrainerCallback.example",$$slots:{default:[Pi]},$$scope:{ctx:L}}}),$t=new $({props:{name:"on_epoch_begin",anchor:"transformers.TrainerCallback.on_epoch_begin",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L368"}}),Ct=new $({props:{name:"on_epoch_end",anchor:"transformers.TrainerCallback.on_epoch_end",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L374"}}),kt=new $({props:{name:"on_evaluate",anchor:"transformers.TrainerCallback.on_evaluate",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L412"}}),wt=new $({props:{name:"on_init_end",anchor:"transformers.TrainerCallback.on_init_end",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L350"}}),yt=new $({props:{name:"on_log",anchor:"transformers.TrainerCallback.on_log",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L430"}}),xt=new $({props:{name:"on_optimizer_step",anchor:"transformers.TrainerCallback.on_optimizer_step",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L393"}}),Mt=new $({props:{name:"on_pre_optimizer_step",anchor:"transformers.TrainerCallback.on_pre_optimizer_step",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L387"}}),Lt=new $({props:{name:"on_predict",anchor:"transformers.TrainerCallback.on_predict",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"metrics",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L418"}}),It=new $({props:{name:"on_prediction_step",anchor:"transformers.TrainerCallback.on_prediction_step",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L436"}}),Et=new $({props:{name:"on_save",anchor:"transformers.TrainerCallback.on_save",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L424"}}),Ht=new $({props:{name:"on_step_begin",anchor:"transformers.TrainerCallback.on_step_begin",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L380"}}),At=new $({props:{name:"on_step_end",anchor:"transformers.TrainerCallback.on_step_end",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L405"}}),jt=new $({props:{name:"on_substep_end",anchor:"transformers.TrainerCallback.on_substep_end",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L399"}}),St=new $({props:{name:"on_train_begin",anchor:"transformers.TrainerCallback.on_train_begin",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L356"}}),Nt=new $({props:{name:"on_train_end",anchor:"transformers.TrainerCallback.on_train_end",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L362"}}),Dt=new Ia({props:{code:"Y2xhc3MlMjBNeUNhbGxiYWNrKFRyYWluZXJDYWxsYmFjayklM0ElMEElMjAlMjAlMjAlMjAlMjJBJTIwY2FsbGJhY2slMjB0aGF0JTIwcHJpbnRzJTIwYSUyMG1lc3NhZ2UlMjBhdCUyMHRoZSUyMGJlZ2lubmluZyUyMG9mJTIwdHJhaW5pbmclMjIlMEElMEElMjAlMjAlMjAlMjBkZWYlMjBvbl90cmFpbl9iZWdpbihzZWxmJTJDJTIwYXJncyUyQyUyMHN0YXRlJTJDJTIwY29udHJvbCUyQyUyMCoqa3dhcmdzKSUzQSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMHByaW50KCUyMlN0YXJ0aW5nJTIwdHJhaW5pbmclMjIpJTBBJTBBJTBBdHJhaW5lciUyMCUzRCUyMFRyYWluZXIoJTBBJTIwJTIwJTIwJTIwbW9kZWwlMkMlMEElMjAlMjAlMjAlMjBhcmdzJTJDJTBBJTIwJTIwJTIwJTIwdHJhaW5fZGF0YXNldCUzRHRyYWluX2RhdGFzZXQlMkMlMEElMjAlMjAlMjAlMjBldmFsX2RhdGFzZXQlM0RldmFsX2RhdGFzZXQlMkMlMEElMjAlMjAlMjAlMjBjYWxsYmFja3MlM0QlNUJNeUNhbGxiYWNrJTVEJTJDJTIwJTIwJTIzJTIwV2UlMjBjYW4lMjBlaXRoZXIlMjBwYXNzJTIwdGhlJTIwY2FsbGJhY2slMjBjbGFzcyUyMHRoaXMlMjB3YXklMjBvciUyMGFuJTIwaW5zdGFuY2UlMjBvZiUyMGl0JTIwKE15Q2FsbGJhY2soKSklMEEp",highlighted:`<span class="hljs-keyword">class</span> <span class="hljs-title class_">MyCallback</span>(<span class="hljs-title class_ inherited__">TrainerCallback</span>):
    <span class="hljs-string">&quot;A callback that prints a message at the beginning of training&quot;</span>

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">on_train_begin</span>(<span class="hljs-params">self, args, state, control, **kwargs</span>):
        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Starting training&quot;</span>)


trainer = Trainer(
    model,
    args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    callbacks=[MyCallback],  <span class="hljs-comment"># We can either pass the callback class this way or an instance of it (MyCallback())</span>
)`,wrap:!1}}),Jt=new Ia({props:{code:"dHJhaW5lciUyMCUzRCUyMFRyYWluZXIoLi4uKSUwQXRyYWluZXIuYWRkX2NhbGxiYWNrKE15Q2FsbGJhY2spJTBBJTIzJTIwQWx0ZXJuYXRpdmVseSUyQyUyMHdlJTIwY2FuJTIwcGFzcyUyMGFuJTIwaW5zdGFuY2UlMjBvZiUyMHRoZSUyMGNhbGxiYWNrJTIwY2xhc3MlMEF0cmFpbmVyLmFkZF9jYWxsYmFjayhNeUNhbGxiYWNrKCkp",highlighted:`trainer = Trainer(...)
trainer.add_callback(MyCallback)
<span class="hljs-comment"># Alternatively, we can pass an instance of the callback class</span>
trainer.add_callback(MyCallback())`,wrap:!1}}),Wt=new La({props:{title:"TrainerState",local:"transformers.TrainerState",headingTag:"h2"}}),Ft=new $({props:{name:"class transformers.TrainerState",anchor:"transformers.TrainerState",parameters:[{name:"epoch",val:": typing.Optional[float] = None"},{name:"global_step",val:": int = 0"},{name:"max_steps",val:": int = 0"},{name:"logging_steps",val:": int = 500"},{name:"eval_steps",val:": int = 500"},{name:"save_steps",val:": int = 500"},{name:"train_batch_size",val:": typing.Optional[int] = None"},{name:"num_train_epochs",val:": int = 0"},{name:"num_input_tokens_seen",val:": int = 0"},{name:"total_flos",val:": float = 0"},{name:"log_history",val:": list = None"},{name:"best_metric",val:": typing.Optional[float] = None"},{name:"best_global_step",val:": typing.Optional[int] = None"},{name:"best_model_checkpoint",val:": typing.Optional[str] = None"},{name:"is_local_process_zero",val:": bool = True"},{name:"is_world_process_zero",val:": bool = True"},{name:"is_hyper_param_search",val:": bool = False"},{name:"trial_name",val:": typing.Optional[str] = None"},{name:"trial_params",val:": dict = None"},{name:"stateful_callbacks",val:": list = None"}],parametersDescription:[{anchor:"transformers.TrainerState.epoch",description:`<strong>epoch</strong> (<code>float</code>, <em>optional</em>) &#x2014;
Only set during training, will represent the epoch the training is at (the decimal part being the
percentage of the current epoch completed).`,name:"epoch"},{anchor:"transformers.TrainerState.global_step",description:`<strong>global_step</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
During training, represents the number of update steps completed.`,name:"global_step"},{anchor:"transformers.TrainerState.max_steps",description:`<strong>max_steps</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The number of update steps to do during the current training.`,name:"max_steps"},{anchor:"transformers.TrainerState.logging_steps",description:`<strong>logging_steps</strong> (<code>int</code>, <em>optional</em>, defaults to 500) &#x2014;
Log every X updates steps`,name:"logging_steps"},{anchor:"transformers.TrainerState.eval_steps",description:`<strong>eval_steps</strong> (<code>int</code>, <em>optional</em>) &#x2014;
Run an evaluation every X steps.`,name:"eval_steps"},{anchor:"transformers.TrainerState.save_steps",description:`<strong>save_steps</strong> (<code>int</code>, <em>optional</em>, defaults to 500) &#x2014;
Save checkpoint every X updates steps.`,name:"save_steps"},{anchor:"transformers.TrainerState.train_batch_size",description:`<strong>train_batch_size</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The batch size for the training dataloader. Only needed when
<code>auto_find_batch_size</code> has been used.`,name:"train_batch_size"},{anchor:"transformers.TrainerState.num_input_tokens_seen",description:`<strong>num_input_tokens_seen</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
When tracking the inputs tokens, the number of tokens seen during training (number of input tokens, not the
number of prediction tokens).`,name:"num_input_tokens_seen"},{anchor:"transformers.TrainerState.total_flos",description:`<strong>total_flos</strong> (<code>float</code>, <em>optional</em>, defaults to 0) &#x2014;
The total number of floating operations done by the model since the beginning of training (stored as floats
to avoid overflow).`,name:"total_flos"},{anchor:"transformers.TrainerState.log_history",description:`<strong>log_history</strong> (<code>list[dict[str, float]]</code>, <em>optional</em>) &#x2014;
The list of logs done since the beginning of training.`,name:"log_history"},{anchor:"transformers.TrainerState.best_metric",description:`<strong>best_metric</strong> (<code>float</code>, <em>optional</em>) &#x2014;
When tracking the best model, the value of the best metric encountered so far.`,name:"best_metric"},{anchor:"transformers.TrainerState.best_global_step",description:`<strong>best_global_step</strong> (<code>int</code>, <em>optional</em>) &#x2014;
When tracking the best model, the step at which the best metric was encountered.
Used for setting <code>best_model_checkpoint</code>.`,name:"best_global_step"},{anchor:"transformers.TrainerState.best_model_checkpoint",description:`<strong>best_model_checkpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
When tracking the best model, the value of the name of the checkpoint for the best model encountered so
far.`,name:"best_model_checkpoint"},{anchor:"transformers.TrainerState.is_local_process_zero",description:`<strong>is_local_process_zero</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not this process is the local (e.g., on one machine if training in a distributed fashion on
several machines) main process.`,name:"is_local_process_zero"},{anchor:"transformers.TrainerState.is_world_process_zero",description:`<strong>is_world_process_zero</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not this process is the global main process (when training in a distributed fashion on several
machines, this is only going to be <code>True</code> for one process).`,name:"is_world_process_zero"},{anchor:"transformers.TrainerState.is_hyper_param_search",description:`<strong>is_hyper_param_search</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether we are in the process of a hyper parameter search using Trainer.hyperparameter_search. This will
impact the way data will be logged in TensorBoard.`,name:"is_hyper_param_search"},{anchor:"transformers.TrainerState.stateful_callbacks",description:`<strong>stateful_callbacks</strong> (<code>list[StatefulTrainerCallback]</code>, <em>optional</em>) &#x2014;
Callbacks attached to the <code>Trainer</code> that should have their states be saved or restored.
Relevant callbacks should implement a <code>state</code> and <code>from_state</code> function.`,name:"stateful_callbacks"}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L36"}}),Ee=new Ti({props:{$$slots:{default:[Di]},$$scope:{ctx:L}}}),zt=new $({props:{name:"compute_steps",anchor:"transformers.TrainerState.compute_steps",parameters:[{name:"args",val:""},{name:"max_steps",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L157"}}),Bt=new $({props:{name:"init_training_references",anchor:"transformers.TrainerState.init_training_references",parameters:[{name:"trainer",val:""},{name:"max_steps",val:""},{name:"num_train_epochs",val:""},{name:"trial",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L170"}}),qt=new $({props:{name:"load_from_json",anchor:"transformers.TrainerState.load_from_json",parameters:[{name:"json_path",val:": str"}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L150"}}),Rt=new $({props:{name:"save_to_json",anchor:"transformers.TrainerState.save_to_json",parameters:[{name:"json_path",val:": str"}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L144"}}),Ot=new La({props:{title:"TrainerControl",local:"transformers.TrainerControl",headingTag:"h2"}}),Vt=new $({props:{name:"class transformers.TrainerControl",anchor:"transformers.TrainerControl",parameters:[{name:"should_training_stop",val:": bool = False"},{name:"should_epoch_stop",val:": bool = False"},{name:"should_save",val:": bool = False"},{name:"should_evaluate",val:": bool = False"},{name:"should_log",val:": bool = False"}],parametersDescription:[{anchor:"transformers.TrainerControl.should_training_stop",description:`<strong>should_training_stop</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the training should be interrupted.</p>
<p>If <code>True</code>, this variable will not be set back to <code>False</code>. The training will just stop.`,name:"should_training_stop"},{anchor:"transformers.TrainerControl.should_epoch_stop",description:`<strong>should_epoch_stop</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the current epoch should be interrupted.</p>
<p>If <code>True</code>, this variable will be set back to <code>False</code> at the beginning of the next epoch.`,name:"should_epoch_stop"},{anchor:"transformers.TrainerControl.should_save",description:`<strong>should_save</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the model should be saved at this step.</p>
<p>If <code>True</code>, this variable will be set back to <code>False</code> at the beginning of the next step.`,name:"should_save"},{anchor:"transformers.TrainerControl.should_evaluate",description:`<strong>should_evaluate</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the model should be evaluated at this step.</p>
<p>If <code>True</code>, this variable will be set back to <code>False</code> at the beginning of the next step.`,name:"should_evaluate"},{anchor:"transformers.TrainerControl.should_log",description:`<strong>should_log</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the logs should be reported at this step.</p>
<p>If <code>True</code>, this variable will be set back to <code>False</code> at the beginning of the next step.`,name:"should_log"}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/trainer_callback.py#L236"}}),Gt=new Li({props:{source:"https://github.com/huggingface/transformers/blob/main/docs/source/en/main_classes/callback.md"}}),{c(){d=n("meta"),M=r(),v=n("p"),C=r(),g(y.$$.fragment),b=r(),x=n("p"),x.innerHTML=I,H=r(),Fe=n("p"),Fe.innerHTML=Jo,Ha=r(),ze=n("p"),ze.innerHTML=Wo,Aa=r(),Be=n("ul"),Be.innerHTML=Fo,ja=r(),qe=n("p"),qe.innerHTML=zo,Sa=r(),Re=n("p"),Re.innerHTML=Bo,Na=r(),g(Oe.$$.fragment),Pa=r(),Ve=n("p"),Ve.innerHTML=qo,Da=r(),R=n("div"),g(Ge.$$.fragment),Un=r(),Qt=n("p"),Qt.innerHTML=Ro,Jn=r(),S=n("div"),g(Ye.$$.fragment),Wn=r(),Kt=n("p"),Kt.textContent=Oo,Fn=r(),er=n("p"),er.textContent=Vo,zn=r(),tr=n("ul"),tr.innerHTML=Go,Bn=r(),rr=n("p"),rr.innerHTML=Yo,Ua=r(),ae=n("div"),g(Xe.$$.fragment),qn=r(),ar=n("p"),ar.innerHTML=Xo,Ja=r(),ne=n("div"),g(Ze.$$.fragment),Rn=r(),nr=n("p"),nr.innerHTML=Zo,Wa=r(),se=n("div"),g(Qe.$$.fragment),On=r(),sr=n("p"),sr.innerHTML=Qo,Fa=r(),O=n("div"),g(Ke.$$.fragment),Vn=r(),or=n("p"),or.innerHTML=Ko,Gn=r(),lr=n("p"),lr.innerHTML=el,za=r(),oe=n("div"),g(et.$$.fragment),Yn=r(),ir=n("p"),ir.innerHTML=tl,Ba=r(),j=n("div"),g(tt.$$.fragment),Xn=r(),cr=n("p"),cr.innerHTML=rl,Zn=r(),dr=n("p"),dr.innerHTML=al,Qn=r(),g(me.$$.fragment),Kn=r(),N=n("div"),g(rt.$$.fragment),es=r(),mr=n("p"),mr.textContent=nl,ts=r(),pr=n("p"),pr.textContent=sl,rs=r(),gr=n("p"),gr.textContent=ol,as=r(),fr=n("ul"),fr.innerHTML=ll,qa=r(),V=n("div"),g(at.$$.fragment),ns=r(),hr=n("p"),hr.innerHTML=il,ss=r(),P=n("div"),g(nt.$$.fragment),os=r(),ur=n("p"),ur.innerHTML=cl,ls=r(),br=n("p"),br.innerHTML=dl,is=r(),vr=n("p"),vr.textContent=ml,cs=r(),G=n("ul"),st=n("li"),_r=n("p"),_r.innerHTML=pl,ds=r(),g(pe.$$.fragment),ms=r(),Tr=n("li"),Tr.innerHTML=gl,ps=r(),$r=n("li"),$r.innerHTML=fl,gs=r(),Cr=n("li"),Cr.innerHTML=hl,Ra=r(),Y=n("div"),g(ot.$$.fragment),fs=r(),kr=n("p"),kr.innerHTML=ul,hs=r(),F=n("div"),g(lt.$$.fragment),us=r(),wr=n("p"),wr.textContent=bl,bs=r(),yr=n("p"),yr.textContent=vl,vs=r(),xr=n("ul"),xr.innerHTML=_l,Oa=r(),le=n("div"),g(it.$$.fragment),_s=r(),Mr=n("p"),Mr.innerHTML=Tl,Va=r(),ie=n("div"),g(ct.$$.fragment),Ts=r(),Lr=n("p"),Lr.innerHTML=$l,Ga=r(),X=n("div"),g(dt.$$.fragment),$s=r(),Ir=n("p"),Ir.innerHTML=Cl,Cs=r(),Er=n("p"),Er.innerHTML=kl,Ya=r(),U=n("div"),g(mt.$$.fragment),ks=r(),Hr=n("p"),Hr.innerHTML=wl,ws=r(),Ar=n("p"),Ar.textContent=yl,ys=r(),jr=n("ul"),jr.innerHTML=xl,Xa=r(),Z=n("div"),g(pt.$$.fragment),xs=r(),Sr=n("p"),Sr.innerHTML=Ml,Ms=r(),z=n("div"),g(gt.$$.fragment),Ls=r(),Nr=n("p"),Nr.textContent=Ll,Is=r(),Pr=n("p"),Pr.textContent=Il,Es=r(),Dr=n("ul"),Dr.innerHTML=El,Za=r(),Q=n("div"),g(ft.$$.fragment),Hs=r(),Ur=n("p"),Ur.innerHTML=Hl,As=r(),g(ge.$$.fragment),Qa=r(),J=n("div"),g(ht.$$.fragment),js=r(),Jr=n("p"),Jr.innerHTML=Al,Ss=r(),Wr=n("p"),Wr.innerHTML=jl,Ns=r(),B=n("div"),g(ut.$$.fragment),Ps=r(),Fr=n("p"),Fr.innerHTML=Sl,Ds=r(),zr=n("p"),zr.textContent=Nl,Us=r(),Br=n("ul"),Br.innerHTML=Pl,Ka=r(),K=n("div"),g(bt.$$.fragment),Js=r(),qr=n("p"),qr.innerHTML=Dl,Ws=r(),A=n("div"),g(vt.$$.fragment),Fs=r(),Rr=n("p"),Rr.innerHTML=Ul,zs=r(),Or=n("p"),Or.innerHTML=Jl,Bs=r(),Vr=n("p"),Vr.innerHTML=Wl,qs=r(),Gr=n("p"),Gr.textContent=Fl,Rs=r(),Yr=n("ul"),Yr.innerHTML=zl,en=r(),g(_t.$$.fragment),tn=r(),k=n("div"),g(Tt.$$.fragment),Os=r(),Xr=n("p"),Xr.textContent=Bl,Vs=r(),Zr=n("p"),Zr.innerHTML=ql,Gs=r(),Qr=n("p"),Qr.innerHTML=Rl,Ys=r(),g(fe.$$.fragment),Xs=r(),he=n("div"),g($t.$$.fragment),Zs=r(),Kr=n("p"),Kr.textContent=Ol,Qs=r(),ue=n("div"),g(Ct.$$.fragment),Ks=r(),ea=n("p"),ea.textContent=Vl,eo=r(),be=n("div"),g(kt.$$.fragment),to=r(),ta=n("p"),ta.textContent=Gl,ro=r(),ve=n("div"),g(wt.$$.fragment),ao=r(),ra=n("p"),ra.innerHTML=Yl,no=r(),_e=n("div"),g(yt.$$.fragment),so=r(),aa=n("p"),aa.textContent=Xl,oo=r(),Te=n("div"),g(xt.$$.fragment),lo=r(),na=n("p"),na.textContent=Zl,io=r(),$e=n("div"),g(Mt.$$.fragment),co=r(),sa=n("p"),sa.textContent=Ql,mo=r(),Ce=n("div"),g(Lt.$$.fragment),po=r(),oa=n("p"),oa.textContent=Kl,go=r(),ke=n("div"),g(It.$$.fragment),fo=r(),la=n("p"),la.textContent=ei,ho=r(),we=n("div"),g(Et.$$.fragment),uo=r(),ia=n("p"),ia.textContent=ti,bo=r(),ye=n("div"),g(Ht.$$.fragment),vo=r(),ca=n("p"),ca.textContent=ri,_o=r(),xe=n("div"),g(At.$$.fragment),To=r(),da=n("p"),da.textContent=ai,$o=r(),Me=n("div"),g(jt.$$.fragment),Co=r(),ma=n("p"),ma.textContent=ni,ko=r(),Le=n("div"),g(St.$$.fragment),wo=r(),pa=n("p"),pa.textContent=si,yo=r(),Ie=n("div"),g(Nt.$$.fragment),xo=r(),ga=n("p"),ga.textContent=oi,rn=r(),Pt=n("p"),Pt.innerHTML=li,an=r(),g(Dt.$$.fragment),nn=r(),Ut=n("p"),Ut.innerHTML=ii,sn=r(),g(Jt.$$.fragment),on=r(),g(Wt.$$.fragment),ln=r(),E=n("div"),g(Ft.$$.fragment),Mo=r(),fa=n("p"),fa.innerHTML=ci,Lo=r(),g(Ee.$$.fragment),Io=r(),He=n("div"),g(zt.$$.fragment),Eo=r(),ha=n("p"),ha.textContent=di,Ho=r(),Ae=n("div"),g(Bt.$$.fragment),Ao=r(),ua=n("p"),ua.innerHTML=mi,jo=r(),je=n("div"),g(qt.$$.fragment),So=r(),ba=n("p"),ba.innerHTML=pi,No=r(),Se=n("div"),g(Rt.$$.fragment),Po=r(),va=n("p"),va.innerHTML=gi,cn=r(),g(Ot.$$.fragment),dn=r(),ce=n("div"),g(Vt.$$.fragment),Do=r(),_a=n("p"),_a.innerHTML=fi,mn=r(),g(Gt.$$.fragment),pn=r(),Ma=n("p"),this.h()},l(e){const l=Mi("svelte-u9bgzb",document.head);d=s(l,"META",{name:!0,content:!0}),l.forEach(o),M=a(e),v=s(e,"P",{}),_(v).forEach(o),C=a(e),f(y.$$.fragment,e),b=a(e),x=s(e,"P",{"data-svelte-h":!0}),i(x)!=="svelte-1rcb37r"&&(x.innerHTML=I),H=a(e),Fe=s(e,"P",{"data-svelte-h":!0}),i(Fe)!=="svelte-9fs3lp"&&(Fe.innerHTML=Jo),Ha=a(e),ze=s(e,"P",{"data-svelte-h":!0}),i(ze)!=="svelte-1qd7bfk"&&(ze.innerHTML=Wo),Aa=a(e),Be=s(e,"UL",{"data-svelte-h":!0}),i(Be)!=="svelte-exxomr"&&(Be.innerHTML=Fo),ja=a(e),qe=s(e,"P",{"data-svelte-h":!0}),i(qe)!=="svelte-1lrio7c"&&(qe.innerHTML=zo),Sa=a(e),Re=s(e,"P",{"data-svelte-h":!0}),i(Re)!=="svelte-r80i2u"&&(Re.innerHTML=Bo),Na=a(e),f(Oe.$$.fragment,e),Pa=a(e),Ve=s(e,"P",{"data-svelte-h":!0}),i(Ve)!=="svelte-1uh3cmd"&&(Ve.innerHTML=qo),Da=a(e),R=s(e,"DIV",{class:!0});var de=_(R);f(Ge.$$.fragment,de),Un=a(de),Qt=s(de,"P",{"data-svelte-h":!0}),i(Qt)!=="svelte-zahuk4"&&(Qt.innerHTML=Ro),Jn=a(de),S=s(de,"DIV",{class:!0});var W=_(S);f(Ye.$$.fragment,W),Wn=a(W),Kt=s(W,"P",{"data-svelte-h":!0}),i(Kt)!=="svelte-frc23a"&&(Kt.textContent=Oo),Fn=a(W),er=s(W,"P",{"data-svelte-h":!0}),i(er)!=="svelte-1fkshtn"&&(er.textContent=Vo),zn=a(W),tr=s(W,"UL",{"data-svelte-h":!0}),i(tr)!=="svelte-rt862w"&&(tr.innerHTML=Go),Bn=a(W),rr=s(W,"P",{"data-svelte-h":!0}),i(rr)!=="svelte-1baxs6u"&&(rr.innerHTML=Yo),W.forEach(o),de.forEach(o),Ua=a(e),ae=s(e,"DIV",{class:!0});var Yt=_(ae);f(Xe.$$.fragment,Yt),qn=a(Yt),ar=s(Yt,"P",{"data-svelte-h":!0}),i(ar)!=="svelte-147nxaz"&&(ar.innerHTML=Xo),Yt.forEach(o),Ja=a(e),ne=s(e,"DIV",{class:!0});var Xt=_(ne);f(Ze.$$.fragment,Xt),Rn=a(Xt),nr=s(Xt,"P",{"data-svelte-h":!0}),i(nr)!=="svelte-rjsnxm"&&(nr.innerHTML=Zo),Xt.forEach(o),Wa=a(e),se=s(e,"DIV",{class:!0});var Zt=_(se);f(Qe.$$.fragment,Zt),On=a(Zt),sr=s(Zt,"P",{"data-svelte-h":!0}),i(sr)!=="svelte-1okzqxq"&&(sr.innerHTML=Qo),Zt.forEach(o),Fa=a(e),O=s(e,"DIV",{class:!0});var Ta=_(O);f(Ke.$$.fragment,Ta),Vn=a(Ta),or=s(Ta,"P",{"data-svelte-h":!0}),i(or)!=="svelte-ixaan0"&&(or.innerHTML=Ko),Gn=a(Ta),lr=s(Ta,"P",{"data-svelte-h":!0}),i(lr)!=="svelte-am52iy"&&(lr.innerHTML=el),Ta.forEach(o),za=a(e),oe=s(e,"DIV",{class:!0});var fn=_(oe);f(et.$$.fragment,fn),Yn=a(fn),ir=s(fn,"P",{"data-svelte-h":!0}),i(ir)!=="svelte-t8zzp1"&&(ir.innerHTML=tl),fn.forEach(o),Ba=a(e),j=s(e,"DIV",{class:!0});var ee=_(j);f(tt.$$.fragment,ee),Xn=a(ee),cr=s(ee,"P",{"data-svelte-h":!0}),i(cr)!=="svelte-1a6jpgs"&&(cr.innerHTML=rl),Zn=a(ee),dr=s(ee,"P",{"data-svelte-h":!0}),i(dr)!=="svelte-1wmvuxj"&&(dr.innerHTML=al),Qn=a(ee),f(me.$$.fragment,ee),Kn=a(ee),N=s(ee,"DIV",{class:!0});var te=_(N);f(rt.$$.fragment,te),es=a(te),mr=s(te,"P",{"data-svelte-h":!0}),i(mr)!=="svelte-1r6cdlb"&&(mr.textContent=nl),ts=a(te),pr=s(te,"P",{"data-svelte-h":!0}),i(pr)!=="svelte-1lpqq3e"&&(pr.textContent=sl),rs=a(te),gr=s(te,"P",{"data-svelte-h":!0}),i(gr)!=="svelte-1fkshtn"&&(gr.textContent=ol),as=a(te),fr=s(te,"UL",{"data-svelte-h":!0}),i(fr)!=="svelte-4xy2s9"&&(fr.innerHTML=ll),te.forEach(o),ee.forEach(o),qa=a(e),V=s(e,"DIV",{class:!0});var $a=_(V);f(at.$$.fragment,$a),ns=a($a),hr=s($a,"P",{"data-svelte-h":!0}),i(hr)!=="svelte-184hgq8"&&(hr.innerHTML=il),ss=a($a),P=s($a,"DIV",{class:!0});var re=_(P);f(nt.$$.fragment,re),os=a(re),ur=s(re,"P",{"data-svelte-h":!0}),i(ur)!=="svelte-op70zs"&&(ur.innerHTML=cl),ls=a(re),br=s(re,"P",{"data-svelte-h":!0}),i(br)!=="svelte-m2rt7w"&&(br.innerHTML=dl),is=a(re),vr=s(re,"P",{"data-svelte-h":!0}),i(vr)!=="svelte-1fkshtn"&&(vr.textContent=ml),cs=a(re),G=s(re,"UL",{});var Ne=_(G);st=s(Ne,"LI",{});var hn=_(st);_r=s(hn,"P",{"data-svelte-h":!0}),i(_r)!=="svelte-py3r3s"&&(_r.innerHTML=pl),ds=a(hn),f(pe.$$.fragment,hn),hn.forEach(o),ms=a(Ne),Tr=s(Ne,"LI",{"data-svelte-h":!0}),i(Tr)!=="svelte-dx3m30"&&(Tr.innerHTML=gl),ps=a(Ne),$r=s(Ne,"LI",{"data-svelte-h":!0}),i($r)!=="svelte-n1uh6c"&&($r.innerHTML=fl),gs=a(Ne),Cr=s(Ne,"LI",{"data-svelte-h":!0}),i(Cr)!=="svelte-ybo66z"&&(Cr.innerHTML=hl),Ne.forEach(o),re.forEach(o),$a.forEach(o),Ra=a(e),Y=s(e,"DIV",{class:!0});var Ca=_(Y);f(ot.$$.fragment,Ca),fs=a(Ca),kr=s(Ca,"P",{"data-svelte-h":!0}),i(kr)!=="svelte-19txsw"&&(kr.innerHTML=ul),hs=a(Ca),F=s(Ca,"DIV",{class:!0});var Pe=_(F);f(lt.$$.fragment,Pe),us=a(Pe),wr=s(Pe,"P",{"data-svelte-h":!0}),i(wr)!=="svelte-nmg16f"&&(wr.textContent=bl),bs=a(Pe),yr=s(Pe,"P",{"data-svelte-h":!0}),i(yr)!=="svelte-1fkshtn"&&(yr.textContent=vl),vs=a(Pe),xr=s(Pe,"UL",{"data-svelte-h":!0}),i(xr)!=="svelte-1b5g15"&&(xr.innerHTML=_l),Pe.forEach(o),Ca.forEach(o),Oa=a(e),le=s(e,"DIV",{class:!0});var un=_(le);f(it.$$.fragment,un),_s=a(un),Mr=s(un,"P",{"data-svelte-h":!0}),i(Mr)!=="svelte-1fgufx"&&(Mr.innerHTML=Tl),un.forEach(o),Va=a(e),ie=s(e,"DIV",{class:!0});var bn=_(ie);f(ct.$$.fragment,bn),Ts=a(bn),Lr=s(bn,"P",{"data-svelte-h":!0}),i(Lr)!=="svelte-ewjko1"&&(Lr.innerHTML=$l),bn.forEach(o),Ga=a(e),X=s(e,"DIV",{class:!0});var ka=_(X);f(dt.$$.fragment,ka),$s=a(ka),Ir=s(ka,"P",{"data-svelte-h":!0}),i(Ir)!=="svelte-4ag9j6"&&(Ir.innerHTML=Cl),Cs=a(ka),Er=s(ka,"P",{"data-svelte-h":!0}),i(Er)!=="svelte-1mhjcx0"&&(Er.innerHTML=kl),ka.forEach(o),Ya=a(e),U=s(e,"DIV",{class:!0});var De=_(U);f(mt.$$.fragment,De),ks=a(De),Hr=s(De,"P",{"data-svelte-h":!0}),i(Hr)!=="svelte-coh69v"&&(Hr.innerHTML=wl),ws=a(De),Ar=s(De,"P",{"data-svelte-h":!0}),i(Ar)!=="svelte-1fkshtn"&&(Ar.textContent=yl),ys=a(De),jr=s(De,"UL",{"data-svelte-h":!0}),i(jr)!=="svelte-15svthu"&&(jr.innerHTML=xl),De.forEach(o),Xa=a(e),Z=s(e,"DIV",{class:!0});var wa=_(Z);f(pt.$$.fragment,wa),xs=a(wa),Sr=s(wa,"P",{"data-svelte-h":!0}),i(Sr)!=="svelte-1y178n0"&&(Sr.innerHTML=Ml),Ms=a(wa),z=s(wa,"DIV",{class:!0});var Ue=_(z);f(gt.$$.fragment,Ue),Ls=a(Ue),Nr=s(Ue,"P",{"data-svelte-h":!0}),i(Nr)!=="svelte-1wbmj3"&&(Nr.textContent=Ll),Is=a(Ue),Pr=s(Ue,"P",{"data-svelte-h":!0}),i(Pr)!=="svelte-1fkshtn"&&(Pr.textContent=Il),Es=a(Ue),Dr=s(Ue,"UL",{"data-svelte-h":!0}),i(Dr)!=="svelte-dna85o"&&(Dr.innerHTML=El),Ue.forEach(o),wa.forEach(o),Za=a(e),Q=s(e,"DIV",{class:!0});var ya=_(Q);f(ft.$$.fragment,ya),Hs=a(ya),Ur=s(ya,"P",{"data-svelte-h":!0}),i(Ur)!=="svelte-yo6mmx"&&(Ur.innerHTML=Hl),As=a(ya),f(ge.$$.fragment,ya),ya.forEach(o),Qa=a(e),J=s(e,"DIV",{class:!0});var Je=_(J);f(ht.$$.fragment,Je),js=a(Je),Jr=s(Je,"P",{"data-svelte-h":!0}),i(Jr)!=="svelte-6iktyy"&&(Jr.innerHTML=Al),Ss=a(Je),Wr=s(Je,"P",{"data-svelte-h":!0}),i(Wr)!=="svelte-eu3kj7"&&(Wr.innerHTML=jl),Ns=a(Je),B=s(Je,"DIV",{class:!0});var We=_(B);f(ut.$$.fragment,We),Ps=a(We),Fr=s(We,"P",{"data-svelte-h":!0}),i(Fr)!=="svelte-jjkenj"&&(Fr.innerHTML=Sl),Ds=a(We),zr=s(We,"P",{"data-svelte-h":!0}),i(zr)!=="svelte-1fkshtn"&&(zr.textContent=Nl),Us=a(We),Br=s(We,"UL",{"data-svelte-h":!0}),i(Br)!=="svelte-9lkncs"&&(Br.innerHTML=Pl),We.forEach(o),Je.forEach(o),Ka=a(e),K=s(e,"DIV",{class:!0});var xa=_(K);f(bt.$$.fragment,xa),Js=a(xa),qr=s(xa,"P",{"data-svelte-h":!0}),i(qr)!=="svelte-6zzunb"&&(qr.innerHTML=Dl),Ws=a(xa),A=s(xa,"DIV",{class:!0});var q=_(A);f(vt.$$.fragment,q),Fs=a(q),Rr=s(q,"P",{"data-svelte-h":!0}),i(Rr)!=="svelte-1pnk5m4"&&(Rr.innerHTML=Ul),zs=a(q),Or=s(q,"P",{"data-svelte-h":!0}),i(Or)!=="svelte-s781co"&&(Or.innerHTML=Jl),Bs=a(q),Vr=s(q,"P",{"data-svelte-h":!0}),i(Vr)!=="svelte-g9rl62"&&(Vr.innerHTML=Wl),qs=a(q),Gr=s(q,"P",{"data-svelte-h":!0}),i(Gr)!=="svelte-1fkshtn"&&(Gr.textContent=Fl),Rs=a(q),Yr=s(q,"UL",{"data-svelte-h":!0}),i(Yr)!=="svelte-jaaggq"&&(Yr.innerHTML=zl),q.forEach(o),xa.forEach(o),en=a(e),f(_t.$$.fragment,e),tn=a(e),k=s(e,"DIV",{class:!0});var w=_(k);f(Tt.$$.fragment,w),Os=a(w),Xr=s(w,"P",{"data-svelte-h":!0}),i(Xr)!=="svelte-14xg00o"&&(Xr.textContent=Bl),Vs=a(w),Zr=s(w,"P",{"data-svelte-h":!0}),i(Zr)!=="svelte-1xprdvt"&&(Zr.innerHTML=ql),Gs=a(w),Qr=s(w,"P",{"data-svelte-h":!0}),i(Qr)!=="svelte-2a379d"&&(Qr.innerHTML=Rl),Ys=a(w),f(fe.$$.fragment,w),Xs=a(w),he=s(w,"DIV",{class:!0});var vn=_(he);f($t.$$.fragment,vn),Zs=a(vn),Kr=s(vn,"P",{"data-svelte-h":!0}),i(Kr)!=="svelte-106889p"&&(Kr.textContent=Ol),vn.forEach(o),Qs=a(w),ue=s(w,"DIV",{class:!0});var _n=_(ue);f(Ct.$$.fragment,_n),Ks=a(_n),ea=s(_n,"P",{"data-svelte-h":!0}),i(ea)!=="svelte-oshcpj"&&(ea.textContent=Vl),_n.forEach(o),eo=a(w),be=s(w,"DIV",{class:!0});var Tn=_(be);f(kt.$$.fragment,Tn),to=a(Tn),ta=s(Tn,"P",{"data-svelte-h":!0}),i(ta)!=="svelte-1o0xh73"&&(ta.textContent=Gl),Tn.forEach(o),ro=a(w),ve=s(w,"DIV",{class:!0});var $n=_(ve);f(wt.$$.fragment,$n),ao=a($n),ra=s($n,"P",{"data-svelte-h":!0}),i(ra)!=="svelte-seoc6"&&(ra.innerHTML=Yl),$n.forEach(o),no=a(w),_e=s(w,"DIV",{class:!0});var Cn=_(_e);f(yt.$$.fragment,Cn),so=a(Cn),aa=s(Cn,"P",{"data-svelte-h":!0}),i(aa)!=="svelte-10eiwg0"&&(aa.textContent=Xl),Cn.forEach(o),oo=a(w),Te=s(w,"DIV",{class:!0});var kn=_(Te);f(xt.$$.fragment,kn),lo=a(kn),na=s(kn,"P",{"data-svelte-h":!0}),i(na)!=="svelte-1mpbj2z"&&(na.textContent=Zl),kn.forEach(o),io=a(w),$e=s(w,"DIV",{class:!0});var wn=_($e);f(Mt.$$.fragment,wn),co=a(wn),sa=s(wn,"P",{"data-svelte-h":!0}),i(sa)!=="svelte-qj3qgf"&&(sa.textContent=Ql),wn.forEach(o),mo=a(w),Ce=s(w,"DIV",{class:!0});var yn=_(Ce);f(Lt.$$.fragment,yn),po=a(yn),oa=s(yn,"P",{"data-svelte-h":!0}),i(oa)!=="svelte-1df7x4n"&&(oa.textContent=Kl),yn.forEach(o),go=a(w),ke=s(w,"DIV",{class:!0});var xn=_(ke);f(It.$$.fragment,xn),fo=a(xn),la=s(xn,"P",{"data-svelte-h":!0}),i(la)!=="svelte-18swygp"&&(la.textContent=ei),xn.forEach(o),ho=a(w),we=s(w,"DIV",{class:!0});var Mn=_(we);f(Et.$$.fragment,Mn),uo=a(Mn),ia=s(Mn,"P",{"data-svelte-h":!0}),i(ia)!=="svelte-19xp05v"&&(ia.textContent=ti),Mn.forEach(o),bo=a(w),ye=s(w,"DIV",{class:!0});var Ln=_(ye);f(Ht.$$.fragment,Ln),vo=a(Ln),ca=s(Ln,"P",{"data-svelte-h":!0}),i(ca)!=="svelte-7af61p"&&(ca.textContent=ri),Ln.forEach(o),_o=a(w),xe=s(w,"DIV",{class:!0});var In=_(xe);f(At.$$.fragment,In),To=a(In),da=s(In,"P",{"data-svelte-h":!0}),i(da)!=="svelte-8cdxjr"&&(da.textContent=ai),In.forEach(o),$o=a(w),Me=s(w,"DIV",{class:!0});var En=_(Me);f(jt.$$.fragment,En),Co=a(En),ma=s(En,"P",{"data-svelte-h":!0}),i(ma)!=="svelte-sluvs0"&&(ma.textContent=ni),En.forEach(o),ko=a(w),Le=s(w,"DIV",{class:!0});var Hn=_(Le);f(St.$$.fragment,Hn),wo=a(Hn),pa=s(Hn,"P",{"data-svelte-h":!0}),i(pa)!=="svelte-6bvy6d"&&(pa.textContent=si),Hn.forEach(o),yo=a(w),Ie=s(w,"DIV",{class:!0});var An=_(Ie);f(Nt.$$.fragment,An),xo=a(An),ga=s(An,"P",{"data-svelte-h":!0}),i(ga)!=="svelte-zzwxsv"&&(ga.textContent=oi),An.forEach(o),w.forEach(o),rn=a(e),Pt=s(e,"P",{"data-svelte-h":!0}),i(Pt)!=="svelte-1c1xgtb"&&(Pt.innerHTML=li),an=a(e),f(Dt.$$.fragment,e),nn=a(e),Ut=s(e,"P",{"data-svelte-h":!0}),i(Ut)!=="svelte-8gc48t"&&(Ut.innerHTML=ii),sn=a(e),f(Jt.$$.fragment,e),on=a(e),f(Wt.$$.fragment,e),ln=a(e),E=s(e,"DIV",{class:!0});var D=_(E);f(Ft.$$.fragment,D),Mo=a(D),fa=s(D,"P",{"data-svelte-h":!0}),i(fa)!=="svelte-we3evm"&&(fa.innerHTML=ci),Lo=a(D),f(Ee.$$.fragment,D),Io=a(D),He=s(D,"DIV",{class:!0});var jn=_(He);f(zt.$$.fragment,jn),Eo=a(jn),ha=s(jn,"P",{"data-svelte-h":!0}),i(ha)!=="svelte-754oj0"&&(ha.textContent=di),jn.forEach(o),Ho=a(D),Ae=s(D,"DIV",{class:!0});var Sn=_(Ae);f(Bt.$$.fragment,Sn),Ao=a(Sn),ua=s(Sn,"P",{"data-svelte-h":!0}),i(ua)!=="svelte-1mzjlie"&&(ua.innerHTML=mi),Sn.forEach(o),jo=a(D),je=s(D,"DIV",{class:!0});var Nn=_(je);f(qt.$$.fragment,Nn),So=a(Nn),ba=s(Nn,"P",{"data-svelte-h":!0}),i(ba)!=="svelte-hbs6ga"&&(ba.innerHTML=pi),Nn.forEach(o),No=a(D),Se=s(D,"DIV",{class:!0});var Pn=_(Se);f(Rt.$$.fragment,Pn),Po=a(Pn),va=s(Pn,"P",{"data-svelte-h":!0}),i(va)!=="svelte-dkslae"&&(va.innerHTML=gi),Pn.forEach(o),D.forEach(o),cn=a(e),f(Ot.$$.fragment,e),dn=a(e),ce=s(e,"DIV",{class:!0});var Dn=_(ce);f(Vt.$$.fragment,Dn),Do=a(Dn),_a=s(Dn,"P",{"data-svelte-h":!0}),i(_a)!=="svelte-lce1dq"&&(_a.innerHTML=fi),Dn.forEach(o),mn=a(e),f(Gt.$$.fragment,e),pn=a(e),Ma=s(e,"P",{}),_(Ma).forEach(o),this.h()},h(){T(d,"name","hf:doc:metadata"),T(d,"content",Ji),T(S,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(R,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(ae,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(ne,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(se,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(O,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(oe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(N,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(j,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(P,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(V,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(Y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(le,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(ie,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(X,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(U,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(Z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(Q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(B,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(J,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(A,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(K,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(he,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(be,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(ve,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(_e,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(Te,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T($e,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(Ce,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(we,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(xe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(Me,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(Le,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(Ie,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(k,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(Ae,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(Se,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(E,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(ce,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,l){t(document.head,d),c(e,M,l),c(e,v,l),c(e,C,l),h(y,e,l),c(e,b,l),c(e,x,l),c(e,H,l),c(e,Fe,l),c(e,Ha,l),c(e,ze,l),c(e,Aa,l),c(e,Be,l),c(e,ja,l),c(e,qe,l),c(e,Sa,l),c(e,Re,l),c(e,Na,l),h(Oe,e,l),c(e,Pa,l),c(e,Ve,l),c(e,Da,l),c(e,R,l),h(Ge,R,null),t(R,Un),t(R,Qt),t(R,Jn),t(R,S),h(Ye,S,null),t(S,Wn),t(S,Kt),t(S,Fn),t(S,er),t(S,zn),t(S,tr),t(S,Bn),t(S,rr),c(e,Ua,l),c(e,ae,l),h(Xe,ae,null),t(ae,qn),t(ae,ar),c(e,Ja,l),c(e,ne,l),h(Ze,ne,null),t(ne,Rn),t(ne,nr),c(e,Wa,l),c(e,se,l),h(Qe,se,null),t(se,On),t(se,sr),c(e,Fa,l),c(e,O,l),h(Ke,O,null),t(O,Vn),t(O,or),t(O,Gn),t(O,lr),c(e,za,l),c(e,oe,l),h(et,oe,null),t(oe,Yn),t(oe,ir),c(e,Ba,l),c(e,j,l),h(tt,j,null),t(j,Xn),t(j,cr),t(j,Zn),t(j,dr),t(j,Qn),h(me,j,null),t(j,Kn),t(j,N),h(rt,N,null),t(N,es),t(N,mr),t(N,ts),t(N,pr),t(N,rs),t(N,gr),t(N,as),t(N,fr),c(e,qa,l),c(e,V,l),h(at,V,null),t(V,ns),t(V,hr),t(V,ss),t(V,P),h(nt,P,null),t(P,os),t(P,ur),t(P,ls),t(P,br),t(P,is),t(P,vr),t(P,cs),t(P,G),t(G,st),t(st,_r),t(st,ds),h(pe,st,null),t(G,ms),t(G,Tr),t(G,ps),t(G,$r),t(G,gs),t(G,Cr),c(e,Ra,l),c(e,Y,l),h(ot,Y,null),t(Y,fs),t(Y,kr),t(Y,hs),t(Y,F),h(lt,F,null),t(F,us),t(F,wr),t(F,bs),t(F,yr),t(F,vs),t(F,xr),c(e,Oa,l),c(e,le,l),h(it,le,null),t(le,_s),t(le,Mr),c(e,Va,l),c(e,ie,l),h(ct,ie,null),t(ie,Ts),t(ie,Lr),c(e,Ga,l),c(e,X,l),h(dt,X,null),t(X,$s),t(X,Ir),t(X,Cs),t(X,Er),c(e,Ya,l),c(e,U,l),h(mt,U,null),t(U,ks),t(U,Hr),t(U,ws),t(U,Ar),t(U,ys),t(U,jr),c(e,Xa,l),c(e,Z,l),h(pt,Z,null),t(Z,xs),t(Z,Sr),t(Z,Ms),t(Z,z),h(gt,z,null),t(z,Ls),t(z,Nr),t(z,Is),t(z,Pr),t(z,Es),t(z,Dr),c(e,Za,l),c(e,Q,l),h(ft,Q,null),t(Q,Hs),t(Q,Ur),t(Q,As),h(ge,Q,null),c(e,Qa,l),c(e,J,l),h(ht,J,null),t(J,js),t(J,Jr),t(J,Ss),t(J,Wr),t(J,Ns),t(J,B),h(ut,B,null),t(B,Ps),t(B,Fr),t(B,Ds),t(B,zr),t(B,Us),t(B,Br),c(e,Ka,l),c(e,K,l),h(bt,K,null),t(K,Js),t(K,qr),t(K,Ws),t(K,A),h(vt,A,null),t(A,Fs),t(A,Rr),t(A,zs),t(A,Or),t(A,Bs),t(A,Vr),t(A,qs),t(A,Gr),t(A,Rs),t(A,Yr),c(e,en,l),h(_t,e,l),c(e,tn,l),c(e,k,l),h(Tt,k,null),t(k,Os),t(k,Xr),t(k,Vs),t(k,Zr),t(k,Gs),t(k,Qr),t(k,Ys),h(fe,k,null),t(k,Xs),t(k,he),h($t,he,null),t(he,Zs),t(he,Kr),t(k,Qs),t(k,ue),h(Ct,ue,null),t(ue,Ks),t(ue,ea),t(k,eo),t(k,be),h(kt,be,null),t(be,to),t(be,ta),t(k,ro),t(k,ve),h(wt,ve,null),t(ve,ao),t(ve,ra),t(k,no),t(k,_e),h(yt,_e,null),t(_e,so),t(_e,aa),t(k,oo),t(k,Te),h(xt,Te,null),t(Te,lo),t(Te,na),t(k,io),t(k,$e),h(Mt,$e,null),t($e,co),t($e,sa),t(k,mo),t(k,Ce),h(Lt,Ce,null),t(Ce,po),t(Ce,oa),t(k,go),t(k,ke),h(It,ke,null),t(ke,fo),t(ke,la),t(k,ho),t(k,we),h(Et,we,null),t(we,uo),t(we,ia),t(k,bo),t(k,ye),h(Ht,ye,null),t(ye,vo),t(ye,ca),t(k,_o),t(k,xe),h(At,xe,null),t(xe,To),t(xe,da),t(k,$o),t(k,Me),h(jt,Me,null),t(Me,Co),t(Me,ma),t(k,ko),t(k,Le),h(St,Le,null),t(Le,wo),t(Le,pa),t(k,yo),t(k,Ie),h(Nt,Ie,null),t(Ie,xo),t(Ie,ga),c(e,rn,l),c(e,Pt,l),c(e,an,l),h(Dt,e,l),c(e,nn,l),c(e,Ut,l),c(e,sn,l),h(Jt,e,l),c(e,on,l),h(Wt,e,l),c(e,ln,l),c(e,E,l),h(Ft,E,null),t(E,Mo),t(E,fa),t(E,Lo),h(Ee,E,null),t(E,Io),t(E,He),h(zt,He,null),t(He,Eo),t(He,ha),t(E,Ho),t(E,Ae),h(Bt,Ae,null),t(Ae,Ao),t(Ae,ua),t(E,jo),t(E,je),h(qt,je,null),t(je,So),t(je,ba),t(E,No),t(E,Se),h(Rt,Se,null),t(Se,Po),t(Se,va),c(e,cn,l),h(Ot,e,l),c(e,dn,l),c(e,ce,l),h(Vt,ce,null),t(ce,Do),t(ce,_a),c(e,mn,l),h(Gt,e,l),c(e,pn,l),c(e,Ma,l),gn=!0},p(e,[l]){const de={};l&2&&(de.$$scope={dirty:l,ctx:e}),me.$set(de);const W={};l&2&&(W.$$scope={dirty:l,ctx:e}),pe.$set(W);const Yt={};l&2&&(Yt.$$scope={dirty:l,ctx:e}),ge.$set(Yt);const Xt={};l&2&&(Xt.$$scope={dirty:l,ctx:e}),fe.$set(Xt);const Zt={};l&2&&(Zt.$$scope={dirty:l,ctx:e}),Ee.$set(Zt)},i(e){gn||(m(y.$$.fragment,e),m(Oe.$$.fragment,e),m(Ge.$$.fragment,e),m(Ye.$$.fragment,e),m(Xe.$$.fragment,e),m(Ze.$$.fragment,e),m(Qe.$$.fragment,e),m(Ke.$$.fragment,e),m(et.$$.fragment,e),m(tt.$$.fragment,e),m(me.$$.fragment,e),m(rt.$$.fragment,e),m(at.$$.fragment,e),m(nt.$$.fragment,e),m(pe.$$.fragment,e),m(ot.$$.fragment,e),m(lt.$$.fragment,e),m(it.$$.fragment,e),m(ct.$$.fragment,e),m(dt.$$.fragment,e),m(mt.$$.fragment,e),m(pt.$$.fragment,e),m(gt.$$.fragment,e),m(ft.$$.fragment,e),m(ge.$$.fragment,e),m(ht.$$.fragment,e),m(ut.$$.fragment,e),m(bt.$$.fragment,e),m(vt.$$.fragment,e),m(_t.$$.fragment,e),m(Tt.$$.fragment,e),m(fe.$$.fragment,e),m($t.$$.fragment,e),m(Ct.$$.fragment,e),m(kt.$$.fragment,e),m(wt.$$.fragment,e),m(yt.$$.fragment,e),m(xt.$$.fragment,e),m(Mt.$$.fragment,e),m(Lt.$$.fragment,e),m(It.$$.fragment,e),m(Et.$$.fragment,e),m(Ht.$$.fragment,e),m(At.$$.fragment,e),m(jt.$$.fragment,e),m(St.$$.fragment,e),m(Nt.$$.fragment,e),m(Dt.$$.fragment,e),m(Jt.$$.fragment,e),m(Wt.$$.fragment,e),m(Ft.$$.fragment,e),m(Ee.$$.fragment,e),m(zt.$$.fragment,e),m(Bt.$$.fragment,e),m(qt.$$.fragment,e),m(Rt.$$.fragment,e),m(Ot.$$.fragment,e),m(Vt.$$.fragment,e),m(Gt.$$.fragment,e),gn=!0)},o(e){p(y.$$.fragment,e),p(Oe.$$.fragment,e),p(Ge.$$.fragment,e),p(Ye.$$.fragment,e),p(Xe.$$.fragment,e),p(Ze.$$.fragment,e),p(Qe.$$.fragment,e),p(Ke.$$.fragment,e),p(et.$$.fragment,e),p(tt.$$.fragment,e),p(me.$$.fragment,e),p(rt.$$.fragment,e),p(at.$$.fragment,e),p(nt.$$.fragment,e),p(pe.$$.fragment,e),p(ot.$$.fragment,e),p(lt.$$.fragment,e),p(it.$$.fragment,e),p(ct.$$.fragment,e),p(dt.$$.fragment,e),p(mt.$$.fragment,e),p(pt.$$.fragment,e),p(gt.$$.fragment,e),p(ft.$$.fragment,e),p(ge.$$.fragment,e),p(ht.$$.fragment,e),p(ut.$$.fragment,e),p(bt.$$.fragment,e),p(vt.$$.fragment,e),p(_t.$$.fragment,e),p(Tt.$$.fragment,e),p(fe.$$.fragment,e),p($t.$$.fragment,e),p(Ct.$$.fragment,e),p(kt.$$.fragment,e),p(wt.$$.fragment,e),p(yt.$$.fragment,e),p(xt.$$.fragment,e),p(Mt.$$.fragment,e),p(Lt.$$.fragment,e),p(It.$$.fragment,e),p(Et.$$.fragment,e),p(Ht.$$.fragment,e),p(At.$$.fragment,e),p(jt.$$.fragment,e),p(St.$$.fragment,e),p(Nt.$$.fragment,e),p(Dt.$$.fragment,e),p(Jt.$$.fragment,e),p(Wt.$$.fragment,e),p(Ft.$$.fragment,e),p(Ee.$$.fragment,e),p(zt.$$.fragment,e),p(Bt.$$.fragment,e),p(qt.$$.fragment,e),p(Rt.$$.fragment,e),p(Ot.$$.fragment,e),p(Vt.$$.fragment,e),p(Gt.$$.fragment,e),gn=!1},d(e){e&&(o(M),o(v),o(C),o(b),o(x),o(H),o(Fe),o(Ha),o(ze),o(Aa),o(Be),o(ja),o(qe),o(Sa),o(Re),o(Na),o(Pa),o(Ve),o(Da),o(R),o(Ua),o(ae),o(Ja),o(ne),o(Wa),o(se),o(Fa),o(O),o(za),o(oe),o(Ba),o(j),o(qa),o(V),o(Ra),o(Y),o(Oa),o(le),o(Va),o(ie),o(Ga),o(X),o(Ya),o(U),o(Xa),o(Z),o(Za),o(Q),o(Qa),o(J),o(Ka),o(K),o(en),o(tn),o(k),o(rn),o(Pt),o(an),o(nn),o(Ut),o(sn),o(on),o(ln),o(E),o(cn),o(dn),o(ce),o(mn),o(pn),o(Ma)),o(d),u(y,e),u(Oe,e),u(Ge),u(Ye),u(Xe),u(Ze),u(Qe),u(Ke),u(et),u(tt),u(me),u(rt),u(at),u(nt),u(pe),u(ot),u(lt),u(it),u(ct),u(dt),u(mt),u(pt),u(gt),u(ft),u(ge),u(ht),u(ut),u(bt),u(vt),u(_t,e),u(Tt),u(fe),u($t),u(Ct),u(kt),u(wt),u(yt),u(xt),u(Mt),u(Lt),u(It),u(Et),u(Ht),u(At),u(jt),u(St),u(Nt),u(Dt,e),u(Jt,e),u(Wt,e),u(Ft),u(Ee),u(zt),u(Bt),u(qt),u(Rt),u(Ot,e),u(Vt),u(Gt,e)}}}const Ji='{"title":"Callbacks","local":"callbacks","sections":[{"title":"Available Callbacks","local":"transformers.integrations.CometCallback","sections":[],"depth":2},{"title":"TrainerCallback","local":"transformers.TrainerCallback","sections":[],"depth":2},{"title":"TrainerState","local":"transformers.TrainerState","sections":[],"depth":2},{"title":"TrainerControl","local":"transformers.TrainerControl","sections":[],"depth":2}],"depth":1}';function Wi(L){return yi(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Gi extends vi{constructor(d){super(),_i(this,d,Wi,Ui,bi,{})}}export{Gi as component};
