import{s as De,o as Ke,n as Ce}from"../chunks/scheduler.18a86fab.js";import{S as Oe,i as et,g as o,s as l,r as c,A as tt,h as p,f as a,c as r,j as Pe,u,x as g,k as Ae,y as at,a as s,v as f,d as h,t as d,w as y}from"../chunks/index.98837b22.js";import{T as Ie}from"../chunks/Tip.77304350.js";import{Y as st}from"../chunks/Youtube.14fb207c.js";import{C as Z}from"../chunks/CodeBlock.8d0c2e8a.js";import{D as nt}from"../chunks/DocNotebookDropdown.a04a6b2a.js";import{H as je,E as lt}from"../chunks/getInferenceSnippets.06c2775f.js";function rt($){let n,b="Learn how to fine-tune models for other tasks in our Task Recipes section in Resources!";return{c(){n=o("p"),n.textContent=b},l(i){n=p(i,"P",{"data-svelte-h":!0}),g(n)!=="svelte-c44oek"&&(n.textContent=b)},m(i,T){s(i,n,T)},p:Ce,d(i){i&&a(n)}}}function it($){let n,b="Fine-tune on a smaller subset of the full dataset to reduce the time it takes. The results won’t be as good compared to fine-tuning on the full dataset, but it is useful to make sure everything works as expected first before committing to training on the full dataset.",i,T,w;return T=new Z({props:{code:"c21hbGxfdHJhaW4lMjAlM0QlMjBkYXRhc2V0JTVCJTIydHJhaW4lMjIlNUQuc2h1ZmZsZShzZWVkJTNENDIpLnNlbGVjdChyYW5nZSgxMDAwKSklMEFzbWFsbF9ldmFsJTIwJTNEJTIwZGF0YXNldCU1QiUyMnRlc3QlMjIlNUQuc2h1ZmZsZShzZWVkJTNENDIpLnNlbGVjdChyYW5nZSgxMDAwKSk=",highlighted:`small_train = dataset[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))
small_eval = dataset[<span class="hljs-string">&quot;test&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))`,wrap:!1}}),{c(){n=o("p"),n.textContent=b,i=l(),c(T.$$.fragment)},l(m){n=p(m,"P",{"data-svelte-h":!0}),g(n)!=="svelte-xwrr2c"&&(n.textContent=b),i=r(m),u(T.$$.fragment,m)},m(m,J){s(m,n,J),s(m,i,J),f(T,m,J),w=!0},p:Ce,i(m){w||(h(T.$$.fragment,m),w=!0)},o(m){d(T.$$.fragment,m),w=!1},d(m){m&&(a(n),a(i)),y(T,m)}}}function ot($){let n,b="The message above is a reminder that the models pretrained head is discarded and replaced with a randomly initialized classification head. The randomly initialized head needs to be fine-tuned on your specific task to output meaningful predictions.";return{c(){n=o("p"),n.textContent=b},l(i){n=p(i,"P",{"data-svelte-h":!0}),g(n)!=="svelte-ph0mbv"&&(n.textContent=b)},m(i,T){s(i,n,T)},p:Ce,d(i){i&&a(n)}}}function pt($){let n,b,i,T,w,m,J,O,k,We="Fine-tuning adapts a pretrained model to a specific task with a smaller specialized dataset. This approach requires far less data and compute compared to training a model from scratch, which makes it a more accessible option for many users.",ee,_,Re='Transformers provides the <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> API, which offers a comprehensive set of training features, for fine-tuning any of the models on the <a href="https://hf.co/models" rel="nofollow">Hub</a>.',te,M,ae,I,Be='This guide will show you how to fine-tune a model with <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> to classify Yelp reviews.',se,j,xe="Log in to your Hugging Face account with your user token to ensure you can access gated models and share your models on the Hub.",ne,C,le,W,Ge='Start by loading the <a href="https://hf.co/datasets/yelp_review_full" rel="nofollow">Yelp Reviews</a> dataset and <a href="./fast_tokenizers#preprocess">preprocess</a> (tokenize, pad, and truncate) it for training. Use <a href="https://huggingface.co/docs/datasets/v4.1.0/en/package_reference/main_classes#datasets.Dataset.map" rel="nofollow">map</a> to preprocess the entire dataset in one step.',re,R,ie,v,oe,B,pe,x,me,G,Xe='<a href="./trainer">Trainer</a> is an optimized training loop for Transformers models, making it easy to start training right away without manually writing your own training code. Pick and choose from a wide range of training features in <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> such as gradient accumulation, mixed precision, and options for reporting and logging training metrics.',ce,X,Fe='Load a model and provide the number of expected labels (you can find this information on the Yelp Review <a href="https://huggingface.co/datasets/yelp_review_full#data-fields" rel="nofollow">dataset card</a>).',ue,F,fe,U,he,H,He='With the model loaded, set up your training hyperparameters in <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>. Hyperparameters are variables that control the training process - such as the learning rate, batch size, number of epochs - which in turn impacts model performance. Selecting the correct hyperparameters is important and you should experiment with them to find the best configuration for your task.',de,Y,Ye="For this guide, you can use the default hyperparameters which provide a good baseline to begin with. The only settings to configure in this guide are where to save the checkpoint, how to evaluate model performance during training, and pushing the model to the Hub.",ye,z,ze='<a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> requires a function to compute and report your metric. For a classification task, you’ll use <a href="https://huggingface.co/docs/evaluate/v0.4.5/en/package_reference/loading_methods#evaluate.load" rel="nofollow">evaluate.load</a> to load the <a href="https://hf.co/spaces/evaluate-metric/accuracy" rel="nofollow">accuracy</a> function from the <a href="https://hf.co/docs/evaluate/index" rel="nofollow">Evaluate</a> library. Gather the predictions and labels in <a href="https://huggingface.co/docs/evaluate/v0.4.5/en/package_reference/main_classes#evaluate.EvaluationModule.compute" rel="nofollow">compute</a> to calculate the accuracy.',ge,V,Te,N,Ve='Set up <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> with where to save the model and when to compute accuracy during training. The example below sets it to <code>&quot;epoch&quot;</code>, which reports the accuracy at the end of each epoch. Add <code>push_to_hub=True</code> to upload the model to the Hub after training.',be,Q,we,S,Ne='Create a <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> instance and pass it the model, training arguments, training and test datasets, and evaluation function. Call <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer.train">train()</a> to start training.',Je,q,$e,E,Qe='Finally, use <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer.push_to_hub">push_to_hub()</a> to upload your model and tokenizer to the Hub.',Me,L,ve,P,Ue,A,Se='Refer to the Transformers <a href="https://github.com/huggingface/transformers/tree/main/examples" rel="nofollow">examples</a> for more detailed training scripts on various tasks. You can also check out the <a href="./notebooks">notebooks</a> for interactive examples.',Ze,D,ke,K,_e;return w=new je({props:{title:"Fine-tuning",local:"fine-tuning",headingTag:"h1"}}),J=new nt({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/training.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/training.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/tensorflow/training.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/training.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/training.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/tensorflow/training.ipynb"}]}}),M=new Ie({props:{warning:!1,$$slots:{default:[rt]},$$scope:{ctx:$}}}),C=new Z({props:{code:"ZnJvbSUyMGh1Z2dpbmdmYWNlX2h1YiUyMGltcG9ydCUyMGxvZ2luJTBBJTBBbG9naW4oKQ==",highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> login

login()`,wrap:!1}}),R=new Z({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEFkYXRhc2V0JTIwJTNEJTIwbG9hZF9kYXRhc2V0KCUyMnllbHBfcmV2aWV3X2Z1bGwlMjIpJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQoJTIyZ29vZ2xlLWJlcnQlMkZiZXJ0LWJhc2UtY2FzZWQlMjIpJTBBJTBBZGVmJTIwdG9rZW5pemUoZXhhbXBsZXMpJTNBJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwdG9rZW5pemVyKGV4YW1wbGVzJTVCJTIydGV4dCUyMiU1RCUyQyUyMHBhZGRpbmclM0QlMjJtYXhfbGVuZ3RoJTIyJTJDJTIwdHJ1bmNhdGlvbiUzRFRydWUpJTBBJTBBZGF0YXNldCUyMCUzRCUyMGRhdGFzZXQubWFwKHRva2VuaXplJTJDJTIwYmF0Y2hlZCUzRFRydWUp",highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

dataset = load_dataset(<span class="hljs-string">&quot;yelp_review_full&quot;</span>)
tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-cased&quot;</span>)

<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize</span>(<span class="hljs-params">examples</span>):
    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&quot;text&quot;</span>], padding=<span class="hljs-string">&quot;max_length&quot;</span>, truncation=<span class="hljs-literal">True</span>)

dataset = dataset.<span class="hljs-built_in">map</span>(tokenize, batched=<span class="hljs-literal">True</span>)`,wrap:!1}}),v=new Ie({props:{warning:!1,$$slots:{default:[it]},$$scope:{ctx:$}}}),B=new je({props:{title:"Trainer",local:"trainer",headingTag:"h2"}}),x=new st({props:{id:"nvBXf7s7vTI"}}),F=new Z({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMmdvb2dsZS1iZXJ0JTJGYmVydC1iYXNlLWNhc2VkJTIyJTJDJTIwbnVtX2xhYmVscyUzRDUpJTBBJTIyU29tZSUyMHdlaWdodHMlMjBvZiUyMEJlcnRGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uJTIwd2VyZSUyMG5vdCUyMGluaXRpYWxpemVkJTIwZnJvbSUyMHRoZSUyMG1vZGVsJTIwY2hlY2twb2ludCUyMGF0JTIwZ29vZ2xlLWJlcnQlMkZiZXJ0LWJhc2UtY2FzZWQlMjBhbmQlMjBhcmUlMjBuZXdseSUyMGluaXRpYWxpemVkJTNBJTIwJTVCJ2NsYXNzaWZpZXIuYmlhcyclMkMlMjAnY2xhc3NpZmllci53ZWlnaHQnJTVEJTIyJTBBJTIyWW91JTIwc2hvdWxkJTIwcHJvYmFibHklMjBUUkFJTiUyMHRoaXMlMjBtb2RlbCUyMG9uJTIwYSUyMGRvd24tc3RyZWFtJTIwdGFzayUyMHRvJTIwYmUlMjBhYmxlJTIwdG8lMjB1c2UlMjBpdCUyMGZvciUyMHByZWRpY3Rpb25zJTIwYW5kJTIwaW5mZXJlbmNlLiUyMg==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-cased&quot;</span>, num_labels=<span class="hljs-number">5</span>)
<span class="hljs-string">&quot;Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: [&#x27;classifier.bias&#x27;, &#x27;classifier.weight&#x27;]&quot;</span>
<span class="hljs-string">&quot;You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.&quot;</span>`,wrap:!1}}),U=new Ie({props:{warning:!1,$$slots:{default:[ot]},$$scope:{ctx:$}}}),V=new Z({props:{code:"aW1wb3J0JTIwbnVtcHklMjBhcyUyMG5wJTBBaW1wb3J0JTIwZXZhbHVhdGUlMEElMEFtZXRyaWMlMjAlM0QlMjBldmFsdWF0ZS5sb2FkKCUyMmFjY3VyYWN5JTIyKSUwQSUwQWRlZiUyMGNvbXB1dGVfbWV0cmljcyhldmFsX3ByZWQpJTNBJTBBJTIwJTIwJTIwJTIwbG9naXRzJTJDJTIwbGFiZWxzJTIwJTNEJTIwZXZhbF9wcmVkJTBBJTIwJTIwJTIwJTIwJTIzJTIwY29udmVydCUyMHRoZSUyMGxvZ2l0cyUyMHRvJTIwdGhlaXIlMjBwcmVkaWN0ZWQlMjBjbGFzcyUwQSUyMCUyMCUyMCUyMHByZWRpY3Rpb25zJTIwJTNEJTIwbnAuYXJnbWF4KGxvZ2l0cyUyQyUyMGF4aXMlM0QtMSklMEElMjAlMjAlMjAlMjByZXR1cm4lMjBtZXRyaWMuY29tcHV0ZShwcmVkaWN0aW9ucyUzRHByZWRpY3Rpb25zJTJDJTIwcmVmZXJlbmNlcyUzRGxhYmVscyk=",highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> evaluate

metric = evaluate.load(<span class="hljs-string">&quot;accuracy&quot;</span>)

<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):
    logits, labels = eval_pred
    <span class="hljs-comment"># convert the logits to their predicted class</span>
    predictions = np.argmax(logits, axis=-<span class="hljs-number">1</span>)
    <span class="hljs-keyword">return</span> metric.compute(predictions=predictions, references=labels)`,wrap:!1}}),Q=new Z({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRyYWluaW5nQXJndW1lbnRzJTBBJTBBdHJhaW5pbmdfYXJncyUyMCUzRCUyMFRyYWluaW5nQXJndW1lbnRzKCUwQSUyMCUyMCUyMCUyMG91dHB1dF9kaXIlM0QlMjJ5ZWxwX3Jldmlld19jbGFzc2lmaWVyJTIyJTJDJTBBJTIwJTIwJTIwJTIwZXZhbF9zdHJhdGVneSUzRCUyMmVwb2NoJTIyJTJDJTBBJTIwJTIwJTIwJTIwcHVzaF90b19odWIlM0RUcnVlJTJDJTBBKQ==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

training_args = TrainingArguments(
    output_dir=<span class="hljs-string">&quot;yelp_review_classifier&quot;</span>,
    eval_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    push_to_hub=<span class="hljs-literal">True</span>,
)`,wrap:!1}}),q=new Z({props:{code:"dHJhaW5lciUyMCUzRCUyMFRyYWluZXIoJTBBJTIwJTIwJTIwJTIwbW9kZWwlM0Rtb2RlbCUyQyUwQSUyMCUyMCUyMCUyMGFyZ3MlM0R0cmFpbmluZ19hcmdzJTJDJTBBJTIwJTIwJTIwJTIwdHJhaW5fZGF0YXNldCUzRGRhdGFzZXQlNUIlMjJ0cmFpbiUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMGV2YWxfZGF0YXNldCUzRGRhdGFzZXQlNUIlMjJ0ZXN0JTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwY29tcHV0ZV9tZXRyaWNzJTNEY29tcHV0ZV9tZXRyaWNzJTJDJTBBKSUwQXRyYWluZXIudHJhaW4oKQ==",highlighted:`trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset[<span class="hljs-string">&quot;train&quot;</span>],
    eval_dataset=dataset[<span class="hljs-string">&quot;test&quot;</span>],
    compute_metrics=compute_metrics,
)
trainer.train()`,wrap:!1}}),L=new Z({props:{code:"dHJhaW5lci5wdXNoX3RvX2h1Yigp",highlighted:"trainer.push_to_hub()",wrap:!1}}),P=new je({props:{title:"Resources",local:"resources",headingTag:"h2"}}),D=new lt({props:{source:"https://github.com/huggingface/transformers/blob/main/docs/source/en/training.md"}}),{c(){n=o("meta"),b=l(),i=o("p"),T=l(),c(w.$$.fragment),m=l(),c(J.$$.fragment),O=l(),k=o("p"),k.textContent=We,ee=l(),_=o("p"),_.innerHTML=Re,te=l(),c(M.$$.fragment),ae=l(),I=o("p"),I.innerHTML=Be,se=l(),j=o("p"),j.textContent=xe,ne=l(),c(C.$$.fragment),le=l(),W=o("p"),W.innerHTML=Ge,re=l(),c(R.$$.fragment),ie=l(),c(v.$$.fragment),oe=l(),c(B.$$.fragment),pe=l(),c(x.$$.fragment),me=l(),G=o("p"),G.innerHTML=Xe,ce=l(),X=o("p"),X.innerHTML=Fe,ue=l(),c(F.$$.fragment),fe=l(),c(U.$$.fragment),he=l(),H=o("p"),H.innerHTML=He,de=l(),Y=o("p"),Y.textContent=Ye,ye=l(),z=o("p"),z.innerHTML=ze,ge=l(),c(V.$$.fragment),Te=l(),N=o("p"),N.innerHTML=Ve,be=l(),c(Q.$$.fragment),we=l(),S=o("p"),S.innerHTML=Ne,Je=l(),c(q.$$.fragment),$e=l(),E=o("p"),E.innerHTML=Qe,Me=l(),c(L.$$.fragment),ve=l(),c(P.$$.fragment),Ue=l(),A=o("p"),A.innerHTML=Se,Ze=l(),c(D.$$.fragment),ke=l(),K=o("p"),this.h()},l(e){const t=tt("svelte-u9bgzb",document.head);n=p(t,"META",{name:!0,content:!0}),t.forEach(a),b=r(e),i=p(e,"P",{}),Pe(i).forEach(a),T=r(e),u(w.$$.fragment,e),m=r(e),u(J.$$.fragment,e),O=r(e),k=p(e,"P",{"data-svelte-h":!0}),g(k)!=="svelte-cwu0pk"&&(k.textContent=We),ee=r(e),_=p(e,"P",{"data-svelte-h":!0}),g(_)!=="svelte-1gkhold"&&(_.innerHTML=Re),te=r(e),u(M.$$.fragment,e),ae=r(e),I=p(e,"P",{"data-svelte-h":!0}),g(I)!=="svelte-wotkj8"&&(I.innerHTML=Be),se=r(e),j=p(e,"P",{"data-svelte-h":!0}),g(j)!=="svelte-1tkhazs"&&(j.textContent=xe),ne=r(e),u(C.$$.fragment,e),le=r(e),W=p(e,"P",{"data-svelte-h":!0}),g(W)!=="svelte-yhlxgb"&&(W.innerHTML=Ge),re=r(e),u(R.$$.fragment,e),ie=r(e),u(v.$$.fragment,e),oe=r(e),u(B.$$.fragment,e),pe=r(e),u(x.$$.fragment,e),me=r(e),G=p(e,"P",{"data-svelte-h":!0}),g(G)!=="svelte-y03bju"&&(G.innerHTML=Xe),ce=r(e),X=p(e,"P",{"data-svelte-h":!0}),g(X)!=="svelte-6y6p4w"&&(X.innerHTML=Fe),ue=r(e),u(F.$$.fragment,e),fe=r(e),u(U.$$.fragment,e),he=r(e),H=p(e,"P",{"data-svelte-h":!0}),g(H)!=="svelte-rir8lc"&&(H.innerHTML=He),de=r(e),Y=p(e,"P",{"data-svelte-h":!0}),g(Y)!=="svelte-13wgkko"&&(Y.textContent=Ye),ye=r(e),z=p(e,"P",{"data-svelte-h":!0}),g(z)!=="svelte-10uzk51"&&(z.innerHTML=ze),ge=r(e),u(V.$$.fragment,e),Te=r(e),N=p(e,"P",{"data-svelte-h":!0}),g(N)!=="svelte-1ft91ms"&&(N.innerHTML=Ve),be=r(e),u(Q.$$.fragment,e),we=r(e),S=p(e,"P",{"data-svelte-h":!0}),g(S)!=="svelte-19fa8p7"&&(S.innerHTML=Ne),Je=r(e),u(q.$$.fragment,e),$e=r(e),E=p(e,"P",{"data-svelte-h":!0}),g(E)!=="svelte-q1fxl"&&(E.innerHTML=Qe),Me=r(e),u(L.$$.fragment,e),ve=r(e),u(P.$$.fragment,e),Ue=r(e),A=p(e,"P",{"data-svelte-h":!0}),g(A)!=="svelte-4454x9"&&(A.innerHTML=Se),Ze=r(e),u(D.$$.fragment,e),ke=r(e),K=p(e,"P",{}),Pe(K).forEach(a),this.h()},h(){Ae(n,"name","hf:doc:metadata"),Ae(n,"content",mt)},m(e,t){at(document.head,n),s(e,b,t),s(e,i,t),s(e,T,t),f(w,e,t),s(e,m,t),f(J,e,t),s(e,O,t),s(e,k,t),s(e,ee,t),s(e,_,t),s(e,te,t),f(M,e,t),s(e,ae,t),s(e,I,t),s(e,se,t),s(e,j,t),s(e,ne,t),f(C,e,t),s(e,le,t),s(e,W,t),s(e,re,t),f(R,e,t),s(e,ie,t),f(v,e,t),s(e,oe,t),f(B,e,t),s(e,pe,t),f(x,e,t),s(e,me,t),s(e,G,t),s(e,ce,t),s(e,X,t),s(e,ue,t),f(F,e,t),s(e,fe,t),f(U,e,t),s(e,he,t),s(e,H,t),s(e,de,t),s(e,Y,t),s(e,ye,t),s(e,z,t),s(e,ge,t),f(V,e,t),s(e,Te,t),s(e,N,t),s(e,be,t),f(Q,e,t),s(e,we,t),s(e,S,t),s(e,Je,t),f(q,e,t),s(e,$e,t),s(e,E,t),s(e,Me,t),f(L,e,t),s(e,ve,t),f(P,e,t),s(e,Ue,t),s(e,A,t),s(e,Ze,t),f(D,e,t),s(e,ke,t),s(e,K,t),_e=!0},p(e,[t]){const qe={};t&2&&(qe.$$scope={dirty:t,ctx:e}),M.$set(qe);const Ee={};t&2&&(Ee.$$scope={dirty:t,ctx:e}),v.$set(Ee);const Le={};t&2&&(Le.$$scope={dirty:t,ctx:e}),U.$set(Le)},i(e){_e||(h(w.$$.fragment,e),h(J.$$.fragment,e),h(M.$$.fragment,e),h(C.$$.fragment,e),h(R.$$.fragment,e),h(v.$$.fragment,e),h(B.$$.fragment,e),h(x.$$.fragment,e),h(F.$$.fragment,e),h(U.$$.fragment,e),h(V.$$.fragment,e),h(Q.$$.fragment,e),h(q.$$.fragment,e),h(L.$$.fragment,e),h(P.$$.fragment,e),h(D.$$.fragment,e),_e=!0)},o(e){d(w.$$.fragment,e),d(J.$$.fragment,e),d(M.$$.fragment,e),d(C.$$.fragment,e),d(R.$$.fragment,e),d(v.$$.fragment,e),d(B.$$.fragment,e),d(x.$$.fragment,e),d(F.$$.fragment,e),d(U.$$.fragment,e),d(V.$$.fragment,e),d(Q.$$.fragment,e),d(q.$$.fragment,e),d(L.$$.fragment,e),d(P.$$.fragment,e),d(D.$$.fragment,e),_e=!1},d(e){e&&(a(b),a(i),a(T),a(m),a(O),a(k),a(ee),a(_),a(te),a(ae),a(I),a(se),a(j),a(ne),a(le),a(W),a(re),a(ie),a(oe),a(pe),a(me),a(G),a(ce),a(X),a(ue),a(fe),a(he),a(H),a(de),a(Y),a(ye),a(z),a(ge),a(Te),a(N),a(be),a(we),a(S),a(Je),a($e),a(E),a(Me),a(ve),a(Ue),a(A),a(Ze),a(ke),a(K)),a(n),y(w,e),y(J,e),y(M,e),y(C,e),y(R,e),y(v,e),y(B,e),y(x,e),y(F,e),y(U,e),y(V,e),y(Q,e),y(q,e),y(L,e),y(P,e),y(D,e)}}}const mt='{"title":"Fine-tuning","local":"fine-tuning","sections":[{"title":"Trainer","local":"trainer","sections":[],"depth":2},{"title":"Resources","local":"resources","sections":[],"depth":2}],"depth":1}';function ct($){return Ke(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class bt extends Oe{constructor(n){super(),et(this,n,ct,pt,De,{})}}export{bt as component};
