import{s as Ho,o as So,n as Re}from"../chunks/scheduler.18a86fab.js";import{S as Po,i as No,g as l,s as r,r as p,A as Vo,h as d,f as o,c as a,j as H,x as _,u as m,k as S,l as Xo,y as w,a as n,v as u,d as f,t as h,w as g}from"../chunks/index.98837b22.js";import{T as Eo}from"../chunks/Tip.77304350.js";import{D as Qe}from"../chunks/Docstring.a1ef7999.js";import{C as Oe}from"../chunks/CodeBlock.8d0c2e8a.js";import{E as Go}from"../chunks/ExampleCodeBlock.8c3ee1f9.js";import{P as Nt}from"../chunks/PipelineTag.7749150e.js";import{H as C,E as Qo}from"../chunks/getInferenceSnippets.06c2775f.js";import{H as Yo,a as lo}from"../chunks/HfOption.6641485e.js";function Do($){let s,T="Click on the ALBERT models in the right sidebar for more examples of how to apply ALBERT to different language tasks.";return{c(){s=l("p"),s.textContent=T},l(i){s=d(i,"P",{"data-svelte-h":!0}),_(s)!=="svelte-1e1fenn"&&(s.textContent=T)},m(i,y){n(i,s,y)},p:Re,d(i){i&&o(s)}}}function Oo($){let s,T;return s=new Oe({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwdHJhbnNmb3JtZXJzJTIwaW1wb3J0JTIwcGlwZWxpbmUlMEElMEFwaXBlbGluZSUyMCUzRCUyMHBpcGVsaW5lKCUwQSUyMCUyMCUyMCUyMHRhc2slM0QlMjJmaWxsLW1hc2slMjIlMkMlMEElMjAlMjAlMjAlMjBtb2RlbCUzRCUyMmFsYmVydC1iYXNlLXYyJTIyJTJDJTBBJTIwJTIwJTIwJTIwZHR5cGUlM0R0b3JjaC5mbG9hdDE2JTJDJTBBJTIwJTIwJTIwJTIwZGV2aWNlJTNEMCUwQSklMEFwaXBlbGluZSglMjJQbGFudHMlMjBjcmVhdGUlMjAlNUJNQVNLJTVEJTIwdGhyb3VnaCUyMGElMjBwcm9jZXNzJTIwa25vd24lMjBhcyUyMHBob3Rvc3ludGhlc2lzLiUyMiUyQyUyMHRvcF9rJTNENSk=",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

pipeline = pipeline(
    task=<span class="hljs-string">&quot;fill-mask&quot;</span>,
    model=<span class="hljs-string">&quot;albert-base-v2&quot;</span>,
    dtype=torch.float16,
    device=<span class="hljs-number">0</span>
)
pipeline(<span class="hljs-string">&quot;Plants create [MASK] through a process known as photosynthesis.&quot;</span>, top_k=<span class="hljs-number">5</span>)`,wrap:!1}}),{c(){p(s.$$.fragment)},l(i){m(s.$$.fragment,i)},m(i,y){u(s,i,y),T=!0},p:Re,i(i){T||(f(s.$$.fragment,i),T=!0)},o(i){h(s.$$.fragment,i),T=!1},d(i){g(s,i)}}}function Ko($){let s,T;return s=new Oe({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwdHJhbnNmb3JtZXJzJTIwaW1wb3J0JTIwQXV0b01vZGVsRm9yTWFza2VkTE0lMkMlMjBBdXRvVG9rZW5pemVyJTBBJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQoJTIyYWxiZXJ0JTJGYWxiZXJ0LWJhc2UtdjIlMjIpJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JNYXNrZWRMTS5mcm9tX3ByZXRyYWluZWQoJTBBJTIwJTIwJTIwJTIwJTIyYWxiZXJ0JTJGYWxiZXJ0LWJhc2UtdjIlMjIlMkMlMEElMjAlMjAlMjAlMjBkdHlwZSUzRHRvcmNoLmZsb2F0MTYlMkMlMEElMjAlMjAlMjAlMjBhdHRuX2ltcGxlbWVudGF0aW9uJTNEJTIyc2RwYSUyMiUyQyUwQSUyMCUyMCUyMCUyMGRldmljZV9tYXAlM0QlMjJhdXRvJTIyJTBBKSUwQSUwQXByb21wdCUyMCUzRCUyMCUyMlBsYW50cyUyMGNyZWF0ZSUyMGVuZXJneSUyMHRocm91Z2glMjBhJTIwcHJvY2VzcyUyMGtub3duJTIwYXMlMjAlNUJNQVNLJTVELiUyMiUwQWlucHV0cyUyMCUzRCUyMHRva2VuaXplcihwcm9tcHQlMkMlMjByZXR1cm5fdGVuc29ycyUzRCUyMnB0JTIyKS50byhtb2RlbC5kZXZpY2UpJTBBJTBBd2l0aCUyMHRvcmNoLm5vX2dyYWQoKSUzQSUwQSUyMCUyMCUyMCUyMG91dHB1dHMlMjAlM0QlMjBtb2RlbCgqKmlucHV0cyklMEElMjAlMjAlMjAlMjBtYXNrX3Rva2VuX2luZGV4JTIwJTNEJTIwdG9yY2gud2hlcmUoaW5wdXRzJTVCJTIyaW5wdXRfaWRzJTIyJTVEJTIwJTNEJTNEJTIwdG9rZW5pemVyLm1hc2tfdG9rZW5faWQpJTVCMSU1RCUwQSUyMCUyMCUyMCUyMHByZWRpY3Rpb25zJTIwJTNEJTIwb3V0cHV0cy5sb2dpdHMlNUIwJTJDJTIwbWFza190b2tlbl9pbmRleCU1RCUwQSUwQXRvcF9rJTIwJTNEJTIwdG9yY2gudG9wayhwcmVkaWN0aW9ucyUyQyUyMGslM0Q1KS5pbmRpY2VzLnRvbGlzdCgpJTBBZm9yJTIwdG9rZW5faWQlMjBpbiUyMHRvcF9rJTVCMCU1RCUzQSUwQSUyMCUyMCUyMCUyMHByaW50KGYlMjJQcmVkaWN0aW9uJTNBJTIwJTdCdG9rZW5pemVyLmRlY29kZSglNUJ0b2tlbl9pZCU1RCklN0QlMjIp",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForMaskedLM, AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;albert/albert-base-v2&quot;</span>)
model = AutoModelForMaskedLM.from_pretrained(
    <span class="hljs-string">&quot;albert/albert-base-v2&quot;</span>,
    dtype=torch.float16,
    attn_implementation=<span class="hljs-string">&quot;sdpa&quot;</span>,
    device_map=<span class="hljs-string">&quot;auto&quot;</span>
)

prompt = <span class="hljs-string">&quot;Plants create energy through a process known as [MASK].&quot;</span>
inputs = tokenizer(prompt, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).to(model.device)

<span class="hljs-keyword">with</span> torch.no_grad():
    outputs = model(**inputs)
    mask_token_index = torch.where(inputs[<span class="hljs-string">&quot;input_ids&quot;</span>] == tokenizer.mask_token_id)[<span class="hljs-number">1</span>]
    predictions = outputs.logits[<span class="hljs-number">0</span>, mask_token_index]

top_k = torch.topk(predictions, k=<span class="hljs-number">5</span>).indices.tolist()
<span class="hljs-keyword">for</span> token_id <span class="hljs-keyword">in</span> top_k[<span class="hljs-number">0</span>]:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Prediction: <span class="hljs-subst">{tokenizer.decode([token_id])}</span>&quot;</span>)`,wrap:!1}}),{c(){p(s.$$.fragment)},l(i){m(s.$$.fragment,i)},m(i,y){u(s,i,y),T=!0},p:Re,i(i){T||(f(s.$$.fragment,i),T=!0)},o(i){h(s.$$.fragment,i),T=!1},d(i){g(s,i)}}}function en($){let s,T;return s=new Oe({props:{code:"ZWNobyUyMC1lJTIwJTIyUGxhbnRzJTIwY3JlYXRlJTIwJTVCTUFTSyU1RCUyMHRocm91Z2glMjBhJTIwcHJvY2VzcyUyMGtub3duJTIwYXMlMjBwaG90b3N5bnRoZXNpcy4lMjIlMjAlN0MlMjB0cmFuc2Zvcm1lcnMlMjBydW4lMjAtLXRhc2slMjBmaWxsLW1hc2slMjAtLW1vZGVsJTIwYWxiZXJ0LWJhc2UtdjIlMjAtLWRldmljZSUyMDA=",highlighted:'<span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;Plants create [MASK] through a process known as photosynthesis.&quot;</span> | transformers run --task fill-mask --model albert-base-v2 --device 0',wrap:!1}}),{c(){p(s.$$.fragment)},l(i){m(s.$$.fragment,i)},m(i,y){u(s,i,y),T=!0},p:Re,i(i){T||(f(s.$$.fragment,i),T=!0)},o(i){h(s.$$.fragment,i),T=!1},d(i){g(s,i)}}}function tn($){let s,T,i,y,M,b;return s=new lo({props:{id:"usage",option:"Pipeline",$$slots:{default:[Oo]},$$scope:{ctx:$}}}),i=new lo({props:{id:"usage",option:"AutoModel",$$slots:{default:[Ko]},$$scope:{ctx:$}}}),M=new lo({props:{id:"usage",option:"transformers CLI",$$slots:{default:[en]},$$scope:{ctx:$}}}),{c(){p(s.$$.fragment),T=r(),p(i.$$.fragment),y=r(),p(M.$$.fragment)},l(c){m(s.$$.fragment,c),T=a(c),m(i.$$.fragment,c),y=a(c),m(M.$$.fragment,c)},m(c,k){u(s,c,k),n(c,T,k),u(i,c,k),n(c,y,k),u(M,c,k),b=!0},p(c,k){const Ye={};k&2&&(Ye.$$scope={dirty:k,ctx:c}),s.$set(Ye);const P={};k&2&&(P.$$scope={dirty:k,ctx:c}),i.$set(P);const z={};k&2&&(z.$$scope={dirty:k,ctx:c}),M.$set(z)},i(c){b||(f(s.$$.fragment,c),f(i.$$.fragment,c),f(M.$$.fragment,c),b=!0)},o(c){h(s.$$.fragment,c),h(i.$$.fragment,c),h(M.$$.fragment,c),b=!1},d(c){c&&(o(T),o(y)),g(s,c),g(i,c),g(M,c)}}}function on($){let s,T="Examples:",i,y,M;return y=new Oe({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEFsYmVydENvbmZpZyUyQyUyMEFsYmVydE1vZGVsJTBBJTBBJTIzJTIwSW5pdGlhbGl6aW5nJTIwYW4lMjBBTEJFUlQteHhsYXJnZSUyMHN0eWxlJTIwY29uZmlndXJhdGlvbiUwQWFsYmVydF94eGxhcmdlX2NvbmZpZ3VyYXRpb24lMjAlM0QlMjBBbGJlcnRDb25maWcoKSUwQSUwQSUyMyUyMEluaXRpYWxpemluZyUyMGFuJTIwQUxCRVJULWJhc2UlMjBzdHlsZSUyMGNvbmZpZ3VyYXRpb24lMEFhbGJlcnRfYmFzZV9jb25maWd1cmF0aW9uJTIwJTNEJTIwQWxiZXJ0Q29uZmlnKCUwQSUyMCUyMCUyMCUyMGhpZGRlbl9zaXplJTNENzY4JTJDJTBBJTIwJTIwJTIwJTIwbnVtX2F0dGVudGlvbl9oZWFkcyUzRDEyJTJDJTBBJTIwJTIwJTIwJTIwaW50ZXJtZWRpYXRlX3NpemUlM0QzMDcyJTJDJTBBKSUwQSUwQSUyMyUyMEluaXRpYWxpemluZyUyMGElMjBtb2RlbCUyMCh3aXRoJTIwcmFuZG9tJTIwd2VpZ2h0cyklMjBmcm9tJTIwdGhlJTIwQUxCRVJULWJhc2UlMjBzdHlsZSUyMGNvbmZpZ3VyYXRpb24lMEFtb2RlbCUyMCUzRCUyMEFsYmVydE1vZGVsKGFsYmVydF94eGxhcmdlX2NvbmZpZ3VyYXRpb24pJTBBJTBBJTIzJTIwQWNjZXNzaW5nJTIwdGhlJTIwbW9kZWwlMjBjb25maWd1cmF0aW9uJTBBY29uZmlndXJhdGlvbiUyMCUzRCUyMG1vZGVsLmNvbmZpZw==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AlbertConfig, AlbertModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Initializing an ALBERT-xxlarge style configuration</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>albert_xxlarge_configuration = AlbertConfig()

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Initializing an ALBERT-base style configuration</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>albert_base_configuration = AlbertConfig(
<span class="hljs-meta">... </span>    hidden_size=<span class="hljs-number">768</span>,
<span class="hljs-meta">... </span>    num_attention_heads=<span class="hljs-number">12</span>,
<span class="hljs-meta">... </span>    intermediate_size=<span class="hljs-number">3072</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Initializing a model (with random weights) from the ALBERT-base style configuration</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AlbertModel(albert_xxlarge_configuration)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Accessing the model configuration</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>configuration = model.config`,wrap:!1}}),{c(){s=l("p"),s.textContent=T,i=r(),p(y.$$.fragment)},l(b){s=d(b,"P",{"data-svelte-h":!0}),_(s)!=="svelte-kvfsh7"&&(s.textContent=T),i=a(b),m(y.$$.fragment,b)},m(b,c){n(b,s,c),n(b,i,c),u(y,b,c),M=!0},p:Re,i(b){M||(f(y.$$.fragment,b),M=!0)},o(b){h(y.$$.fragment,b),M=!1},d(b){b&&(o(s),o(i)),g(y,b)}}}function nn($){let s,T=`Although the recipe for forward pass needs to be defined within this function, one should call the <code>Module</code>
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`;return{c(){s=l("p"),s.innerHTML=T},l(i){s=d(i,"P",{"data-svelte-h":!0}),_(s)!=="svelte-fincs2"&&(s.innerHTML=T)},m(i,y){n(i,s,y)},p:Re,d(i){i&&o(s)}}}function sn($){let s,T="Example:",i,y,M;return y=new Oe({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMkMlMjBBbGJlcnRGb3JNdWx0aXBsZUNob2ljZSUwQWltcG9ydCUyMHRvcmNoJTBBJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQoJTIyYWxiZXJ0JTJGYWxiZXJ0LXh4bGFyZ2UtdjIlMjIpJTBBbW9kZWwlMjAlM0QlMjBBbGJlcnRGb3JNdWx0aXBsZUNob2ljZS5mcm9tX3ByZXRyYWluZWQoJTIyYWxiZXJ0JTJGYWxiZXJ0LXh4bGFyZ2UtdjIlMjIpJTBBJTBBcHJvbXB0JTIwJTNEJTIwJTIySW4lMjBJdGFseSUyQyUyMHBpenphJTIwc2VydmVkJTIwaW4lMjBmb3JtYWwlMjBzZXR0aW5ncyUyQyUyMHN1Y2glMjBhcyUyMGF0JTIwYSUyMHJlc3RhdXJhbnQlMkMlMjBpcyUyMHByZXNlbnRlZCUyMHVuc2xpY2VkLiUyMiUwQWNob2ljZTAlMjAlM0QlMjAlMjJJdCUyMGlzJTIwZWF0ZW4lMjB3aXRoJTIwYSUyMGZvcmslMjBhbmQlMjBhJTIwa25pZmUuJTIyJTBBY2hvaWNlMSUyMCUzRCUyMCUyMkl0JTIwaXMlMjBlYXRlbiUyMHdoaWxlJTIwaGVsZCUyMGluJTIwdGhlJTIwaGFuZC4lMjIlMEFsYWJlbHMlMjAlM0QlMjB0b3JjaC50ZW5zb3IoMCkudW5zcXVlZXplKDApJTIwJTIwJTIzJTIwY2hvaWNlMCUyMGlzJTIwY29ycmVjdCUyMChhY2NvcmRpbmclMjB0byUyMFdpa2lwZWRpYSUyMCUzQikpJTJDJTIwYmF0Y2glMjBzaXplJTIwMSUwQSUwQWVuY29kaW5nJTIwJTNEJTIwdG9rZW5pemVyKCU1QnByb21wdCUyQyUyMHByb21wdCU1RCUyQyUyMCU1QmNob2ljZTAlMkMlMjBjaG9pY2UxJTVEJTJDJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJwdCUyMiUyQyUyMHBhZGRpbmclM0RUcnVlKSUwQW91dHB1dHMlMjAlM0QlMjBtb2RlbCgqKiU3QmslM0ElMjB2LnVuc3F1ZWV6ZSgwKSUyMGZvciUyMGslMkMlMjB2JTIwaW4lMjBlbmNvZGluZy5pdGVtcygpJTdEJTJDJTIwbGFiZWxzJTNEbGFiZWxzKSUyMCUyMCUyMyUyMGJhdGNoJTIwc2l6ZSUyMGlzJTIwMSUwQSUwQSUyMyUyMHRoZSUyMGxpbmVhciUyMGNsYXNzaWZpZXIlMjBzdGlsbCUyMG5lZWRzJTIwdG8lMjBiZSUyMHRyYWluZWQlMEFsb3NzJTIwJTNEJTIwb3V0cHV0cy5sb3NzJTBBbG9naXRzJTIwJTNEJTIwb3V0cHV0cy5sb2dpdHM=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AlbertForMultipleChoice
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;albert/albert-xxlarge-v2&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AlbertForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;albert/albert-xxlarge-v2&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>prompt = <span class="hljs-string">&quot;In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>choice0 = <span class="hljs-string">&quot;It is eaten with a fork and a knife.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>choice1 = <span class="hljs-string">&quot;It is eaten while held in the hand.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>labels = torch.tensor(<span class="hljs-number">0</span>).unsqueeze(<span class="hljs-number">0</span>)  <span class="hljs-comment"># choice0 is correct (according to Wikipedia ;)), batch size 1</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>encoding = tokenizer([prompt, prompt], [choice0, choice1], return_tensors=<span class="hljs-string">&quot;pt&quot;</span>, padding=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**{k: v.unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> encoding.items()}, labels=labels)  <span class="hljs-comment"># batch size is 1</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># the linear classifier still needs to be trained</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>loss = outputs.loss
<span class="hljs-meta">&gt;&gt;&gt; </span>logits = outputs.logits`,wrap:!1}}),{c(){s=l("p"),s.textContent=T,i=r(),p(y.$$.fragment)},l(b){s=d(b,"P",{"data-svelte-h":!0}),_(s)!=="svelte-11lpom8"&&(s.textContent=T),i=a(b),m(y.$$.fragment,b)},m(b,c){n(b,s,c),n(b,i,c),u(y,b,c),M=!0},p:Re,i(b){M||(f(y.$$.fragment,b),M=!0)},o(b){h(y.$$.fragment,b),M=!1},d(b){b&&(o(s),o(i)),g(y,b)}}}function rn($){let s,T,i,y,M,b="<em>This model was released on 2019-09-26 and added to Hugging Face Transformers on 2020-11-16.</em>",c,k,Ye='<div class="flex flex-wrap space-x-1"><img alt="PyTorch" src="https://img.shields.io/badge/PyTorch-DE3412?style=flat&amp;logo=pytorch&amp;logoColor=white"/> <img alt="SDPA" src="https://img.shields.io/badge/SDPA-DE3412?style=flat&amp;logo=pytorch&amp;logoColor=white"/></div>',P,z,Ke,N,co='<a href="https://huggingface.co/papers/1909.11942" rel="nofollow">ALBERT</a> is designed to address memory limitations of scaling and training of <a href="./bert">BERT</a>. It adds two parameter reduction techniques. The first, factorized embedding parametrization, splits the larger vocabulary embedding matrix into two smaller matrices so you can grow the hidden size without adding a lot more parameters. The second, cross-layer parameter sharing, allows layer to share parameters which keeps the number of learnable parameters lower.',et,V,po="ALBERT was created to address problems like ‚Äî GPU/TPU memory limitations, longer training times, and unexpected model degradation in BERT. ALBERT uses two parameter-reduction techniques to lower memory consumption and increase the training speed of BERT:",tt,X,mo="<li><strong>Factorized embedding parameterization:</strong> The large vocabulary embedding matrix is decomposed into two smaller matrices, reducing memory consumption.</li> <li><strong>Cross-layer parameter sharing:</strong> Instead of learning separate parameters for each transformer layer, ALBERT shares parameters across layers, further reducing the number of learnable weights.</li>",ot,Q,uo="ALBERT uses absolute position embeddings (like BERT) so padding is applied at right. Size of embeddings is 128 While BERT uses 768. ALBERT can processes maximum 512 token at a time.",nt,Y,fo='You can find all the original ALBERT checkpoints under the <a href="https://huggingface.co/albert" rel="nofollow">ALBERT community</a> organization.',st,W,rt,D,ho='The example below demonstrates how to predict the <code>[MASK]</code> token with <a href="/docs/transformers/v4.56.2/en/main_classes/pipelines#transformers.Pipeline">Pipeline</a>, <a href="/docs/transformers/v4.56.2/en/model_doc/auto#transformers.AutoModel">AutoModel</a>, and from the command line.',at,R,it,O,lt,K,go="<li>Inputs should be padded on the right because BERT uses absolute position embeddings.</li> <li>The embedding size <code>E</code> is different from the hidden size <code>H</code> because the embeddings are context independent (one embedding vector represents one token) and the hidden states are context dependent (one hidden state represents a sequence of tokens). The embedding matrix is also larger because <code>V x E</code> where <code>V</code> is the vocabulary size. As a result, it‚Äôs more logical if <code>H &gt;&gt; E</code>. If <code>E &lt; H</code>, the model has less parameters.</li>",dt,ee,ct,te,bo="The resources provided in the following sections consist of a list of official Hugging Face and community (indicated by üåé) resources to help you get started with AlBERT. If you‚Äôre interested in submitting a resource to be included here, please feel free to open a Pull Request and we‚Äôll review it! The resource should ideally demonstrate something new instead of duplicating an existing resource.",pt,oe,mt,ne,_o='<li><p><code>AlbertForSequenceClassification</code> is supported by this <a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-classification" rel="nofollow">example script</a>.</p></li> <li><p>Check the <a href="../tasks/sequence_classification">Text classification task guide</a> on how to use the model.</p></li>',ut,se,ft,re,To='<li><p><code>AlbertForTokenClassification</code> is supported by this <a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/token-classification" rel="nofollow">example script</a>.</p></li> <li><p><a href="https://huggingface.co/course/chapter7/2?fw=pt" rel="nofollow">Token classification</a> chapter of the ü§ó Hugging Face Course.</p></li> <li><p>Check the <a href="../tasks/token_classification">Token classification task guide</a> on how to use the model.</p></li>',ht,ae,gt,ie,yo='<li><code>AlbertForMaskedLM</code> is supported by this <a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/language-modeling#robertabertdistilbert-and-masked-language-modeling" rel="nofollow">example script</a> and <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb" rel="nofollow">notebook</a>.</li> <li><a href="https://huggingface.co/course/chapter7/3?fw=pt" rel="nofollow">Masked language modeling</a> chapter of the ü§ó Hugging Face Course.</li> <li>Check the <a href="../tasks/masked_language_modeling">Masked language modeling task guide</a> on how to use the model.</li>',bt,le,_t,de,wo='<li><code>AlbertForQuestionAnswering</code> is supported by this <a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/question-answering" rel="nofollow">example script</a> and <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering.ipynb" rel="nofollow">notebook</a>.</li> <li><a href="https://huggingface.co/course/chapter7/7?fw=pt" rel="nofollow">Question answering</a> chapter of the ü§ó Hugging Face Course.</li> <li>Check the <a href="../tasks/question_answering">Question answering task guide</a> on how to use the model.</li>',Tt,ce,Mo="<strong>Multiple choice</strong>",yt,pe,ko='<li><a href="/docs/transformers/v4.56.2/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> is supported by this <a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/multiple-choice" rel="nofollow">example script</a> and <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb" rel="nofollow">notebook</a>.</li> <li>Check the <a href="../tasks/multiple_choice">Multiple choice task guide</a> on how to use the model.</li>',wt,me,Mt,J,ue,Vt,Ze,$o=`This is the configuration class to store the configuration of a <code>AlbertModel</code> or a <code>TFAlbertModel</code>. It is used
to instantiate an ALBERT model according to the specified arguments, defining the model architecture. Instantiating
a configuration with the defaults will yield a similar configuration to that of the ALBERT
<a href="https://huggingface.co/albert/albert-xxlarge-v2" rel="nofollow">albert/albert-xxlarge-v2</a> architecture.`,Xt,Le,vo=`Configuration objects inherit from <a href="/docs/transformers/v4.56.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a> and can be used to control the model outputs. Read the
documentation from <a href="/docs/transformers/v4.56.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a> for more information.`,Qt,Z,kt,fe,$t,he,Co="[[autodoc]] AlbertTokenizer - build_inputs_with_special_tokens - get_special_tokens_mask - create_token_type_ids_from_sequences - save_vocabulary",vt,ge,Ct,U,be,Yt,Ee,Jo=`Construct a ‚Äúfast‚Äù ALBERT tokenizer (backed by HuggingFace‚Äôs <em>tokenizers</em> library). Based on
<a href="https://huggingface.co/docs/tokenizers/python/latest/components.html?highlight=unigram#models" rel="nofollow">Unigram</a>. This
tokenizer inherits from <a href="/docs/transformers/v4.56.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast">PreTrainedTokenizerFast</a> which contains most of the main methods. Users should refer to
this superclass for more information regarding those methods`,Dt,F,_e,Ot,Ge,xo=`Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and
adding special tokens. An ALBERT sequence has the following format:`,Kt,He,Ao="<li>single sequence: <code>[CLS] X [SEP]</code></li> <li>pair of sequences: <code>[CLS] A [SEP] B [SEP]</code></li>",Jt,Te,xt,I,ye,eo,Se,Uo="Output type of <code>AlbertForPreTraining</code>.",At,we,Ut,Me,jo="[[autodoc]] AlbertModel - forward",jt,ke,zt,$e,zo="[[autodoc]] AlbertForPreTraining - forward",Ft,ve,It,Ce,Fo="[[autodoc]] AlbertForMaskedLM - forward",Bt,Je,qt,xe,Io="[[autodoc]] AlbertForSequenceClassification - forward",Wt,Ae,Rt,v,Ue,to,Pe,Bo=`The Albert Model with a multiple choice classification head on top (a linear layer on top of the pooled output and a
softmax) e.g. for RocStories/SWAG tasks.`,oo,Ne,qo=`This model inherits from <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel">PreTrainedModel</a>. Check the superclass documentation for the generic methods the
library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads
etc.)`,no,Ve,Wo=`This model is also a PyTorch <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module" rel="nofollow">torch.nn.Module</a> subclass.
Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage
and behavior.`,so,A,je,ro,Xe,Ro='The <a href="/docs/transformers/v4.56.2/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> forward method, overrides the <code>__call__</code> special method.',ao,L,io,E,Zt,ze,Lt,Fe,Zo="[[autodoc]] AlbertForTokenClassification - forward",Et,Ie,Gt,Be,Lo="[[autodoc]] AlbertForQuestionAnswering - forward",Ht,qe,St,De,Pt;return z=new C({props:{title:"ALBERT",local:"albert",headingTag:"h1"}}),W=new Eo({props:{warning:!1,$$slots:{default:[Do]},$$scope:{ctx:$}}}),R=new Yo({props:{id:"usage",options:["Pipeline","AutoModel","transformers CLI"],$$slots:{default:[tn]},$$scope:{ctx:$}}}),O=new C({props:{title:"Notes",local:"notes",headingTag:"h2"}}),ee=new C({props:{title:"Resources",local:"resources",headingTag:"h2"}}),oe=new Nt({props:{pipeline:"text-classification"}}),se=new Nt({props:{pipeline:"token-classification"}}),ae=new Nt({props:{pipeline:"fill-mask"}}),le=new Nt({props:{pipeline:"question-answering"}}),me=new C({props:{title:"AlbertConfig",local:"transformers.AlbertConfig",headingTag:"h2"}}),ue=new Qe({props:{name:"class transformers.AlbertConfig",anchor:"transformers.AlbertConfig",parameters:[{name:"vocab_size",val:" = 30000"},{name:"embedding_size",val:" = 128"},{name:"hidden_size",val:" = 4096"},{name:"num_hidden_layers",val:" = 12"},{name:"num_hidden_groups",val:" = 1"},{name:"num_attention_heads",val:" = 64"},{name:"intermediate_size",val:" = 16384"},{name:"inner_group_num",val:" = 1"},{name:"hidden_act",val:" = 'gelu_new'"},{name:"hidden_dropout_prob",val:" = 0"},{name:"attention_probs_dropout_prob",val:" = 0"},{name:"max_position_embeddings",val:" = 512"},{name:"type_vocab_size",val:" = 2"},{name:"initializer_range",val:" = 0.02"},{name:"layer_norm_eps",val:" = 1e-12"},{name:"classifier_dropout_prob",val:" = 0.1"},{name:"position_embedding_type",val:" = 'absolute'"},{name:"pad_token_id",val:" = 0"},{name:"bos_token_id",val:" = 2"},{name:"eos_token_id",val:" = 3"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AlbertConfig.vocab_size",description:`<strong>vocab_size</strong> (<code>int</code>, <em>optional</em>, defaults to 30000) &#x2014;
Vocabulary size of the ALBERT model. Defines the number of different tokens that can be represented by the
<code>inputs_ids</code> passed when calling <code>AlbertModel</code> or <code>TFAlbertModel</code>.`,name:"vocab_size"},{anchor:"transformers.AlbertConfig.embedding_size",description:`<strong>embedding_size</strong> (<code>int</code>, <em>optional</em>, defaults to 128) &#x2014;
Dimensionality of vocabulary embeddings.`,name:"embedding_size"},{anchor:"transformers.AlbertConfig.hidden_size",description:`<strong>hidden_size</strong> (<code>int</code>, <em>optional</em>, defaults to 4096) &#x2014;
Dimensionality of the encoder layers and the pooler layer.`,name:"hidden_size"},{anchor:"transformers.AlbertConfig.num_hidden_layers",description:`<strong>num_hidden_layers</strong> (<code>int</code>, <em>optional</em>, defaults to 12) &#x2014;
Number of hidden layers in the Transformer encoder.`,name:"num_hidden_layers"},{anchor:"transformers.AlbertConfig.num_hidden_groups",description:`<strong>num_hidden_groups</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
Number of groups for the hidden layers, parameters in the same group are shared.`,name:"num_hidden_groups"},{anchor:"transformers.AlbertConfig.num_attention_heads",description:`<strong>num_attention_heads</strong> (<code>int</code>, <em>optional</em>, defaults to 64) &#x2014;
Number of attention heads for each attention layer in the Transformer encoder.`,name:"num_attention_heads"},{anchor:"transformers.AlbertConfig.intermediate_size",description:`<strong>intermediate_size</strong> (<code>int</code>, <em>optional</em>, defaults to 16384) &#x2014;
The dimensionality of the &#x201C;intermediate&#x201D; (often named feed-forward) layer in the Transformer encoder.`,name:"intermediate_size"},{anchor:"transformers.AlbertConfig.inner_group_num",description:`<strong>inner_group_num</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
The number of inner repetition of attention and ffn.`,name:"inner_group_num"},{anchor:"transformers.AlbertConfig.hidden_act",description:`<strong>hidden_act</strong> (<code>str</code> or <code>Callable</code>, <em>optional</em>, defaults to <code>&quot;gelu_new&quot;</code>) &#x2014;
The non-linear activation function (function or string) in the encoder and pooler. If string, <code>&quot;gelu&quot;</code>,
<code>&quot;relu&quot;</code>, <code>&quot;silu&quot;</code> and <code>&quot;gelu_new&quot;</code> are supported.`,name:"hidden_act"},{anchor:"transformers.AlbertConfig.hidden_dropout_prob",description:`<strong>hidden_dropout_prob</strong> (<code>float</code>, <em>optional</em>, defaults to 0) &#x2014;
The dropout probability for all fully connected layers in the embeddings, encoder, and pooler.`,name:"hidden_dropout_prob"},{anchor:"transformers.AlbertConfig.attention_probs_dropout_prob",description:`<strong>attention_probs_dropout_prob</strong> (<code>float</code>, <em>optional</em>, defaults to 0) &#x2014;
The dropout ratio for the attention probabilities.`,name:"attention_probs_dropout_prob"},{anchor:"transformers.AlbertConfig.max_position_embeddings",description:`<strong>max_position_embeddings</strong> (<code>int</code>, <em>optional</em>, defaults to 512) &#x2014;
The maximum sequence length that this model might ever be used with. Typically set this to something large
(e.g., 512 or 1024 or 2048).`,name:"max_position_embeddings"},{anchor:"transformers.AlbertConfig.type_vocab_size",description:`<strong>type_vocab_size</strong> (<code>int</code>, <em>optional</em>, defaults to 2) &#x2014;
The vocabulary size of the <code>token_type_ids</code> passed when calling <code>AlbertModel</code> or <code>TFAlbertModel</code>.`,name:"type_vocab_size"},{anchor:"transformers.AlbertConfig.initializer_range",description:`<strong>initializer_range</strong> (<code>float</code>, <em>optional</em>, defaults to 0.02) &#x2014;
The standard deviation of the truncated_normal_initializer for initializing all weight matrices.`,name:"initializer_range"},{anchor:"transformers.AlbertConfig.layer_norm_eps",description:`<strong>layer_norm_eps</strong> (<code>float</code>, <em>optional</em>, defaults to 1e-12) &#x2014;
The epsilon used by the layer normalization layers.`,name:"layer_norm_eps"},{anchor:"transformers.AlbertConfig.classifier_dropout_prob",description:`<strong>classifier_dropout_prob</strong> (<code>float</code>, <em>optional</em>, defaults to 0.1) &#x2014;
The dropout ratio for attached classifiers.`,name:"classifier_dropout_prob"},{anchor:"transformers.AlbertConfig.position_embedding_type",description:`<strong>position_embedding_type</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;absolute&quot;</code>) &#x2014;
Type of position embedding. Choose one of <code>&quot;absolute&quot;</code>, <code>&quot;relative_key&quot;</code>, <code>&quot;relative_key_query&quot;</code>. For
positional embeddings use <code>&quot;absolute&quot;</code>. For more information on <code>&quot;relative_key&quot;</code>, please refer to
<a href="https://huggingface.co/papers/1803.02155" rel="nofollow">Self-Attention with Relative Position Representations (Shaw et al.)</a>.
For more information on <code>&quot;relative_key_query&quot;</code>, please refer to <em>Method 4</em> in <a href="https://huggingface.co/papers/2009.13658" rel="nofollow">Improve Transformer Models
with Better Relative Position Embeddings (Huang et al.)</a>.`,name:"position_embedding_type"},{anchor:"transformers.AlbertConfig.pad_token_id",description:`<strong>pad_token_id</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
Padding token id.`,name:"pad_token_id"},{anchor:"transformers.AlbertConfig.bos_token_id",description:`<strong>bos_token_id</strong> (<code>int</code>, <em>optional</em>, defaults to 2) &#x2014;
Beginning of stream token id.`,name:"bos_token_id"},{anchor:"transformers.AlbertConfig.eos_token_id",description:`<strong>eos_token_id</strong> (<code>int</code>, <em>optional</em>, defaults to 3) &#x2014;
End of stream token id.`,name:"eos_token_id"}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/models/albert/configuration_albert.py#L25"}}),Z=new Go({props:{anchor:"transformers.AlbertConfig.example",$$slots:{default:[on]},$$scope:{ctx:$}}}),fe=new C({props:{title:"AlbertTokenizer",local:"alberttokenizer",headingTag:"h2"}}),ge=new C({props:{title:"AlbertTokenizerFast",local:"transformers.AlbertTokenizerFast",headingTag:"h2"}}),be=new Qe({props:{name:"class transformers.AlbertTokenizerFast",anchor:"transformers.AlbertTokenizerFast",parameters:[{name:"vocab_file",val:" = None"},{name:"tokenizer_file",val:" = None"},{name:"do_lower_case",val:" = True"},{name:"remove_space",val:" = True"},{name:"keep_accents",val:" = False"},{name:"bos_token",val:" = '[CLS]'"},{name:"eos_token",val:" = '[SEP]'"},{name:"unk_token",val:" = '<unk>'"},{name:"sep_token",val:" = '[SEP]'"},{name:"pad_token",val:" = '<pad>'"},{name:"cls_token",val:" = '[CLS]'"},{name:"mask_token",val:" = '[MASK]'"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AlbertTokenizerFast.vocab_file",description:`<strong>vocab_file</strong> (<code>str</code>) &#x2014;
<a href="https://github.com/google/sentencepiece" rel="nofollow">SentencePiece</a> file (generally has a <em>.spm</em> extension) that
contains the vocabulary necessary to instantiate a tokenizer.`,name:"vocab_file"},{anchor:"transformers.AlbertTokenizerFast.do_lower_case",description:`<strong>do_lower_case</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to lowercase the input when tokenizing.`,name:"do_lower_case"},{anchor:"transformers.AlbertTokenizerFast.remove_space",description:`<strong>remove_space</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to strip the text when tokenizing (removing excess spaces before and after the string).`,name:"remove_space"},{anchor:"transformers.AlbertTokenizerFast.keep_accents",description:`<strong>keep_accents</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to keep accents when tokenizing.`,name:"keep_accents"},{anchor:"transformers.AlbertTokenizerFast.bos_token",description:`<strong>bos_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;[CLS]&quot;</code>) &#x2014;
The beginning of sequence token that was used during pretraining. Can be used a sequence classifier token.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>When building a sequence using special tokens, this is not the token that is used for the beginning of
sequence. The token used is the <code>cls_token</code>.</p>

					</div>`,name:"bos_token"},{anchor:"transformers.AlbertTokenizerFast.eos_token",description:`<strong>eos_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;[SEP]&quot;</code>) &#x2014;
The end of sequence token. .. note:: When building a sequence using special tokens, this is not the token
that is used for the end of sequence. The token used is the <code>sep_token</code>.`,name:"eos_token"},{anchor:"transformers.AlbertTokenizerFast.unk_token",description:`<strong>unk_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;unk&gt;&quot;</code>) &#x2014;
The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be this
token instead.`,name:"unk_token"},{anchor:"transformers.AlbertTokenizerFast.sep_token",description:`<strong>sep_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;[SEP]&quot;</code>) &#x2014;
The separator token, which is used when building a sequence from multiple sequences, e.g. two sequences for
sequence classification or for a text and a question for question answering. It is also used as the last
token of a sequence built with special tokens.`,name:"sep_token"},{anchor:"transformers.AlbertTokenizerFast.pad_token",description:`<strong>pad_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;pad&gt;&quot;</code>) &#x2014;
The token used for padding, for example when batching sequences of different lengths.`,name:"pad_token"},{anchor:"transformers.AlbertTokenizerFast.cls_token",description:`<strong>cls_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;[CLS]&quot;</code>) &#x2014;
The classifier token which is used when doing sequence classification (classification of the whole sequence
instead of per-token classification). It is the first token of the sequence when built with special tokens.`,name:"cls_token"},{anchor:"transformers.AlbertTokenizerFast.mask_token",description:`<strong>mask_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;[MASK]&quot;</code>) &#x2014;
The token used for masking values. This is the token used when training this model with masked language
modeling. This is the token which the model will try to predict.`,name:"mask_token"}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/models/albert/tokenization_albert_fast.py#L38"}}),_e=new Qe({props:{name:"build_inputs_with_special_tokens",anchor:"transformers.AlbertTokenizerFast.build_inputs_with_special_tokens",parameters:[{name:"token_ids_0",val:": list"},{name:"token_ids_1",val:": typing.Optional[list[int]] = None"}],parametersDescription:[{anchor:"transformers.AlbertTokenizerFast.build_inputs_with_special_tokens.token_ids_0",description:`<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014;
List of IDs to which the special tokens will be added`,name:"token_ids_0"},{anchor:"transformers.AlbertTokenizerFast.build_inputs_with_special_tokens.token_ids_1",description:`<strong>token_ids_1</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014;
Optional second list of IDs for sequence pairs.`,name:"token_ids_1"}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/models/albert/tokenization_albert_fast.py#L133",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>list of <a href="../glossary#input-ids">input IDs</a> with the appropriate special tokens.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>List[int]</code></p>
`}}),Te=new C({props:{title:"Albert specific outputs",local:"transformers.models.albert.modeling_albert.AlbertForPreTrainingOutput",headingTag:"h2"}}),ye=new Qe({props:{name:"class transformers.models.albert.modeling_albert.AlbertForPreTrainingOutput",anchor:"transformers.models.albert.modeling_albert.AlbertForPreTrainingOutput",parameters:[{name:"loss",val:": typing.Optional[torch.FloatTensor] = None"},{name:"prediction_logits",val:": typing.Optional[torch.FloatTensor] = None"},{name:"sop_logits",val:": typing.Optional[torch.FloatTensor] = None"},{name:"hidden_states",val:": typing.Optional[tuple[torch.FloatTensor]] = None"},{name:"attentions",val:": typing.Optional[tuple[torch.FloatTensor]] = None"}],parametersDescription:[{anchor:"transformers.models.albert.modeling_albert.AlbertForPreTrainingOutput.loss",description:`<strong>loss</strong> (<code>*optional*</code>, returned when <code>labels</code> is provided, <code>torch.FloatTensor</code> of shape <code>(1,)</code>) &#x2014;
Total loss as the sum of the masked language modeling loss and the next sequence prediction
(classification) loss.`,name:"loss"},{anchor:"transformers.models.albert.modeling_albert.AlbertForPreTrainingOutput.prediction_logits",description:`<strong>prediction_logits</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, config.vocab_size)</code>) &#x2014;
Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).`,name:"prediction_logits"},{anchor:"transformers.models.albert.modeling_albert.AlbertForPreTrainingOutput.sop_logits",description:`<strong>sop_logits</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, 2)</code>) &#x2014;
Prediction scores of the next sequence prediction (classification) head (scores of True/False continuation
before SoftMax).`,name:"sop_logits"},{anchor:"transformers.models.albert.modeling_albert.AlbertForPreTrainingOutput.hidden_states",description:`<strong>hidden_states</strong> (<code>tuple[torch.FloatTensor]</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings, if the model has an embedding layer, +
one for the output of each layer) of shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.`,name:"hidden_states"},{anchor:"transformers.models.albert.modeling_albert.AlbertForPreTrainingOutput.attentions",description:`<strong>attentions</strong> (<code>tuple[torch.FloatTensor]</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) &#x2014;
Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.`,name:"attentions"}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/models/albert/modeling_albert.py#L578"}}),we=new C({props:{title:"AlbertModel",local:"albertmodel",headingTag:"h2"}}),ke=new C({props:{title:"AlbertForPreTraining",local:"albertforpretraining",headingTag:"h2"}}),ve=new C({props:{title:"AlbertForMaskedLM",local:"albertformaskedlm",headingTag:"h2"}}),Je=new C({props:{title:"AlbertForSequenceClassification",local:"albertforsequenceclassification",headingTag:"h2"}}),Ae=new C({props:{title:"AlbertForMultipleChoice",local:"transformers.AlbertForMultipleChoice",headingTag:"h2"}}),Ue=new Qe({props:{name:"class transformers.AlbertForMultipleChoice",anchor:"transformers.AlbertForMultipleChoice",parameters:[{name:"config",val:": AlbertConfig"}],parametersDescription:[{anchor:"transformers.AlbertForMultipleChoice.config",description:`<strong>config</strong> (<a href="/docs/transformers/v4.56.2/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a>) &#x2014;
Model configuration class with all the parameters of the model. Initializing with a config file does not
load the weights associated with the model, only the configuration. Check out the
<a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/models/albert/modeling_albert.py#L1237"}}),je=new Qe({props:{name:"forward",anchor:"transformers.AlbertForMultipleChoice.forward",parameters:[{name:"input_ids",val:": typing.Optional[torch.LongTensor] = None"},{name:"attention_mask",val:": typing.Optional[torch.FloatTensor] = None"},{name:"token_type_ids",val:": typing.Optional[torch.LongTensor] = None"},{name:"position_ids",val:": typing.Optional[torch.LongTensor] = None"},{name:"head_mask",val:": typing.Optional[torch.FloatTensor] = None"},{name:"inputs_embeds",val:": typing.Optional[torch.FloatTensor] = None"},{name:"labels",val:": typing.Optional[torch.LongTensor] = None"},{name:"output_attentions",val:": typing.Optional[bool] = None"},{name:"output_hidden_states",val:": typing.Optional[bool] = None"},{name:"return_dict",val:": typing.Optional[bool] = None"}],parametersDescription:[{anchor:"transformers.AlbertForMultipleChoice.forward.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, num_choices, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.56.2/en/model_doc/auto#transformers.AutoTokenizer">AutoTokenizer</a>. See <a href="/docs/transformers/v4.56.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> and
<a href="/docs/transformers/v4.56.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">PreTrainedTokenizer.encode()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.AlbertForMultipleChoice.forward.attention_mask",description:`<strong>attention_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>) &#x2014;
Mask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:</p>
<ul>
<li>1 for tokens that are <strong>not masked</strong>,</li>
<li>0 for tokens that are <strong>masked</strong>.</li>
</ul>
<p><a href="../glossary#attention-mask">What are attention masks?</a>`,name:"attention_mask"},{anchor:"transformers.AlbertForMultipleChoice.forward.token_type_ids",description:`<strong>token_type_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, num_choices, sequence_length)</code>, <em>optional</em>) &#x2014;
Segment token indices to indicate first and second portions of the inputs. Indices are selected in <code>[0, 1]</code>:</p>
<ul>
<li>0 corresponds to a <em>sentence A</em> token,</li>
<li>1 corresponds to a <em>sentence B</em> token.</li>
</ul>
<p><a href="../glossary#token-type-ids">What are token type IDs?</a>`,name:"token_type_ids"},{anchor:"transformers.AlbertForMultipleChoice.forward.position_ids",description:`<strong>position_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, num_choices, sequence_length)</code>, <em>optional</em>) &#x2014;
Indices of positions of each input sequence tokens in the position embeddings. Selected in the range <code>[0, config.max_position_embeddings - 1]</code>.</p>
<p><a href="../glossary#position-ids">What are position IDs?</a>`,name:"position_ids"},{anchor:"transformers.AlbertForMultipleChoice.forward.head_mask",description:`<strong>head_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(num_heads,)</code> or <code>(num_layers, num_heads)</code>, <em>optional</em>) &#x2014;
Mask to nullify selected heads of the self-attention modules. Mask values selected in <code>[0, 1]</code>:</p>
<ul>
<li>1 indicates the head is <strong>not masked</strong>,</li>
<li>0 indicates the head is <strong>masked</strong>.</li>
</ul>`,name:"head_mask"},{anchor:"transformers.AlbertForMultipleChoice.forward.inputs_embeds",description:`<strong>inputs_embeds</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, num_choices, sequence_length, hidden_size)</code>, <em>optional</em>) &#x2014;
Optionally, instead of passing <code>input_ids</code> you can choose to directly pass an embedded representation. This
is useful if you want more control over how to convert <code>input_ids</code> indices into associated vectors than the
model&#x2019;s internal embedding lookup matrix.`,name:"inputs_embeds"},{anchor:"transformers.AlbertForMultipleChoice.forward.labels",description:`<strong>labels</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>) &#x2014;
Labels for computing the multiple choice classification loss. Indices should be in <code>[0, ..., num_choices-1]</code> where <em>num_choices</em> is the size of the second dimension of the input tensors. (see
<em>input_ids</em> above)`,name:"labels"},{anchor:"transformers.AlbertForMultipleChoice.forward.output_attentions",description:`<strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the attentions tensors of all attention layers. See <code>attentions</code> under returned
tensors for more detail.`,name:"output_attentions"},{anchor:"transformers.AlbertForMultipleChoice.forward.output_hidden_states",description:`<strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the hidden states of all layers. See <code>hidden_states</code> under returned tensors for
more detail.`,name:"output_hidden_states"},{anchor:"transformers.AlbertForMultipleChoice.forward.return_dict",description:`<strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return a <a href="/docs/transformers/v4.56.2/en/main_classes/output#transformers.utils.ModelOutput">ModelOutput</a> instead of a plain tuple.`,name:"return_dict"}],source:"https://github.com/huggingface/transformers/blob/v4.56.2/src/transformers/models/albert/modeling_albert.py#L1248",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>A <a
  href="/docs/transformers/v4.56.2/en/model_doc/albert#transformers.models.albert.modeling_albert.AlbertForPreTrainingOutput"
>transformers.models.albert.modeling_albert.AlbertForPreTrainingOutput</a> or a tuple of
<code>torch.FloatTensor</code> (if <code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various
elements depending on the configuration (<a
  href="/docs/transformers/v4.56.2/en/model_doc/albert#transformers.AlbertConfig"
>AlbertConfig</a>) and inputs.</p>
<ul>
<li>
<p><strong>loss</strong> (<code>*optional*</code>, returned when <code>labels</code> is provided, <code>torch.FloatTensor</code> of shape <code>(1,)</code>) ‚Äî Total loss as the sum of the masked language modeling loss and the next sequence prediction
(classification) loss.</p>
</li>
<li>
<p><strong>prediction_logits</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, config.vocab_size)</code>) ‚Äî Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).</p>
</li>
<li>
<p><strong>sop_logits</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, 2)</code>) ‚Äî Prediction scores of the next sequence prediction (classification) head (scores of True/False continuation
before SoftMax).</p>
</li>
<li>
<p><strong>hidden_states</strong> (<code>tuple[torch.FloatTensor]</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) ‚Äî Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings, if the model has an embedding layer, +
one for the output of each layer) of shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.</p>
</li>
<li>
<p><strong>attentions</strong> (<code>tuple[torch.FloatTensor]</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) ‚Äî Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.</p>
</li>
</ul>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><a
  href="/docs/transformers/v4.56.2/en/model_doc/albert#transformers.models.albert.modeling_albert.AlbertForPreTrainingOutput"
>transformers.models.albert.modeling_albert.AlbertForPreTrainingOutput</a> or <code>tuple(torch.FloatTensor)</code></p>
`}}),L=new Eo({props:{$$slots:{default:[nn]},$$scope:{ctx:$}}}),E=new Go({props:{anchor:"transformers.AlbertForMultipleChoice.forward.example",$$slots:{default:[sn]},$$scope:{ctx:$}}}),ze=new C({props:{title:"AlbertForTokenClassification",local:"albertfortokenclassification",headingTag:"h2"}}),Ie=new C({props:{title:"AlbertForQuestionAnswering",local:"albertforquestionanswering",headingTag:"h2"}}),qe=new Qo({props:{source:"https://github.com/huggingface/transformers/blob/main/docs/source/en/model_doc/albert.md"}}),{c(){s=l("meta"),T=r(),i=l("p"),y=r(),M=l("p"),M.innerHTML=b,c=r(),k=l("div"),k.innerHTML=Ye,P=r(),p(z.$$.fragment),Ke=r(),N=l("p"),N.innerHTML=co,et=r(),V=l("p"),V.textContent=po,tt=r(),X=l("ul"),X.innerHTML=mo,ot=r(),Q=l("p"),Q.textContent=uo,nt=r(),Y=l("p"),Y.innerHTML=fo,st=r(),p(W.$$.fragment),rt=r(),D=l("p"),D.innerHTML=ho,at=r(),p(R.$$.fragment),it=r(),p(O.$$.fragment),lt=r(),K=l("ul"),K.innerHTML=go,dt=r(),p(ee.$$.fragment),ct=r(),te=l("p"),te.textContent=bo,pt=r(),p(oe.$$.fragment),mt=r(),ne=l("ul"),ne.innerHTML=_o,ut=r(),p(se.$$.fragment),ft=r(),re=l("ul"),re.innerHTML=To,ht=r(),p(ae.$$.fragment),gt=r(),ie=l("ul"),ie.innerHTML=yo,bt=r(),p(le.$$.fragment),_t=r(),de=l("ul"),de.innerHTML=wo,Tt=r(),ce=l("p"),ce.innerHTML=Mo,yt=r(),pe=l("ul"),pe.innerHTML=ko,wt=r(),p(me.$$.fragment),Mt=r(),J=l("div"),p(ue.$$.fragment),Vt=r(),Ze=l("p"),Ze.innerHTML=$o,Xt=r(),Le=l("p"),Le.innerHTML=vo,Qt=r(),p(Z.$$.fragment),kt=r(),p(fe.$$.fragment),$t=r(),he=l("p"),he.textContent=Co,vt=r(),p(ge.$$.fragment),Ct=r(),U=l("div"),p(be.$$.fragment),Yt=r(),Ee=l("p"),Ee.innerHTML=Jo,Dt=r(),F=l("div"),p(_e.$$.fragment),Ot=r(),Ge=l("p"),Ge.textContent=xo,Kt=r(),He=l("ul"),He.innerHTML=Ao,Jt=r(),p(Te.$$.fragment),xt=r(),I=l("div"),p(ye.$$.fragment),eo=r(),Se=l("p"),Se.innerHTML=Uo,At=r(),p(we.$$.fragment),Ut=r(),Me=l("p"),Me.textContent=jo,jt=r(),p(ke.$$.fragment),zt=r(),$e=l("p"),$e.textContent=zo,Ft=r(),p(ve.$$.fragment),It=r(),Ce=l("p"),Ce.textContent=Fo,Bt=r(),p(Je.$$.fragment),qt=r(),xe=l("p"),xe.textContent=Io,Wt=r(),p(Ae.$$.fragment),Rt=r(),v=l("div"),p(Ue.$$.fragment),to=r(),Pe=l("p"),Pe.textContent=Bo,oo=r(),Ne=l("p"),Ne.innerHTML=qo,no=r(),Ve=l("p"),Ve.innerHTML=Wo,so=r(),A=l("div"),p(je.$$.fragment),ro=r(),Xe=l("p"),Xe.innerHTML=Ro,ao=r(),p(L.$$.fragment),io=r(),p(E.$$.fragment),Zt=r(),p(ze.$$.fragment),Lt=r(),Fe=l("p"),Fe.textContent=Zo,Et=r(),p(Ie.$$.fragment),Gt=r(),Be=l("p"),Be.textContent=Lo,Ht=r(),p(qe.$$.fragment),St=r(),De=l("p"),this.h()},l(e){const t=Vo("svelte-u9bgzb",document.head);s=d(t,"META",{name:!0,content:!0}),t.forEach(o),T=a(e),i=d(e,"P",{}),H(i).forEach(o),y=a(e),M=d(e,"P",{"data-svelte-h":!0}),_(M)!=="svelte-24eok0"&&(M.innerHTML=b),c=a(e),k=d(e,"DIV",{style:!0,"data-svelte-h":!0}),_(k)!=="svelte-ithiq1"&&(k.innerHTML=Ye),P=a(e),m(z.$$.fragment,e),Ke=a(e),N=d(e,"P",{"data-svelte-h":!0}),_(N)!=="svelte-rqkw99"&&(N.innerHTML=co),et=a(e),V=d(e,"P",{"data-svelte-h":!0}),_(V)!=="svelte-9f12d0"&&(V.textContent=po),tt=a(e),X=d(e,"UL",{"data-svelte-h":!0}),_(X)!=="svelte-1ykgtxs"&&(X.innerHTML=mo),ot=a(e),Q=d(e,"P",{"data-svelte-h":!0}),_(Q)!=="svelte-1uei9tf"&&(Q.textContent=uo),nt=a(e),Y=d(e,"P",{"data-svelte-h":!0}),_(Y)!=="svelte-1g7jweq"&&(Y.innerHTML=fo),st=a(e),m(W.$$.fragment,e),rt=a(e),D=d(e,"P",{"data-svelte-h":!0}),_(D)!=="svelte-lqa8w5"&&(D.innerHTML=ho),at=a(e),m(R.$$.fragment,e),it=a(e),m(O.$$.fragment,e),lt=a(e),K=d(e,"UL",{"data-svelte-h":!0}),_(K)!=="svelte-qx3pwm"&&(K.innerHTML=go),dt=a(e),m(ee.$$.fragment,e),ct=a(e),te=d(e,"P",{"data-svelte-h":!0}),_(te)!=="svelte-asr93v"&&(te.textContent=bo),pt=a(e),m(oe.$$.fragment,e),mt=a(e),ne=d(e,"UL",{"data-svelte-h":!0}),_(ne)!=="svelte-w2sx8g"&&(ne.innerHTML=_o),ut=a(e),m(se.$$.fragment,e),ft=a(e),re=d(e,"UL",{"data-svelte-h":!0}),_(re)!=="svelte-e7zq7n"&&(re.innerHTML=To),ht=a(e),m(ae.$$.fragment,e),gt=a(e),ie=d(e,"UL",{"data-svelte-h":!0}),_(ie)!=="svelte-2ibt7z"&&(ie.innerHTML=yo),bt=a(e),m(le.$$.fragment,e),_t=a(e),de=d(e,"UL",{"data-svelte-h":!0}),_(de)!=="svelte-jkzvpy"&&(de.innerHTML=wo),Tt=a(e),ce=d(e,"P",{"data-svelte-h":!0}),_(ce)!=="svelte-cplu6u"&&(ce.innerHTML=Mo),yt=a(e),pe=d(e,"UL",{"data-svelte-h":!0}),_(pe)!=="svelte-11ge52b"&&(pe.innerHTML=ko),wt=a(e),m(me.$$.fragment,e),Mt=a(e),J=d(e,"DIV",{class:!0});var j=H(J);m(ue.$$.fragment,j),Vt=a(j),Ze=d(j,"P",{"data-svelte-h":!0}),_(Ze)!=="svelte-fz1iqw"&&(Ze.innerHTML=$o),Xt=a(j),Le=d(j,"P",{"data-svelte-h":!0}),_(Le)!=="svelte-1ek1ss9"&&(Le.innerHTML=vo),Qt=a(j),m(Z.$$.fragment,j),j.forEach(o),kt=a(e),m(fe.$$.fragment,e),$t=a(e),he=d(e,"P",{"data-svelte-h":!0}),_(he)!=="svelte-xxecs8"&&(he.textContent=Co),vt=a(e),m(ge.$$.fragment,e),Ct=a(e),U=d(e,"DIV",{class:!0});var B=H(U);m(be.$$.fragment,B),Yt=a(B),Ee=d(B,"P",{"data-svelte-h":!0}),_(Ee)!=="svelte-173ttlp"&&(Ee.innerHTML=Jo),Dt=a(B),F=d(B,"DIV",{class:!0});var q=H(F);m(_e.$$.fragment,q),Ot=a(q),Ge=d(q,"P",{"data-svelte-h":!0}),_(Ge)!=="svelte-1bnx1ll"&&(Ge.textContent=xo),Kt=a(q),He=d(q,"UL",{"data-svelte-h":!0}),_(He)!=="svelte-xi6653"&&(He.innerHTML=Ao),q.forEach(o),B.forEach(o),Jt=a(e),m(Te.$$.fragment,e),xt=a(e),I=d(e,"DIV",{class:!0});var We=H(I);m(ye.$$.fragment,We),eo=a(We),Se=d(We,"P",{"data-svelte-h":!0}),_(Se)!=="svelte-z83gql"&&(Se.innerHTML=Uo),We.forEach(o),At=a(e),m(we.$$.fragment,e),Ut=a(e),Me=d(e,"P",{"data-svelte-h":!0}),_(Me)!=="svelte-ykigbm"&&(Me.textContent=jo),jt=a(e),m(ke.$$.fragment,e),zt=a(e),$e=d(e,"P",{"data-svelte-h":!0}),_($e)!=="svelte-1r4jm1x"&&($e.textContent=zo),Ft=a(e),m(ve.$$.fragment,e),It=a(e),Ce=d(e,"P",{"data-svelte-h":!0}),_(Ce)!=="svelte-wffnyu"&&(Ce.textContent=Fo),Bt=a(e),m(Je.$$.fragment,e),qt=a(e),xe=d(e,"P",{"data-svelte-h":!0}),_(xe)!=="svelte-1fv7dn1"&&(xe.textContent=Io),Wt=a(e),m(Ae.$$.fragment,e),Rt=a(e),v=d(e,"DIV",{class:!0});var x=H(v);m(Ue.$$.fragment,x),to=a(x),Pe=d(x,"P",{"data-svelte-h":!0}),_(Pe)!=="svelte-1chpzf3"&&(Pe.textContent=Bo),oo=a(x),Ne=d(x,"P",{"data-svelte-h":!0}),_(Ne)!=="svelte-q52n56"&&(Ne.innerHTML=qo),no=a(x),Ve=d(x,"P",{"data-svelte-h":!0}),_(Ve)!=="svelte-hswkmf"&&(Ve.innerHTML=Wo),so=a(x),A=d(x,"DIV",{class:!0});var G=H(A);m(je.$$.fragment,G),ro=a(G),Xe=d(G,"P",{"data-svelte-h":!0}),_(Xe)!=="svelte-1ct09sl"&&(Xe.innerHTML=Ro),ao=a(G),m(L.$$.fragment,G),io=a(G),m(E.$$.fragment,G),G.forEach(o),x.forEach(o),Zt=a(e),m(ze.$$.fragment,e),Lt=a(e),Fe=d(e,"P",{"data-svelte-h":!0}),_(Fe)!=="svelte-tzi4vv"&&(Fe.textContent=Zo),Et=a(e),m(Ie.$$.fragment,e),Gt=a(e),Be=d(e,"P",{"data-svelte-h":!0}),_(Be)!=="svelte-1hwl95y"&&(Be.textContent=Lo),Ht=a(e),m(qe.$$.fragment,e),St=a(e),De=d(e,"P",{}),H(De).forEach(o),this.h()},h(){S(s,"name","hf:doc:metadata"),S(s,"content",an),Xo(k,"float","right"),S(J,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),S(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),S(U,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),S(I,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),S(A,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),S(v,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,t){w(document.head,s),n(e,T,t),n(e,i,t),n(e,y,t),n(e,M,t),n(e,c,t),n(e,k,t),n(e,P,t),u(z,e,t),n(e,Ke,t),n(e,N,t),n(e,et,t),n(e,V,t),n(e,tt,t),n(e,X,t),n(e,ot,t),n(e,Q,t),n(e,nt,t),n(e,Y,t),n(e,st,t),u(W,e,t),n(e,rt,t),n(e,D,t),n(e,at,t),u(R,e,t),n(e,it,t),u(O,e,t),n(e,lt,t),n(e,K,t),n(e,dt,t),u(ee,e,t),n(e,ct,t),n(e,te,t),n(e,pt,t),u(oe,e,t),n(e,mt,t),n(e,ne,t),n(e,ut,t),u(se,e,t),n(e,ft,t),n(e,re,t),n(e,ht,t),u(ae,e,t),n(e,gt,t),n(e,ie,t),n(e,bt,t),u(le,e,t),n(e,_t,t),n(e,de,t),n(e,Tt,t),n(e,ce,t),n(e,yt,t),n(e,pe,t),n(e,wt,t),u(me,e,t),n(e,Mt,t),n(e,J,t),u(ue,J,null),w(J,Vt),w(J,Ze),w(J,Xt),w(J,Le),w(J,Qt),u(Z,J,null),n(e,kt,t),u(fe,e,t),n(e,$t,t),n(e,he,t),n(e,vt,t),u(ge,e,t),n(e,Ct,t),n(e,U,t),u(be,U,null),w(U,Yt),w(U,Ee),w(U,Dt),w(U,F),u(_e,F,null),w(F,Ot),w(F,Ge),w(F,Kt),w(F,He),n(e,Jt,t),u(Te,e,t),n(e,xt,t),n(e,I,t),u(ye,I,null),w(I,eo),w(I,Se),n(e,At,t),u(we,e,t),n(e,Ut,t),n(e,Me,t),n(e,jt,t),u(ke,e,t),n(e,zt,t),n(e,$e,t),n(e,Ft,t),u(ve,e,t),n(e,It,t),n(e,Ce,t),n(e,Bt,t),u(Je,e,t),n(e,qt,t),n(e,xe,t),n(e,Wt,t),u(Ae,e,t),n(e,Rt,t),n(e,v,t),u(Ue,v,null),w(v,to),w(v,Pe),w(v,oo),w(v,Ne),w(v,no),w(v,Ve),w(v,so),w(v,A),u(je,A,null),w(A,ro),w(A,Xe),w(A,ao),u(L,A,null),w(A,io),u(E,A,null),n(e,Zt,t),u(ze,e,t),n(e,Lt,t),n(e,Fe,t),n(e,Et,t),u(Ie,e,t),n(e,Gt,t),n(e,Be,t),n(e,Ht,t),u(qe,e,t),n(e,St,t),n(e,De,t),Pt=!0},p(e,[t]){const j={};t&2&&(j.$$scope={dirty:t,ctx:e}),W.$set(j);const B={};t&2&&(B.$$scope={dirty:t,ctx:e}),R.$set(B);const q={};t&2&&(q.$$scope={dirty:t,ctx:e}),Z.$set(q);const We={};t&2&&(We.$$scope={dirty:t,ctx:e}),L.$set(We);const x={};t&2&&(x.$$scope={dirty:t,ctx:e}),E.$set(x)},i(e){Pt||(f(z.$$.fragment,e),f(W.$$.fragment,e),f(R.$$.fragment,e),f(O.$$.fragment,e),f(ee.$$.fragment,e),f(oe.$$.fragment,e),f(se.$$.fragment,e),f(ae.$$.fragment,e),f(le.$$.fragment,e),f(me.$$.fragment,e),f(ue.$$.fragment,e),f(Z.$$.fragment,e),f(fe.$$.fragment,e),f(ge.$$.fragment,e),f(be.$$.fragment,e),f(_e.$$.fragment,e),f(Te.$$.fragment,e),f(ye.$$.fragment,e),f(we.$$.fragment,e),f(ke.$$.fragment,e),f(ve.$$.fragment,e),f(Je.$$.fragment,e),f(Ae.$$.fragment,e),f(Ue.$$.fragment,e),f(je.$$.fragment,e),f(L.$$.fragment,e),f(E.$$.fragment,e),f(ze.$$.fragment,e),f(Ie.$$.fragment,e),f(qe.$$.fragment,e),Pt=!0)},o(e){h(z.$$.fragment,e),h(W.$$.fragment,e),h(R.$$.fragment,e),h(O.$$.fragment,e),h(ee.$$.fragment,e),h(oe.$$.fragment,e),h(se.$$.fragment,e),h(ae.$$.fragment,e),h(le.$$.fragment,e),h(me.$$.fragment,e),h(ue.$$.fragment,e),h(Z.$$.fragment,e),h(fe.$$.fragment,e),h(ge.$$.fragment,e),h(be.$$.fragment,e),h(_e.$$.fragment,e),h(Te.$$.fragment,e),h(ye.$$.fragment,e),h(we.$$.fragment,e),h(ke.$$.fragment,e),h(ve.$$.fragment,e),h(Je.$$.fragment,e),h(Ae.$$.fragment,e),h(Ue.$$.fragment,e),h(je.$$.fragment,e),h(L.$$.fragment,e),h(E.$$.fragment,e),h(ze.$$.fragment,e),h(Ie.$$.fragment,e),h(qe.$$.fragment,e),Pt=!1},d(e){e&&(o(T),o(i),o(y),o(M),o(c),o(k),o(P),o(Ke),o(N),o(et),o(V),o(tt),o(X),o(ot),o(Q),o(nt),o(Y),o(st),o(rt),o(D),o(at),o(it),o(lt),o(K),o(dt),o(ct),o(te),o(pt),o(mt),o(ne),o(ut),o(ft),o(re),o(ht),o(gt),o(ie),o(bt),o(_t),o(de),o(Tt),o(ce),o(yt),o(pe),o(wt),o(Mt),o(J),o(kt),o($t),o(he),o(vt),o(Ct),o(U),o(Jt),o(xt),o(I),o(At),o(Ut),o(Me),o(jt),o(zt),o($e),o(Ft),o(It),o(Ce),o(Bt),o(qt),o(xe),o(Wt),o(Rt),o(v),o(Zt),o(Lt),o(Fe),o(Et),o(Gt),o(Be),o(Ht),o(St),o(De)),o(s),g(z,e),g(W,e),g(R,e),g(O,e),g(ee,e),g(oe,e),g(se,e),g(ae,e),g(le,e),g(me,e),g(ue),g(Z),g(fe,e),g(ge,e),g(be),g(_e),g(Te,e),g(ye),g(we,e),g(ke,e),g(ve,e),g(Je,e),g(Ae,e),g(Ue),g(je),g(L),g(E),g(ze,e),g(Ie,e),g(qe,e)}}}const an='{"title":"ALBERT","local":"albert","sections":[{"title":"Notes","local":"notes","sections":[],"depth":2},{"title":"Resources","local":"resources","sections":[],"depth":2},{"title":"AlbertConfig","local":"transformers.AlbertConfig","sections":[],"depth":2},{"title":"AlbertTokenizer","local":"alberttokenizer","sections":[],"depth":2},{"title":"AlbertTokenizerFast","local":"transformers.AlbertTokenizerFast","sections":[],"depth":2},{"title":"Albert specific outputs","local":"transformers.models.albert.modeling_albert.AlbertForPreTrainingOutput","sections":[],"depth":2},{"title":"AlbertModel","local":"albertmodel","sections":[],"depth":2},{"title":"AlbertForPreTraining","local":"albertforpretraining","sections":[],"depth":2},{"title":"AlbertForMaskedLM","local":"albertformaskedlm","sections":[],"depth":2},{"title":"AlbertForSequenceClassification","local":"albertforsequenceclassification","sections":[],"depth":2},{"title":"AlbertForMultipleChoice","local":"transformers.AlbertForMultipleChoice","sections":[],"depth":2},{"title":"AlbertForTokenClassification","local":"albertfortokenclassification","sections":[],"depth":2},{"title":"AlbertForQuestionAnswering","local":"albertforquestionanswering","sections":[],"depth":2}],"depth":1}';function ln($){return So(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class _n extends Po{constructor(s){super(),No(this,s,ln,rn,Ho,{})}}export{_n as component};
