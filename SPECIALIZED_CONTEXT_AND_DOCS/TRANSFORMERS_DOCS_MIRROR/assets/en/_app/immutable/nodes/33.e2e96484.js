import{s as xe,o as Te,n as _e}from"../chunks/scheduler.18a86fab.js";import{S as be,i as ye,g as o,s as a,r as E,A as Le,h as l,f as n,c as r,j as we,u as F,x as m,k as ae,y as He,a as i,v as S,d as z,t as A,w as j}from"../chunks/index.98837b22.js";import{T as Me}from"../chunks/Tip.77304350.js";import{H as re,E as Pe}from"../chunks/getInferenceSnippets.06c2775f.js";function Ce(I){let s,c='Read our <a href="./philosophy">Philosophy</a> to learn more about Transformers’ design principles.';return{c(){s=o("p"),s.innerHTML=c},l(f){s=l(f,"P",{"data-svelte-h":!0}),m(s)!=="svelte-u3vi8l"&&(s.innerHTML=c)},m(f,k){i(f,s,k)},p:_e,d(f){f&&n(s)}}}function ke(I){let s,c,f,k,h,q,p,se='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/transformers_as_a_model_definition.png"/>',G,g,oe=`Transformers acts as the model-definition framework for state-of-the-art machine learning models in text, computer
vision, audio, video, and multimodal model, for both inference and training.`,R,$,le=`It centralizes the model definition so that this definition is agreed upon across the ecosystem. <code>transformers</code> is the
pivot across frameworks: if a model definition is supported, it will be compatible with the majority of training
frameworks (Axolotl, Unsloth, DeepSpeed, FSDP, PyTorch-Lightning, …), inference engines (vLLM, SGLang, TGI, …),
and adjacent modeling libraries (llama.cpp, mlx, …) which leverage the model definition from <code>transformers</code>.`,U,v,me=`We pledge to help support new state-of-the-art models and democratize their usage by having their model definition be
simple, customizable, and efficient.`,O,w,fe='There are over 1M+ Transformers <a href="https://huggingface.co/models?library=transformers&amp;sort=trending" rel="nofollow">model checkpoints</a> on the <a href="https://huggingface.com/models" rel="nofollow">Hugging Face Hub</a> you can use.',V,x,pe='Explore the <a href="https://huggingface.com/" rel="nofollow">Hub</a> today to find a model and use Transformers to help you get started right away.',W,T,Y,_,de="Transformers provides everything you need for inference or training with state-of-the-art pretrained models. Some of the main features include:",B,b,ue='<li><a href="./pipeline_tutorial">Pipeline</a>: Simple and optimized inference class for many machine learning tasks like text generation, image segmentation, automatic speech recognition, document question answering, and more.</li> <li><a href="./trainer">Trainer</a>: A comprehensive trainer that supports features such as mixed precision, torch.compile, and FlashAttention for training and distributed training for PyTorch models.</li> <li><a href="./llm_tutorial">generate</a>: Fast text generation with large language models (LLMs) and vision language models (VLMs), including support for streaming and multiple decoding strategies.</li>',J,y,K,d,N,L,ce="Transformers is designed for developers and machine learning engineers and researchers. Its main design principles are:",Q,H,he='<li>Fast and easy to use: Every model is implemented from only three main classes (configuration, model, and preprocessor) and can be quickly used for inference or training with <a href="/docs/transformers/v4.56.2/en/main_classes/pipelines#transformers.Pipeline">Pipeline</a> or <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a>.</li> <li>Pretrained models: Reduce your carbon footprint, compute cost and time by using a pretrained model instead of training an entirely new one. Each pretrained model is reproduced as closely as possible to the original model and offers state-of-the-art performance.</li>',X,u,ge='<a target="_blank" href="https://huggingface.co/support"><img alt="HuggingFace Expert Acceleration Program" src="https://hf.co/datasets/huggingface/documentation-images/resolve/81d7d9201fd4ceb537fc4cebc22c29c37a2ed216/transformers/transformers-index.png" style="width: 100%; max-width: 600px; border: 1px solid #eee; border-radius: 4px; box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05);"/></a>',Z,M,ee,P,$e='If you’re new to Transformers or want to learn more about transformer models, we recommend starting with the <a href="https://huggingface.co/learn/llm-course/chapter1/1?fw=pt" rel="nofollow">LLM course</a>. This comprehensive course covers everything from the fundamentals of how transformer models work to practical applications across various tasks. You’ll learn the complete workflow, from curating high-quality datasets to fine-tuning large language models and implementing reasoning capabilities. The course contains both theoretical and hands-on exercises to build a solid foundational knowledge of transformer models as you learn.',te,C,ne,D,ie;return h=new re({props:{title:"Transformers",local:"transformers",headingTag:"h1"}}),T=new re({props:{title:"Features",local:"features",headingTag:"h2"}}),y=new re({props:{title:"Design",local:"design",headingTag:"h2"}}),d=new Me({props:{warning:!1,$$slots:{default:[Ce]},$$scope:{ctx:I}}}),M=new re({props:{title:"Learn",local:"learn",headingTag:"h2"}}),C=new Pe({props:{source:"https://github.com/huggingface/transformers/blob/main/docs/source/en/index.md"}}),{c(){s=o("meta"),c=a(),f=o("p"),k=a(),E(h.$$.fragment),q=a(),p=o("h3"),p.innerHTML=se,G=a(),g=o("p"),g.textContent=oe,R=a(),$=o("p"),$.innerHTML=le,U=a(),v=o("p"),v.textContent=me,O=a(),w=o("p"),w.innerHTML=fe,V=a(),x=o("p"),x.innerHTML=pe,W=a(),E(T.$$.fragment),Y=a(),_=o("p"),_.textContent=de,B=a(),b=o("ul"),b.innerHTML=ue,J=a(),E(y.$$.fragment),K=a(),E(d.$$.fragment),N=a(),L=o("p"),L.textContent=ce,Q=a(),H=o("ol"),H.innerHTML=he,X=a(),u=o("div"),u.innerHTML=ge,Z=a(),E(M.$$.fragment),ee=a(),P=o("p"),P.innerHTML=$e,te=a(),E(C.$$.fragment),ne=a(),D=o("p"),this.h()},l(e){const t=Le("svelte-u9bgzb",document.head);s=l(t,"META",{name:!0,content:!0}),t.forEach(n),c=r(e),f=l(e,"P",{}),we(f).forEach(n),k=r(e),F(h.$$.fragment,e),q=r(e),p=l(e,"H3",{align:!0,"data-svelte-h":!0}),m(p)!=="svelte-1nlupxk"&&(p.innerHTML=se),G=r(e),g=l(e,"P",{"data-svelte-h":!0}),m(g)!=="svelte-1trv972"&&(g.textContent=oe),R=r(e),$=l(e,"P",{"data-svelte-h":!0}),m($)!=="svelte-6u7em8"&&($.innerHTML=le),U=r(e),v=l(e,"P",{"data-svelte-h":!0}),m(v)!=="svelte-fnb0vj"&&(v.textContent=me),O=r(e),w=l(e,"P",{"data-svelte-h":!0}),m(w)!=="svelte-1ls1544"&&(w.innerHTML=fe),V=r(e),x=l(e,"P",{"data-svelte-h":!0}),m(x)!=="svelte-mgweem"&&(x.innerHTML=pe),W=r(e),F(T.$$.fragment,e),Y=r(e),_=l(e,"P",{"data-svelte-h":!0}),m(_)!=="svelte-mkwxsu"&&(_.textContent=de),B=r(e),b=l(e,"UL",{"data-svelte-h":!0}),m(b)!=="svelte-dgmznb"&&(b.innerHTML=ue),J=r(e),F(y.$$.fragment,e),K=r(e),F(d.$$.fragment,e),N=r(e),L=l(e,"P",{"data-svelte-h":!0}),m(L)!=="svelte-1w46htb"&&(L.textContent=ce),Q=r(e),H=l(e,"OL",{"data-svelte-h":!0}),m(H)!=="svelte-1k4zrch"&&(H.innerHTML=he),X=r(e),u=l(e,"DIV",{class:!0,"data-svelte-h":!0}),m(u)!=="svelte-1tufcem"&&(u.innerHTML=ge),Z=r(e),F(M.$$.fragment,e),ee=r(e),P=l(e,"P",{"data-svelte-h":!0}),m(P)!=="svelte-hpc4yw"&&(P.innerHTML=$e),te=r(e),F(C.$$.fragment,e),ne=r(e),D=l(e,"P",{}),we(D).forEach(n),this.h()},h(){ae(s,"name","hf:doc:metadata"),ae(s,"content",Ee),ae(p,"align","center"),ae(u,"class","flex justify-center")},m(e,t){He(document.head,s),i(e,c,t),i(e,f,t),i(e,k,t),S(h,e,t),i(e,q,t),i(e,p,t),i(e,G,t),i(e,g,t),i(e,R,t),i(e,$,t),i(e,U,t),i(e,v,t),i(e,O,t),i(e,w,t),i(e,V,t),i(e,x,t),i(e,W,t),S(T,e,t),i(e,Y,t),i(e,_,t),i(e,B,t),i(e,b,t),i(e,J,t),S(y,e,t),i(e,K,t),S(d,e,t),i(e,N,t),i(e,L,t),i(e,Q,t),i(e,H,t),i(e,X,t),i(e,u,t),i(e,Z,t),S(M,e,t),i(e,ee,t),i(e,P,t),i(e,te,t),S(C,e,t),i(e,ne,t),i(e,D,t),ie=!0},p(e,[t]){const ve={};t&2&&(ve.$$scope={dirty:t,ctx:e}),d.$set(ve)},i(e){ie||(z(h.$$.fragment,e),z(T.$$.fragment,e),z(y.$$.fragment,e),z(d.$$.fragment,e),z(M.$$.fragment,e),z(C.$$.fragment,e),ie=!0)},o(e){A(h.$$.fragment,e),A(T.$$.fragment,e),A(y.$$.fragment,e),A(d.$$.fragment,e),A(M.$$.fragment,e),A(C.$$.fragment,e),ie=!1},d(e){e&&(n(c),n(f),n(k),n(q),n(p),n(G),n(g),n(R),n($),n(U),n(v),n(O),n(w),n(V),n(x),n(W),n(Y),n(_),n(B),n(b),n(J),n(K),n(N),n(L),n(Q),n(H),n(X),n(u),n(Z),n(ee),n(P),n(te),n(ne),n(D)),n(s),j(h,e),j(T,e),j(y,e),j(d,e),j(M,e),j(C,e)}}}const Ee='{"title":"Transformers","local":"transformers","sections":[{"title":"Features","local":"features","sections":[],"depth":2},{"title":"Design","local":"design","sections":[],"depth":2},{"title":"Learn","local":"learn","sections":[],"depth":2}],"depth":1}';function Fe(I){return Te(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class De extends be{constructor(s){super(),ye(this,s,Fe,ke,xe,{})}}export{De as component};
