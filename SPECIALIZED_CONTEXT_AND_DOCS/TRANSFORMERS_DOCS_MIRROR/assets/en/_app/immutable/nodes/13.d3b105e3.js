import{s as it,o as rt,n as Ns}from"../chunks/scheduler.18a86fab.js";import{S as yt,i as Jt,g as T,s as M,r as m,A as Tt,h as c,f as l,c as p,j as Mt,u as d,x as I,k as pt,y as ct,a as e,v as u,d as h,t as w,w as U}from"../chunks/index.98837b22.js";import{T as jt}from"../chunks/Tip.77304350.js";import{C as b}from"../chunks/CodeBlock.8d0c2e8a.js";import{H as Ms,E as mt}from"../chunks/getInferenceSnippets.06c2775f.js";import{H as dt,a as Xs}from"../chunks/HfOption.6641485e.js";function ut(C){let n,g="Loading a video from <code>&quot;url&quot;</code> is only supported by the PyAV or Decord backends.";return{c(){n=T("p"),n.innerHTML=g},l(r){n=c(r,"P",{"data-svelte-h":!0}),I(n)!=="svelte-1ddif0x"&&(n.innerHTML=g)},m(r,y){e(r,n,y)},p:Ns,d(r){r&&l(n)}}}function ht(C){let n,g="The <code>num_frames</code> parameter controls how many frames to uniformly sample from the video. Each checkpoint has a maximum frame count it was pretrained with and exceeding this count can significantly lower generation quality. It’s important to choose a frame count that fits both the model capacity and your hardware resources. If <code>num_frames</code> isn’t specified, the entire video is loaded without any frame sampling.",r,y,J,i,a='These inputs are now ready to be used in <a href="/docs/transformers/v4.56.2/en/main_classes/text_generation#transformers.GenerationMixin.generate">generate()</a>.',j;return y=new b({props:{code:"cHJvY2Vzc2VkX2NoYXQlMjAlM0QlMjBwcm9jZXNzb3IuYXBwbHlfY2hhdF90ZW1wbGF0ZSglMEElMjAlMjAlMjAlMjBtZXNzYWdlcyUyQyUwQSUyMCUyMCUyMCUyMGFkZF9nZW5lcmF0aW9uX3Byb21wdCUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjB0b2tlbml6ZSUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjByZXR1cm5fZGljdCUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjByZXR1cm5fdGVuc29ycyUzRCUyMnB0JTIyJTJDJTBBJTIwJTIwJTIwJTIwbnVtX2ZyYW1lcyUzRDMyJTJDJTBBJTIwJTIwJTIwJTIwdmlkZW9fbG9hZF9iYWNrZW5kJTNEJTIyZGVjb3JkJTIyJTJDJTBBKSUwQXByaW50KHByb2Nlc3NlZF9jaGF0LmtleXMoKSk=",highlighted:`processed_chat = processor.apply_chat_template(
    messages,
    add_generation_prompt=<span class="hljs-literal">True</span>,
    tokenize=<span class="hljs-literal">True</span>,
    return_dict=<span class="hljs-literal">True</span>,
    return_tensors=<span class="hljs-string">&quot;pt&quot;</span>,
    num_frames=<span class="hljs-number">32</span>,
    video_load_backend=<span class="hljs-string">&quot;decord&quot;</span>,
)
<span class="hljs-built_in">print</span>(processed_chat.keys())`,wrap:!1}}),{c(){n=T("p"),n.innerHTML=g,r=M(),m(y.$$.fragment),J=M(),i=T("p"),i.innerHTML=a},l(o){n=c(o,"P",{"data-svelte-h":!0}),I(n)!=="svelte-1ilhsfw"&&(n.innerHTML=g),r=p(o),d(y.$$.fragment,o),J=p(o),i=c(o,"P",{"data-svelte-h":!0}),I(i)!=="svelte-ah65hi"&&(i.innerHTML=a)},m(o,f){e(o,n,f),e(o,r,f),u(y,o,f),e(o,J,f),e(o,i,f),j=!0},p:Ns,i(o){j||(h(y.$$.fragment,o),j=!0)},o(o){w(y.$$.fragment,o),j=!1},d(o){o&&(l(n),l(r),l(J),l(i)),U(y,o)}}}function wt(C){let n,g="For longer videos, it may be better to sample more frames for better representation with the <code>video_fps</code> parameter. This determines how many frames per second to extract. As an example, if a video is 10 seconds long and <code>video_fps=2</code>, then the model samples 20 frames. In other words, 2 frames are uniformly sampled every 10 seconds.",r,y,J;return y=new b({props:{code:"cHJvY2Vzc2VkX2NoYXQlMjAlM0QlMjBwcm9jZXNzb3IuYXBwbHlfY2hhdF90ZW1wbGF0ZSglMEElMjAlMjAlMjAlMjBtZXNzYWdlcyUyQyUwQSUyMCUyMCUyMCUyMGFkZF9nZW5lcmF0aW9uX3Byb21wdCUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjB0b2tlbml6ZSUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjByZXR1cm5fZGljdCUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjB2aWRlb19mcHMlM0QxNiUyQyUwQSUyMCUyMCUyMCUyMHZpZGVvX2xvYWRfYmFja2VuZCUzRCUyMmRlY29yZCUyMiUyQyUwQSklMEFwcmludChwcm9jZXNzZWRfY2hhdC5rZXlzKCkp",highlighted:`processed_chat = processor.apply_chat_template(
    messages,
    add_generation_prompt=<span class="hljs-literal">True</span>,
    tokenize=<span class="hljs-literal">True</span>,
    return_dict=<span class="hljs-literal">True</span>,
    video_fps=<span class="hljs-number">16</span>,
    video_load_backend=<span class="hljs-string">&quot;decord&quot;</span>,
)
<span class="hljs-built_in">print</span>(processed_chat.keys())`,wrap:!1}}),{c(){n=T("p"),n.innerHTML=g,r=M(),m(y.$$.fragment)},l(i){n=c(i,"P",{"data-svelte-h":!0}),I(n)!=="svelte-xuidqz"&&(n.innerHTML=g),r=p(i),d(y.$$.fragment,i)},m(i,a){e(i,n,a),e(i,r,a),u(y,i,a),J=!0},p:Ns,i(i){J||(h(y.$$.fragment,i),J=!0)},o(i){w(y.$$.fragment,i),J=!1},d(i){i&&(l(n),l(r)),U(y,i)}}}function Ut(C){let n,g="Videos may also exist as a set of sampled frames stored as images rather than the full video file.",r,y,J="In this case, pass a list of image file paths and the processor automatically concatenates them into a video. Make sure all images are the same size since they are assumed to be from the same video.",i,a,j;return a=new b({props:{code:"ZnJhbWVzX3BhdGhzJTIwJTNEJTIwJTVCJTIyJTJGcGF0aCUyRnRvJTJGZnJhbWUwLnBuZyUyMiUyQyUyMCUyMiUyRnBhdGglMkZ0byUyRmZyYW1lNS5wbmclMjIlMkMlMjAlMjIlMkZwYXRoJTJGdG8lMkZmcmFtZTEwLnBuZyUyMiU1RCUwQW1lc3NhZ2VzJTIwJTNEJTIwJTVCJTBBJTIwJTIwJTIwJTIwJTdCJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIycm9sZSUyMiUzQSUyMCUyMnN5c3RlbSUyMiUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMmNvbnRlbnQlMjIlM0ElMjAlNUIlN0IlMjJ0eXBlJTIyJTNBJTIwJTIydGV4dCUyMiUyQyUyMCUyMnRleHQlMjIlM0ElMjAlMjJZb3UlMjBhcmUlMjBhJTIwZnJpZW5kbHklMjBjaGF0Ym90JTIwd2hvJTIwYWx3YXlzJTIwcmVzcG9uZHMlMjBpbiUyMHRoZSUyMHN0eWxlJTIwb2YlMjBhJTIwcGlyYXRlJTIyJTdEJTVEJTJDJTBBJTIwJTIwJTIwJTIwJTdEJTJDJTBBJTIwJTIwJTIwJTIwJTdCJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIycm9sZSUyMiUzQSUyMCUyMnVzZXIlMjIlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjJjb250ZW50JTIyJTNBJTIwJTVCJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTdCJTIydHlwZSUyMiUzQSUyMCUyMnZpZGVvJTIyJTJDJTIwJTIycGF0aCUyMiUzQSUyMGZyYW1lc19wYXRocyU3RCUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCU3QiUyMnR5cGUlMjIlM0ElMjAlMjJ0ZXh0JTIyJTJDJTIwJTIydGV4dCUyMiUzQSUyMCUyMldoYXQlMjBkbyUyMHlvdSUyMHNlZSUyMGluJTIwdGhpcyUyMHZpZGVvJTNGJTIyJTdEJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTVEJTJDJTBBJTIwJTIwJTIwJTIwJTdEJTJDJTBBJTVEJTBBJTBBcHJvY2Vzc2VkX2NoYXQlMjAlM0QlMjBwcm9jZXNzb3IuYXBwbHlfY2hhdF90ZW1wbGF0ZSglMEElMjAlMjAlMjAlMjBtZXNzYWdlcyUyQyUwQSUyMCUyMCUyMCUyMGFkZF9nZW5lcmF0aW9uX3Byb21wdCUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjB0b2tlbml6ZSUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjByZXR1cm5fZGljdCUzRFRydWUlMkMlMEEpJTBBcHJpbnQocHJvY2Vzc2VkX2NoYXQua2V5cygpKQ==",highlighted:`frames_paths = [<span class="hljs-string">&quot;/path/to/frame0.png&quot;</span>, <span class="hljs-string">&quot;/path/to/frame5.png&quot;</span>, <span class="hljs-string">&quot;/path/to/frame10.png&quot;</span>]
messages = [
    {
        <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>,
        <span class="hljs-string">&quot;content&quot;</span>: [{<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;You are a friendly chatbot who always responds in the style of a pirate&quot;</span>}],
    },
    {
      <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>,
      <span class="hljs-string">&quot;content&quot;</span>: [
            {<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;video&quot;</span>, <span class="hljs-string">&quot;path&quot;</span>: frames_paths},
            {<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;What do you see in this video?&quot;</span>},
        ],
    },
]

processed_chat = processor.apply_chat_template(
    messages,
    add_generation_prompt=<span class="hljs-literal">True</span>,
    tokenize=<span class="hljs-literal">True</span>,
    return_dict=<span class="hljs-literal">True</span>,
)
<span class="hljs-built_in">print</span>(processed_chat.keys())`,wrap:!1}}),{c(){n=T("p"),n.textContent=g,r=M(),y=T("p"),y.textContent=J,i=M(),m(a.$$.fragment)},l(o){n=c(o,"P",{"data-svelte-h":!0}),I(n)!=="svelte-o026q6"&&(n.textContent=g),r=p(o),y=c(o,"P",{"data-svelte-h":!0}),I(y)!=="svelte-l4ijxy"&&(y.textContent=J),i=p(o),d(a.$$.fragment,o)},m(o,f){e(o,n,f),e(o,r,f),e(o,y,f),e(o,i,f),u(a,o,f),j=!0},p:Ns,i(o){j||(h(a.$$.fragment,o),j=!0)},o(o){w(a.$$.fragment,o),j=!1},d(o){o&&(l(n),l(r),l(y),l(i)),U(a,o)}}}function It(C){let n,g,r,y,J,i;return n=new Xs({props:{id:"sampling",option:"fixed number of frames",$$slots:{default:[ht]},$$scope:{ctx:C}}}),r=new Xs({props:{id:"sampling",option:"fps",$$slots:{default:[wt]},$$scope:{ctx:C}}}),J=new Xs({props:{id:"sampling",option:"list of image frames",$$slots:{default:[Ut]},$$scope:{ctx:C}}}),{c(){m(n.$$.fragment),g=M(),m(r.$$.fragment),y=M(),m(J.$$.fragment)},l(a){d(n.$$.fragment,a),g=p(a),d(r.$$.fragment,a),y=p(a),d(J.$$.fragment,a)},m(a,j){u(n,a,j),e(a,g,j),u(r,a,j),e(a,y,j),u(J,a,j),i=!0},p(a,j){const o={};j&2&&(o.$$scope={dirty:j,ctx:a}),n.$set(o);const f={};j&2&&(f.$$scope={dirty:j,ctx:a}),r.$set(f);const ns={};j&2&&(ns.$$scope={dirty:j,ctx:a}),J.$set(ns)},i(a){i||(h(n.$$.fragment,a),h(r.$$.fragment,a),h(J.$$.fragment,a),i=!0)},o(a){w(n.$$.fragment,a),w(r.$$.fragment,a),w(J.$$.fragment,a),i=!1},d(a){a&&(l(g),l(y)),U(n,a),U(r,a),U(J,a)}}}function ft(C){let n,g,r,y,J,i,a,j="Multimodal chat models accept inputs like images, audio or video, in addition to text. The <code>content</code> key in a multimodal chat history is a list containing multiple items of different types. This is unlike text-only chat models whose <code>content</code> key is a single string.",o,f,ns=`In the same way the <a href="./fast_tokenizer">Tokenizer</a> class handles chat templates and tokenization for text-only models,
the <a href="./processors">Processor</a> class handles preprocessing, tokenization and chat templates for multimodal models. Their <a href="/docs/transformers/v4.56.2/en/main_classes/processors#transformers.ProcessorMixin.apply_chat_template">apply_chat_template()</a> methods are almost identical.`,ps,A,zs='This guide will show you how to chat with multimodal models with the high-level <a href="/docs/transformers/v4.56.2/en/main_classes/pipelines#transformers.ImageTextToTextPipeline">ImageTextToTextPipeline</a> and at a lower level using the <a href="/docs/transformers/v4.56.2/en/main_classes/processors#transformers.ProcessorMixin.apply_chat_template">apply_chat_template()</a> and <a href="/docs/transformers/v4.56.2/en/main_classes/text_generation#transformers.GenerationMixin.generate">generate()</a> methods.',is,B,rs,v,Hs='<a href="/docs/transformers/v4.56.2/en/main_classes/pipelines#transformers.ImageTextToTextPipeline">ImageTextToTextPipeline</a> is a high-level image and text generation class with a “chat mode”. Chat mode is enabled when a conversational model is detected and the chat prompt is <a href="./llm_tutorial#wrong-prompt-format">properly formatted</a>.',ys,$,Ss="Add image and text blocks to the <code>content</code> key in the chat history.",Js,k,Ts,_,Ys='Create an <a href="/docs/transformers/v4.56.2/en/main_classes/pipelines#transformers.ImageTextToTextPipeline">ImageTextToTextPipeline</a> and pass the chat to it. For large models, setting <a href="./models#big-model-inference">device_map=“auto”</a> helps load the model quicker and automatically places it on the fastest device available. Setting the data type to <a href="./models#model-data-type">auto</a> also helps save memory and improve speed.',cs,G,js,Q,ms,E,Fs="Aside from the gradual descent from pirate-speak into modern American English (it <strong>is</strong> only a 3B model, after all), this is correct!",ds,x,us,W,Ls=`Like <a href="./chat_templating">text-only models</a>, use the <a href="/docs/transformers/v4.56.2/en/main_classes/processors#transformers.ProcessorMixin.apply_chat_template">apply_chat_template()</a> method to prepare the chat messages for multimodal models.
This method handles the tokenization and formatting of the chat messages, including images and other media types. The resulting inputs are passed to the model for generation.`,hs,R,ws,V,Ds=`Pass <code>messages</code> to <a href="/docs/transformers/v4.56.2/en/main_classes/processors#transformers.ProcessorMixin.apply_chat_template">apply_chat_template()</a> to tokenize the input content. Unlike text models, the output of <code>apply_chat_template</code>
contains a <code>pixel_values</code> key with the preprocessed image data, in addition to the tokenized text.`,Us,N,Is,X,fs,z,Ps='Pass these inputs to <a href="/docs/transformers/v4.56.2/en/main_classes/text_generation#transformers.GenerationMixin.generate">generate()</a>.',gs,H,bs,S,Ks="The decoded output contains the full conversation so far, including the user message and the placeholder tokens that contain the image information. You may need to trim the previous conversation from the output before displaying it to the user.",Cs,Y,qs,F,Os='Some vision models also support video inputs. The message format is very similar to the format for <a href="#image-inputs">image inputs</a>.',Zs,L,st='<li>The content <code>&quot;type&quot;</code> should be <code>&quot;video&quot;</code> to indicate the content is a video.</li> <li>For videos, it can be a link to the video (<code>&quot;url&quot;</code>) or it could be a file path (<code>&quot;path&quot;</code>). Videos loaded from a URL can only be decoded with <a href="https://pyav.basswood-io.com/docs/stable/" rel="nofollow">PyAV</a> or <a href="https://github.com/dmlc/decord" rel="nofollow">Decord</a>.</li> <li>In addition to loading videos from a URL or file path, you can also pass decoded video data directly. This is useful if you’ve already preprocessed or decoded video frames elsewhere in memory (e.g., using OpenCV, decord, or torchvision). You don’t need to save to files or store it in an URL.</li>',As,q,Bs,D,vs,P,$s,K,ks,O,tt="You can also use existing (<code>&quot;load_video()&quot;</code>) function to load a video, edit the video in memory and pass it in the messages.",_s,ss,Gs,ts,lt='Pass <code>messages</code> to <a href="/docs/transformers/v4.56.2/en/main_classes/processors#transformers.ProcessorMixin.apply_chat_template">apply_chat_template()</a> to tokenize the input content. There are a few extra parameters to include in <a href="/docs/transformers/v4.56.2/en/main_classes/processors#transformers.ProcessorMixin.apply_chat_template">apply_chat_template()</a> that controls the sampling process.',Qs,ls,et='The <code>video_load_backend</code> parameter refers to a specific framework to load a video. It supports <a href="https://pyav.basswood-io.com/docs/stable/" rel="nofollow">PyAV</a>, <a href="https://github.com/dmlc/decord" rel="nofollow">Decord</a>, <a href="https://github.com/opencv/opencv" rel="nofollow">OpenCV</a>, and <a href="https://pytorch.org/vision/stable/index.html" rel="nofollow">torchvision</a>.',Es,es,at="The examples below use Decord as the backend because it is a bit faster than PyAV.",xs,Z,Ws,as,Rs,os,Vs;return J=new Ms({props:{title:"Multimodal chat templates",local:"multimodal-chat-templates",headingTag:"h1"}}),B=new Ms({props:{title:"ImageTextToTextPipeline",local:"imagetexttotextpipeline",headingTag:"h2"}}),k=new b({props:{code:"bWVzc2FnZXMlMjAlM0QlMjAlNUIlMEElMjAlMjAlMjAlMjAlN0IlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJyb2xlJTIyJTNBJTIwJTIyc3lzdGVtJTIyJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIyY29udGVudCUyMiUzQSUyMCU1QiU3QiUyMnR5cGUlMjIlM0ElMjAlMjJ0ZXh0JTIyJTJDJTIwJTIydGV4dCUyMiUzQSUyMCUyMllvdSUyMGFyZSUyMGElMjBmcmllbmRseSUyMGNoYXRib3QlMjB3aG8lMjBhbHdheXMlMjByZXNwb25kcyUyMGluJTIwdGhlJTIwc3R5bGUlMjBvZiUyMGElMjBwaXJhdGUlMjIlN0QlNUQlMkMlMEElMjAlMjAlMjAlMjAlN0QlMkMlMEElMjAlMjAlMjAlMjAlN0IlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjJyb2xlJTIyJTNBJTIwJTIydXNlciUyMiUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMmNvbnRlbnQlMjIlM0ElMjAlNUIlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlN0IlMjJ0eXBlJTIyJTNBJTIwJTIyaW1hZ2UlMjIlMkMlMjAlMjJ1cmwlMjIlM0ElMjAlMjJodHRwJTNBJTJGJTJGaW1hZ2VzLmNvY29kYXRhc2V0Lm9yZyUyRnZhbDIwMTclMkYwMDAwMDAwMzk3NjkuanBnJTIyJTdEJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTdCJTIydHlwZSUyMiUzQSUyMCUyMnRleHQlMjIlMkMlMjAlMjJ0ZXh0JTIyJTNBJTIwJTIyV2hhdCUyMGFyZSUyMHRoZXNlJTNGJTIyJTdEJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTVEJTJDJTBBJTIwJTIwJTIwJTIwJTdEJTJDJTBBJTVE",highlighted:`messages = [
    {
        <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>,
        <span class="hljs-string">&quot;content&quot;</span>: [{<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;You are a friendly chatbot who always responds in the style of a pirate&quot;</span>}],
    },
    {
      <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>,
      <span class="hljs-string">&quot;content&quot;</span>: [
            {<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;image&quot;</span>, <span class="hljs-string">&quot;url&quot;</span>: <span class="hljs-string">&quot;http://images.cocodataset.org/val2017/000000039769.jpg&quot;</span>},
            {<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;What are these?&quot;</span>},
        ],
    },
]`,wrap:!1}}),G=new b({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwdHJhbnNmb3JtZXJzJTIwaW1wb3J0JTIwcGlwZWxpbmUlMEElMEFwaXBlJTIwJTNEJTIwcGlwZWxpbmUoJTIyaW1hZ2UtdGV4dC10by10ZXh0JTIyJTJDJTIwbW9kZWwlM0QlMjJRd2VuJTJGUXdlbjIuNS1WTC0zQi1JbnN0cnVjdCUyMiUyQyUyMGRldmljZV9tYXAlM0QlMjJhdXRvJTIyJTJDJTIwZHR5cGUlM0QlMjJhdXRvJTIyKSUwQW91dCUyMCUzRCUyMHBpcGUodGV4dCUzRG1lc3NhZ2VzJTJDJTIwbWF4X25ld190b2tlbnMlM0QxMjgpJTBBcHJpbnQob3V0JTVCMCU1RCU1QidnZW5lcmF0ZWRfdGV4dCclNUQlNUItMSU1RCU1Qidjb250ZW50JyU1RCk=",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

pipe = pipeline(<span class="hljs-string">&quot;image-text-to-text&quot;</span>, model=<span class="hljs-string">&quot;Qwen/Qwen2.5-VL-3B-Instruct&quot;</span>, device_map=<span class="hljs-string">&quot;auto&quot;</span>, dtype=<span class="hljs-string">&quot;auto&quot;</span>)
out = pipe(text=messages, max_new_tokens=<span class="hljs-number">128</span>)
<span class="hljs-built_in">print</span>(out[<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;generated_text&#x27;</span>][-<span class="hljs-number">1</span>][<span class="hljs-string">&#x27;content&#x27;</span>])`,wrap:!1}}),Q=new b({props:{code:"QWhveSUyQyUyMG1lJTIwaGVhcnR5ISUyMFRoZXNlJTIwYmUlMjB0d28lMjBmZWxpbmUlMjBmcmllbmRzJTJDJTIwbGlrZWx5JTIwc29tZSUyMHRhYmJ5JTIwY2F0cyUyQyUyMHRha2luZyUyMGElMjBzaWVzdGElMjBvbiUyMGElMjBjb3p5JTIwcGluayUyMGJsYW5rZXQuJTIwVGhleSdyZSUyMHJlc3RpbmclMjBuZWFyJTIwcmVtb3RlJTIwY29udHJvbHMlMkMlMjBwZXJoYXBzJTIwYWZ0ZXIlMjB3YXRjaGluZyUyMHNvbWUlMjBUViUyMG9yJTIwanVzdCUyMGVuam95aW5nJTIwc29tZSUyMHF1aWV0JTIwdGltZSUyMHRvZ2V0aGVyLiUyMENhdHMlMjBzdXJlJTIwa25vdyUyMGhvdyUyMHRvJTIwZmluZCUyMGNvbWZvcnQlMjBhbmQlMjByZWxheGF0aW9uJTJDJTIwZG9uJ3QlMjB0aGV5JTNG",highlighted:'Ahoy, <span class="hljs-keyword">me</span> hearty! These be two feline friends, likely <span class="hljs-keyword">some</span> tabby cats, taking a siesta <span class="hljs-keyword">on</span> a cozy pink blanket. They&#x27;re resting near remote controls, perhaps <span class="hljs-keyword">after</span> watching <span class="hljs-keyword">some</span> TV <span class="hljs-keyword">or</span> just enjoying <span class="hljs-keyword">some</span> quiet <span class="hljs-built_in">time</span> together. Cats sure know how <span class="hljs-keyword">to</span> find comfort <span class="hljs-keyword">and</span> relaxation, don&#x27;t they?',wrap:!1}}),x=new Ms({props:{title:"Using apply_chat_template",local:"using-applychattemplate",headingTag:"h2"}}),R=new b({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Qcm9jZXNzb3IlMkMlMjBBdXRvTW9kZWxGb3JJbWFnZVRleHRUb1RleHQlMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvckltYWdlVGV4dFRvVGV4dC5mcm9tX3ByZXRyYWluZWQoJTIyUXdlbiUyRlF3ZW4yLjUtVkwtM0ItSW5zdHJ1Y3QlMjIlMkMlMjBkZXZpY2VfbWFwJTNEJTIyYXV0byUyMiUyQyUyMHRvcmNoX2R0eXBlJTNEJTIyYXV0byUyMiklMEFwcm9jZXNzb3IlMjAlM0QlMjBBdXRvUHJvY2Vzc29yLmZyb21fcHJldHJhaW5lZCglMjJRd2VuJTJGUXdlbjIuNS1WTC0zQi1JbnN0cnVjdCUyMiklMEElMEFtZXNzYWdlcyUyMCUzRCUyMCU1QiUwQSUyMCUyMCUyMCUyMCU3QiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMnJvbGUlMjIlM0ElMjAlMjJzeXN0ZW0lMjIlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjJjb250ZW50JTIyJTNBJTIwJTVCJTdCJTIydHlwZSUyMiUzQSUyMCUyMnRleHQlMjIlMkMlMjAlMjJ0ZXh0JTIyJTNBJTIwJTIyWW91JTIwYXJlJTIwYSUyMGZyaWVuZGx5JTIwY2hhdGJvdCUyMHdobyUyMGFsd2F5cyUyMHJlc3BvbmRzJTIwaW4lMjB0aGUlMjBzdHlsZSUyMG9mJTIwYSUyMHBpcmF0ZSUyMiU3RCU1RCUyQyUwQSUyMCUyMCUyMCUyMCU3RCUyQyUwQSUyMCUyMCUyMCUyMCU3QiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMnJvbGUlMjIlM0ElMjAlMjJ1c2VyJTIyJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIyY29udGVudCUyMiUzQSUyMCU1QiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCU3QiUyMnR5cGUlMjIlM0ElMjAlMjJpbWFnZSUyMiUyQyUyMCUyMnVybCUyMiUzQSUyMCUyMmh0dHAlM0ElMkYlMkZpbWFnZXMuY29jb2RhdGFzZXQub3JnJTJGdmFsMjAxNyUyRjAwMDAwMDAzOTc2OS5qcGclMjIlN0QlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlN0IlMjJ0eXBlJTIyJTNBJTIwJTIydGV4dCUyMiUyQyUyMCUyMnRleHQlMjIlM0ElMjAlMjJXaGF0JTIwYXJlJTIwdGhlc2UlM0YlMjIlN0QlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlNUQlMkMlMEElMjAlMjAlMjAlMjAlN0QlMkMlMEElNUQ=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor, AutoModelForImageTextToText

model = AutoModelForImageTextToText.from_pretrained(<span class="hljs-string">&quot;Qwen/Qwen2.5-VL-3B-Instruct&quot;</span>, device_map=<span class="hljs-string">&quot;auto&quot;</span>, torch_dtype=<span class="hljs-string">&quot;auto&quot;</span>)
processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;Qwen/Qwen2.5-VL-3B-Instruct&quot;</span>)

messages = [
    {
      <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>,
      <span class="hljs-string">&quot;content&quot;</span>: [{<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;You are a friendly chatbot who always responds in the style of a pirate&quot;</span>}],
    },
    {
      <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>,
      <span class="hljs-string">&quot;content&quot;</span>: [
            {<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;image&quot;</span>, <span class="hljs-string">&quot;url&quot;</span>: <span class="hljs-string">&quot;http://images.cocodataset.org/val2017/000000039769.jpg&quot;</span>},
            {<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;What are these?&quot;</span>},
        ],
    },
]`,wrap:!1}}),N=new b({props:{code:"cHJvY2Vzc2VkX2NoYXQlMjAlM0QlMjBwcm9jZXNzb3IuYXBwbHlfY2hhdF90ZW1wbGF0ZShtZXNzYWdlcyUyQyUyMGFkZF9nZW5lcmF0aW9uX3Byb21wdCUzRFRydWUlMkMlMjB0b2tlbml6ZSUzRFRydWUlMkMlMjByZXR1cm5fZGljdCUzRFRydWUlMkMlMjByZXR1cm5fdGVuc29ycyUzRCUyMnB0JTIyKSUwQXByaW50KGxpc3QocHJvY2Vzc2VkX2NoYXQua2V5cygpKSk=",highlighted:`processed_chat = processor.apply_chat_template(messages, add_generation_prompt=<span class="hljs-literal">True</span>, tokenize=<span class="hljs-literal">True</span>, return_dict=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-built_in">list</span>(processed_chat.keys()))`,wrap:!1}}),X=new b({props:{code:"JTVCJ2lucHV0X2lkcyclMkMlMjAnYXR0ZW50aW9uX21hc2snJTJDJTIwJ3BpeGVsX3ZhbHVlcyclMkMlMjAnaW1hZ2VfZ3JpZF90aHcnJTVE",highlighted:'[<span class="hljs-symbol">&#x27;input_ids</span>&#x27;, <span class="hljs-symbol">&#x27;attention_mask</span>&#x27;, <span class="hljs-symbol">&#x27;pixel_values</span>&#x27;, <span class="hljs-symbol">&#x27;image_grid_thw</span>&#x27;]',wrap:!1}}),H=new b({props:{code:"b3V0JTIwJTNEJTIwbW9kZWwuZ2VuZXJhdGUoKipwcm9jZXNzZWRfY2hhdC50byhtb2RlbC5kZXZpY2UpJTJDJTIwbWF4X25ld190b2tlbnMlM0QxMjgpJTBBcHJpbnQocHJvY2Vzc29yLmRlY29kZShvdXQlNUIwJTVEKSk=",highlighted:`out = model.generate(**processed_chat.to(model.device), max_new_tokens=<span class="hljs-number">128</span>)
<span class="hljs-built_in">print</span>(processor.decode(out[<span class="hljs-number">0</span>]))`,wrap:!1}}),Y=new Ms({props:{title:"Video inputs",local:"video-inputs",headingTag:"h2"}}),q=new jt({props:{warning:!0,$$slots:{default:[ut]},$$scope:{ctx:C}}}),D=new b({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Qcm9jZXNzb3IlMkMlMjBMbGF2YU9uZXZpc2lvbkZvckNvbmRpdGlvbmFsR2VuZXJhdGlvbiUwQSUwQW1vZGVsX2lkJTIwJTNEJTIwJTIybGxhdmEtaGYlMkZsbGF2YS1vbmV2aXNpb24tcXdlbjItMC41Yi1vdi1oZiUyMiUwQW1vZGVsJTIwJTNEJTIwTGxhdmFPbmV2aXNpb25Gb3JDb25kaXRpb25hbEdlbmVyYXRpb24uZnJvbV9wcmV0cmFpbmVkKG1vZGVsX2lkKSUwQXByb2Nlc3NvciUyMCUzRCUyMEF1dG9Qcm9jZXNzb3IuZnJvbV9wcmV0cmFpbmVkKG1vZGVsX2lkKSUwQSUwQW1lc3NhZ2VzJTIwJTNEJTIwJTVCJTBBJTIwJTIwJTIwJTIwJTdCJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIycm9sZSUyMiUzQSUyMCUyMnN5c3RlbSUyMiUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMmNvbnRlbnQlMjIlM0ElMjAlNUIlN0IlMjJ0eXBlJTIyJTNBJTIwJTIydGV4dCUyMiUyQyUyMCUyMnRleHQlMjIlM0ElMjAlMjJZb3UlMjBhcmUlMjBhJTIwZnJpZW5kbHklMjBjaGF0Ym90JTIwd2hvJTIwYWx3YXlzJTIwcmVzcG9uZHMlMjBpbiUyMHRoZSUyMHN0eWxlJTIwb2YlMjBhJTIwcGlyYXRlJTIyJTdEJTVEJTJDJTBBJTIwJTIwJTIwJTIwJTdEJTJDJTBBJTIwJTIwJTIwJTIwJTdCJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIycm9sZSUyMiUzQSUyMCUyMnVzZXIlMjIlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjJjb250ZW50JTIyJTNBJTIwJTVCJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTdCJTIydHlwZSUyMiUzQSUyMCUyMnZpZGVvJTIyJTJDJTIwJTIydXJsJTIyJTNBJTIwJTIyaHR0cHMlM0ElMkYlMkZ0ZXN0LXZpZGVvcy5jby51ayUyRnZpZHMlMkZiaWdidWNrYnVubnklMkZtcDQlMkZoMjY0JTJGNzIwJTJGQmlnX0J1Y2tfQnVubnlfNzIwXzEwc18xME1CLm1wNCUyMiU3RCUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCU3QiUyMnR5cGUlMjIlM0ElMjAlMjJ0ZXh0JTIyJTJDJTIwJTIydGV4dCUyMiUzQSUyMCUyMldoYXQlMjBkbyUyMHlvdSUyMHNlZSUyMGluJTIwdGhpcyUyMHZpZGVvJTNGJTIyJTdEJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTVEJTJDJTBBJTIwJTIwJTIwJTIwJTdEJTJDJTBBJTVE",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor, LlavaOnevisionForConditionalGeneration

model_id = <span class="hljs-string">&quot;llava-hf/llava-onevision-qwen2-0.5b-ov-hf&quot;</span>
model = LlavaOnevisionForConditionalGeneration.from_pretrained(model_id)
processor = AutoProcessor.from_pretrained(model_id)

messages = [
    {
      <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>,
      <span class="hljs-string">&quot;content&quot;</span>: [{<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;You are a friendly chatbot who always responds in the style of a pirate&quot;</span>}],
    },
    {
      <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>,
      <span class="hljs-string">&quot;content&quot;</span>: [
            {<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;video&quot;</span>, <span class="hljs-string">&quot;url&quot;</span>: <span class="hljs-string">&quot;https://test-videos.co.uk/vids/bigbuckbunny/mp4/h264/720/Big_Buck_Bunny_720_10s_10MB.mp4&quot;</span>},
            {<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;What do you see in this video?&quot;</span>},
        ],
    },
]`,wrap:!1}}),P=new Ms({props:{title:"Example: Passing decoded video objects",local:"example-passing-decoded-video-objects",headingTag:"h3"}}),K=new b({props:{code:"aW1wb3J0JTIwbnVtcHklMjBhcyUyMG5wJTBBJTBBdmlkZW9fb2JqZWN0MSUyMCUzRCUyMG5wLnJhbmRvbS5yYW5kaW50KDAlMkMlMjAyNTUlMkMlMjBzaXplJTNEKDE2JTJDJTIwMjI0JTJDJTIwMjI0JTJDJTIwMyklMkMlMjBkdHlwZSUzRG5wLnVpbnQ4KSUyQyUwQSUwQW1lc3NhZ2VzJTIwJTNEJTIwJTVCJTBBJTIwJTIwJTIwJTIwJTdCJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIycm9sZSUyMiUzQSUyMCUyMnN5c3RlbSUyMiUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMmNvbnRlbnQlMjIlM0ElMjAlNUIlN0IlMjJ0eXBlJTIyJTNBJTIwJTIydGV4dCUyMiUyQyUyMCUyMnRleHQlMjIlM0ElMjAlMjJZb3UlMjBhcmUlMjBhJTIwZnJpZW5kbHklMjBjaGF0Ym90JTIwd2hvJTIwYWx3YXlzJTIwcmVzcG9uZHMlMjBpbiUyMHRoZSUyMHN0eWxlJTIwb2YlMjBhJTIwcGlyYXRlJTIyJTdEJTVEJTJDJTBBJTIwJTIwJTIwJTIwJTdEJTJDJTBBJTIwJTIwJTIwJTIwJTdCJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIycm9sZSUyMiUzQSUyMCUyMnVzZXIlMjIlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJjb250ZW50JTIyJTNBJTIwJTVCJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTdCJTIydHlwZSUyMiUzQSUyMCUyMnZpZGVvJTIyJTJDJTIwJTIydmlkZW8lMjIlM0ElMjB2aWRlb19vYmplY3QxJTdEJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTdCJTIydHlwZSUyMiUzQSUyMCUyMnRleHQlMjIlMkMlMjAlMjJ0ZXh0JTIyJTNBJTIwJTIyV2hhdCUyMGRvJTIweW91JTIwc2VlJTIwaW4lMjB0aGlzJTIwdmlkZW8lM0YlMjIlN0QlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlNUQlMkMlMEElMjAlMjAlMjAlMjAlN0QlMkMlMEElNUQ=",highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

video_object1 = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">255</span>, size=(<span class="hljs-number">16</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>, <span class="hljs-number">3</span>), dtype=np.uint8),

messages = [
    {
        <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>,
        <span class="hljs-string">&quot;content&quot;</span>: [{<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;You are a friendly chatbot who always responds in the style of a pirate&quot;</span>}],
    },
    {
        <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>,
        <span class="hljs-string">&quot;content&quot;</span>: [
            {<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;video&quot;</span>, <span class="hljs-string">&quot;video&quot;</span>: video_object1},
            {<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;What do you see in this video?&quot;</span>}
        ],
    },
]`,wrap:!1}}),ss=new b({props:{code:"JTBBJTIzJTIwTWFrZSUyMHN1cmUlMjBhJTIwdmlkZW8lMjBiYWNrZW5kJTIwbGlicmFyeSUyMChweWF2JTJDJTIwZGVjb3JkJTJDJTIwb3IlMjB0b3JjaHZpc2lvbiklMjBpcyUyMGF2YWlsYWJsZS4lMEFmcm9tJTIwdHJhbnNmb3JtZXJzLnZpZGVvX3V0aWxzJTIwaW1wb3J0JTIwbG9hZF92aWRlbyUwQSUwQSUyMyUyMGxvYWQlMjBhJTIwdmlkZW8lMjBmaWxlJTIwaW4lMjBtZW1vcnklMjBmb3IlMjB0ZXN0aW5nJTBBdmlkZW9fb2JqZWN0MiUyQyUyMF8lMjAlM0QlMjBsb2FkX3ZpZGVvKCUwQSUyMCUyMCUyMCUyMCUyMmh0dHBzJTNBJTJGJTJGdGVzdC12aWRlb3MuY28udWslMkZ2aWRzJTJGYmlnYnVja2J1bm55JTJGbXA0JTJGaDI2NCUyRjcyMCUyRkJpZ19CdWNrX0J1bm55XzcyMF8xMHNfMTBNQi5tcDQlMjIlMEEpJTBBJTBBbWVzc2FnZXMlMjAlM0QlMjAlNUIlMEElMjAlMjAlMjAlMjAlN0IlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJyb2xlJTIyJTNBJTIwJTIyc3lzdGVtJTIyJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIyY29udGVudCUyMiUzQSUyMCU1QiU3QiUyMnR5cGUlMjIlM0ElMjAlMjJ0ZXh0JTIyJTJDJTIwJTIydGV4dCUyMiUzQSUyMCUyMllvdSUyMGFyZSUyMGElMjBmcmllbmRseSUyMGNoYXRib3QlMjB3aG8lMjBhbHdheXMlMjByZXNwb25kcyUyMGluJTIwdGhlJTIwc3R5bGUlMjBvZiUyMGElMjBwaXJhdGUlMjIlN0QlNUQlMkMlMEElMjAlMjAlMjAlMjAlN0QlMkMlMEElMjAlMjAlMjAlMjAlN0IlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJyb2xlJTIyJTNBJTIwJTIydXNlciUyMiUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMmNvbnRlbnQlMjIlM0ElMjAlNUIlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlN0IlMjJ0eXBlJTIyJTNBJTIwJTIydmlkZW8lMjIlMkMlMjAlMjJ2aWRlbyUyMiUzQSUyMHZpZGVvX29iamVjdDIlN0QlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlN0IlMjJ0eXBlJTIyJTNBJTIwJTIydGV4dCUyMiUyQyUyMCUyMnRleHQlMjIlM0ElMjAlMjJXaGF0JTIwZG8lMjB5b3UlMjBzZWUlMjBpbiUyMHRoaXMlMjB2aWRlbyUzRiUyMiU3RCUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCU1RCUyQyUwQSUyMCUyMCUyMCUyMCU3RCUyQyUwQSU1RA==",highlighted:`
<span class="hljs-comment"># Make sure a video backend library (pyav, decord, or torchvision) is available.</span>
<span class="hljs-keyword">from</span> transformers.video_utils <span class="hljs-keyword">import</span> load_video

<span class="hljs-comment"># load a video file in memory for testing</span>
video_object2, _ = load_video(
    <span class="hljs-string">&quot;https://test-videos.co.uk/vids/bigbuckbunny/mp4/h264/720/Big_Buck_Bunny_720_10s_10MB.mp4&quot;</span>
)

messages = [
    {
        <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>,
        <span class="hljs-string">&quot;content&quot;</span>: [{<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;You are a friendly chatbot who always responds in the style of a pirate&quot;</span>}],
    },
    {
        <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>,
        <span class="hljs-string">&quot;content&quot;</span>: [
            {<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;video&quot;</span>, <span class="hljs-string">&quot;video&quot;</span>: video_object2},
            {<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;What do you see in this video?&quot;</span>}
        ],
    },
]`,wrap:!1}}),Z=new dt({props:{id:"sampling",options:["fixed number of frames","fps","list of image frames"],$$slots:{default:[It]},$$scope:{ctx:C}}}),as=new mt({props:{source:"https://github.com/huggingface/transformers/blob/main/docs/source/en/chat_templating_multimodal.md"}}),{c(){n=T("meta"),g=M(),r=T("p"),y=M(),m(J.$$.fragment),i=M(),a=T("p"),a.innerHTML=j,o=M(),f=T("p"),f.innerHTML=ns,ps=M(),A=T("p"),A.innerHTML=zs,is=M(),m(B.$$.fragment),rs=M(),v=T("p"),v.innerHTML=Hs,ys=M(),$=T("p"),$.innerHTML=Ss,Js=M(),m(k.$$.fragment),Ts=M(),_=T("p"),_.innerHTML=Ys,cs=M(),m(G.$$.fragment),js=M(),m(Q.$$.fragment),ms=M(),E=T("p"),E.innerHTML=Fs,ds=M(),m(x.$$.fragment),us=M(),W=T("p"),W.innerHTML=Ls,hs=M(),m(R.$$.fragment),ws=M(),V=T("p"),V.innerHTML=Ds,Us=M(),m(N.$$.fragment),Is=M(),m(X.$$.fragment),fs=M(),z=T("p"),z.innerHTML=Ps,gs=M(),m(H.$$.fragment),bs=M(),S=T("p"),S.textContent=Ks,Cs=M(),m(Y.$$.fragment),qs=M(),F=T("p"),F.innerHTML=Os,Zs=M(),L=T("ul"),L.innerHTML=st,As=M(),m(q.$$.fragment),Bs=M(),m(D.$$.fragment),vs=M(),m(P.$$.fragment),$s=M(),m(K.$$.fragment),ks=M(),O=T("p"),O.innerHTML=tt,_s=M(),m(ss.$$.fragment),Gs=M(),ts=T("p"),ts.innerHTML=lt,Qs=M(),ls=T("p"),ls.innerHTML=et,Es=M(),es=T("p"),es.textContent=at,xs=M(),m(Z.$$.fragment),Ws=M(),m(as.$$.fragment),Rs=M(),os=T("p"),this.h()},l(s){const t=Tt("svelte-u9bgzb",document.head);n=c(t,"META",{name:!0,content:!0}),t.forEach(l),g=p(s),r=c(s,"P",{}),Mt(r).forEach(l),y=p(s),d(J.$$.fragment,s),i=p(s),a=c(s,"P",{"data-svelte-h":!0}),I(a)!=="svelte-1huyv8o"&&(a.innerHTML=j),o=p(s),f=c(s,"P",{"data-svelte-h":!0}),I(f)!=="svelte-n8e5qm"&&(f.innerHTML=ns),ps=p(s),A=c(s,"P",{"data-svelte-h":!0}),I(A)!=="svelte-6hi4y4"&&(A.innerHTML=zs),is=p(s),d(B.$$.fragment,s),rs=p(s),v=c(s,"P",{"data-svelte-h":!0}),I(v)!=="svelte-1jhowwc"&&(v.innerHTML=Hs),ys=p(s),$=c(s,"P",{"data-svelte-h":!0}),I($)!=="svelte-kgzni1"&&($.innerHTML=Ss),Js=p(s),d(k.$$.fragment,s),Ts=p(s),_=c(s,"P",{"data-svelte-h":!0}),I(_)!=="svelte-1cfkonp"&&(_.innerHTML=Ys),cs=p(s),d(G.$$.fragment,s),js=p(s),d(Q.$$.fragment,s),ms=p(s),E=c(s,"P",{"data-svelte-h":!0}),I(E)!=="svelte-177xju4"&&(E.innerHTML=Fs),ds=p(s),d(x.$$.fragment,s),us=p(s),W=c(s,"P",{"data-svelte-h":!0}),I(W)!=="svelte-1j2bk90"&&(W.innerHTML=Ls),hs=p(s),d(R.$$.fragment,s),ws=p(s),V=c(s,"P",{"data-svelte-h":!0}),I(V)!=="svelte-131vkrr"&&(V.innerHTML=Ds),Us=p(s),d(N.$$.fragment,s),Is=p(s),d(X.$$.fragment,s),fs=p(s),z=c(s,"P",{"data-svelte-h":!0}),I(z)!=="svelte-uhlldb"&&(z.innerHTML=Ps),gs=p(s),d(H.$$.fragment,s),bs=p(s),S=c(s,"P",{"data-svelte-h":!0}),I(S)!=="svelte-k1zhta"&&(S.textContent=Ks),Cs=p(s),d(Y.$$.fragment,s),qs=p(s),F=c(s,"P",{"data-svelte-h":!0}),I(F)!=="svelte-1ldrrkv"&&(F.innerHTML=Os),Zs=p(s),L=c(s,"UL",{"data-svelte-h":!0}),I(L)!=="svelte-y7asjp"&&(L.innerHTML=st),As=p(s),d(q.$$.fragment,s),Bs=p(s),d(D.$$.fragment,s),vs=p(s),d(P.$$.fragment,s),$s=p(s),d(K.$$.fragment,s),ks=p(s),O=c(s,"P",{"data-svelte-h":!0}),I(O)!=="svelte-idaz45"&&(O.innerHTML=tt),_s=p(s),d(ss.$$.fragment,s),Gs=p(s),ts=c(s,"P",{"data-svelte-h":!0}),I(ts)!=="svelte-1tddrs"&&(ts.innerHTML=lt),Qs=p(s),ls=c(s,"P",{"data-svelte-h":!0}),I(ls)!=="svelte-mmdb9c"&&(ls.innerHTML=et),Es=p(s),es=c(s,"P",{"data-svelte-h":!0}),I(es)!=="svelte-12n779"&&(es.textContent=at),xs=p(s),d(Z.$$.fragment,s),Ws=p(s),d(as.$$.fragment,s),Rs=p(s),os=c(s,"P",{}),Mt(os).forEach(l),this.h()},h(){pt(n,"name","hf:doc:metadata"),pt(n,"content",gt)},m(s,t){ct(document.head,n),e(s,g,t),e(s,r,t),e(s,y,t),u(J,s,t),e(s,i,t),e(s,a,t),e(s,o,t),e(s,f,t),e(s,ps,t),e(s,A,t),e(s,is,t),u(B,s,t),e(s,rs,t),e(s,v,t),e(s,ys,t),e(s,$,t),e(s,Js,t),u(k,s,t),e(s,Ts,t),e(s,_,t),e(s,cs,t),u(G,s,t),e(s,js,t),u(Q,s,t),e(s,ms,t),e(s,E,t),e(s,ds,t),u(x,s,t),e(s,us,t),e(s,W,t),e(s,hs,t),u(R,s,t),e(s,ws,t),e(s,V,t),e(s,Us,t),u(N,s,t),e(s,Is,t),u(X,s,t),e(s,fs,t),e(s,z,t),e(s,gs,t),u(H,s,t),e(s,bs,t),e(s,S,t),e(s,Cs,t),u(Y,s,t),e(s,qs,t),e(s,F,t),e(s,Zs,t),e(s,L,t),e(s,As,t),u(q,s,t),e(s,Bs,t),u(D,s,t),e(s,vs,t),u(P,s,t),e(s,$s,t),u(K,s,t),e(s,ks,t),e(s,O,t),e(s,_s,t),u(ss,s,t),e(s,Gs,t),e(s,ts,t),e(s,Qs,t),e(s,ls,t),e(s,Es,t),e(s,es,t),e(s,xs,t),u(Z,s,t),e(s,Ws,t),u(as,s,t),e(s,Rs,t),e(s,os,t),Vs=!0},p(s,[t]){const nt={};t&2&&(nt.$$scope={dirty:t,ctx:s}),q.$set(nt);const ot={};t&2&&(ot.$$scope={dirty:t,ctx:s}),Z.$set(ot)},i(s){Vs||(h(J.$$.fragment,s),h(B.$$.fragment,s),h(k.$$.fragment,s),h(G.$$.fragment,s),h(Q.$$.fragment,s),h(x.$$.fragment,s),h(R.$$.fragment,s),h(N.$$.fragment,s),h(X.$$.fragment,s),h(H.$$.fragment,s),h(Y.$$.fragment,s),h(q.$$.fragment,s),h(D.$$.fragment,s),h(P.$$.fragment,s),h(K.$$.fragment,s),h(ss.$$.fragment,s),h(Z.$$.fragment,s),h(as.$$.fragment,s),Vs=!0)},o(s){w(J.$$.fragment,s),w(B.$$.fragment,s),w(k.$$.fragment,s),w(G.$$.fragment,s),w(Q.$$.fragment,s),w(x.$$.fragment,s),w(R.$$.fragment,s),w(N.$$.fragment,s),w(X.$$.fragment,s),w(H.$$.fragment,s),w(Y.$$.fragment,s),w(q.$$.fragment,s),w(D.$$.fragment,s),w(P.$$.fragment,s),w(K.$$.fragment,s),w(ss.$$.fragment,s),w(Z.$$.fragment,s),w(as.$$.fragment,s),Vs=!1},d(s){s&&(l(g),l(r),l(y),l(i),l(a),l(o),l(f),l(ps),l(A),l(is),l(rs),l(v),l(ys),l($),l(Js),l(Ts),l(_),l(cs),l(js),l(ms),l(E),l(ds),l(us),l(W),l(hs),l(ws),l(V),l(Us),l(Is),l(fs),l(z),l(gs),l(bs),l(S),l(Cs),l(qs),l(F),l(Zs),l(L),l(As),l(Bs),l(vs),l($s),l(ks),l(O),l(_s),l(Gs),l(ts),l(Qs),l(ls),l(Es),l(es),l(xs),l(Ws),l(Rs),l(os)),l(n),U(J,s),U(B,s),U(k,s),U(G,s),U(Q,s),U(x,s),U(R,s),U(N,s),U(X,s),U(H,s),U(Y,s),U(q,s),U(D,s),U(P,s),U(K,s),U(ss,s),U(Z,s),U(as,s)}}}const gt='{"title":"Multimodal chat templates","local":"multimodal-chat-templates","sections":[{"title":"ImageTextToTextPipeline","local":"imagetexttotextpipeline","sections":[],"depth":2},{"title":"Using apply_chat_template","local":"using-applychattemplate","sections":[],"depth":2},{"title":"Video inputs","local":"video-inputs","sections":[{"title":"Example: Passing decoded video objects","local":"example-passing-decoded-video-objects","sections":[],"depth":3}],"depth":2}],"depth":1}';function bt(C){return rt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class $t extends yt{constructor(n){super(),Jt(this,n,bt,ft,it,{})}}export{$t as component};
