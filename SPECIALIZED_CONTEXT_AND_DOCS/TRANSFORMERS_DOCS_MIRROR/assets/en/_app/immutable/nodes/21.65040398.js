import{s as Mo,o as po,n as N}from"../chunks/scheduler.18a86fab.js";import{S as uo,i as yo,g as c,s as M,r as d,A as mo,h as T,f as l,c as p,j as Za,u as J,x as f,k as ro,y as P,a as s,v as w,d as U,t as j,w as h}from"../chunks/index.98837b22.js";import{T as K}from"../chunks/Tip.77304350.js";import{C as W}from"../chunks/CodeBlock.8d0c2e8a.js";import{H as k,E as co}from"../chunks/getInferenceSnippets.06c2775f.js";import{H as se,a as X}from"../chunks/HfOption.6641485e.js";function To(v){let t,y;return t=new W({props:{code:"cGlwJTIwaW5zdGFsbCUyMGRlZXBzcGVlZA==",highlighted:"pip install deepspeed",wrap:!1}}),{c(){d(t.$$.fragment)},l(n){J(t.$$.fragment,n)},m(n,r){w(t,n,r),y=!0},p:N,i(n){y||(U(t.$$.fragment,n),y=!0)},o(n){j(t.$$.fragment,n),y=!1},d(n){h(t,n)}}}function fo(v){let t,y;return t=new W({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRyYW5zZm9ybWVycyU1QmRlZXBzcGVlZCU1RA==",highlighted:"pip install transformers[deepspeed]",wrap:!1}}),{c(){d(t.$$.fragment)},l(n){J(t.$$.fragment,n)},m(n,r){w(t,n,r),y=!0},p:N,i(n){y||(U(t.$$.fragment,n),y=!0)},o(n){j(t.$$.fragment,n),y=!1},d(n){h(t,n)}}}function Jo(v){let t,y,n,r;return t=new X({props:{id:"installation",option:"PyPI",$$slots:{default:[To]},$$scope:{ctx:v}}}),n=new X({props:{id:"installation",option:"Transformers",$$slots:{default:[fo]},$$scope:{ctx:v}}}),{c(){d(t.$$.fragment),y=M(),d(n.$$.fragment)},l(o){J(t.$$.fragment,o),y=p(o),J(n.$$.fragment,o)},m(o,i){w(t,o,i),s(o,y,i),w(n,o,i),r=!0},p(o,i){const u={};i&2&&(u.$$scope={dirty:i,ctx:o}),t.$set(u);const C={};i&2&&(C.$$scope={dirty:i,ctx:o}),n.$set(C)},i(o){r||(U(t.$$.fragment,o),U(n.$$.fragment,o),r=!0)},o(o){j(t.$$.fragment,o),j(n.$$.fragment,o),r=!1},d(o){o&&l(y),h(t,o),h(n,o)}}}function wo(v){let t,y='Refer to the <a href="./debugging#deepspeed-cuda-issues">DeepSpeed CUDA installation</a> if you’re having trouble with your installation. While DeepSpeed has a pip installable package, it is highly recommended to <a href="https://www.deepspeed.ai/tutorials/advanced-install/#install-deepspeed-from-source" rel="nofollow">install it from source</a> to ensure it matches your hardware and to support certain features which aren’t available in the PyPI distribution.';return{c(){t=c("p"),t.innerHTML=y},l(n){t=T(n,"P",{"data-svelte-h":!0}),f(t)!=="svelte-7p0cdy"&&(t.innerHTML=y)},m(n,r){s(n,t,r)},p:N,d(n){n&&l(t)}}}function Uo(v){let t,y="If you have enough GPU memory, disable CPU and NVMe offload to speed everything up.";return{c(){t=c("p"),t.textContent=y},l(n){t=T(n,"P",{"data-svelte-h":!0}),f(t)!=="svelte-yvgfp7"&&(t.textContent=y)},m(n,r){s(n,t,r)},p:N,d(n){n&&l(t)}}}function jo(v){let t,y='Find a complete list of DeepSpeed configuration options on the <a href="https://www.deepspeed.ai/docs/config-json/" rel="nofollow">DeepSpeed Configuration JSON</a> reference. There are also practical examples of various DeepSpeed configuration examples in the <a href="https://github.com/microsoft/DeepSpeedExamples" rel="nofollow">DeepSpeedExamples</a> main <a href="https://github.com/microsoft/DeepSpeed" rel="nofollow">DeepSpeed</a> repository. Run the command below to quickly find specific examples.',n,r,o;return r=new W({props:{code:"Z2l0JTIwY2xvbmUlMjBodHRwcyUzQSUyRiUyRmdpdGh1Yi5jb20lMkZtaWNyb3NvZnQlMkZEZWVwU3BlZWRFeGFtcGxlcyUwQWNkJTIwRGVlcFNwZWVkRXhhbXBsZXMlMEFmaW5kJTIwLiUyMC1uYW1lJTIwJypqc29uJyUwQSUyMyUyMGZpbmQlMjBleGFtcGxlcyUyMHdpdGglMjB0aGUlMjBMYW1iJTIwb3B0aW1pemVyJTBBZ3JlcCUyMC1pJTIwTGFtYiUyMCUyNChmaW5kJTIwLiUyMC1uYW1lJTIwJypqc29uJyk=",highlighted:`git <span class="hljs-built_in">clone</span> https://github.com/microsoft/DeepSpeedExamples
<span class="hljs-built_in">cd</span> DeepSpeedExamples
find . -name <span class="hljs-string">&#x27;*json&#x27;</span>
<span class="hljs-comment"># find examples with the Lamb optimizer</span>
grep -i Lamb $(find . -name <span class="hljs-string">&#x27;*json&#x27;</span>)`,wrap:!1}}),{c(){t=c("p"),t.innerHTML=y,n=M(),d(r.$$.fragment)},l(i){t=T(i,"P",{"data-svelte-h":!0}),f(t)!=="svelte-139nygf"&&(t.innerHTML=y),n=p(i),J(r.$$.fragment,i)},m(i,u){s(i,t,u),s(i,n,u),w(r,i,u),o=!0},p:N,i(i){o||(U(r.$$.fragment,i),o=!0)},o(i){j(r.$$.fragment,i),o=!1},d(i){i&&(l(t),l(n)),h(r,i)}}}function ho(v){let t,y;return t=new W({props:{code:"VHJhaW5pbmdBcmd1bWVudHMoJTBBJTIwJTIwJTIwJTIwZGVlcHNwZWVkJTNEJTIycGF0aCUyRnRvJTJGZGVlcHNwZWVkX2NvbmZpZy5qc29uJTIyJTJDJTBBJTIwJTIwJTIwJTIwLi4uJTJDJTBBKQ==",highlighted:`TrainingArguments(
    deepspeed=<span class="hljs-string">&quot;path/to/deepspeed_config.json&quot;</span>,
    ...,
)`,wrap:!1}}),{c(){d(t.$$.fragment)},l(n){J(t.$$.fragment,n)},m(n,r){w(t,n,r),y=!0},p:N,i(n){y||(U(t.$$.fragment,n),y=!0)},o(n){j(t.$$.fragment,n),y=!1},d(n){h(t,n)}}}function Io(v){let t,y;return t=new W({props:{code:"ZHNfY29uZmlnX2RpY3QlMjAlM0QlMjBkaWN0KHNjaGVkdWxlciUzRHNjaGVkdWxlcl9wYXJhbXMlMkMlMjBvcHRpbWl6ZXIlM0RvcHRpbWl6ZXJfcGFyYW1zKSUwQWFyZ3MlMjAlM0QlMjBUcmFpbmluZ0FyZ3VtZW50cyglMEElMjAlMjAlMjAlMjBkZWVwc3BlZWQlM0Rkc19jb25maWdfZGljdCUyQyUwQSUyMCUyMCUyMCUyMC4uLiUyQyUwQSklMEF0cmFpbmVyJTIwJTNEJTIwVHJhaW5lciglMEElMjAlMjAlMjAlMjBtb2RlbCUyQyUwQSUyMCUyMCUyMCUyMGFyZ3MlMkMlMEElMjAlMjAlMjAlMjAuLi4lMkMlMEEp",highlighted:`ds_config_dict = <span class="hljs-built_in">dict</span>(scheduler=scheduler_params, optimizer=optimizer_params)
args = TrainingArguments(
    deepspeed=ds_config_dict,
    ...,
)
trainer = Trainer(
    model,
    args,
    ...,
)`,wrap:!1}}),{c(){d(t.$$.fragment)},l(n){J(t.$$.fragment,n)},m(n,r){w(t,n,r),y=!0},p:N,i(n){y||(U(t.$$.fragment,n),y=!0)},o(n){j(t.$$.fragment,n),y=!1},d(n){h(t,n)}}}function Co(v){let t,y,n,r;return t=new X({props:{id:"pass-config",option:"path to file",$$slots:{default:[ho]},$$scope:{ctx:v}}}),n=new X({props:{id:"pass-config",option:"nested dict",$$slots:{default:[Io]},$$scope:{ctx:v}}}),{c(){d(t.$$.fragment),y=M(),d(n.$$.fragment)},l(o){J(t.$$.fragment,o),y=p(o),J(n.$$.fragment,o)},m(o,i){w(t,o,i),s(o,y,i),w(n,o,i),r=!0},p(o,i){const u={};i&2&&(u.$$scope={dirty:i,ctx:o}),t.$set(u);const C={};i&2&&(C.$$scope={dirty:i,ctx:o}),n.$set(C)},i(o){r||(U(t.$$.fragment,o),U(n.$$.fragment,o),r=!0)},o(o){j(t.$$.fragment,o),j(n.$$.fragment,o),r=!1},d(o){o&&l(y),h(t,o),h(n,o)}}}function $o(v){let t,y='Some values, such as <code>scheduler.params.total_num_steps</code>, are calculated by <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> during training.';return{c(){t=c("p"),t.innerHTML=y},l(n){t=T(n,"P",{"data-svelte-h":!0}),f(t)!=="svelte-g566je"&&(t.innerHTML=y)},m(n,r){s(n,t,r)},p:N,d(n){n&&l(t)}}}function go(v){let t,y="DeepSpeed doesn’t validate parameter names and any typos will fallback on the parameters default setting. Observe the DeepSpeed engine startup log messages to see what values are being used.";return{c(){t=c("p"),t.textContent=y},l(n){t=T(n,"P",{"data-svelte-h":!0}),f(t)!=="svelte-3mkhni"&&(t.textContent=y)},m(n,r){s(n,t,r)},p:N,d(n){n&&l(t)}}}function Ao(v){let t,y="ZeRO-1 shards the optimizer states across GPUs and you can expect a small speed up.",n,r,o;return r=new W({props:{code:"JTdCJTBBJTIwJTIwJTIwJTIwJTIyemVyb19vcHRpbWl6YXRpb24lMjIlM0ElMjAlN0IlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJzdGFnZSUyMiUzQSUyMDElMEElMjAlMjAlMjAlMjAlN0QlMEElN0Q=",highlighted:`{
    <span class="hljs-attr">&quot;zero_optimization&quot;:</span> {
        <span class="hljs-attr">&quot;stage&quot;:</span> <span class="hljs-number">1</span>
    }
}`,wrap:!1}}),{c(){t=c("p"),t.textContent=y,n=M(),d(r.$$.fragment)},l(i){t=T(i,"P",{"data-svelte-h":!0}),f(t)!=="svelte-49w3aw"&&(t.textContent=y),n=p(i),J(r.$$.fragment,i)},m(i,u){s(i,t,u),s(i,n,u),w(r,i,u),o=!0},p:N,i(i){o||(U(r.$$.fragment,i),o=!0)},o(i){j(r.$$.fragment,i),o=!1},d(i){i&&(l(t),l(n)),h(r,i)}}}function bo(v){let t,y="ZeRO-2 shards the optimizer and gradient states across GPUs. This stage is primarily used for training since its features are not relevant to inference. Some important parameters to configure for better performance include the following.",n,r,o="<li><code>offload_optimizer</code> should be enabled to reduce GPU memory usage.</li> <li><code>overlap_comm</code> when set to <code>true</code> uses more GPU memory in exchange for lower allreduce latency. This feature uses 4.5x the <code>allgather_bucket_size</code> and <code>reduce_bucket_size</code> values. In this example, they’re set to <code>5e8</code> which means it requires 9GB of GPU memory. If your GPU memory is 8GB or less, you should reduce <code>overlap_comm</code> to lower the memory requirements and prevent an out-of-memory (OOM) error.</li> <li><code>allgather_bucket_size</code> and <code>reduce_bucket_size</code> trade-off available GPU memory for communication speed. The smaller their values, the slower communication is and the more GPU memory is available. You can balance, for example, whether a bigger batch size is more important than a slightly slower training time.</li> <li><code>round_robin_gradients</code> is available in DeepSpeed 0.4.4 for CPU offloading. It parallelizes gradient copying to CPU memory among ranks by fine-grained gradient partitioning. Performance benefit grows with gradient accumulation steps (more copying between optimizer steps) or GPU count (increased parallelism).</li>",i,u,C;return u=new W({props:{code:"JTdCJTBBJTIwJTIwJTIwJTIwJTIyemVyb19vcHRpbWl6YXRpb24lMjIlM0ElMjAlN0IlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJzdGFnZSUyMiUzQSUyMDIlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJvZmZsb2FkX29wdGltaXplciUyMiUzQSUyMCU3QiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMmRldmljZSUyMiUzQSUyMCUyMmNwdSUyMiUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMnBpbl9tZW1vcnklMjIlM0ElMjB0cnVlJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTdEJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIyYWxsZ2F0aGVyX3BhcnRpdGlvbnMlMjIlM0ElMjB0cnVlJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIyYWxsZ2F0aGVyX2J1Y2tldF9zaXplJTIyJTNBJTIwNWU4JTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIyb3ZlcmxhcF9jb21tJTIyJTNBJTIwdHJ1ZSUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMnJlZHVjZV9zY2F0dGVyJTIyJTNBJTIwdHJ1ZSUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMnJlZHVjZV9idWNrZXRfc2l6ZSUyMiUzQSUyMDVlOCUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMmNvbnRpZ3VvdXNfZ3JhZGllbnRzJTIyJTNBJTIwdHJ1ZSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMnJvdW5kX3JvYmluX2dyYWRpZW50cyUyMiUzQSUyMHRydWUlMEElMjAlMjAlMjAlMjAlN0QlMEElN0Q=",highlighted:`{
    <span class="hljs-attr">&quot;zero_optimization&quot;:</span> {
        <span class="hljs-attr">&quot;stage&quot;:</span> <span class="hljs-number">2</span>,
        <span class="hljs-attr">&quot;offload_optimizer&quot;:</span> {
            <span class="hljs-attr">&quot;device&quot;:</span> <span class="hljs-string">&quot;cpu&quot;</span>,
            <span class="hljs-attr">&quot;pin_memory&quot;:</span> <span class="hljs-literal">true</span>
        },
        <span class="hljs-attr">&quot;allgather_partitions&quot;:</span> <span class="hljs-literal">true</span>,
        <span class="hljs-attr">&quot;allgather_bucket_size&quot;:</span> <span class="hljs-number">5e8</span>,
        <span class="hljs-attr">&quot;overlap_comm&quot;:</span> <span class="hljs-literal">true</span>,
        <span class="hljs-attr">&quot;reduce_scatter&quot;:</span> <span class="hljs-literal">true</span>,
        <span class="hljs-attr">&quot;reduce_bucket_size&quot;:</span> <span class="hljs-number">5e8</span>,
        <span class="hljs-attr">&quot;contiguous_gradients&quot;:</span> <span class="hljs-literal">true</span>
        <span class="hljs-attr">&quot;round_robin_gradients&quot;:</span> <span class="hljs-literal">true</span>
    }
}`,wrap:!1}}),{c(){t=c("p"),t.textContent=y,n=M(),r=c("ul"),r.innerHTML=o,i=M(),d(u.$$.fragment)},l(I){t=T(I,"P",{"data-svelte-h":!0}),f(t)!=="svelte-ugsi2r"&&(t.textContent=y),n=p(I),r=T(I,"UL",{"data-svelte-h":!0}),f(r)!=="svelte-nz1izj"&&(r.innerHTML=o),i=p(I),J(u.$$.fragment,I)},m(I,Z){s(I,t,Z),s(I,n,Z),s(I,r,Z),s(I,i,Z),w(u,I,Z),C=!0},p:N,i(I){C||(U(u.$$.fragment,I),C=!0)},o(I){j(u.$$.fragment,I),C=!1},d(I){I&&(l(t),l(n),l(r),l(i)),h(u,I)}}}function _o(v){let t,y='You’ll need ZeRO-3 when the fp16 weights don’t fit on a single GPU. But if you’re able to load the fp16 weights, set <code>dtype=torch.float16</code> in <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a>.';return{c(){t=c("p"),t.innerHTML=y},l(n){t=T(n,"P",{"data-svelte-h":!0}),f(t)!=="svelte-10hcp6t"&&(t.innerHTML=y)},m(n,r){s(n,t,r)},p:N,d(n){n&&l(t)}}}function vo(v){let t,y='For more information about initializing large models with ZeRO-3 and accessing the parameters, take a look at the <a href="https://deepspeed.readthedocs.io/en/latest/zero3.html#constructing-massive-models" rel="nofollow">Constructing Massive Models</a> and <a href="https://deepspeed.readthedocs.io/en/latest/zero3.html#gathering-parameters" rel="nofollow">Gathering Parameters</a> guides.';return{c(){t=c("p"),t.innerHTML=y},l(n){t=T(n,"P",{"data-svelte-h":!0}),f(t)!=="svelte-16wfnex"&&(t.innerHTML=y)},m(n,r){s(n,t,r)},p:N,d(n){n&&l(t)}}}function Zo(v){let t,y="ZeRO-3 shards the optimizer and gradient states, and parameters across GPUs. Unlike ZeRO-2, ZeRO-3 can also be used for inference in addition to training because it loads large models onto multiple GPUs. Some important parameters to configure include the following.",n,r,o='<li><p><code>device: &quot;cpu&quot;</code> can help if you’re running out of GPU memory and if you have free CPU memory available. This offloads model parameters to the CPU.</p></li> <li><p><code>pin_memory: true</code> can improve throughput, but less memory becomes available for other processes because the pinned memory is reserved for the specific process that requested it and it’s typically accessed much faster than normal CPU memory.</p></li> <li><p><code>stage3_max_live_parameters</code> is the upper limit on how many full parameters to keep on the GPU at any given time. Reduce this value if you encounter an OOM error.</p></li> <li><p><code>stage3_max_reuse_distance</code> is a value for determining when a parameter is used again in the future, and it helps decide whether to throw the parameter away or to keep it. If the parameter is going to be reused (if the value is less than <code>stage3_max_reuse_distance</code>), then it is kept to reduce communication overhead. This is helpful when activation checkpointing is enabled and you want to keep the parameter in the forward recompute until the backward pass. Reduce this value if you encounter an OOM error.</p></li> <li><p><code>stage3_gather_16bit_weights_on_model_save</code> consolidates fp16 weights when a model is saved. For large models and multiple GPUs, this is expensive in terms of memory and speed. You should enable it if you’re planning on resuming training.</p></li> <li><p><code>sub_group_size</code> controls which parameters are updated during the optimizer step. Parameters are grouped into buckets of <code>sub_group_size</code> and each bucket is updated one at a time. When used with NVMe offload, <code>sub_group_size</code> determines when model states are moved in and out of CPU memory during the optimization step. This prevents running out of CPU memory for extremely large models. <code>sub_group_size</code> can be left to its default value if you aren’t using NVMe offload, but you may want to change it if you:</p> <ol><li>Run into an OOM error during the optimization step. In this case, reduce <code>sub_group_size</code> to reduce memory usage of the temporary buffers.</li> <li>The optimization step is taking a really long time. In this case, increase <code>sub_group_size</code> to improve bandwidth utilization as a result of increased data buffers.</li></ol></li> <li><p><code>reduce_bucket_size</code>, <code>stage3_prefetch_bucket_size</code>, and <code>stage3_param_persistence_threshold</code> are dependent on a models hidden size. It is recommended to set these values to <code>auto</code> and allow <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> to automatically assign the values.</p></li>',i,u,C,I,Z,g,B='With ZeRO-3, use the <a href="https://deepspeed.readthedocs.io/en/latest/zero3.html#deepspeed.zero.Init" rel="nofollow">deepspeed.zero.Init</a> context manager to initialize a model faster.',A,m,q,R,S='The DeepSped config file needs to have <code>is_deepspeed_zero3_enabled: true</code> setup in <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> and it needs a ZeRO configuration enabled. The <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> object must be created <strong>before</strong> calling <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a>.',$,b,G,Y,x,L,O='When there are multiple GPUs, no single GPU has all the parameters unless it’s the parameters of the currently executing layer. To access all parameters from all the layers at once, such as loading pretrained model weights in <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a>, one layer is loaded at a time and immediately partitioned to all GPUs. For very large models, it isn’t possible to load the weights onto one GPU and then distribute them across the other GPUs due to memory limitations.',te,E,Ul="If you encounter a model parameter weight where <code>tensor([1.])</code> or the parameter size is 1 instead of a larger multidimensional shape, it means the parameter is partitioned and this is a ZeRO-3 placeholder.",le,Q,Te,H,D;return u=new W({props:{code:"JTdCJTBBJTIwJTIwJTIwJTIwJTIyemVyb19vcHRpbWl6YXRpb24lMjIlM0ElMjAlN0IlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJzdGFnZSUyMiUzQSUyMDMlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJvZmZsb2FkX29wdGltaXplciUyMiUzQSUyMCU3QiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMmRldmljZSUyMiUzQSUyMCUyMmNwdSUyMiUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMnBpbl9tZW1vcnklMjIlM0ElMjB0cnVlJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTdEJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIyb2ZmbG9hZF9wYXJhbSUyMiUzQSUyMCU3QiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMmRldmljZSUyMiUzQSUyMCUyMmNwdSUyMiUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMnBpbl9tZW1vcnklMjIlM0ElMjB0cnVlJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTdEJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIyb3ZlcmxhcF9jb21tJTIyJTNBJTIwdHJ1ZSUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMmNvbnRpZ3VvdXNfZ3JhZGllbnRzJTIyJTNBJTIwdHJ1ZSUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMnN1Yl9ncm91cF9zaXplJTIyJTNBJTIwMWU5JTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIycmVkdWNlX2J1Y2tldF9zaXplJTIyJTNBJTIwJTIyYXV0byUyMiUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMnN0YWdlM19wcmVmZXRjaF9idWNrZXRfc2l6ZSUyMiUzQSUyMCUyMmF1dG8lMjIlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJzdGFnZTNfcGFyYW1fcGVyc2lzdGVuY2VfdGhyZXNob2xkJTIyJTNBJTIwJTIyYXV0byUyMiUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMnN0YWdlM19tYXhfbGl2ZV9wYXJhbWV0ZXJzJTIyJTNBJTIwMWU5JTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIyc3RhZ2UzX21heF9yZXVzZV9kaXN0YW5jZSUyMiUzQSUyMDFlOSUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMnN0YWdlM19nYXRoZXJfMTZiaXRfd2VpZ2h0c19vbl9tb2RlbF9zYXZlJTIyJTNBJTIwdHJ1ZSUwQSUyMCUyMCUyMCUyMCU3RCUwQSU3RA==",highlighted:`{
    <span class="hljs-attr">&quot;zero_optimization&quot;:</span> {
        <span class="hljs-attr">&quot;stage&quot;:</span> <span class="hljs-number">3</span>,
        <span class="hljs-attr">&quot;offload_optimizer&quot;:</span> {
            <span class="hljs-attr">&quot;device&quot;:</span> <span class="hljs-string">&quot;cpu&quot;</span>,
            <span class="hljs-attr">&quot;pin_memory&quot;:</span> <span class="hljs-literal">true</span>
        },
        <span class="hljs-attr">&quot;offload_param&quot;:</span> {
            <span class="hljs-attr">&quot;device&quot;:</span> <span class="hljs-string">&quot;cpu&quot;</span>,
            <span class="hljs-attr">&quot;pin_memory&quot;:</span> <span class="hljs-literal">true</span>
        },
        <span class="hljs-attr">&quot;overlap_comm&quot;:</span> <span class="hljs-literal">true</span>,
        <span class="hljs-attr">&quot;contiguous_gradients&quot;:</span> <span class="hljs-literal">true</span>,
        <span class="hljs-attr">&quot;sub_group_size&quot;:</span> <span class="hljs-number">1e9</span>,
        <span class="hljs-attr">&quot;reduce_bucket_size&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
        <span class="hljs-attr">&quot;stage3_prefetch_bucket_size&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
        <span class="hljs-attr">&quot;stage3_param_persistence_threshold&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
        <span class="hljs-attr">&quot;stage3_max_live_parameters&quot;:</span> <span class="hljs-number">1e9</span>,
        <span class="hljs-attr">&quot;stage3_max_reuse_distance&quot;:</span> <span class="hljs-number">1e9</span>,
        <span class="hljs-attr">&quot;stage3_gather_16bit_weights_on_model_save&quot;:</span> <span class="hljs-literal">true</span>
    }
}`,wrap:!1}}),I=new k({props:{title:"Initialize large models",local:"initialize-large-models",headingTag:"h3"}}),m=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFQ1Rm9yQ29uZGl0aW9uYWxHZW5lcmF0aW9uJTJDJTIwVDVDb25maWclMEFpbXBvcnQlMjBkZWVwc3BlZWQlMEElMEF3aXRoJTIwZGVlcHNwZWVkLnplcm8uSW5pdCgpJTNBJTBBJTIwJTIwJTIwJTIwY29uZmlnJTIwJTNEJTIwVDVDb25maWcuZnJvbV9wcmV0cmFpbmVkKCUyMmdvb2dsZS10NSUyRnQ1LXNtYWxsJTIyKSUwQSUyMCUyMCUyMCUyMG1vZGVsJTIwJTNEJTIwVDVGb3JDb25kaXRpb25hbEdlbmVyYXRpb24oY29uZmlnKQ==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> T5ForConditionalGeneration, T5Config
<span class="hljs-keyword">import</span> deepspeed

<span class="hljs-keyword">with</span> deepspeed.zero.Init():
    config = T5Config.from_pretrained(<span class="hljs-string">&quot;google-t5/t5-small&quot;</span>)
    model = T5ForConditionalGeneration(config)`,wrap:!1}}),b=new K({props:{warning:!1,$$slots:{default:[_o]},$$scope:{ctx:v}}}),Y=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbCUyQyUyMFRyYWluZXIlMkMlMjBUcmFpbmluZ0FyZ3VtZW50cyUwQSUwQXRyYWluaW5nX2FyZ3MlMjAlM0QlMjBUcmFpbmluZ0FyZ3VtZW50cyguLi4lMkMlMjBkZWVwc3BlZWQlM0Rkc19jb25maWcpJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWwuZnJvbV9wcmV0cmFpbmVkKCUyMmdvb2dsZS10NSUyRnQ1LXNtYWxsJTIyKSUwQXRyYWluZXIlMjAlM0QlMjBUcmFpbmVyKG1vZGVsJTNEbW9kZWwlMkMlMjBhcmdzJTNEdHJhaW5pbmdfYXJncyUyQyUyMC4uLik=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel, Trainer, TrainingArguments

training_args = TrainingArguments(..., deepspeed=ds_config)
model = AutoModel.from_pretrained(<span class="hljs-string">&quot;google-t5/t5-small&quot;</span>)
trainer = Trainer(model=model, args=training_args, ...)`,wrap:!1}}),Q=new W({props:{code:"dGVuc29yKCU1QjEuMCU1RCUyQyUyMGRldmljZSUzRCUyMmN1ZGElM0EwJTIyJTJDJTIwZHR5cGUlM0R0b3JjaC5mbG9hdDE2JTJDJTIwcmVxdWlyZXNfZ3JhZCUzRFRydWUp",highlighted:'tensor([<span class="hljs-number">1.0</span>], device=<span class="hljs-string">&quot;cuda:0&quot;</span>, dtype=torch.float16, requires_grad=<span class="hljs-literal">True</span>)',wrap:!1}}),H=new K({props:{warning:!1,$$slots:{default:[vo]},$$scope:{ctx:v}}}),{c(){t=c("p"),t.textContent=y,n=M(),r=c("ul"),r.innerHTML=o,i=M(),d(u.$$.fragment),C=M(),d(I.$$.fragment),Z=M(),g=c("p"),g.innerHTML=B,A=M(),d(m.$$.fragment),q=M(),R=c("p"),R.innerHTML=S,$=M(),d(b.$$.fragment),G=M(),d(Y.$$.fragment),x=M(),L=c("p"),L.innerHTML=O,te=M(),E=c("p"),E.innerHTML=Ul,le=M(),d(Q.$$.fragment),Te=M(),d(H.$$.fragment)},l(_){t=T(_,"P",{"data-svelte-h":!0}),f(t)!=="svelte-f85qjo"&&(t.textContent=y),n=p(_),r=T(_,"UL",{"data-svelte-h":!0}),f(r)!=="svelte-9t3com"&&(r.innerHTML=o),i=p(_),J(u.$$.fragment,_),C=p(_),J(I.$$.fragment,_),Z=p(_),g=T(_,"P",{"data-svelte-h":!0}),f(g)!=="svelte-1yjopxj"&&(g.innerHTML=B),A=p(_),J(m.$$.fragment,_),q=p(_),R=T(_,"P",{"data-svelte-h":!0}),f(R)!=="svelte-15504yr"&&(R.innerHTML=S),$=p(_),J(b.$$.fragment,_),G=p(_),J(Y.$$.fragment,_),x=p(_),L=T(_,"P",{"data-svelte-h":!0}),f(L)!=="svelte-rq91r4"&&(L.innerHTML=O),te=p(_),E=T(_,"P",{"data-svelte-h":!0}),f(E)!=="svelte-1geame9"&&(E.innerHTML=Ul),le=p(_),J(Q.$$.fragment,_),Te=p(_),J(H.$$.fragment,_)},m(_,z){s(_,t,z),s(_,n,z),s(_,r,z),s(_,i,z),w(u,_,z),s(_,C,z),w(I,_,z),s(_,Z,z),s(_,g,z),s(_,A,z),w(m,_,z),s(_,q,z),s(_,R,z),s(_,$,z),w(b,_,z),s(_,G,z),w(Y,_,z),s(_,x,z),s(_,L,z),s(_,te,z),s(_,E,z),s(_,le,z),w(Q,_,z),s(_,Te,z),w(H,_,z),D=!0},p(_,z){const fe={};z&2&&(fe.$$scope={dirty:z,ctx:_}),b.$set(fe);const ee={};z&2&&(ee.$$scope={dirty:z,ctx:_}),H.$set(ee)},i(_){D||(U(u.$$.fragment,_),U(I.$$.fragment,_),U(m.$$.fragment,_),U(b.$$.fragment,_),U(Y.$$.fragment,_),U(Q.$$.fragment,_),U(H.$$.fragment,_),D=!0)},o(_){j(u.$$.fragment,_),j(I.$$.fragment,_),j(m.$$.fragment,_),j(b.$$.fragment,_),j(Y.$$.fragment,_),j(Q.$$.fragment,_),j(H.$$.fragment,_),D=!1},d(_){_&&(l(t),l(n),l(r),l(i),l(C),l(Z),l(g),l(A),l(q),l(R),l($),l(G),l(x),l(L),l(te),l(E),l(le),l(Te)),h(u,_),h(I,_),h(m,_),h(b,_),h(Y,_),h(Q,_),h(H,_)}}}function Bo(v){let t,y,n,r,o,i;return t=new X({props:{id:"zero-config",option:"ZeRO-1",$$slots:{default:[Ao]},$$scope:{ctx:v}}}),n=new X({props:{id:"zero-config",option:"ZeRO-2",$$slots:{default:[bo]},$$scope:{ctx:v}}}),o=new X({props:{id:"zero-config",option:"ZeRO-3",$$slots:{default:[Zo]},$$scope:{ctx:v}}}),{c(){d(t.$$.fragment),y=M(),d(n.$$.fragment),r=M(),d(o.$$.fragment)},l(u){J(t.$$.fragment,u),y=p(u),J(n.$$.fragment,u),r=p(u),J(o.$$.fragment,u)},m(u,C){w(t,u,C),s(u,y,C),w(n,u,C),s(u,r,C),w(o,u,C),i=!0},p(u,C){const I={};C&2&&(I.$$scope={dirty:C,ctx:u}),t.$set(I);const Z={};C&2&&(Z.$$scope={dirty:C,ctx:u}),n.$set(Z);const g={};C&2&&(g.$$scope={dirty:C,ctx:u}),o.$set(g)},i(u){i||(U(t.$$.fragment,u),U(n.$$.fragment,u),U(o.$$.fragment,u),i=!0)},o(u){j(t.$$.fragment,u),j(n.$$.fragment,u),j(o.$$.fragment,u),i=!1},d(u){u&&(l(y),l(r)),h(t,u),h(n,u),h(o,u)}}}function qo(v){let t,y="Train in fp32 if a model wasn’t pretrained in mixed precision because it may cause underflow or overflow errors. Disable fp16, the default, in this case.",n,r,o,i,u='For Ampere GPUs and PyTorch 1.7+, the more efficient <a href="https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices" rel="nofollow">tf32</a> mode is automatically enabled for some operations but the results are still in fp32. Configure it in <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> by setting <code>--tf32</code> to enable it, and <code>--tf32 0</code> or <code>--no_tf32</code> to disable it.',C;return r=new W({props:{code:"JTdCJTBBJTIwJTIwJTIwJTIwJTIyZnAxNiUyMiUzQSUyMCU3QiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMmVuYWJsZWQlMjIlM0ElMjBmYWxzZSUwQSUyMCUyMCUyMCUyMCU3RCUwQSU3RA==",highlighted:`{
    <span class="hljs-attr">&quot;fp16&quot;:</span> {
        <span class="hljs-attr">&quot;enabled&quot;:</span> <span class="hljs-literal">false</span>
    }
}`,wrap:!1}}),{c(){t=c("p"),t.textContent=y,n=M(),d(r.$$.fragment),o=M(),i=c("p"),i.innerHTML=u},l(I){t=T(I,"P",{"data-svelte-h":!0}),f(t)!=="svelte-4l2sai"&&(t.textContent=y),n=p(I),J(r.$$.fragment,I),o=p(I),i=T(I,"P",{"data-svelte-h":!0}),f(i)!=="svelte-nkeqz2"&&(i.innerHTML=u)},m(I,Z){s(I,t,Z),s(I,n,Z),w(r,I,Z),s(I,o,Z),s(I,i,Z),C=!0},p:N,i(I){C||(U(r.$$.fragment,I),C=!0)},o(I){j(r.$$.fragment,I),C=!1},d(I){I&&(l(t),l(n),l(o),l(i)),h(r,I)}}}function Wo(v){let t,y='To configure AMP-like fp16 mixed precision, set up the config as shown below with <code>&quot;auto&quot;</code> or your own values. <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> automatically enables or disables fp16 based on the value of <code>fp16_backend</code>, and the rest of the config can be set by you. fp16 is enabled from the command line when the following arguments are passed: <code>--fp16</code>, <code>--fp16_backend amp</code> or <code>--fp16_full_eval</code>.',n,r,o,i,u='For additional DeepSpeed fp16 training options, take a look at the <a href="https://www.deepspeed.ai/docs/config-json/#fp16-training-options" rel="nofollow">FP16 Training Options</a> reference.',C,I,Z='To configure Apex-like fp16 mixed precision, set up the config as shown below with <code>&quot;auto&quot;</code> or your own values. <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> automatically configures <code>amp</code> based on the values of <code>fp16_backend</code> and <code>fp16_opt_level</code>. It can also be enabled from the command line when the following arguments are passed: <code>--fp16</code>, <code>--fp16_backend apex</code> or <code>--fp16_opt_level 01</code>.',g,B,A;return r=new W({props:{code:"JTdCJTBBJTIwJTIwJTIwJTIwJTIyZnAxNiUyMiUzQSUyMCU3QiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMmVuYWJsZWQlMjIlM0ElMjAlMjJhdXRvJTIyJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIybG9zc19zY2FsZSUyMiUzQSUyMDAlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJsb3NzX3NjYWxlX3dpbmRvdyUyMiUzQSUyMDEwMDAlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJpbml0aWFsX3NjYWxlX3Bvd2VyJTIyJTNBJTIwMTYlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJoeXN0ZXJlc2lzJTIyJTNBJTIwMiUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMm1pbl9sb3NzX3NjYWxlJTIyJTNBJTIwMSUwQSUyMCUyMCUyMCUyMCU3RCUwQSU3RA==",highlighted:`{
    <span class="hljs-attr">&quot;fp16&quot;:</span> {
        <span class="hljs-attr">&quot;enabled&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
        <span class="hljs-attr">&quot;loss_scale&quot;:</span> <span class="hljs-number">0</span>,
        <span class="hljs-attr">&quot;loss_scale_window&quot;:</span> <span class="hljs-number">1000</span>,
        <span class="hljs-attr">&quot;initial_scale_power&quot;:</span> <span class="hljs-number">16</span>,
        <span class="hljs-attr">&quot;hysteresis&quot;:</span> <span class="hljs-number">2</span>,
        <span class="hljs-attr">&quot;min_loss_scale&quot;:</span> <span class="hljs-number">1</span>
    }
}`,wrap:!1}}),B=new W({props:{code:"JTdCJTBBJTIwJTIwJTIwJTIwJTIyYW1wJTIyJTNBJTIwJTdCJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIyZW5hYmxlZCUyMiUzQSUyMCUyMmF1dG8lMjIlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJvcHRfbGV2ZWwlMjIlM0ElMjAlMjJhdXRvJTIyJTBBJTIwJTIwJTIwJTIwJTdEJTBBJTdE",highlighted:`{
    <span class="hljs-attr">&quot;amp&quot;:</span> {
        <span class="hljs-attr">&quot;enabled&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
        <span class="hljs-attr">&quot;opt_level&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>
    }
}`,wrap:!1}}),{c(){t=c("p"),t.innerHTML=y,n=M(),d(r.$$.fragment),o=M(),i=c("p"),i.innerHTML=u,C=M(),I=c("p"),I.innerHTML=Z,g=M(),d(B.$$.fragment)},l(m){t=T(m,"P",{"data-svelte-h":!0}),f(t)!=="svelte-1v68rht"&&(t.innerHTML=y),n=p(m),J(r.$$.fragment,m),o=p(m),i=T(m,"P",{"data-svelte-h":!0}),f(i)!=="svelte-rsxg0g"&&(i.innerHTML=u),C=p(m),I=T(m,"P",{"data-svelte-h":!0}),f(I)!=="svelte-y0jb57"&&(I.innerHTML=Z),g=p(m),J(B.$$.fragment,m)},m(m,q){s(m,t,q),s(m,n,q),w(r,m,q),s(m,o,q),s(m,i,q),s(m,C,q),s(m,I,q),s(m,g,q),w(B,m,q),A=!0},p:N,i(m){A||(U(r.$$.fragment,m),U(B.$$.fragment,m),A=!0)},o(m){j(r.$$.fragment,m),j(B.$$.fragment,m),A=!1},d(m){m&&(l(t),l(n),l(o),l(i),l(C),l(I),l(g)),h(r,m),h(B,m)}}}function Ro(v){let t,y="bf16 requires DeepSpeed 0.6.0.";return{c(){t=c("p"),t.textContent=y},l(n){t=T(n,"P",{"data-svelte-h":!0}),f(t)!=="svelte-1htv7ke"&&(t.textContent=y)},m(n,r){s(n,t,r)},p:N,d(n){n&&l(t)}}}function zo(v){let t,y,n,r='bf16 has the same dynamic range as fp32, and doesn’t require loss scaling unlike fp16. However, if you use <a href="#gradient-accumulation">gradient accumulation</a> with bf16, gradients are accumulated in bf16 which may not be desirable because the lower precision can lead to lossy accumulation.',o,i,u="bf16 can be set up in the config file or enabled from the command line when the following arguments are passed: <code>--bf16</code> or <code>--bf16_full_eval</code>.",C,I,Z;return t=new K({props:{warning:!1,$$slots:{default:[Ro]},$$scope:{ctx:v}}}),I=new W({props:{code:"JTdCJTBBJTIwJTIwJTIwJTIwJTIyYmYxNiUyMiUzQSUyMCU3QiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMmVuYWJsZWQlMjIlM0ElMjAlMjJhdXRvJTIyJTBBJTIwJTIwJTIwJTIwJTdEJTBBJTdE",highlighted:`{
    <span class="hljs-attr">&quot;bf16&quot;:</span> {
        <span class="hljs-attr">&quot;enabled&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>
    }
}`,wrap:!1}}),{c(){d(t.$$.fragment),y=M(),n=c("p"),n.innerHTML=r,o=M(),i=c("p"),i.innerHTML=u,C=M(),d(I.$$.fragment)},l(g){J(t.$$.fragment,g),y=p(g),n=T(g,"P",{"data-svelte-h":!0}),f(n)!=="svelte-ticf5p"&&(n.innerHTML=r),o=p(g),i=T(g,"P",{"data-svelte-h":!0}),f(i)!=="svelte-16y6xu3"&&(i.innerHTML=u),C=p(g),J(I.$$.fragment,g)},m(g,B){w(t,g,B),s(g,y,B),s(g,n,B),s(g,o,B),s(g,i,B),s(g,C,B),w(I,g,B),Z=!0},p(g,B){const A={};B&2&&(A.$$scope={dirty:B,ctx:g}),t.$set(A)},i(g){Z||(U(t.$$.fragment,g),U(I.$$.fragment,g),Z=!0)},o(g){j(t.$$.fragment,g),j(I.$$.fragment,g),Z=!1},d(g){g&&(l(y),l(n),l(o),l(i),l(C)),h(t,g),h(I,g)}}}function ko(v){let t,y,n,r,o,i;return t=new X({props:{id:"precision",option:"fp32",$$slots:{default:[qo]},$$scope:{ctx:v}}}),n=new X({props:{id:"precision",option:"fp16",$$slots:{default:[Wo]},$$scope:{ctx:v}}}),o=new X({props:{id:"precision",option:"bf16",$$slots:{default:[zo]},$$scope:{ctx:v}}}),{c(){d(t.$$.fragment),y=M(),d(n.$$.fragment),r=M(),d(o.$$.fragment)},l(u){J(t.$$.fragment,u),y=p(u),J(n.$$.fragment,u),r=p(u),J(o.$$.fragment,u)},m(u,C){w(t,u,C),s(u,y,C),w(n,u,C),s(u,r,C),w(o,u,C),i=!0},p(u,C){const I={};C&2&&(I.$$scope={dirty:C,ctx:u}),t.$set(I);const Z={};C&2&&(Z.$$scope={dirty:C,ctx:u}),n.$set(Z);const g={};C&2&&(g.$$scope={dirty:C,ctx:u}),o.$set(g)},i(u){i||(U(t.$$.fragment,u),U(n.$$.fragment,u),U(o.$$.fragment,u),i=!0)},o(u){j(t.$$.fragment,u),j(n.$$.fragment,u),j(o.$$.fragment,u),i=!1},d(u){u&&(l(y),l(r)),h(t,u),h(n,u),h(o,u)}}}function No(v){let t,y='DeepSpeed offers several <a href="https://www.deepspeed.ai/docs/config-json/#optimizer-parameters" rel="nofollow">optimizers</a> (Adam, AdamW, OneBitAdam, and LAMB) but you can also import other optimizers from PyTorch. If you don’t configure the optimizer in the config, <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> automatically selects AdamW and either uses the supplied values or the default values for the following parameters from the command line: <code>lr</code>, <code>adam_beta1</code>, <code>adam_beta2</code>, <code>adam_epsilon</code>, <code>weight_decay</code>.',n,r,o="You can set the parameters to <code>&quot;auto&quot;</code> or manually input your own values.",i,u,C,I,Z="Use an unsupported optimizer by adding the following to the top level configuration.",g,B,A,m,q="From DeepSpeed 0.8.3+, if you want to use offload, you’ll also need to add the following to the top level configuration because offload works best with DeepSpeed’s CPU Adam optimizer.",R,S,$;return u=new W({props:{code:"JTdCJTBBJTIwJTIwJTIwJTIyb3B0aW1pemVyJTIyJTNBJTIwJTdCJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIydHlwZSUyMiUzQSUyMCUyMkFkYW1XJTIyJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIycGFyYW1zJTIyJTNBJTIwJTdCJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIybHIlMjIlM0ElMjAlMjJhdXRvJTIyJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIyYmV0YXMlMjIlM0ElMjAlMjJhdXRvJTIyJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIyZXBzJTIyJTNBJTIwJTIyYXV0byUyMiUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMndlaWdodF9kZWNheSUyMiUzQSUyMCUyMmF1dG8lMjIlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlN0QlMEElMjAlMjAlMjAlN0QlMEElN0Q=",highlighted:`{
   <span class="hljs-attr">&quot;optimizer&quot;:</span> {
       <span class="hljs-attr">&quot;type&quot;:</span> <span class="hljs-string">&quot;AdamW&quot;</span>,
       <span class="hljs-attr">&quot;params&quot;:</span> {
         <span class="hljs-attr">&quot;lr&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
         <span class="hljs-attr">&quot;betas&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
         <span class="hljs-attr">&quot;eps&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
         <span class="hljs-attr">&quot;weight_decay&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>
       }
   }
}`,wrap:!1}}),B=new W({props:{code:"JTdCJTBBJTIwJTIwJTIwJTIyemVyb19hbGxvd191bnRlc3RlZF9vcHRpbWl6ZXIlMjIlM0ElMjB0cnVlJTBBJTdE",highlighted:`{
   <span class="hljs-attr">&quot;zero_allow_untested_optimizer&quot;:</span> <span class="hljs-literal">true</span>
}`,wrap:!1}}),S=new W({props:{code:"JTdCJTBBJTIwJTIwJTIwJTIyemVyb19mb3JjZV9kc19jcHVfb3B0aW1pemVyJTIyJTNBJTIwZmFsc2UlMEElN0Q=",highlighted:`{
   <span class="hljs-attr">&quot;zero_force_ds_cpu_optimizer&quot;:</span> <span class="hljs-literal">false</span>
}`,wrap:!1}}),{c(){t=c("p"),t.innerHTML=y,n=M(),r=c("p"),r.innerHTML=o,i=M(),d(u.$$.fragment),C=M(),I=c("p"),I.textContent=Z,g=M(),d(B.$$.fragment),A=M(),m=c("p"),m.textContent=q,R=M(),d(S.$$.fragment)},l(b){t=T(b,"P",{"data-svelte-h":!0}),f(t)!=="svelte-v1koo2"&&(t.innerHTML=y),n=p(b),r=T(b,"P",{"data-svelte-h":!0}),f(r)!=="svelte-1uw9d8y"&&(r.innerHTML=o),i=p(b),J(u.$$.fragment,b),C=p(b),I=T(b,"P",{"data-svelte-h":!0}),f(I)!=="svelte-1k1vfhb"&&(I.textContent=Z),g=p(b),J(B.$$.fragment,b),A=p(b),m=T(b,"P",{"data-svelte-h":!0}),f(m)!=="svelte-cul5b4"&&(m.textContent=q),R=p(b),J(S.$$.fragment,b)},m(b,G){s(b,t,G),s(b,n,G),s(b,r,G),s(b,i,G),w(u,b,G),s(b,C,G),s(b,I,G),s(b,g,G),w(B,b,G),s(b,A,G),s(b,m,G),s(b,R,G),w(S,b,G),$=!0},p:N,i(b){$||(U(u.$$.fragment,b),U(B.$$.fragment,b),U(S.$$.fragment,b),$=!0)},o(b){j(u.$$.fragment,b),j(B.$$.fragment,b),j(S.$$.fragment,b),$=!1},d(b){b&&(l(t),l(n),l(r),l(i),l(C),l(I),l(g),l(A),l(m),l(R)),h(u,b),h(B,b),h(S,b)}}}function Go(v){let t,y='DeepSpeed supports the LRRangeTest, OneCycle, WarmupLR and WarmupDecayLR learning rate <a href="https://www.deepspeed.ai/docs/config-json/#scheduler-parameters" rel="nofollow">schedulers</a>.',n,r,o="Transformers and DeepSpeed provide two of the same schedulers:",i,u,C="<li>WarmupLR is the same as <code>--lr_scheduler_type constant_with_warmup</code> in Transformers.</li> <li>WarmupDecayLR is the same as  <code>--lr_scheduler_type linear</code> in Transformers (this is the default scheduler used in Transformers).</li>",I,Z,g='If you don’t configure the scheduler in the config file, <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> automatically selects WarmupDecayLR and either uses the supplied values or the default values for the following parameters from the command line: <code>warmup_min_lr</code>, <code>warmup_max_lr</code>, <code>warmup_num_steps</code>, <code>total_num_steps</code> (automatically calculated during run time if <code>max_steps</code> is not provided).',B,A,m="You can set the parameters to <code>&quot;auto&quot;</code> or manually input your own values.",q,R,S;return R=new W({props:{code:"JTdCJTBBJTIwJTIwJTIwJTIyc2NoZWR1bGVyJTIyJTNBJTIwJTdCJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIydHlwZSUyMiUzQSUyMCUyMldhcm11cERlY2F5TFIlMjIlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJwYXJhbXMlMjIlM0ElMjAlN0IlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJ0b3RhbF9udW1fc3RlcHMlMjIlM0ElMjAlMjJhdXRvJTIyJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIyd2FybXVwX21pbl9sciUyMiUzQSUyMCUyMmF1dG8lMjIlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJ3YXJtdXBfbWF4X2xyJTIyJTNBJTIwJTIyYXV0byUyMiUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMndhcm11cF9udW1fc3RlcHMlMjIlM0ElMjAlMjJhdXRvJTIyJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTdEJTBBJTIwJTIwJTIwJTIwJTIwJTdEJTBBJTdE",highlighted:`{
   <span class="hljs-attr">&quot;scheduler&quot;:</span> {
         <span class="hljs-attr">&quot;type&quot;:</span> <span class="hljs-string">&quot;WarmupDecayLR&quot;</span>,
         <span class="hljs-attr">&quot;params&quot;:</span> {
             <span class="hljs-attr">&quot;total_num_steps&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
             <span class="hljs-attr">&quot;warmup_min_lr&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
             <span class="hljs-attr">&quot;warmup_max_lr&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
             <span class="hljs-attr">&quot;warmup_num_steps&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>
         }
     }
}`,wrap:!1}}),{c(){t=c("p"),t.innerHTML=y,n=M(),r=c("p"),r.textContent=o,i=M(),u=c("ul"),u.innerHTML=C,I=M(),Z=c("p"),Z.innerHTML=g,B=M(),A=c("p"),A.innerHTML=m,q=M(),d(R.$$.fragment)},l($){t=T($,"P",{"data-svelte-h":!0}),f(t)!=="svelte-1te33vu"&&(t.innerHTML=y),n=p($),r=T($,"P",{"data-svelte-h":!0}),f(r)!=="svelte-6jv6ql"&&(r.textContent=o),i=p($),u=T($,"UL",{"data-svelte-h":!0}),f(u)!=="svelte-1en9xj"&&(u.innerHTML=C),I=p($),Z=T($,"P",{"data-svelte-h":!0}),f(Z)!=="svelte-1w5aqjy"&&(Z.innerHTML=g),B=p($),A=T($,"P",{"data-svelte-h":!0}),f(A)!=="svelte-1uw9d8y"&&(A.innerHTML=m),q=p($),J(R.$$.fragment,$)},m($,b){s($,t,b),s($,n,b),s($,r,b),s($,i,b),s($,u,b),s($,I,b),s($,Z,b),s($,B,b),s($,A,b),s($,q,b),w(R,$,b),S=!0},p:N,i($){S||(U(R.$$.fragment,$),S=!0)},o($){j(R.$$.fragment,$),S=!1},d($){$&&(l(t),l(n),l(r),l(i),l(u),l(I),l(Z),l(B),l(A),l(q)),h(R,$)}}}function So(v){let t,y,n,r;return t=new X({props:{id:"opt-sched",option:"optimizer",$$slots:{default:[No]},$$scope:{ctx:v}}}),n=new X({props:{id:"opt-sched",option:"scheduler",$$slots:{default:[Go]},$$scope:{ctx:v}}}),{c(){d(t.$$.fragment),y=M(),d(n.$$.fragment)},l(o){J(t.$$.fragment,o),y=p(o),J(n.$$.fragment,o)},m(o,i){w(t,o,i),s(o,y,i),w(n,o,i),r=!0},p(o,i){const u={};i&2&&(u.$$scope={dirty:i,ctx:o}),t.$set(u);const C={};i&2&&(C.$$scope={dirty:i,ctx:o}),n.$set(C)},i(o){r||(U(t.$$.fragment,o),U(n.$$.fragment,o),r=!0)},o(o){j(t.$$.fragment,o),j(n.$$.fragment,o),r=!1},d(o){o&&l(y),h(t,o),h(n,o)}}}function Xo(v){let t,y="To deploy DeepSpeed on multiple GPUs, add <code>--num_gpus</code>. You don’t need to add <code>--num_gpus</code> if you’re planning on using all available GPUs.",n,r,o;return r=new W({props:{code:"ZGVlcHNwZWVkJTIwLS1udW1fZ3B1cyUzRDIlMjBleGFtcGxlcyUyRnB5dG9yY2glMkZ0cmFuc2xhdGlvbiUyRnJ1bl90cmFuc2xhdGlvbi5weSUyMCU1QyUwQS0tZGVlcHNwZWVkJTIwdGVzdHMlMkZkZWVwc3BlZWQlMkZkc19jb25maWdfemVybzMuanNvbiUyMCU1QyUwQS0tbW9kZWxfbmFtZV9vcl9wYXRoJTIwZ29vZ2xlLXQ1JTJGdDUtc21hbGwlMjAtLXBlcl9kZXZpY2VfdHJhaW5fYmF0Y2hfc2l6ZSUyMDElMjAlNUMlMEEtLW91dHB1dF9kaXIlMjBvdXRwdXRfZGlyJTIwLS1vdmVyd3JpdGVfb3V0cHV0X2RpciUyMC0tZnAxNiUyMCU1QyUwQS0tZG9fdHJhaW4lMjAtLW1heF90cmFpbl9zYW1wbGVzJTIwNTAwJTIwLS1udW1fdHJhaW5fZXBvY2hzJTIwMSUyMCU1QyUwQS0tZGF0YXNldF9uYW1lJTIwd210MTYlMjAtLWRhdGFzZXRfY29uZmlnJTIwJTIycm8tZW4lMjIlMjAlNUMlMEEtLXNvdXJjZV9sYW5nJTIwZW4lMjAtLXRhcmdldF9sYW5nJTIwcm8=",highlighted:`deepspeed --num_gpus=2 examples/pytorch/translation/run_translation.py \\
--deepspeed tests/deepspeed/ds_config_zero3.json \\
--model_name_or_path google-t5/t5-small --per_device_train_batch_size 1 \\
--output_dir output_dir --overwrite_output_dir --fp16 \\
--do_train --max_train_samples 500 --num_train_epochs 1 \\
--dataset_name wmt16 --dataset_config <span class="hljs-string">&quot;ro-en&quot;</span> \\
--source_lang en --target_lang ro`,wrap:!1}}),{c(){t=c("p"),t.innerHTML=y,n=M(),d(r.$$.fragment)},l(i){t=T(i,"P",{"data-svelte-h":!0}),f(t)!=="svelte-1njfqta"&&(t.innerHTML=y),n=p(i),J(r.$$.fragment,i)},m(i,u){s(i,t,u),s(i,n,u),w(r,i,u),o=!0},p:N,i(i){o||(U(r.$$.fragment,i),o=!0)},o(i){j(r.$$.fragment,i),o=!1},d(i){i&&(l(t),l(n)),h(r,i)}}}function Eo(v){let t,y='Set the <code>allgather_bucket_size</code> and <code>reduce_bucket_size</code> values to 2e8 in the <a href="#zero-configuration">ZeRO-2</a> configuration file to get better performance on a single GPU.';return{c(){t=c("p"),t.innerHTML=y},l(n){t=T(n,"P",{"data-svelte-h":!0}),f(t)!=="svelte-dwa9lr"&&(t.innerHTML=y)},m(n,r){s(n,t,r)},p:N,d(n){n&&l(t)}}}function Qo(v){let t,y="DeepSpeed is still useful with just one GPU because you can:",n,r,o="<li>Offload some computations and memory to the CPU to make more GPU resources available to your model to use a larger batch size or fit a very large model that normally won’t fit.</li> <li>Minimize memory fragmentation with its smart GPU memory management system which also allows you to fit bigger models and data batches.</li>",i,u,C="To deploy DeepSpeed on a single GPU, add <code>--num_gpus</code>. You don’t need to add <code>--num_gpus</code> if you only have one GPU because DeepSpeed deploys all GPUs it can see on a given node.",I,Z,g,B,A;return Z=new K({props:{warning:!1,$$slots:{default:[Eo]},$$scope:{ctx:v}}}),B=new W({props:{code:"ZGVlcHNwZWVkJTIwLS1udW1fZ3B1cyUzRDElMjBleGFtcGxlcyUyRnB5dG9yY2glMkZ0cmFuc2xhdGlvbiUyRnJ1bl90cmFuc2xhdGlvbi5weSUyMCU1QyUwQS0tZGVlcHNwZWVkJTIwdGVzdHMlMkZkZWVwc3BlZWQlMkZkc19jb25maWdfemVybzIuanNvbiUyMCU1QyUwQS0tbW9kZWxfbmFtZV9vcl9wYXRoJTIwZ29vZ2xlLXQ1JTJGdDUtc21hbGwlMjAtLXBlcl9kZXZpY2VfdHJhaW5fYmF0Y2hfc2l6ZSUyMDElMjAlNUMlMEEtLW91dHB1dF9kaXIlMjBvdXRwdXRfZGlyJTIwLS1vdmVyd3JpdGVfb3V0cHV0X2RpciUyMC0tZnAxNiUyMCU1QyUwQS0tZG9fdHJhaW4lMjAtLW1heF90cmFpbl9zYW1wbGVzJTIwNTAwJTIwLS1udW1fdHJhaW5fZXBvY2hzJTIwMSUyMCU1QyUwQS0tZGF0YXNldF9uYW1lJTIwd210MTYlMjAtLWRhdGFzZXRfY29uZmlnJTIwJTIycm8tZW4lMjIlMjAlNUMlMEEtLXNvdXJjZV9sYW5nJTIwZW4lMjAtLXRhcmdldF9sYW5nJTIwcm8=",highlighted:`deepspeed --num_gpus=1 examples/pytorch/translation/run_translation.py \\
--deepspeed tests/deepspeed/ds_config_zero2.json \\
--model_name_or_path google-t5/t5-small --per_device_train_batch_size 1 \\
--output_dir output_dir --overwrite_output_dir --fp16 \\
--do_train --max_train_samples 500 --num_train_epochs 1 \\
--dataset_name wmt16 --dataset_config <span class="hljs-string">&quot;ro-en&quot;</span> \\
--source_lang en --target_lang ro`,wrap:!1}}),{c(){t=c("p"),t.textContent=y,n=M(),r=c("ol"),r.innerHTML=o,i=M(),u=c("p"),u.innerHTML=C,I=M(),d(Z.$$.fragment),g=M(),d(B.$$.fragment)},l(m){t=T(m,"P",{"data-svelte-h":!0}),f(t)!=="svelte-184totu"&&(t.textContent=y),n=p(m),r=T(m,"OL",{"data-svelte-h":!0}),f(r)!=="svelte-1wgqgx9"&&(r.innerHTML=o),i=p(m),u=T(m,"P",{"data-svelte-h":!0}),f(u)!=="svelte-1hslfhv"&&(u.innerHTML=C),I=p(m),J(Z.$$.fragment,m),g=p(m),J(B.$$.fragment,m)},m(m,q){s(m,t,q),s(m,n,q),s(m,r,q),s(m,i,q),s(m,u,q),s(m,I,q),w(Z,m,q),s(m,g,q),w(B,m,q),A=!0},p(m,q){const R={};q&2&&(R.$$scope={dirty:q,ctx:m}),Z.$set(R)},i(m){A||(U(Z.$$.fragment,m),U(B.$$.fragment,m),A=!0)},o(m){j(Z.$$.fragment,m),j(B.$$.fragment,m),A=!1},d(m){m&&(l(t),l(n),l(r),l(i),l(u),l(I),l(g)),h(Z,m),h(B,m)}}}function Vo(v){let t,y,n,r;return t=new X({props:{id:"deploy",option:"multi-GPU",$$slots:{default:[Xo]},$$scope:{ctx:v}}}),n=new X({props:{id:"deploy",option:"single-GPU",$$slots:{default:[Qo]},$$scope:{ctx:v}}}),{c(){d(t.$$.fragment),y=M(),d(n.$$.fragment)},l(o){J(t.$$.fragment,o),y=p(o),J(n.$$.fragment,o)},m(o,i){w(t,o,i),s(o,y,i),w(n,o,i),r=!0},p(o,i){const u={};i&2&&(u.$$scope={dirty:i,ctx:o}),t.$set(u);const C={};i&2&&(C.$$scope={dirty:i,ctx:o}),n.$set(C)},i(o){r||(U(t.$$.fragment,o),U(n.$$.fragment,o),r=!0)},o(o){j(t.$$.fragment,o),j(n.$$.fragment,o),r=!1},d(o){o&&l(y),h(t,o),h(n,o)}}}function xo(v){let t,y='With <a href="https://pytorch.org/docs/stable/elastic/run.html" rel="nofollow">torchrun</a>, ssh to each node and run the following command on both of them. The launcher waits until both nodes are synchronized before launching the training.',n,r,o;return r=new W({props:{code:"dG9yY2hydW4lMjAtLW5wcm9jX3Blcl9ub2RlJTNEOCUyMC0tbm5vZGUlM0QyJTIwLS1ub2RlX3JhbmslM0QwJTIwLS1tYXN0ZXJfYWRkciUzRGhvc3RuYW1lMSUyMCU1QyUwQS0tbWFzdGVyX3BvcnQlM0Q5OTAxJTIweW91cl9wcm9ncmFtLnB5JTIwJTNDbm9ybWFsJTIwY2wlMjBhcmdzJTNFJTIwLS1kZWVwc3BlZWQlMjBkc19jb25maWcuanNvbg==",highlighted:`torchrun --nproc_per_node=8 --nnode=2 --node_rank=0 --master_addr=hostname1 \\
--master_port=9901 your_program.py &lt;normal cl args&gt; --deepspeed ds_config.json`,wrap:!1}}),{c(){t=c("p"),t.innerHTML=y,n=M(),d(r.$$.fragment)},l(i){t=T(i,"P",{"data-svelte-h":!0}),f(t)!=="svelte-bd1gud"&&(t.innerHTML=y),n=p(i),J(r.$$.fragment,i)},m(i,u){s(i,t,u),s(i,n,u),w(r,i,u),o=!0},p:N,i(i){o||(U(r.$$.fragment,i),o=!0)},o(i){j(r.$$.fragment,i),o=!1},d(i){i&&(l(t),l(n)),h(r,i)}}}function Ho(v){let t,y="Create a <code>hostfile</code> for the DeepSpeed launcher.",n,r,o,i,u="The DeepSpeed launcher automatically launches the command on both nodes at once with the command below.",C,I,Z,g,B='Check out the <a href="https://www.deepspeed.ai/getting-started/#resource-configuration-multi-node" rel="nofollow">Resource Configuration (multi-node)</a> guide for more details about configuring multi-node compute resources.',A;return r=new W({props:{code:"aG9zdG5hbWUxJTIwc2xvdHMlM0Q4JTBBaG9zdG5hbWUyJTIwc2xvdHMlM0Q4",highlighted:`hostname1 slots=8
hostname2 slots=8`,wrap:!1}}),I=new W({props:{code:"ZGVlcHNwZWVkJTIwLS1udW1fZ3B1cyUyMDglMjAtLW51bV9ub2RlcyUyMDIlMjAtLWhvc3RmaWxlJTIwaG9zdGZpbGUlMjAtLW1hc3Rlcl9hZGRyJTIwaG9zdG5hbWUxJTIwLS1tYXN0ZXJfcG9ydCUzRDk5MDElMjAlNUMlMEF5b3VyX3Byb2dyYW0ucHklMjAlM0Nub3JtYWwlMjBjbCUyMGFyZ3MlM0UlMjAtLWRlZXBzcGVlZCUyMGRzX2NvbmZpZy5qc29u",highlighted:`deepspeed --num_gpus 8 --num_nodes 2 --hostfile hostfile --master_addr hostname1 --master_port=9901 \\
your_program.py &lt;normal cl args&gt; --deepspeed ds_config.json`,wrap:!1}}),{c(){t=c("p"),t.innerHTML=y,n=M(),d(r.$$.fragment),o=M(),i=c("p"),i.textContent=u,C=M(),d(I.$$.fragment),Z=M(),g=c("p"),g.innerHTML=B},l(m){t=T(m,"P",{"data-svelte-h":!0}),f(t)!=="svelte-ugaro7"&&(t.innerHTML=y),n=p(m),J(r.$$.fragment,m),o=p(m),i=T(m,"P",{"data-svelte-h":!0}),f(i)!=="svelte-1o29984"&&(i.textContent=u),C=p(m),J(I.$$.fragment,m),Z=p(m),g=T(m,"P",{"data-svelte-h":!0}),f(g)!=="svelte-1ahoskn"&&(g.innerHTML=B)},m(m,q){s(m,t,q),s(m,n,q),w(r,m,q),s(m,o,q),s(m,i,q),s(m,C,q),w(I,m,q),s(m,Z,q),s(m,g,q),A=!0},p:N,i(m){A||(U(r.$$.fragment,m),U(I.$$.fragment,m),A=!0)},o(m){j(r.$$.fragment,m),j(I.$$.fragment,m),A=!1},d(m){m&&(l(t),l(n),l(o),l(i),l(C),l(Z),l(g)),h(r,m),h(I,m)}}}function Fo(v){let t,y,n,r;return t=new X({props:{id:"multinode",option:"torchrun",$$slots:{default:[xo]},$$scope:{ctx:v}}}),n=new X({props:{id:"multinode",option:"DeepSpeed",$$slots:{default:[Ho]},$$scope:{ctx:v}}}),{c(){d(t.$$.fragment),y=M(),d(n.$$.fragment)},l(o){J(t.$$.fragment,o),y=p(o),J(n.$$.fragment,o)},m(o,i){w(t,o,i),s(o,y,i),w(n,o,i),r=!0},p(o,i){const u={};i&2&&(u.$$scope={dirty:i,ctx:o}),t.$set(u);const C={};i&2&&(C.$$scope={dirty:i,ctx:o}),n.$set(C)},i(o){r||(U(t.$$.fragment,o),U(n.$$.fragment,o),r=!0)},o(o){j(t.$$.fragment,o),j(n.$$.fragment,o),r=!1},d(o){o&&l(y),h(t,o),h(n,o)}}}function Yo(v){let t,y="Run <code>python zero_to_fp32.py -h</code> for more usage details. The script requires 2x the general RAM of the final fp32 weights.";return{c(){t=c("p"),t.innerHTML=y},l(n){t=T(n,"P",{"data-svelte-h":!0}),f(t)!=="svelte-1ds22pg"&&(t.innerHTML=y)},m(n,r){s(n,t,r)},p:N,d(n){n&&l(t)}}}function Lo(v){let t,y='DeepSpeed provides a <a href="https://github.com/microsoft/DeepSpeed/blob/91829476a8fd4d0d9268c03c1d56795d20a51c12/deepspeed/utils/zero_to_fp32.py#L14" rel="nofollow">zero_to_fp32.py</a> script at the top-level checkpoint folder for extracting weights at any point. This is a standalone script and you don’t need a config file or <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a>.',n,r,o="For example, if your checkpoint folder looks like the one shown below, then you can run the following command to create and consolidate the fp32 weights from multiple GPUs into a single <code>pytorch_model.bin</code> file. The script automatically discovers the subfolder <code>global_step1</code> which contains the checkpoint.",i,u,C,I,Z,g,B;return u=new W({props:{code:"JTI0JTIwbHMlMjAtbCUyMG91dHB1dF9kaXIlMkZjaGVja3BvaW50LTElMkYlMEEtcnctcnctci0tJTIwMSUyMHN0YXMlMjBzdGFzJTIwMS40SyUyME1hciUyMDI3JTIwMjAlM0E0MiUyMGNvbmZpZy5qc29uJTBBZHJ3eHJ3eHIteCUyMDIlMjBzdGFzJTIwc3RhcyUyMDQuMEslMjBNYXIlMjAyNSUyMDE5JTNBNTIlMjBnbG9iYWxfc3RlcDElMkYlMEEtcnctcnctci0tJTIwMSUyMHN0YXMlMjBzdGFzJTIwJTIwJTIwMTIlMjBNYXIlMjAyNyUyMDEzJTNBMTYlMjBsYXRlc3QlMEEtcnctcnctci0tJTIwMSUyMHN0YXMlMjBzdGFzJTIwODI3SyUyME1hciUyMDI3JTIwMjAlM0E0MiUyMG9wdGltaXplci5wdCUwQS1ydy1ydy1yLS0lMjAxJTIwc3RhcyUyMHN0YXMlMjAyMzFNJTIwTWFyJTIwMjclMjAyMCUzQTQyJTIwcHl0b3JjaF9tb2RlbC5iaW4lMEEtcnctcnctci0tJTIwMSUyMHN0YXMlMjBzdGFzJTIwJTIwNjIzJTIwTWFyJTIwMjclMjAyMCUzQTQyJTIwc2NoZWR1bGVyLnB0JTBBLXJ3LXJ3LXItLSUyMDElMjBzdGFzJTIwc3RhcyUyMDEuOEslMjBNYXIlMjAyNyUyMDIwJTNBNDIlMjBzcGVjaWFsX3Rva2Vuc19tYXAuanNvbiUwQS1ydy1ydy1yLS0lMjAxJTIwc3RhcyUyMHN0YXMlMjA3NzRLJTIwTWFyJTIwMjclMjAyMCUzQTQyJTIwc3BpZWNlLm1vZGVsJTBBLXJ3LXJ3LXItLSUyMDElMjBzdGFzJTIwc3RhcyUyMDEuOUslMjBNYXIlMjAyNyUyMDIwJTNBNDIlMjB0b2tlbml6ZXJfY29uZmlnLmpzb24lMEEtcnctcnctci0tJTIwMSUyMHN0YXMlMjBzdGFzJTIwJTIwMzM5JTIwTWFyJTIwMjclMjAyMCUzQTQyJTIwdHJhaW5lcl9zdGF0ZS5qc29uJTBBLXJ3LXJ3LXItLSUyMDElMjBzdGFzJTIwc3RhcyUyMDIuM0slMjBNYXIlMjAyNyUyMDIwJTNBNDIlMjB0cmFpbmluZ19hcmdzLmJpbiUwQS1yd3hydy1yLS0lMjAxJTIwc3RhcyUyMHN0YXMlMjA1LjVLJTIwTWFyJTIwMjclMjAxMyUzQTE2JTIwemVyb190b19mcDMyLnB5Kg==",highlighted:`$ <span class="hljs-built_in">ls</span> -l output_dir/checkpoint-1/
-rw-rw-r-- 1 stas stas 1.4K Mar 27 20:42 config.json
drwxrwxr-x 2 stas stas 4.0K Mar 25 19:52 global_step1/
-rw-rw-r-- 1 stas stas   12 Mar 27 13:16 latest
-rw-rw-r-- 1 stas stas 827K Mar 27 20:42 optimizer.pt
-rw-rw-r-- 1 stas stas 231M Mar 27 20:42 pytorch_model.bin
-rw-rw-r-- 1 stas stas  623 Mar 27 20:42 scheduler.pt
-rw-rw-r-- 1 stas stas 1.8K Mar 27 20:42 special_tokens_map.json
-rw-rw-r-- 1 stas stas 774K Mar 27 20:42 spiece.model
-rw-rw-r-- 1 stas stas 1.9K Mar 27 20:42 tokenizer_config.json
-rw-rw-r-- 1 stas stas  339 Mar 27 20:42 trainer_state.json
-rw-rw-r-- 1 stas stas 2.3K Mar 27 20:42 training_args.bin
-rwxrw-r-- 1 stas stas 5.5K Mar 27 13:16 zero_to_fp32.py*`,wrap:!1}}),I=new K({props:{warning:!1,$$slots:{default:[Yo]},$$scope:{ctx:v}}}),g=new W({props:{code:"cHl0aG9uJTIwemVyb190b19mcDMyLnB5JTIwLiUyMHB5dG9yY2hfbW9kZWwuYmlu",highlighted:"python zero_to_fp32.py . pytorch_model.bin",wrap:!1}}),{c(){t=c("p"),t.innerHTML=y,n=M(),r=c("p"),r.innerHTML=o,i=M(),d(u.$$.fragment),C=M(),d(I.$$.fragment),Z=M(),d(g.$$.fragment)},l(A){t=T(A,"P",{"data-svelte-h":!0}),f(t)!=="svelte-s5ymcs"&&(t.innerHTML=y),n=p(A),r=T(A,"P",{"data-svelte-h":!0}),f(r)!=="svelte-6k8ztx"&&(r.innerHTML=o),i=p(A),J(u.$$.fragment,A),C=p(A),J(I.$$.fragment,A),Z=p(A),J(g.$$.fragment,A)},m(A,m){s(A,t,m),s(A,n,m),s(A,r,m),s(A,i,m),w(u,A,m),s(A,C,m),w(I,A,m),s(A,Z,m),w(g,A,m),B=!0},p(A,m){const q={};m&2&&(q.$$scope={dirty:m,ctx:A}),I.$set(q)},i(A){B||(U(u.$$.fragment,A),U(I.$$.fragment,A),U(g.$$.fragment,A),B=!0)},o(A){j(u.$$.fragment,A),j(I.$$.fragment,A),j(g.$$.fragment,A),B=!1},d(A){A&&(l(t),l(n),l(r),l(i),l(C),l(Z)),h(u,A),h(I,A),h(g,A)}}}function Do(v){let t,y='Once <a href="https://deepspeed.readthedocs.io/en/stable/model-checkpointing.html#deepspeed.utils.zero_to_fp32.load_state_dict_from_zero_checkpoint" rel="nofollow">load_state_dict_from_zero_checkpoint</a> is run, the model is no longer usable in DeepSpeed in the context of the same application. You’ll need to reinitialize the DeepSpeed engine because <code>model.load_state_dict(state_dict)</code> removes all the DeepSpeed magic from it. Only use this function once training is complete.';return{c(){t=c("p"),t.innerHTML=y},l(n){t=T(n,"P",{"data-svelte-h":!0}),f(t)!=="svelte-crcnd0"&&(t.innerHTML=y)},m(n,r){s(n,t,r)},p:N,d(n){n&&l(t)}}}function Po(v){let t,y='Adding the <code>--load_best_model_at_end</code> parameter in <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> tracks the best checkpoint so you can finish training first and save the final model explicitly. Reload the model as shown below.',n,r,o,i,u,C,I="You must have saved at least one checkpoint to load the latest checkpoint as shown in the example below.",Z,g,B,A,m="Use <code>load_state_dict</code> to extract and load the state_dict of the fp32 weights.",q,R,S;return r=new K({props:{warning:!0,$$slots:{default:[Do]},$$scope:{ctx:v}}}),i=new W({props:{code:"ZnJvbSUyMGRlZXBzcGVlZC51dGlscy56ZXJvX3RvX2ZwMzIlMjBpbXBvcnQlMjBsb2FkX3N0YXRlX2RpY3RfZnJvbV96ZXJvX2NoZWNrcG9pbnQlMEElMEFjaGVja3BvaW50X2RpciUyMCUzRCUyMG9zLnBhdGguam9pbih0cmFpbmVyLmFyZ3Mub3V0cHV0X2RpciUyQyUyMCUyMmNoZWNrcG9pbnQtZmluYWwlMjIpJTBBdHJhaW5lci5kZWVwc3BlZWQuc2F2ZV9jaGVja3BvaW50KGNoZWNrcG9pbnRfZGlyKSUwQWZwMzJfbW9kZWwlMjAlM0QlMjBsb2FkX3N0YXRlX2RpY3RfZnJvbV96ZXJvX2NoZWNrcG9pbnQodHJhaW5lci5tb2RlbCUyQyUyMGNoZWNrcG9pbnRfZGlyKQ==",highlighted:`<span class="hljs-keyword">from</span> deepspeed.utils.zero_to_fp32 <span class="hljs-keyword">import</span> load_state_dict_from_zero_checkpoint

checkpoint_dir = os.path.join(trainer.args.output_dir, <span class="hljs-string">&quot;checkpoint-final&quot;</span>)
trainer.deepspeed.save_checkpoint(checkpoint_dir)
fp32_model = load_state_dict_from_zero_checkpoint(trainer.model, checkpoint_dir)`,wrap:!1}}),g=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycy50cmFpbmVyX3V0aWxzJTIwaW1wb3J0JTIwZ2V0X2xhc3RfY2hlY2twb2ludCUwQWZyb20lMjBkZWVwc3BlZWQudXRpbHMuemVyb190b19mcDMyJTIwaW1wb3J0JTIwbG9hZF9zdGF0ZV9kaWN0X2Zyb21femVyb19jaGVja3BvaW50JTBBJTBBY2hlY2twb2ludF9kaXIlMjAlM0QlMjBnZXRfbGFzdF9jaGVja3BvaW50KHRyYWluZXIuYXJncy5vdXRwdXRfZGlyKSUwQWZwMzJfbW9kZWwlMjAlM0QlMjBsb2FkX3N0YXRlX2RpY3RfZnJvbV96ZXJvX2NoZWNrcG9pbnQodHJhaW5lci5tb2RlbCUyQyUyMGNoZWNrcG9pbnRfZGlyKQ==",highlighted:`<span class="hljs-keyword">from</span> transformers.trainer_utils <span class="hljs-keyword">import</span> get_last_checkpoint
<span class="hljs-keyword">from</span> deepspeed.utils.zero_to_fp32 <span class="hljs-keyword">import</span> load_state_dict_from_zero_checkpoint

checkpoint_dir = get_last_checkpoint(trainer.args.output_dir)
fp32_model = load_state_dict_from_zero_checkpoint(trainer.model, checkpoint_dir)`,wrap:!1}}),R=new W({props:{code:"ZnJvbSUyMGRlZXBzcGVlZC51dGlscy56ZXJvX3RvX2ZwMzIlMjBpbXBvcnQlMjBnZXRfZnAzMl9zdGF0ZV9kaWN0X2Zyb21femVyb19jaGVja3BvaW50JTBBJTBBc3RhdGVfZGljdCUyMCUzRCUyMGdldF9mcDMyX3N0YXRlX2RpY3RfZnJvbV96ZXJvX2NoZWNrcG9pbnQoY2hlY2twb2ludF9kaXIpJTBBbW9kZWwlMjAlM0QlMjBtb2RlbC5jcHUoKSUwQW1vZGVsLmxvYWRfc3RhdGVfZGljdChzdGF0ZV9kaWN0KQ==",highlighted:`<span class="hljs-keyword">from</span> deepspeed.utils.zero_to_fp32 <span class="hljs-keyword">import</span> get_fp32_state_dict_from_zero_checkpoint

state_dict = get_fp32_state_dict_from_zero_checkpoint(checkpoint_dir)
model = model.cpu()
model.load_state_dict(state_dict)`,wrap:!1}}),{c(){t=c("p"),t.innerHTML=y,n=M(),d(r.$$.fragment),o=M(),d(i.$$.fragment),u=M(),C=c("p"),C.textContent=I,Z=M(),d(g.$$.fragment),B=M(),A=c("p"),A.innerHTML=m,q=M(),d(R.$$.fragment)},l($){t=T($,"P",{"data-svelte-h":!0}),f(t)!=="svelte-16a62rx"&&(t.innerHTML=y),n=p($),J(r.$$.fragment,$),o=p($),J(i.$$.fragment,$),u=p($),C=T($,"P",{"data-svelte-h":!0}),f(C)!=="svelte-42s1ya"&&(C.textContent=I),Z=p($),J(g.$$.fragment,$),B=p($),A=T($,"P",{"data-svelte-h":!0}),f(A)!=="svelte-1hz6jnl"&&(A.innerHTML=m),q=p($),J(R.$$.fragment,$)},m($,b){s($,t,b),s($,n,b),w(r,$,b),s($,o,b),w(i,$,b),s($,u,b),s($,C,b),s($,Z,b),w(g,$,b),s($,B,b),s($,A,b),s($,q,b),w(R,$,b),S=!0},p($,b){const G={};b&2&&(G.$$scope={dirty:b,ctx:$}),r.$set(G)},i($){S||(U(r.$$.fragment,$),U(i.$$.fragment,$),U(g.$$.fragment,$),U(R.$$.fragment,$),S=!0)},o($){j(r.$$.fragment,$),j(i.$$.fragment,$),j(g.$$.fragment,$),j(R.$$.fragment,$),S=!1},d($){$&&(l(t),l(n),l(o),l(u),l(C),l(Z),l(B),l(A),l(q)),h(r,$),h(i,$),h(g,$),h(R,$)}}}function Oo(v){let t,y,n,r;return t=new X({props:{id:"save",option:"offline",$$slots:{default:[Lo]},$$scope:{ctx:v}}}),n=new X({props:{id:"save",option:"online",$$slots:{default:[Po]},$$scope:{ctx:v}}}),{c(){d(t.$$.fragment),y=M(),d(n.$$.fragment)},l(o){J(t.$$.fragment,o),y=p(o),J(n.$$.fragment,o)},m(o,i){w(t,o,i),s(o,y,i),w(n,o,i),r=!0},p(o,i){const u={};i&2&&(u.$$scope={dirty:i,ctx:o}),t.$set(u);const C={};i&2&&(C.$$scope={dirty:i,ctx:o}),n.$set(C)},i(o){r||(U(t.$$.fragment,o),U(n.$$.fragment,o),r=!0)},o(o){j(t.$$.fragment,o),j(n.$$.fragment,o),r=!1},d(o){o&&l(y),h(t,o),h(n,o)}}}function Ko(v){let t,y;return t=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycy5pbnRlZ3JhdGlvbnMlMjBpbXBvcnQlMjBIZkRlZXBTcGVlZENvbmZpZyUwQWZyb20lMjB0cmFuc2Zvcm1lcnMlMjBpbXBvcnQlMjBBdXRvTW9kZWwlMEFpbXBvcnQlMjBkZWVwc3BlZWQlMEElMEElMjMlMjBEZWVwU3BlZWQlMjBjb25maWclMjBvYmplY3QlMjBvciUyMHBhdGglMjB0byUyMHRoZSUyMGZpbGUlMEFkc19jb25maWclMjAlM0QlMjAlN0IuLi4lN0QlMEElMjMlMjBtdXN0JTIwcnVuJTIwYmVmb3JlJTIwaW5zdGFudGlhdGluZyUyMHRoZSUyMG1vZGVsJTIwdG8lMjBkZXRlY3QlMjBaZVJPLTMlMEFkc2NoZiUyMCUzRCUyMEhmRGVlcFNwZWVkQ29uZmlnKGRzX2NvbmZpZyklMjAlMjAlMjMlMjBrZWVwJTIwdGhpcyUyMG9iamVjdCUyMGFsaXZlJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWwuZnJvbV9wcmV0cmFpbmVkKCUyMm9wZW5haS1jb21tdW5pdHklMkZncHQyJTIyKSUwQWVuZ2luZSUyMCUzRCUyMGRlZXBzcGVlZC5pbml0aWFsaXplKG1vZGVsJTNEbW9kZWwlMkMlMjBjb25maWdfcGFyYW1zJTNEZHNfY29uZmlnJTJDJTIwLi4uKQ==",highlighted:`<span class="hljs-keyword">from</span> transformers.integrations <span class="hljs-keyword">import</span> HfDeepSpeedConfig
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel
<span class="hljs-keyword">import</span> deepspeed

<span class="hljs-comment"># DeepSpeed config object or path to the file</span>
ds_config = {...}
<span class="hljs-comment"># must run before instantiating the model to detect ZeRO-3</span>
dschf = HfDeepSpeedConfig(ds_config)  <span class="hljs-comment"># keep this object alive</span>
model = AutoModel.from_pretrained(<span class="hljs-string">&quot;openai-community/gpt2&quot;</span>)
engine = deepspeed.initialize(model=model, config_params=ds_config, ...)`,wrap:!1}}),{c(){d(t.$$.fragment)},l(n){J(t.$$.fragment,n)},m(n,r){w(t,n,r),y=!0},p:N,i(n){y||(U(t.$$.fragment,n),y=!0)},o(n){j(t.$$.fragment,n),y=!1},d(n){h(t,n)}}}function ei(v){let t,y='<a href="/docs/transformers/v4.56.2/en/main_classes/deepspeed#transformers.integrations.HfDeepSpeedConfig">HfDeepSpeedConfig</a> is not required for ZeRO-1 or ZeRO-2.',n,r,o;return r=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycy5pbnRlZ3JhdGlvbnMlMjBpbXBvcnQlMjBIZkRlZXBTcGVlZENvbmZpZyUwQWZyb20lMjB0cmFuc2Zvcm1lcnMlMjBpbXBvcnQlMjBBdXRvTW9kZWwlMkMlMjBBdXRvQ29uZmlnJTBBaW1wb3J0JTIwZGVlcHNwZWVkJTBBJTBBJTIzJTIwRGVlcFNwZWVkJTIwY29uZmlnJTIwb2JqZWN0JTIwb3IlMjBwYXRoJTIwdG8lMjB0aGUlMjBmaWxlJTBBZHNfY29uZmlnJTIwJTNEJTIwJTdCLi4uJTdEJTBBJTIzJTIwbXVzdCUyMHJ1biUyMGJlZm9yZSUyMGluc3RhbnRpYXRpbmclMjB0aGUlMjBtb2RlbCUyMHRvJTIwZGV0ZWN0JTIwemVybyUyMDMlMEFkc2NoZiUyMCUzRCUyMEhmRGVlcFNwZWVkQ29uZmlnKGRzX2NvbmZpZyklMjAlMjAlMjMlMjBrZWVwJTIwdGhpcyUyMG9iamVjdCUyMGFsaXZlJTBBJTIzJTIwcmFuZG9tbHklMjBpbml0aWFsaXplJTIwbW9kZWwlMjB3ZWlnaHRzJTBBY29uZmlnJTIwJTNEJTIwQXV0b0NvbmZpZy5mcm9tX3ByZXRyYWluZWQoJTIyb3BlbmFpLWNvbW11bml0eSUyRmdwdDIlMjIpJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWwuZnJvbV9jb25maWcoY29uZmlnKSUwQWVuZ2luZSUyMCUzRCUyMGRlZXBzcGVlZC5pbml0aWFsaXplKG1vZGVsJTNEbW9kZWwlMkMlMjBjb25maWdfcGFyYW1zJTNEZHNfY29uZmlnJTJDJTIwLi4uKQ==",highlighted:`<span class="hljs-keyword">from</span> transformers.integrations <span class="hljs-keyword">import</span> HfDeepSpeedConfig
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel, AutoConfig
<span class="hljs-keyword">import</span> deepspeed

<span class="hljs-comment"># DeepSpeed config object or path to the file</span>
ds_config = {...}
<span class="hljs-comment"># must run before instantiating the model to detect zero 3</span>
dschf = HfDeepSpeedConfig(ds_config)  <span class="hljs-comment"># keep this object alive</span>
<span class="hljs-comment"># randomly initialize model weights</span>
config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;openai-community/gpt2&quot;</span>)
model = AutoModel.from_config(config)
engine = deepspeed.initialize(model=model, config_params=ds_config, ...)`,wrap:!1}}),{c(){t=c("p"),t.innerHTML=y,n=M(),d(r.$$.fragment)},l(i){t=T(i,"P",{"data-svelte-h":!0}),f(t)!=="svelte-kds4wg"&&(t.innerHTML=y),n=p(i),J(r.$$.fragment,i)},m(i,u){s(i,t,u),s(i,n,u),w(r,i,u),o=!0},p:N,i(i){o||(U(r.$$.fragment,i),o=!0)},o(i){j(r.$$.fragment,i),o=!1},d(i){i&&(l(t),l(n)),h(r,i)}}}function ti(v){let t,y,n,r;return t=new X({props:{id:"models",option:"pretrained model",$$slots:{default:[Ko]},$$scope:{ctx:v}}}),n=new X({props:{id:"models",option:"non-pretrained model",$$slots:{default:[ei]},$$scope:{ctx:v}}}),{c(){d(t.$$.fragment),y=M(),d(n.$$.fragment)},l(o){J(t.$$.fragment,o),y=p(o),J(n.$$.fragment,o)},m(o,i){w(t,o,i),s(o,y,i),w(n,o,i),r=!0},p(o,i){const u={};i&2&&(u.$$scope={dirty:i,ctx:o}),t.$set(u);const C={};i&2&&(C.$$scope={dirty:i,ctx:o}),n.$set(C)},i(o){r||(U(t.$$.fragment,o),U(n.$$.fragment,o),r=!0)},o(o){j(t.$$.fragment,o),j(n.$$.fragment,o),r=!1},d(o){o&&l(y),h(t,o),h(n,o)}}}function li(v){let t,y,n,r,o,i,u,C='<a href="https://www.deepspeed.ai/" rel="nofollow">DeepSpeed</a> is designed to optimize distributed training for large models with data, model, pipeline, and even a combination of all three <a href="./perf_train_gpu_many">parallelism</a> strategies to provide better memory efficiency and faster training speeds. This is achieved with the <a href="https://hf.co/papers/1910.02054" rel="nofollow">Zero Redundancy Optimizer (ZeRO)</a> which consists of three stages.',I,Z,g="<thead><tr><th>ZeRO stage</th> <th>description</th></tr></thead> <tbody><tr><td>1</td> <td>partition optimizer states</td></tr> <tr><td>2</td> <td>partition optimizer and gradient states</td></tr> <tr><td>3</td> <td>partition optimizer, gradient, and parameters</td></tr></tbody>",B,A,m='Each stage progressively saves more memory, allowing really large models to fit and train on a single GPU. All ZeRO stages, offloading optimizer memory and computations from the GPU to the CPU are integrated with <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a>. Provide a config file or one of the example templates to <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> to enable DeepSpeed features.',q,R,S='This guide walks you through setting up a DeepSpeed config file, how to enable its features in <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a>, and deploy for training.',$,b,G='Install DeepSpeed from either PyPI or Transformers. For more detailed installation instructions, refer to the DeepSpeed <a href="https://www.deepspeed.ai/tutorials/advanced-install/" rel="nofollow">installation</a> or GitHUB <a href="https://github.com/microsoft/deepspeed#installation" rel="nofollow">README</a>.',Y,x,L,O,te,E,Ul="DeepSpeed provides a tool for estimating the required CPU and GPU memory for the parameters, optimizer and gradient states. You’ll also to need to reserve some memory for the CUDA kernels and activations.",le,Q,Te='Run the command below to check the memory requirements for <a href="https://huggingface.co/docs/transformers/main/en/bigscience/T0_3B" rel="nofollow">bigscience/T0_3B</a> on a single GPU.',H,D,_,z,fe,ee,hl,de,ka="Consider the table below to help you choose the appropriate ZeRO stage for training because there is a trade-off between training speed and memory usage. The table orders the ZeRO stages from fastest to slowest and from least memory usage to most.",Il,Je,Na="<thead><tr><th>fastest</th> <th>least memory usage</th></tr></thead> <tbody><tr><td>ZeRO-1</td> <td>ZeRO-3 + offload</td></tr> <tr><td>ZeRO-2</td> <td>ZeRO-3</td></tr> <tr><td>ZeRO-2 + offload</td> <td>ZeRO-2 + offload</td></tr> <tr><td>ZeRO-3</td> <td>ZeRO-2</td></tr> <tr><td>ZeRO-3 + offload</td> <td>ZeRO-1</td></tr></tbody>",Cl,we,Ga="Decide the type of performance you’re optimizing for, speed or memory, and then work backwards to discover the best ZeRO stage for your use case. For example, if you’re optimizing for speed, start with the fastest ZeRO stage and if you run out of memory, try the next stage which is slower but more memory efficient.",$l,Ue,gl,je,Sa='Once you’ve decided on a ZeRO stage, set up a config file to enable DeepSpeed with <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a>. The config file contains all the parameters for how to configure and set up your training. When the training script is executed, DeepSpeed logs the configuration from <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> to the console so you can see exactly what’s being used.',Al,ae,bl,he,Xa='The config file is passed as a path to a JSON file if you’re training from the command line interface or as a nested dict object if you’re using <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> in a notebook.',_l,ne,vl,Ie,Zl,Ce,Ea="There are three types of config parameters.",Bl,$e,Qa='<li>Some config parameters are shared by DeepSpeed and <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> making it difficult to identify errors when there are conflicting definitions. In this case, configure these parameters from the <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> command line arguments.</li> <li>Some config parameters are automatically derived from the model configuration and don’t need to be manually configured. <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> uses the config value <code>auto</code> to set the most correct or efficient option. You could define these parameters explicitly, but you must take care to ensure the <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> and DeepSpeed config parameters match. Mismatches may cause training to fail in very difficult to detect ways.</li> <li>Some config parameters are specific to DeepSpeed and should be manually set based on your training requirements.</li>',ql,ge,Va="There are two ways to modify the config parameters.",Wl,oe,Rl,Ae,xa='<li>Create or load a DeepSpeed config to use as the main config.</li> <li>Create a <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> object based on the DeepSpeed config values.</li>',zl,be,kl,_e,Ha="Each ZeRO stage config is defined in <code>zero_optimization</code>.",Nl,ve,Fa='For a more detailed explanation of each parameter, refer to the <a href="https://www.deepspeed.ai/docs/config-json/" rel="nofollow">DeepSpeed Configuration JSON</a> reference. These parameters must be set up with DeepSpeed because <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> doesn’t provide equivalent command line arguments.',Gl,ie,Sl,re,Xl,Ze,El,Be,Ya='<a href="https://hf.co/papers/2104.07857" rel="nofollow">ZeRO-Infinity</a> offloads model states to the CPU and/or NVMe to save even more memory. Smart partitioning and tiling algorithms allow each GPU to send and receive very small amounts of data during offloading such that a modern NVMe can fit an even larger total memory pool than is available to your training process. ZeRO-Infinity requires ZeRO-3.',Ql,qe,La='Depending on the CPU and NVMe memory available, you can offload both the <a href="https://www.deepspeed.ai/docs/config-json/#optimizer-offloading" rel="nofollow">optimizer states</a> and <a href="https://www.deepspeed.ai/docs/config-json/#parameter-offloading" rel="nofollow">parameters</a>, just one of them, or none of them. Make sure the <code>nvme_path</code> points to a NVMe device, because while it still works with a regular hard drive or solid state drive, it’ll be significantly slower. With a modern NVMe, you can expect peak transfer speeds of ~3.5GB/s for read operations and ~3GB/s for write operations.',Vl,We,Da='Consider running a <a href="https://github.com/microsoft/DeepSpeed/issues/998" rel="nofollow">benchmark</a> on your training setup to determine the optimal <code>aio</code> configuration.',xl,Re,Pa="The example ZeRO-3 and ZeRO-Infinity config below sets most of the parameter values to <code>auto</code>, but you can also manually set configure these values.",Hl,ze,Fl,ke,Yl,Ne,Oa="DeepSpeed supports many training features that can be configured in the config file. This section describes some of the most important features.",Ll,Ge,Dl,Se,Ka="Gradient checkpointing saves memory by only storing <em>some</em> of the intermediate activations instead of storing <em>all</em> of them. It is useful for fitting larger models on the GPU without running out of memory or to increase the batch size for better performance. Training speed is slower though.",Pl,Xe,en='<li>For a Transformers model, set <code>model.gradient_checkpointing_enable()</code> or add <code>--gradient_checkpointing</code> in the <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>.</li> <li>For a non-Transformers model, use the DeepSpeed <a href="https://deepspeed.readthedocs.io/en/latest/activation-checkpointing.html" rel="nofollow">Activation Checkpointing API</a>. Replacing Transformers modeling code and <a href="https://pytorch.org/docs/stable/checkpoint.html" rel="nofollow">torch.utils.checkpoint</a> with the DeepSpeed API gives you more flexibility because you can offload the forward activations to the CPU memory instead of recalculating them.</li>',Ol,Ee,Kl,Qe,tn='The batch size can be automatically configured or manually set. When you choose the <code>&quot;auto&quot;</code> option, <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> sets <code>train_micro_batch_size_per_gpu</code> and <code>train_batch_size</code> to the value of <code>world_size * per_device_train_batch_size * gradient_accumulation_steps</code>.',es,Ve,ts,xe,ls,He,ln="A separate data type is used for communication collectives like reduction, gathering and scattering operations.",ss,Fe,sn="All gather and scatter operations are performed in the same data type the data is in. For example, if you’re training in bf16, the data is also gathered in bf16 because gathering is a non-lossy operation.",as,Ye,an="Reduce operations are lossy, for example, when gradients are averaged across multiple GPUs. When the communication is done in fp16 or bf16, it’s more likely to be lossy because adding multiple numbers in low precision isn’t exact. This is especially the case with bf16 which has a lower precision than fp16. For this reason, fp16 is the default for reduction operations because the loss is minimal when averaging gradients.",ns,Le,nn="Choose the communication data type by setting the <code>communication_data_type</code> parameter in the config file. For example, choosing fp32 adds a small amount of overhead but ensures the reduction operation is accumulated in fp32 and when it is ready, it’s downcasted to whichever half-precision data type you’re training in.",os,De,is,Pe,rs,Oe,on="Gradient accumulation accumulates gradients over several mini-batches of data before updating parameters. It stores less gradients and enables training with a larger <em>effective batch size</em>. Training speed is slower though, but it’s useful for overcoming memory constraints.",Ms,Ke,rn='Gradient accumulation can be automatically configured or manually set. When you choose the <code>&quot;auto&quot;</code> option, <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> sets it to the value of <code>gradient_accumulation_steps</code>.',ps,et,us,tt,ys,lt,Mn="Gradient clipping is useful for preventing exploding gradients which can lead to instability during training. It sets a maximum threshold value and rescales the gradients if their norm exceeds the threshold.",ms,st,pn='Gradient clipping can be automatically configured or manually set. When you choose the <code>&quot;auto&quot;</code> option, <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> sets it to the value of <code>max_grad_norm</code>.',cs,at,Ts,nt,fs,ot,un="Mixed precision accelerates training speed by performing some calculations in half-precision, but it also maintains some calculations in full-precision to preserve accuracy. DeepSpeed supports fp32, fp16, and bf16 data types.",ds,Me,Js,it,ws,rt,yn="DeepSpeed and Transformers optimizers and schedulers can be mixed and matched if <code>offload_optimizer</code> isn’t enabled. When <code>offload_optimizer</code> is enabled, use a non-DeepSpeed optimizer (except for LAMB) as long as it has it a CPU and GPU implementation.",Us,Mt,mn="Set the optimizer and scheduler parameters for the config file from the command line to avoid hard to find errors. For example, if the learning rate is set to a different value in another place, you can override it from the command line.",js,pe,hs,pt,Is,ut,cn='<a href="https://www.deepspeed.ai/tutorials/universal-checkpointing" rel="nofollow">Universal Checkpointing</a> saves and loads model, optimizer and training scheduler states across different model architectures, parallelism techniques, and training configurations. By saving them in a Universal format, it enables easier model training continuation and fine-tuning.',Cs,yt,Tn="Resume training with a Universal checkpoint by setting <code>load_universal</code> to <code>true</code> in the config file.",$s,mt,gs,ct,As,Tt,fn='DeepSpeed can be deployed with its native launcher, <a href="https://pytorch.org/docs/stable/elastic/run.html" rel="nofollow">torchrun</a> or <a href="https://huggingface.co/docs/accelerate/basic_tutorials/launch#using-accelerate-launch" rel="nofollow">Accelerate</a>.',bs,ft,dn='Add the <code>--deepspeed ds_config.json</code> argument to <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> in the command line. It is recommended to use DeepSpeeds <a href="https://deepspeed.readthedocs.io/en/latest/initialize.html#argument-parsing" rel="nofollow">add_config_arguments</a> utility to add any other command line arguments to your code.',_s,ue,vs,dt,Zs,Jt,Jn='A multi-node setup consists of multiple nodes, where each node has one of more GPUs running a workload. DeepSpeed expects a shared storage system, but if this is not the case, you need to adjust the config file to include a <a href="https://www.deepspeed.ai/docs/config-json/#checkpoint-options" rel="nofollow">checkpoint</a> to allow loading without access to a shared filesystem.',Bs,wt,qs,Ut,wn='You could also use the <code>--save_on_each_node</code> parameter in <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> to automatically add the above <code>checkpoint</code> to your config.',Ws,jt,Un="The examples below for the torchrun and DeepSpeed launcher shows how to deploy two nodes with eight GPUs each. Access the first node with <code>ssh hostname1</code> and the second node with <code>ssh hostname2</code>. Both nodes must be able to communicate with each other locally over ssh without a password.",Rs,ye,zs,ht,ks,It,jn='<a href="https://slurm.schedmd.com/documentation.html" rel="nofollow">Slurm</a> is a cluster management and job scheduling system. An example Slurm script is shown below.',Ns,Ct,Gs,$t,hn="Launch training simultaneously on all nodes with the command below.",Ss,gt,Xs,At,Es,bt,In="To use DeepSpeed in a Jupyter Notebook, you need to emulate a distributed environment because the launcher doesn’t support deployment from a notebook. This is only supported for one GPU. To use multiple GPUs, you must use a multi-process environment, which means you have to use the DeepSpeed launcher which can’t be emulated as shown here.",Qs,_t,Vs,vt,Cn="Create a config file on the fly in the notebook in the current directory with a dedicated cell.",xs,Zt,Hs,Bt,$n="If the training script is in a file and not a notebook cell, launch DeepSpeed from the shell in the notebook cell.",Fs,qt,Ys,Wt,gn="Another option is to use <code>%%bash</code> to run the shell program without emulating the distributed environment. However, you won’t be able to view the logs until training is complete.",Ls,Rt,Ds,zt,Ps,kt,An="DeepSpeed stores the main fp32 weights in custom checkpoint optimizer files (<code>global_step*/*optim_states.pt</code>) which are saved under the normal checkpoint.",Os,Nt,Ks,Gt,bn="ZeRO-2 saves the model weights in fp16. To save the weights in fp16 for ZeRO-3, set <code>&quot;stage3_gather_16bit_weights_on_model_save&quot;: true</code> in the config file, because the weights are distributed across multiple GPUs.",ea,St,_n='If you don’t, <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> won’t save the weights in fp16 and won’t create a <code>pytorch_model.bin</code> file. This is because DeepSpeed’s state_dict contains a placeholder instead of the real weights, so you won’t be able to load it.',ta,Xt,la,Et,sa,Qt,vn="Unless you have a lot of free CPU memory, fp32 weights shouldn’t be saved during training because it can require a lot of memory. It is usually best to save the fp32 weights offline after training is complete.",aa,me,na,Vt,oa,xt,Zn='DeepSpeed also works with Transformers without <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a>. The <a href="/docs/transformers/v4.56.2/en/main_classes/deepspeed#transformers.integrations.HfDeepSpeedConfig">HfDeepSpeedConfig</a> is responsible for gathering ZeRO-3 parameters and partitioning a model across multiple GPUs when <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is called.',ia,Ht,Bn='You must instantiate <a href="/docs/transformers/v4.56.2/en/main_classes/deepspeed#transformers.integrations.HfDeepSpeedConfig">HfDeepSpeedConfig</a> before loading a model to efficiently deploy ZeRO-3.',ra,ce,Ma,Ft,pa,Yt,qn='One of the first things to check when you encounter an error is whether DeepSpeed is the cause (because often it isn’t). Retry your setup without DeepSpeed, and if the error persists, report the issue. If the issue is unrelated to the Transformers integration, please open the issue on the DeepSpeed <a href="https://github.com/microsoft/DeepSpeed" rel="nofollow">repository</a>.',ua,Lt,Wn="For issues related to the Transformers integration, please provide the following information.",ya,V,Tl,Rn="<p>The full DeepSpeed config file.</p>",Ba,fl,zn='<p>The command line arguments for <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> or the <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> if you’re scripting the <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.Trainer">Trainer</a> setup yourself (don’t dump the entire <a href="/docs/transformers/v4.56.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> which contains many irrelevant entries).</p>',qa,Dt,dl,kn="The outputs of the following commands.",Wa,Pt,Ra,Jl,Nn="<p>A link to a Google Colab notebook to reproduce the issue.</p>",za,wl,Gn="<p>A standard or non-custom dataset or an existing example to reproduce the issue.</p>",ma,Ot,Sn="The following sections provide a guide for resolving two of the most common issues.",ca,Kt,Ta,el,Xn="When the DeepSpeed process is killed during launch without a traceback, that usually means the program tried to allocate more CPU memory than is available on your system. Or the process may have tried to allocate more CPU memory than allowed, leading the OS kernel to terminate the process.",fa,tl,En="In this case, check whether your config file has either <code>offload_optimizer</code>, <code>offlload_param</code>, or both configured to offload to the CPU.",da,ll,Qn='If you have NVM3 and ZeRO-3 set up, experiment with offloading to the NVMe (<a href="https://deepspeed.readthedocs.io/en/latest/memory.html" rel="nofollow">estimate</a> the memory requirements of a model first) instead.',Ja,sl,wa,al,Vn="NaN loss often occurs when a model is pretrained in bf16 and you try to use it with fp16 (especially relevant to TPU trained models). To resolve this, use fp32 or bf16 if your hardware (TPUs, Ampere GPUs or newer) supports it.",Ua,nl,xn="It is also possible that fp16 is causing overflow. For example, if your config file looks like the one below, you may see the following overflow errors in the logs.",ja,ol,ha,il,Hn="The <code>OVERFLOW!</code> error below is a result of the DeepSpeed loss scaler unable to find a scaling coefficient to overcome the loss overflow. Try a higher <code>initial_scale_power</code> value in this case (32 usually works).",Ia,rl,Ca,Ml,$a,pl,Fn='DeepSpeed is a powerful technology for scaling large model training. To learn more about DeepSpeed, take a look at their <a href="https://www.microsoft.com/en-us/research/search/?q=deepspeed" rel="nofollow">blog posts</a>, <a href="https://www.deepspeed.ai/getting-started/" rel="nofollow">documentation</a>, and <a href="https://github.com/microsoft/deepspeed" rel="nofollow">GitHub</a>.',ga,ul,Yn="The papers below provide additional details about ZeRO.",Aa,yl,Ln='<li><a href="https://hf.co/papers/1910.02054" rel="nofollow">ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</a></li> <li><a href="https://hf.co/papers/2101.06840" rel="nofollow">ZeRO-Offload: Democratizing Billion-Scale Model Training</a></li> <li><a href="https://hf.co/papers/2104.07857" rel="nofollow">ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning</a></li>',ba,ml,_a,jl,va;return o=new k({props:{title:"DeepSpeed",local:"deepspeed",headingTag:"h1"}}),x=new se({props:{id:"installation",options:["PyPI","Transformers"],$$slots:{default:[Jo]},$$scope:{ctx:v}}}),O=new K({props:{warning:!0,$$slots:{default:[wo]},$$scope:{ctx:v}}}),D=new W({props:{code:"JTI0JTIwcHl0aG9uJTIwLWMlMjAnZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbCUzQiUyMCU1QyUwQWZyb20lMjBkZWVwc3BlZWQucnVudGltZS56ZXJvLnN0YWdlMyUyMGltcG9ydCUyMGVzdGltYXRlX3plcm8zX21vZGVsX3N0YXRlc19tZW1fbmVlZHNfYWxsX2xpdmUlM0IlMjAlNUMlMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbC5mcm9tX3ByZXRyYWluZWQoJTIyYmlnc2NpZW5jZSUyRlQwXzNCJTIyKSUzQiUyMCU1QyUwQWVzdGltYXRlX3plcm8zX21vZGVsX3N0YXRlc19tZW1fbmVlZHNfYWxsX2xpdmUobW9kZWwlMkMlMjBudW1fZ3B1c19wZXJfbm9kZSUzRDElMkMlMjBudW1fbm9kZXMlM0QxKSclMEElNUIuLi4lNUQlMEFFc3RpbWF0ZWQlMjBtZW1vcnklMjBuZWVkZWQlMjBmb3IlMjBwYXJhbXMlMkMlMjBvcHRpbSUyMHN0YXRlcyUyMGFuZCUyMGdyYWRpZW50cyUyMGZvciUyMGElM0ElMEFIVyUzQSUyMFNldHVwJTIwd2l0aCUyMDElMjBub2RlJTJDJTIwMSUyMEdQVSUyMHBlciUyMG5vZGUuJTBBU1clM0ElMjBNb2RlbCUyMHdpdGglMjAyNzgzTSUyMHRvdGFsJTIwcGFyYW1zJTJDJTIwNjVNJTIwbGFyZ2VzdCUyMGxheWVyJTIwcGFyYW1zLiUwQSUyMCUyMHBlciUyMENQVSUyMCUyMCU3QyUyMCUyMHBlciUyMEdQVSUyMCU3QyUyMCUyMCUyME9wdGlvbnMlMEElMjAlMjAlMjA3MC4wMEdCJTIwJTdDJTIwJTIwJTIwMC4yNUdCJTIwJTdDJTIwb2ZmbG9hZF9wYXJhbSUzRGNwdSUyMCUyQyUyMG9mZmxvYWRfb3B0aW1pemVyJTNEY3B1JTIwJTJDJTIwemVyb19pbml0JTNEMSUwQSUyMCUyMCUyMDcwLjAwR0IlMjAlN0MlMjAlMjAlMjAwLjI1R0IlMjAlN0MlMjBvZmZsb2FkX3BhcmFtJTNEY3B1JTIwJTJDJTIwb2ZmbG9hZF9vcHRpbWl6ZXIlM0RjcHUlMjAlMkMlMjB6ZXJvX2luaXQlM0QwJTBBJTIwJTIwJTIwNjIuMjNHQiUyMCU3QyUyMCUyMCUyMDUuNDNHQiUyMCU3QyUyMG9mZmxvYWRfcGFyYW0lM0Rub25lJTJDJTIwb2ZmbG9hZF9vcHRpbWl6ZXIlM0RjcHUlMjAlMkMlMjB6ZXJvX2luaXQlM0QxJTBBJTIwJTIwJTIwNjIuMjNHQiUyMCU3QyUyMCUyMCUyMDUuNDNHQiUyMCU3QyUyMG9mZmxvYWRfcGFyYW0lM0Rub25lJTJDJTIwb2ZmbG9hZF9vcHRpbWl6ZXIlM0RjcHUlMjAlMkMlMjB6ZXJvX2luaXQlM0QwJTBBJTIwJTIwJTIwJTIwMC4zN0dCJTIwJTdDJTIwJTIwNDYuOTFHQiUyMCU3QyUyMG9mZmxvYWRfcGFyYW0lM0Rub25lJTJDJTIwb2ZmbG9hZF9vcHRpbWl6ZXIlM0Rub25lJTJDJTIwemVyb19pbml0JTNEMSUwQSUyMCUyMCUyMDE1LjU2R0IlMjAlN0MlMjAlMjA0Ni45MUdCJTIwJTdDJTIwb2ZmbG9hZF9wYXJhbSUzRG5vbmUlMkMlMjBvZmZsb2FkX29wdGltaXplciUzRG5vbmUlMkMlMjB6ZXJvX2luaXQlM0Qw",highlighted:`$ python -c <span class="hljs-string">&#x27;from transformers import AutoModel; \\
from deepspeed.runtime.zero.stage3 import estimate_zero3_model_states_mem_needs_all_live; \\
model = AutoModel.from_pretrained(&quot;bigscience/T0_3B&quot;); \\
estimate_zero3_model_states_mem_needs_all_live(model, num_gpus_per_node=1, num_nodes=1)&#x27;</span>
[...]
Estimated memory needed <span class="hljs-keyword">for</span> params, optim states and gradients <span class="hljs-keyword">for</span> a:
HW: Setup with 1 node, 1 GPU per node.
SW: Model with 2783M total params, 65M largest layer params.
  per CPU  |  per GPU |   Options
   70.00GB |   0.25GB | offload_param=cpu , offload_optimizer=cpu , zero_init=1
   70.00GB |   0.25GB | offload_param=cpu , offload_optimizer=cpu , zero_init=0
   62.23GB |   5.43GB | offload_param=none, offload_optimizer=cpu , zero_init=1
   62.23GB |   5.43GB | offload_param=none, offload_optimizer=cpu , zero_init=0
    0.37GB |  46.91GB | offload_param=none, offload_optimizer=none, zero_init=1
   15.56GB |  46.91GB | offload_param=none, offload_optimizer=none, zero_init=0`,wrap:!1}}),z=new K({props:{warning:!1,$$slots:{default:[Uo]},$$scope:{ctx:v}}}),ee=new k({props:{title:"Choosing a ZeRO stage",local:"choosing-a-zero-stage",headingTag:"h2"}}),Ue=new k({props:{title:"Config file",local:"config-file",headingTag:"h2"}}),ae=new K({props:{warning:!1,$$slots:{default:[jo]},$$scope:{ctx:v}}}),ne=new se({props:{id:"pass-config",options:["path to file","nested dict"],$$slots:{default:[Co]},$$scope:{ctx:v}}}),Ie=new k({props:{title:"DeepSpeed versus Trainer parameters",local:"deepspeed-versus-trainer-parameters",headingTag:"h3"}}),oe=new K({props:{warning:!1,$$slots:{default:[$o]},$$scope:{ctx:v}}}),be=new k({props:{title:"ZeRO stage",local:"zero-stage",headingTag:"h3"}}),ie=new K({props:{warning:!0,$$slots:{default:[go]},$$scope:{ctx:v}}}),re=new se({props:{id:"zero-config",options:["ZeRO-1","ZeRO-2","ZeRO-3"],$$slots:{default:[Bo]},$$scope:{ctx:v}}}),Ze=new k({props:{title:"NVMe",local:"nvme",headingTag:"h3"}}),ze=new W({props:{code:"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",highlighted:`{
    <span class="hljs-attr">&quot;fp16&quot;:</span> {
        <span class="hljs-attr">&quot;enabled&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
        <span class="hljs-attr">&quot;loss_scale&quot;:</span> <span class="hljs-number">0</span>,
        <span class="hljs-attr">&quot;loss_scale_window&quot;:</span> <span class="hljs-number">1000</span>,
        <span class="hljs-attr">&quot;initial_scale_power&quot;:</span> <span class="hljs-number">16</span>,
        <span class="hljs-attr">&quot;hysteresis&quot;:</span> <span class="hljs-number">2</span>,
        <span class="hljs-attr">&quot;min_loss_scale&quot;:</span> <span class="hljs-number">1</span>
    },

    <span class="hljs-attr">&quot;optimizer&quot;:</span> {
        <span class="hljs-attr">&quot;type&quot;:</span> <span class="hljs-string">&quot;AdamW&quot;</span>,
        <span class="hljs-attr">&quot;params&quot;:</span> {
            <span class="hljs-attr">&quot;lr&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
            <span class="hljs-attr">&quot;betas&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
            <span class="hljs-attr">&quot;eps&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
            <span class="hljs-attr">&quot;weight_decay&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>
        }
    },

    <span class="hljs-attr">&quot;scheduler&quot;:</span> {
        <span class="hljs-attr">&quot;type&quot;:</span> <span class="hljs-string">&quot;WarmupLR&quot;</span>,
        <span class="hljs-attr">&quot;params&quot;:</span> {
            <span class="hljs-attr">&quot;warmup_min_lr&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
            <span class="hljs-attr">&quot;warmup_max_lr&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
            <span class="hljs-attr">&quot;warmup_num_steps&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>
        }
    },

    <span class="hljs-attr">&quot;zero_optimization&quot;:</span> {
        <span class="hljs-attr">&quot;stage&quot;:</span> <span class="hljs-number">3</span>,
        <span class="hljs-attr">&quot;offload_optimizer&quot;:</span> {
            <span class="hljs-attr">&quot;device&quot;:</span> <span class="hljs-string">&quot;nvme&quot;</span>,
            <span class="hljs-attr">&quot;nvme_path&quot;:</span> <span class="hljs-string">&quot;/local_nvme&quot;</span>,
            <span class="hljs-attr">&quot;pin_memory&quot;:</span> <span class="hljs-literal">true</span>,
            <span class="hljs-attr">&quot;buffer_count&quot;:</span> <span class="hljs-number">4</span>,
            <span class="hljs-attr">&quot;fast_init&quot;:</span> <span class="hljs-literal">false</span>
        },
        <span class="hljs-attr">&quot;offload_param&quot;:</span> {
            <span class="hljs-attr">&quot;device&quot;:</span> <span class="hljs-string">&quot;nvme&quot;</span>,
            <span class="hljs-attr">&quot;nvme_path&quot;:</span> <span class="hljs-string">&quot;/local_nvme&quot;</span>,
            <span class="hljs-attr">&quot;pin_memory&quot;:</span> <span class="hljs-literal">true</span>,
            <span class="hljs-attr">&quot;buffer_count&quot;:</span> <span class="hljs-number">5</span>,
            <span class="hljs-attr">&quot;buffer_size&quot;:</span> <span class="hljs-number">1e8</span>,
            <span class="hljs-attr">&quot;max_in_cpu&quot;:</span> <span class="hljs-number">1e9</span>
        },
        <span class="hljs-attr">&quot;aio&quot;:</span> {
            <span class="hljs-attr">&quot;block_size&quot;:</span> <span class="hljs-number">262144</span>,
            <span class="hljs-attr">&quot;queue_depth&quot;:</span> <span class="hljs-number">32</span>,
            <span class="hljs-attr">&quot;thread_count&quot;:</span> <span class="hljs-number">1</span>,
            <span class="hljs-attr">&quot;single_submit&quot;:</span> <span class="hljs-literal">false</span>,
            <span class="hljs-attr">&quot;overlap_events&quot;:</span> <span class="hljs-literal">true</span>
        },
        <span class="hljs-attr">&quot;overlap_comm&quot;:</span> <span class="hljs-literal">true</span>,
        <span class="hljs-attr">&quot;contiguous_gradients&quot;:</span> <span class="hljs-literal">true</span>,
        <span class="hljs-attr">&quot;sub_group_size&quot;:</span> <span class="hljs-number">1e9</span>,
        <span class="hljs-attr">&quot;reduce_bucket_size&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
        <span class="hljs-attr">&quot;stage3_prefetch_bucket_size&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
        <span class="hljs-attr">&quot;stage3_param_persistence_threshold&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
        <span class="hljs-attr">&quot;stage3_max_live_parameters&quot;:</span> <span class="hljs-number">1e9</span>,
        <span class="hljs-attr">&quot;stage3_max_reuse_distance&quot;:</span> <span class="hljs-number">1e9</span>,
        <span class="hljs-attr">&quot;stage3_gather_16bit_weights_on_model_save&quot;:</span> <span class="hljs-literal">true</span>
    },

    <span class="hljs-attr">&quot;gradient_accumulation_steps&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
    <span class="hljs-attr">&quot;gradient_clipping&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
    <span class="hljs-attr">&quot;steps_per_print&quot;:</span> <span class="hljs-number">2000</span>,
    <span class="hljs-attr">&quot;train_batch_size&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
    <span class="hljs-attr">&quot;train_micro_batch_size_per_gpu&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
    <span class="hljs-attr">&quot;wall_clock_breakdown&quot;:</span> <span class="hljs-literal">false</span>
}`,wrap:!1}}),ke=new k({props:{title:"Training features",local:"training-features",headingTag:"h2"}}),Ge=new k({props:{title:"Gradient checkpointing",local:"gradient-checkpointing",headingTag:"h3"}}),Ee=new k({props:{title:"Batch size",local:"batch-size",headingTag:"h3"}}),Ve=new W({props:{code:"JTdCJTBBJTIwJTIwJTIwJTIwJTIydHJhaW5fbWljcm9fYmF0Y2hfc2l6ZV9wZXJfZ3B1JTIyJTNBJTIwJTIyYXV0byUyMiUyQyUwQSUyMCUyMCUyMCUyMCUyMnRyYWluX2JhdGNoX3NpemUlMjIlM0ElMjAlMjJhdXRvJTIyJTBBJTdE",highlighted:`{
    <span class="hljs-attr">&quot;train_micro_batch_size_per_gpu&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
    <span class="hljs-attr">&quot;train_batch_size&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>
}`,wrap:!1}}),xe=new k({props:{title:"Communication data type",local:"communication-data-type",headingTag:"h3"}}),De=new W({props:{code:"JTdCJTBBJTIwJTIwJTIwJTIwJTIyY29tbXVuaWNhdGlvbl9kYXRhX3R5cGUlMjIlM0ElMjAlMjJmcDMyJTIyJTBBJTdE",highlighted:`{
    <span class="hljs-attr">&quot;communication_data_type&quot;:</span> <span class="hljs-string">&quot;fp32&quot;</span>
}`,wrap:!1}}),Pe=new k({props:{title:"Gradient accumulation",local:"gradient-accumulation",headingTag:"h3"}}),et=new W({props:{code:"JTdCJTBBJTIwJTIwJTIwJTIwJTIyZ3JhZGllbnRfYWNjdW11bGF0aW9uX3N0ZXBzJTIyJTNBJTIwJTIyYXV0byUyMiUwQSU3RA==",highlighted:`{
    <span class="hljs-attr">&quot;gradient_accumulation_steps&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>
}`,wrap:!1}}),tt=new k({props:{title:"Gradient clipping",local:"gradient-clipping",headingTag:"h3"}}),at=new W({props:{code:"JTdCJTBBJTIwJTIwJTIwJTIwJTIyZ3JhZGllbnRfY2xpcHBpbmclMjIlM0ElMjAlMjJhdXRvJTIyJTBBJTdE",highlighted:`{
    <span class="hljs-attr">&quot;gradient_clipping&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>
}`,wrap:!1}}),nt=new k({props:{title:"Mixed precision training",local:"mixed-precision-training",headingTag:"h3"}}),Me=new se({props:{id:"precision",options:["fp32","fp16","bf16"],$$slots:{default:[ko]},$$scope:{ctx:v}}}),it=new k({props:{title:"Optimizer and scheduler",local:"optimizer-and-scheduler",headingTag:"h3"}}),pe=new se({props:{id:"opt-sched",options:["optimizer","scheduler"],$$slots:{default:[So]},$$scope:{ctx:v}}}),pt=new k({props:{title:"Universal checkpointing",local:"universal-checkpointing",headingTag:"h3"}}),mt=new W({props:{code:"JTdCJTBBJTIwJTIwJTIwJTIwJTIyY2hlY2twb2ludCUyMiUzQSUyMCU3QiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMmxvYWRfdW5pdmVyc2FsJTIyJTNBJTIwdHJ1ZSUwQSUyMCUyMCUyMCUyMCU3RCUwQSU3RA==",highlighted:`{
    <span class="hljs-attr">&quot;checkpoint&quot;:</span> {
        <span class="hljs-attr">&quot;load_universal&quot;:</span> <span class="hljs-literal">true</span>
    }
}`,wrap:!1}}),ct=new k({props:{title:"Deploy",local:"deploy",headingTag:"h2"}}),ue=new se({props:{id:"deploy",options:["multi-GPU","single-GPU"],$$slots:{default:[Vo]},$$scope:{ctx:v}}}),dt=new k({props:{title:"Multi-node",local:"multi-node",headingTag:"h3"}}),wt=new W({props:{code:"JTdCJTBBJTIwJTIwJTIyY2hlY2twb2ludCUyMiUzQSUyMCU3QiUwQSUyMCUyMCUyMCUyMCUyMnVzZV9ub2RlX2xvY2FsX3N0b3JhZ2UlMjIlM0ElMjB0cnVlJTBBJTIwJTIwJTdEJTBBJTdE",highlighted:`{
  <span class="hljs-attr">&quot;checkpoint&quot;:</span> {
    <span class="hljs-attr">&quot;use_node_local_storage&quot;:</span> <span class="hljs-literal">true</span>
  }
}`,wrap:!1}}),ye=new se({props:{id:"multinode",options:["torchrun","DeepSpeed"],$$slots:{default:[Fo]},$$scope:{ctx:v}}}),ht=new k({props:{title:"Slurm",local:"slurm",headingTag:"h3"}}),Ct=new W({props:{code:"JTIzU0JBVENIJTIwLS1qb2ItbmFtZSUzRHRlc3Qtbm9kZXMlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjMlMjBuYW1lJTBBJTIzU0JBVENIJTIwLS1ub2RlcyUzRDIlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjMlMjBub2RlcyUwQSUyM1NCQVRDSCUyMC0tbnRhc2tzLXBlci1ub2RlJTNEMSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMyUyMGNydWNpYWwlMjAtJTIwb25seSUyMDElMjB0YXNrJTIwcGVyJTIwZGlzdCUyMHBlciUyMG5vZGUhJTBBJTIzU0JBVENIJTIwLS1jcHVzLXBlci10YXNrJTNEMTAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjMlMjBudW1iZXIlMjBvZiUyMGNvcmVzJTIwcGVyJTIwdGFza3MlMEElMjNTQkFUQ0glMjAtLWdyZXMlM0RncHUlM0E4JTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIzJTIwbnVtYmVyJTIwb2YlMjBncHVzJTBBJTIzU0JBVENIJTIwLS10aW1lJTIwMjAlM0EwMCUzQTAwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIzJTIwbWF4aW11bSUyMGV4ZWN1dGlvbiUyMHRpbWUlMjAoSEglM0FNTSUzQVNTKSUwQSUyM1NCQVRDSCUyMC0tb3V0cHV0JTNEJTI1eC0lMjVqLm91dCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMyUyMG91dHB1dCUyMGZpbGUlMjBuYW1lJTBBJTBBZXhwb3J0JTIwR1BVU19QRVJfTk9ERSUzRDglMEFleHBvcnQlMjBNQVNURVJfQUREUiUzRCUyNChzY29udHJvbCUyMHNob3clMjBob3N0bmFtZXMlMjAlMjRTTFVSTV9KT0JfTk9ERUxJU1QlMjAlN0MlMjBoZWFkJTIwLW4lMjAxKSUwQWV4cG9ydCUyME1BU1RFUl9QT1JUJTNEOTkwMSUwQSUwQXNydW4lMjAtLWpvYmlkJTIwJTI0U0xVUk1fSk9CSUQlMjBiYXNoJTIwLWMlMjAncHl0aG9uJTIwLW0lMjB0b3JjaC5kaXN0cmlidXRlZC5ydW4lMjAlNUMlMEElMjAtLW5wcm9jX3Blcl9ub2RlJTIwJTI0R1BVU19QRVJfTk9ERSUyMC0tbm5vZGVzJTIwJTI0U0xVUk1fTk5PREVTJTIwLS1ub2RlX3JhbmslMjAlMjRTTFVSTV9QUk9DSUQlMjAlNUMlMEElMjAtLW1hc3Rlcl9hZGRyJTIwJTI0TUFTVEVSX0FERFIlMjAtLW1hc3Rlcl9wb3J0JTIwJTI0TUFTVEVSX1BPUlQlMjAlNUMlMEF5b3VyX3Byb2dyYW0ucHklMjAlM0Nub3JtYWwlMjBjbCUyMGFyZ3MlM0UlMjAtLWRlZXBzcGVlZCUyMGRzX2NvbmZpZy5qc29uJw==",highlighted:`<span class="hljs-comment">#SBATCH --job-name=test-nodes        # name</span>
<span class="hljs-comment">#SBATCH --nodes=2                    # nodes</span>
<span class="hljs-comment">#SBATCH --ntasks-per-node=1          # crucial - only 1 task per dist per node!</span>
<span class="hljs-comment">#SBATCH --cpus-per-task=10           # number of cores per tasks</span>
<span class="hljs-comment">#SBATCH --gres=gpu:8                 # number of gpus</span>
<span class="hljs-comment">#SBATCH --time 20:00:00              # maximum execution time (HH:MM:SS)</span>
<span class="hljs-comment">#SBATCH --output=%x-%j.out           # output file name</span>

<span class="hljs-built_in">export</span> GPUS_PER_NODE=8
<span class="hljs-built_in">export</span> MASTER_ADDR=$(scontrol show hostnames <span class="hljs-variable">$SLURM_JOB_NODELIST</span> | <span class="hljs-built_in">head</span> -n 1)
<span class="hljs-built_in">export</span> MASTER_PORT=9901

srun --jobid <span class="hljs-variable">$SLURM_JOBID</span> bash -c <span class="hljs-string">&#x27;python -m torch.distributed.run \\
 --nproc_per_node $GPUS_PER_NODE --nnodes $SLURM_NNODES --node_rank $SLURM_PROCID \\
 --master_addr $MASTER_ADDR --master_port $MASTER_PORT \\
your_program.py &lt;normal cl args&gt; --deepspeed ds_config.json&#x27;</span>`,wrap:!1}}),gt=new W({props:{code:"c2JhdGNoJTIwbGF1bmNoLnNsdXJt",highlighted:"sbatch launch.slurm",wrap:!1}}),At=new k({props:{title:"Jupyter Notebook",local:"jupyter-notebook",headingTag:"h3"}}),_t=new W({props:{code:"JTIzJTIwZW11bGF0ZSUyMGElMjBsYXVuY2hlciUyMGluJTIwdGhlJTIwbm90ZWJvb2slMEFpbXBvcnQlMjBvcyUwQSUwQW9zLmVudmlyb24lNUIlMjJNQVNURVJfQUREUiUyMiU1RCUyMCUzRCUyMCUyMmxvY2FsaG9zdCUyMiUwQW9zLmVudmlyb24lNUIlMjJNQVNURVJfUE9SVCUyMiU1RCUyMCUzRCUyMCUyMjk5OTQlMjIlMjAlMjAlMjMlMjBtb2RpZnklMjBpZiUyMFJ1bnRpbWVFcnJvciUzQSUyMEFkZHJlc3MlMjBhbHJlYWR5JTIwaW4lMjB1c2UlMEFvcy5lbnZpcm9uJTVCJTIyUkFOSyUyMiU1RCUyMCUzRCUyMCUyMjAlMjIlMEFvcy5lbnZpcm9uJTVCJTIyTE9DQUxfUkFOSyUyMiU1RCUyMCUzRCUyMCUyMjAlMjIlMEFvcy5lbnZpcm9uJTVCJTIyV09STERfU0laRSUyMiU1RCUyMCUzRCUyMCUyMjElMjIlMEElMEF0cmFpbmluZ19hcmdzJTIwJTNEJTIwVHJhaW5pbmdBcmd1bWVudHMoLi4uJTJDJTIwZGVlcHNwZWVkJTNEJTIyZHNfY29uZmlnX3plcm8zLmpzb24lMjIpJTBBdHJhaW5lciUyMCUzRCUyMFRyYWluZXIoLi4uKSUwQXRyYWluZXIudHJhaW4oKQ==",highlighted:`<span class="hljs-comment"># emulate a launcher in the notebook</span>
<span class="hljs-keyword">import</span> os

os.environ[<span class="hljs-string">&quot;MASTER_ADDR&quot;</span>] = <span class="hljs-string">&quot;localhost&quot;</span>
os.environ[<span class="hljs-string">&quot;MASTER_PORT&quot;</span>] = <span class="hljs-string">&quot;9994&quot;</span>  <span class="hljs-comment"># modify if RuntimeError: Address already in use</span>
os.environ[<span class="hljs-string">&quot;RANK&quot;</span>] = <span class="hljs-string">&quot;0&quot;</span>
os.environ[<span class="hljs-string">&quot;LOCAL_RANK&quot;</span>] = <span class="hljs-string">&quot;0&quot;</span>
os.environ[<span class="hljs-string">&quot;WORLD_SIZE&quot;</span>] = <span class="hljs-string">&quot;1&quot;</span>

training_args = TrainingArguments(..., deepspeed=<span class="hljs-string">&quot;ds_config_zero3.json&quot;</span>)
trainer = Trainer(...)
trainer.train()`,wrap:!1}}),Zt=new W({props:{code:"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",highlighted:`%%bash
cat &lt;&lt;<span class="hljs-string">&#x27;EOT&#x27;</span> &gt; ds_config_zero3.json
{
    <span class="hljs-string">&quot;fp16&quot;</span>: {
        <span class="hljs-string">&quot;enabled&quot;</span>: <span class="hljs-string">&quot;auto&quot;</span>,
        <span class="hljs-string">&quot;loss_scale&quot;</span>: <span class="hljs-number">0</span>,
        <span class="hljs-string">&quot;loss_scale_window&quot;</span>: <span class="hljs-number">1000</span>,
        <span class="hljs-string">&quot;initial_scale_power&quot;</span>: <span class="hljs-number">16</span>,
        <span class="hljs-string">&quot;hysteresis&quot;</span>: <span class="hljs-number">2</span>,
        <span class="hljs-string">&quot;min_loss_scale&quot;</span>: <span class="hljs-number">1</span>
    },

    <span class="hljs-string">&quot;optimizer&quot;</span>: {
        <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;AdamW&quot;</span>,
        <span class="hljs-string">&quot;params&quot;</span>: {
            <span class="hljs-string">&quot;lr&quot;</span>: <span class="hljs-string">&quot;auto&quot;</span>,
            <span class="hljs-string">&quot;betas&quot;</span>: <span class="hljs-string">&quot;auto&quot;</span>,
            <span class="hljs-string">&quot;eps&quot;</span>: <span class="hljs-string">&quot;auto&quot;</span>,
            <span class="hljs-string">&quot;weight_decay&quot;</span>: <span class="hljs-string">&quot;auto&quot;</span>
        }
    },

    <span class="hljs-string">&quot;scheduler&quot;</span>: {
        <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;WarmupLR&quot;</span>,
        <span class="hljs-string">&quot;params&quot;</span>: {
            <span class="hljs-string">&quot;warmup_min_lr&quot;</span>: <span class="hljs-string">&quot;auto&quot;</span>,
            <span class="hljs-string">&quot;warmup_max_lr&quot;</span>: <span class="hljs-string">&quot;auto&quot;</span>,
            <span class="hljs-string">&quot;warmup_num_steps&quot;</span>: <span class="hljs-string">&quot;auto&quot;</span>
        }
    },

    <span class="hljs-string">&quot;zero_optimization&quot;</span>: {
        <span class="hljs-string">&quot;stage&quot;</span>: <span class="hljs-number">3</span>,
        <span class="hljs-string">&quot;offload_optimizer&quot;</span>: {
            <span class="hljs-string">&quot;device&quot;</span>: <span class="hljs-string">&quot;cpu&quot;</span>,
            <span class="hljs-string">&quot;pin_memory&quot;</span>: true
        },
        <span class="hljs-string">&quot;offload_param&quot;</span>: {
            <span class="hljs-string">&quot;device&quot;</span>: <span class="hljs-string">&quot;cpu&quot;</span>,
            <span class="hljs-string">&quot;pin_memory&quot;</span>: true
        },
        <span class="hljs-string">&quot;overlap_comm&quot;</span>: true,
        <span class="hljs-string">&quot;contiguous_gradients&quot;</span>: true,
        <span class="hljs-string">&quot;sub_group_size&quot;</span>: <span class="hljs-number">1e9</span>,
        <span class="hljs-string">&quot;reduce_bucket_size&quot;</span>: <span class="hljs-string">&quot;auto&quot;</span>,
        <span class="hljs-string">&quot;stage3_prefetch_bucket_size&quot;</span>: <span class="hljs-string">&quot;auto&quot;</span>,
        <span class="hljs-string">&quot;stage3_param_persistence_threshold&quot;</span>: <span class="hljs-string">&quot;auto&quot;</span>,
        <span class="hljs-string">&quot;stage3_max_live_parameters&quot;</span>: <span class="hljs-number">1e9</span>,
        <span class="hljs-string">&quot;stage3_max_reuse_distance&quot;</span>: <span class="hljs-number">1e9</span>,
        <span class="hljs-string">&quot;stage3_gather_16bit_weights_on_model_save&quot;</span>: true
    },

    <span class="hljs-string">&quot;gradient_accumulation_steps&quot;</span>: <span class="hljs-string">&quot;auto&quot;</span>,
    <span class="hljs-string">&quot;gradient_clipping&quot;</span>: <span class="hljs-string">&quot;auto&quot;</span>,
    <span class="hljs-string">&quot;steps_per_print&quot;</span>: <span class="hljs-number">2000</span>,
    <span class="hljs-string">&quot;train_batch_size&quot;</span>: <span class="hljs-string">&quot;auto&quot;</span>,
    <span class="hljs-string">&quot;train_micro_batch_size_per_gpu&quot;</span>: <span class="hljs-string">&quot;auto&quot;</span>,
    <span class="hljs-string">&quot;wall_clock_breakdown&quot;</span>: false
}
EOT`,wrap:!1}}),qt=new W({props:{code:"IWdpdCUyMGNsb25lJTIwaHR0cHMlM0ElMkYlMkZnaXRodWIuY29tJTJGaHVnZ2luZ2ZhY2UlMkZ0cmFuc2Zvcm1lcnMlMEEhY2QlMjB0cmFuc2Zvcm1lcnMlM0IlMjBkZWVwc3BlZWQlMjBleGFtcGxlcyUyRnB5dG9yY2glMkZ0cmFuc2xhdGlvbiUyRnJ1bl90cmFuc2xhdGlvbi5weSUyMC4uLg==",highlighted:`!git clone https://github.com/huggingface/transformers
!cd transformers; deepspeed examples/pytorch/translation/run_translation.py ...`,wrap:!1}}),Rt=new W({props:{code:"JTI1JTI1YmFzaCUwQSUwQWdpdCUyMGNsb25lJTIwaHR0cHMlM0ElMkYlMkZnaXRodWIuY29tJTJGaHVnZ2luZ2ZhY2UlMkZ0cmFuc2Zvcm1lcnMlMEFjZCUyMHRyYW5zZm9ybWVycyUwQWRlZXBzcGVlZCUyMGV4YW1wbGVzJTJGcHl0b3JjaCUyRnRyYW5zbGF0aW9uJTJGcnVuX3RyYW5zbGF0aW9uLnB5JTIwLi4u",highlighted:`%%bash

git clone https://github.com/huggingface/transformers
cd transformers
deepspeed examples/pytorch/translation/run_translation.py ...`,wrap:!1}}),zt=new k({props:{title:"Save model weights",local:"save-model-weights",headingTag:"h2"}}),Nt=new k({props:{title:"fp16",local:"fp16",headingTag:"h3"}}),Xt=new W({props:{code:"JTdCJTBBJTIwJTIwJTIwJTIwJTIyemVyb19vcHRpbWl6YXRpb24lMjIlM0ElMjAlN0IlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJzdGFnZSUyMiUzQSUyMDMlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJzdGFnZTNfZ2F0aGVyXzE2Yml0X3dlaWdodHNfb25fbW9kZWxfc2F2ZSUyMiUzQSUyMHRydWUlMEElMjAlMjAlMjAlMjAlN0QlMEElN0Q=",highlighted:`{
    <span class="hljs-attr">&quot;zero_optimization&quot;:</span> {
        <span class="hljs-attr">&quot;stage&quot;:</span> <span class="hljs-number">3</span>,
        <span class="hljs-attr">&quot;stage3_gather_16bit_weights_on_model_save&quot;:</span> <span class="hljs-literal">true</span>
    }
}`,wrap:!1}}),Et=new k({props:{title:"fp32",local:"fp32",headingTag:"h3"}}),me=new se({props:{id:"save",options:["offline","online"],$$slots:{default:[Oo]},$$scope:{ctx:v}}}),Vt=new k({props:{title:"Non-Trainer integration",local:"non-trainer-integration",headingTag:"h2"}}),ce=new se({props:{id:"models",options:["pretrained model","non-pretrained model"],$$slots:{default:[ti]},$$scope:{ctx:v}}}),Ft=new k({props:{title:"Troubleshoot",local:"troubleshoot",headingTag:"h2"}}),Pt=new W({props:{code:"cHl0aG9uJTIwLWMlMjAnaW1wb3J0JTIwdG9yY2glM0IlMjBwcmludChmJTIydG9yY2glM0ElMjAlN0J0b3JjaC5fX3ZlcnNpb25fXyU3RCUyMiknJTBBcHl0aG9uJTIwLWMlMjAnaW1wb3J0JTIwdHJhbnNmb3JtZXJzJTNCJTIwcHJpbnQoZiUyMnRyYW5zZm9ybWVycyUzQSUyMCU3QnRyYW5zZm9ybWVycy5fX3ZlcnNpb25fXyU3RCUyMiknJTBBcHl0aG9uJTIwLWMlMjAnaW1wb3J0JTIwZGVlcHNwZWVkJTNCJTIwcHJpbnQoZiUyMmRlZXBzcGVlZCUzQSUyMCU3QmRlZXBzcGVlZC5fX3ZlcnNpb25fXyU3RCUyMikn",highlighted:`python -c <span class="hljs-string">&#x27;import torch; print(f&quot;torch: {torch.__version__}&quot;)&#x27;</span>
python -c <span class="hljs-string">&#x27;import transformers; print(f&quot;transformers: {transformers.__version__}&quot;)&#x27;</span>
python -c <span class="hljs-string">&#x27;import deepspeed; print(f&quot;deepspeed: {deepspeed.__version__}&quot;)&#x27;</span>`,wrap:!1}}),Kt=new k({props:{title:"Process killed at startup",local:"process-killed-at-startup",headingTag:"h3"}}),sl=new k({props:{title:"NaN loss",local:"nan-loss",headingTag:"h3"}}),ol=new W({props:{code:"JTdCJTBBJTIwJTIwJTIwJTIwJTIyZnAxNiUyMiUzQSUyMCU3QiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMmVuYWJsZWQlMjIlM0ElMjAlMjJhdXRvJTIyJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIybG9zc19zY2FsZSUyMiUzQSUyMDAlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJsb3NzX3NjYWxlX3dpbmRvdyUyMiUzQSUyMDEwMDAlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJpbml0aWFsX3NjYWxlX3Bvd2VyJTIyJTNBJTIwMTYlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJoeXN0ZXJlc2lzJTIyJTNBJTIwMiUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMm1pbl9sb3NzX3NjYWxlJTIyJTNBJTIwMSUwQSUyMCUyMCUyMCUyMCU3RCUwQSU3RA==",highlighted:`{
    <span class="hljs-attr">&quot;fp16&quot;:</span> {
        <span class="hljs-attr">&quot;enabled&quot;:</span> <span class="hljs-string">&quot;auto&quot;</span>,
        <span class="hljs-attr">&quot;loss_scale&quot;:</span> <span class="hljs-number">0</span>,
        <span class="hljs-attr">&quot;loss_scale_window&quot;:</span> <span class="hljs-number">1000</span>,
        <span class="hljs-attr">&quot;initial_scale_power&quot;:</span> <span class="hljs-number">16</span>,
        <span class="hljs-attr">&quot;hysteresis&quot;:</span> <span class="hljs-number">2</span>,
        <span class="hljs-attr">&quot;min_loss_scale&quot;:</span> <span class="hljs-number">1</span>
    }
}`,wrap:!1}}),rl=new W({props:{code:"MCUyNSU3QyUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCU3QyUyMDAlMkYxODklMjAlNUIwMCUzQTAwJTNDJTNGJTJDJTIwJTNGaXQlMkZzJTVEJTBBJTIwJTVCZGVlcHNjYWxlJTVEJTIwT1ZFUkZMT1chJTIwUmFuayUyMDAlMjBTa2lwcGluZyUyMHN0ZXAuJTIwQXR0ZW1wdGVkJTIwbG9zcyUyMHNjYWxlJTNBJTIwMjYyMTQ0JTJDJTIwcmVkdWNpbmclMjB0byUyMDI2MjE0NCUwQSUyMCUyMDElMjUlN0MlRTIlOTYlOEMlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlN0MlMjAxJTJGMTg5JTIwJTVCMDAlM0EwMCUzQzAxJTNBMjYlMkMlMjAlMjAyLjE3aXQlMkZzJTVEJTBBJTIwJTVCZGVlcHNjYWxlJTVEJTIwT1ZFUkZMT1chJTIwUmFuayUyMDAlMjBTa2lwcGluZyUyMHN0ZXAuJTIwQXR0ZW1wdGVkJTIwbG9zcyUyMHNjYWxlJTNBJTIwMjYyMTQ0JTJDJTIwcmVkdWNpbmclMjB0byUyMDEzMTA3Mi4wJTBBJTIwJTIwMSUyNSU3QyVFMiU5NiU4OCVFMiU5NiU4RiUwQSUyMCU1Qi4uLiU1RCUwQSUyMCU1QmRlZXBzY2FsZSU1RCUyME9WRVJGTE9XISUyMFJhbmslMjAwJTIwU2tpcHBpbmclMjBzdGVwLiUyMEF0dGVtcHRlZCUyMGxvc3MlMjBzY2FsZSUzQSUyMDElMkMlMjByZWR1Y2luZyUyMHRvJTIwMSUwQSUyMDE0JTI1JTdDJUUyJTk2JTg4JUUyJTk2JTg4JUUyJTk2JTg4JUUyJTk2JTg4JUUyJTk2JTg4JUUyJTk2JTg4JUUyJTk2JTg4JUUyJTk2JTg4JUUyJTk2JTg4JUUyJTk2JTg4JUUyJTk2JTg4JUUyJTk2JTg4JUUyJTk2JTg4JUUyJTk2JTg4JUUyJTk2JTg4JUUyJTk2JTg4JUUyJTk2JThDJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTdDJTIwMjclMkYxODklMjAlNUIwMCUzQTE0JTNDMDElM0ExMyUyQyUyMCUyMDIuMjFpdCUyRnMlNUQlMEElMjAlNUJkZWVwc2NhbGUlNUQlMjBPVkVSRkxPVyElMjBSYW5rJTIwMCUyMFNraXBwaW5nJTIwc3RlcC4lMjBBdHRlbXB0ZWQlMjBsb3NzJTIwc2NhbGUlM0ElMjAxJTJDJTIwcmVkdWNpbmclMjB0byUyMDElMEElMjAxNSUyNSU3QyVFMiU5NiU4OCVFMiU5NiU4OCVFMiU5NiU4OCVFMiU5NiU4OCVFMiU5NiU4OCVFMiU5NiU4OCVFMiU5NiU4OCVFMiU5NiU4OCVFMiU5NiU4OCVFMiU5NiU4OCVFMiU5NiU4OCVFMiU5NiU4OCVFMiU5NiU4OCVFMiU5NiU4OCVFMiU5NiU4OCVFMiU5NiU4OCVFMiU5NiU4OCVFMiU5NiU4RiUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCU3QyUyMDI4JTJGMTg5JTIwJTVCMDAlM0ExNCUzQzAxJTNBMTMlMkMlMjAlMjAyLjE4aXQlMkZzJTVEJTBBJTIwJTVCZGVlcHNjYWxlJTVEJTIwT1ZFUkZMT1chJTIwUmFuayUyMDAlMjBTa2lwcGluZyUyMHN0ZXAuJTIwQXR0ZW1wdGVkJTIwbG9zcyUyMHNjYWxlJTNBJTIwMSUyQyUyMHJlZHVjaW5nJTIwdG8lMjAxJTBBJTIwMTUlMjUlN0MlRTIlOTYlODglRTIlOTYlODglRTIlOTYlODglRTIlOTYlODglRTIlOTYlODglRTIlOTYlODglRTIlOTYlODglRTIlOTYlODglRTIlOTYlODglRTIlOTYlODglRTIlOTYlODglRTIlOTYlODglRTIlOTYlODglRTIlOTYlODglRTIlOTYlODglRTIlOTYlODglRTIlOTYlODglRTIlOTYlOEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlN0MlMjAyOSUyRjE4OSUyMCU1QjAwJTNBMTUlM0MwMSUzQTEzJTJDJTIwJTIwMi4xOGl0JTJGcyU1RCUwQSUyMCU1QmRlZXBzY2FsZSU1RCUyME9WRVJGTE9XISUyMFJhbmslMjAwJTIwU2tpcHBpbmclMjBzdGVwLiUyMEF0dGVtcHRlZCUyMGxvc3MlMjBzY2FsZSUzQSUyMDElMkMlMjByZWR1Y2luZyUyMHRvJTIwMSUwQSU1Qi4uLiU1RA==",highlighted:`0%|                                                                                                                             | 0/189 [00:00&lt;?, ?it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144, reducing to 262144
  1%|▌                                                                                                                    | 1/189 [00:00&lt;01:26,  2.17it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144, reducing to 131072.0
  1%|█▏
 [...]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1
 14%|████████████████▌                                                                                                   | 27/189 [00:14&lt;01:13,  2.21it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1
 15%|█████████████████▏                                                                                                  | 28/189 [00:14&lt;01:13,  2.18it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1
 15%|█████████████████▊                                                                                                  | 29/189 [00:15&lt;01:13,  2.18it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1
[...]`,wrap:!1}}),Ml=new k({props:{title:"Resources",local:"resources",headingTag:"h2"}}),ml=new co({props:{source:"https://github.com/huggingface/transformers/blob/main/docs/source/en/deepspeed.md"}}),{c(){t=c("meta"),y=M(),n=c("p"),r=M(),d(o.$$.fragment),i=M(),u=c("p"),u.innerHTML=C,I=M(),Z=c("table"),Z.innerHTML=g,B=M(),A=c("p"),A.innerHTML=m,q=M(),R=c("p"),R.innerHTML=S,$=M(),b=c("p"),b.innerHTML=G,Y=M(),d(x.$$.fragment),L=M(),d(O.$$.fragment),te=M(),E=c("p"),E.textContent=Ul,le=M(),Q=c("p"),Q.innerHTML=Te,H=M(),d(D.$$.fragment),_=M(),d(z.$$.fragment),fe=M(),d(ee.$$.fragment),hl=M(),de=c("p"),de.textContent=ka,Il=M(),Je=c("table"),Je.innerHTML=Na,Cl=M(),we=c("p"),we.textContent=Ga,$l=M(),d(Ue.$$.fragment),gl=M(),je=c("p"),je.innerHTML=Sa,Al=M(),d(ae.$$.fragment),bl=M(),he=c("p"),he.innerHTML=Xa,_l=M(),d(ne.$$.fragment),vl=M(),d(Ie.$$.fragment),Zl=M(),Ce=c("p"),Ce.textContent=Ea,Bl=M(),$e=c("ol"),$e.innerHTML=Qa,ql=M(),ge=c("p"),ge.textContent=Va,Wl=M(),d(oe.$$.fragment),Rl=M(),Ae=c("ol"),Ae.innerHTML=xa,zl=M(),d(be.$$.fragment),kl=M(),_e=c("p"),_e.innerHTML=Ha,Nl=M(),ve=c("p"),ve.innerHTML=Fa,Gl=M(),d(ie.$$.fragment),Sl=M(),d(re.$$.fragment),Xl=M(),d(Ze.$$.fragment),El=M(),Be=c("p"),Be.innerHTML=Ya,Ql=M(),qe=c("p"),qe.innerHTML=La,Vl=M(),We=c("p"),We.innerHTML=Da,xl=M(),Re=c("p"),Re.innerHTML=Pa,Hl=M(),d(ze.$$.fragment),Fl=M(),d(ke.$$.fragment),Yl=M(),Ne=c("p"),Ne.textContent=Oa,Ll=M(),d(Ge.$$.fragment),Dl=M(),Se=c("p"),Se.innerHTML=Ka,Pl=M(),Xe=c("ul"),Xe.innerHTML=en,Ol=M(),d(Ee.$$.fragment),Kl=M(),Qe=c("p"),Qe.innerHTML=tn,es=M(),d(Ve.$$.fragment),ts=M(),d(xe.$$.fragment),ls=M(),He=c("p"),He.textContent=ln,ss=M(),Fe=c("p"),Fe.textContent=sn,as=M(),Ye=c("p"),Ye.textContent=an,ns=M(),Le=c("p"),Le.innerHTML=nn,os=M(),d(De.$$.fragment),is=M(),d(Pe.$$.fragment),rs=M(),Oe=c("p"),Oe.innerHTML=on,Ms=M(),Ke=c("p"),Ke.innerHTML=rn,ps=M(),d(et.$$.fragment),us=M(),d(tt.$$.fragment),ys=M(),lt=c("p"),lt.textContent=Mn,ms=M(),st=c("p"),st.innerHTML=pn,cs=M(),d(at.$$.fragment),Ts=M(),d(nt.$$.fragment),fs=M(),ot=c("p"),ot.textContent=un,ds=M(),d(Me.$$.fragment),Js=M(),d(it.$$.fragment),ws=M(),rt=c("p"),rt.innerHTML=yn,Us=M(),Mt=c("p"),Mt.textContent=mn,js=M(),d(pe.$$.fragment),hs=M(),d(pt.$$.fragment),Is=M(),ut=c("p"),ut.innerHTML=cn,Cs=M(),yt=c("p"),yt.innerHTML=Tn,$s=M(),d(mt.$$.fragment),gs=M(),d(ct.$$.fragment),As=M(),Tt=c("p"),Tt.innerHTML=fn,bs=M(),ft=c("p"),ft.innerHTML=dn,_s=M(),d(ue.$$.fragment),vs=M(),d(dt.$$.fragment),Zs=M(),Jt=c("p"),Jt.innerHTML=Jn,Bs=M(),d(wt.$$.fragment),qs=M(),Ut=c("p"),Ut.innerHTML=wn,Ws=M(),jt=c("p"),jt.innerHTML=Un,Rs=M(),d(ye.$$.fragment),zs=M(),d(ht.$$.fragment),ks=M(),It=c("p"),It.innerHTML=jn,Ns=M(),d(Ct.$$.fragment),Gs=M(),$t=c("p"),$t.textContent=hn,Ss=M(),d(gt.$$.fragment),Xs=M(),d(At.$$.fragment),Es=M(),bt=c("p"),bt.textContent=In,Qs=M(),d(_t.$$.fragment),Vs=M(),vt=c("p"),vt.textContent=Cn,xs=M(),d(Zt.$$.fragment),Hs=M(),Bt=c("p"),Bt.textContent=$n,Fs=M(),d(qt.$$.fragment),Ys=M(),Wt=c("p"),Wt.innerHTML=gn,Ls=M(),d(Rt.$$.fragment),Ds=M(),d(zt.$$.fragment),Ps=M(),kt=c("p"),kt.innerHTML=An,Os=M(),d(Nt.$$.fragment),Ks=M(),Gt=c("p"),Gt.innerHTML=bn,ea=M(),St=c("p"),St.innerHTML=_n,ta=M(),d(Xt.$$.fragment),la=M(),d(Et.$$.fragment),sa=M(),Qt=c("p"),Qt.textContent=vn,aa=M(),d(me.$$.fragment),na=M(),d(Vt.$$.fragment),oa=M(),xt=c("p"),xt.innerHTML=Zn,ia=M(),Ht=c("p"),Ht.innerHTML=Bn,ra=M(),d(ce.$$.fragment),Ma=M(),d(Ft.$$.fragment),pa=M(),Yt=c("p"),Yt.innerHTML=qn,ua=M(),Lt=c("p"),Lt.textContent=Wn,ya=M(),V=c("ul"),Tl=c("li"),Tl.innerHTML=Rn,Ba=M(),fl=c("li"),fl.innerHTML=zn,qa=M(),Dt=c("li"),dl=c("p"),dl.textContent=kn,Wa=M(),d(Pt.$$.fragment),Ra=M(),Jl=c("li"),Jl.innerHTML=Nn,za=M(),wl=c("li"),wl.innerHTML=Gn,ma=M(),Ot=c("p"),Ot.textContent=Sn,ca=M(),d(Kt.$$.fragment),Ta=M(),el=c("p"),el.textContent=Xn,fa=M(),tl=c("p"),tl.innerHTML=En,da=M(),ll=c("p"),ll.innerHTML=Qn,Ja=M(),d(sl.$$.fragment),wa=M(),al=c("p"),al.textContent=Vn,Ua=M(),nl=c("p"),nl.textContent=xn,ja=M(),d(ol.$$.fragment),ha=M(),il=c("p"),il.innerHTML=Hn,Ia=M(),d(rl.$$.fragment),Ca=M(),d(Ml.$$.fragment),$a=M(),pl=c("p"),pl.innerHTML=Fn,ga=M(),ul=c("p"),ul.textContent=Yn,Aa=M(),yl=c("ul"),yl.innerHTML=Ln,ba=M(),d(ml.$$.fragment),_a=M(),jl=c("p"),this.h()},l(e){const a=mo("svelte-u9bgzb",document.head);t=T(a,"META",{name:!0,content:!0}),a.forEach(l),y=p(e),n=T(e,"P",{}),Za(n).forEach(l),r=p(e),J(o.$$.fragment,e),i=p(e),u=T(e,"P",{"data-svelte-h":!0}),f(u)!=="svelte-1x58rgl"&&(u.innerHTML=C),I=p(e),Z=T(e,"TABLE",{"data-svelte-h":!0}),f(Z)!=="svelte-g16f2l"&&(Z.innerHTML=g),B=p(e),A=T(e,"P",{"data-svelte-h":!0}),f(A)!=="svelte-1s6jzxy"&&(A.innerHTML=m),q=p(e),R=T(e,"P",{"data-svelte-h":!0}),f(R)!=="svelte-1ddnjv6"&&(R.innerHTML=S),$=p(e),b=T(e,"P",{"data-svelte-h":!0}),f(b)!=="svelte-113jy4c"&&(b.innerHTML=G),Y=p(e),J(x.$$.fragment,e),L=p(e),J(O.$$.fragment,e),te=p(e),E=T(e,"P",{"data-svelte-h":!0}),f(E)!=="svelte-9txqst"&&(E.textContent=Ul),le=p(e),Q=T(e,"P",{"data-svelte-h":!0}),f(Q)!=="svelte-4qy75k"&&(Q.innerHTML=Te),H=p(e),J(D.$$.fragment,e),_=p(e),J(z.$$.fragment,e),fe=p(e),J(ee.$$.fragment,e),hl=p(e),de=T(e,"P",{"data-svelte-h":!0}),f(de)!=="svelte-1hpx19l"&&(de.textContent=ka),Il=p(e),Je=T(e,"TABLE",{"data-svelte-h":!0}),f(Je)!=="svelte-d6tlin"&&(Je.innerHTML=Na),Cl=p(e),we=T(e,"P",{"data-svelte-h":!0}),f(we)!=="svelte-1qh23gw"&&(we.textContent=Ga),$l=p(e),J(Ue.$$.fragment,e),gl=p(e),je=T(e,"P",{"data-svelte-h":!0}),f(je)!=="svelte-bnfew5"&&(je.innerHTML=Sa),Al=p(e),J(ae.$$.fragment,e),bl=p(e),he=T(e,"P",{"data-svelte-h":!0}),f(he)!=="svelte-12w6tlx"&&(he.innerHTML=Xa),_l=p(e),J(ne.$$.fragment,e),vl=p(e),J(Ie.$$.fragment,e),Zl=p(e),Ce=T(e,"P",{"data-svelte-h":!0}),f(Ce)!=="svelte-ugzll6"&&(Ce.textContent=Ea),Bl=p(e),$e=T(e,"OL",{"data-svelte-h":!0}),f($e)!=="svelte-8wacw5"&&($e.innerHTML=Qa),ql=p(e),ge=T(e,"P",{"data-svelte-h":!0}),f(ge)!=="svelte-1xpsv2w"&&(ge.textContent=Va),Wl=p(e),J(oe.$$.fragment,e),Rl=p(e),Ae=T(e,"OL",{"data-svelte-h":!0}),f(Ae)!=="svelte-5rgnkz"&&(Ae.innerHTML=xa),zl=p(e),J(be.$$.fragment,e),kl=p(e),_e=T(e,"P",{"data-svelte-h":!0}),f(_e)!=="svelte-1ewr032"&&(_e.innerHTML=Ha),Nl=p(e),ve=T(e,"P",{"data-svelte-h":!0}),f(ve)!=="svelte-1135gvt"&&(ve.innerHTML=Fa),Gl=p(e),J(ie.$$.fragment,e),Sl=p(e),J(re.$$.fragment,e),Xl=p(e),J(Ze.$$.fragment,e),El=p(e),Be=T(e,"P",{"data-svelte-h":!0}),f(Be)!=="svelte-11g1ewl"&&(Be.innerHTML=Ya),Ql=p(e),qe=T(e,"P",{"data-svelte-h":!0}),f(qe)!=="svelte-1ecykwm"&&(qe.innerHTML=La),Vl=p(e),We=T(e,"P",{"data-svelte-h":!0}),f(We)!=="svelte-2lak25"&&(We.innerHTML=Da),xl=p(e),Re=T(e,"P",{"data-svelte-h":!0}),f(Re)!=="svelte-7arozb"&&(Re.innerHTML=Pa),Hl=p(e),J(ze.$$.fragment,e),Fl=p(e),J(ke.$$.fragment,e),Yl=p(e),Ne=T(e,"P",{"data-svelte-h":!0}),f(Ne)!=="svelte-b95nmg"&&(Ne.textContent=Oa),Ll=p(e),J(Ge.$$.fragment,e),Dl=p(e),Se=T(e,"P",{"data-svelte-h":!0}),f(Se)!=="svelte-e0krdz"&&(Se.innerHTML=Ka),Pl=p(e),Xe=T(e,"UL",{"data-svelte-h":!0}),f(Xe)!=="svelte-1o1v50z"&&(Xe.innerHTML=en),Ol=p(e),J(Ee.$$.fragment,e),Kl=p(e),Qe=T(e,"P",{"data-svelte-h":!0}),f(Qe)!=="svelte-10mrw3d"&&(Qe.innerHTML=tn),es=p(e),J(Ve.$$.fragment,e),ts=p(e),J(xe.$$.fragment,e),ls=p(e),He=T(e,"P",{"data-svelte-h":!0}),f(He)!=="svelte-3cq4r9"&&(He.textContent=ln),ss=p(e),Fe=T(e,"P",{"data-svelte-h":!0}),f(Fe)!=="svelte-18k9mzv"&&(Fe.textContent=sn),as=p(e),Ye=T(e,"P",{"data-svelte-h":!0}),f(Ye)!=="svelte-1b1bpok"&&(Ye.textContent=an),ns=p(e),Le=T(e,"P",{"data-svelte-h":!0}),f(Le)!=="svelte-1y41oji"&&(Le.innerHTML=nn),os=p(e),J(De.$$.fragment,e),is=p(e),J(Pe.$$.fragment,e),rs=p(e),Oe=T(e,"P",{"data-svelte-h":!0}),f(Oe)!=="svelte-5jkqwz"&&(Oe.innerHTML=on),Ms=p(e),Ke=T(e,"P",{"data-svelte-h":!0}),f(Ke)!=="svelte-rkkdtg"&&(Ke.innerHTML=rn),ps=p(e),J(et.$$.fragment,e),us=p(e),J(tt.$$.fragment,e),ys=p(e),lt=T(e,"P",{"data-svelte-h":!0}),f(lt)!=="svelte-l72egn"&&(lt.textContent=Mn),ms=p(e),st=T(e,"P",{"data-svelte-h":!0}),f(st)!=="svelte-oqovot"&&(st.innerHTML=pn),cs=p(e),J(at.$$.fragment,e),Ts=p(e),J(nt.$$.fragment,e),fs=p(e),ot=T(e,"P",{"data-svelte-h":!0}),f(ot)!=="svelte-gbn77h"&&(ot.textContent=un),ds=p(e),J(Me.$$.fragment,e),Js=p(e),J(it.$$.fragment,e),ws=p(e),rt=T(e,"P",{"data-svelte-h":!0}),f(rt)!=="svelte-1hg70p7"&&(rt.innerHTML=yn),Us=p(e),Mt=T(e,"P",{"data-svelte-h":!0}),f(Mt)!=="svelte-1fvcbb2"&&(Mt.textContent=mn),js=p(e),J(pe.$$.fragment,e),hs=p(e),J(pt.$$.fragment,e),Is=p(e),ut=T(e,"P",{"data-svelte-h":!0}),f(ut)!=="svelte-f67kiq"&&(ut.innerHTML=cn),Cs=p(e),yt=T(e,"P",{"data-svelte-h":!0}),f(yt)!=="svelte-1s13dgb"&&(yt.innerHTML=Tn),$s=p(e),J(mt.$$.fragment,e),gs=p(e),J(ct.$$.fragment,e),As=p(e),Tt=T(e,"P",{"data-svelte-h":!0}),f(Tt)!=="svelte-a6t3js"&&(Tt.innerHTML=fn),bs=p(e),ft=T(e,"P",{"data-svelte-h":!0}),f(ft)!=="svelte-zmib8a"&&(ft.innerHTML=dn),_s=p(e),J(ue.$$.fragment,e),vs=p(e),J(dt.$$.fragment,e),Zs=p(e),Jt=T(e,"P",{"data-svelte-h":!0}),f(Jt)!=="svelte-1beh14s"&&(Jt.innerHTML=Jn),Bs=p(e),J(wt.$$.fragment,e),qs=p(e),Ut=T(e,"P",{"data-svelte-h":!0}),f(Ut)!=="svelte-w8kimo"&&(Ut.innerHTML=wn),Ws=p(e),jt=T(e,"P",{"data-svelte-h":!0}),f(jt)!=="svelte-d7ogvj"&&(jt.innerHTML=Un),Rs=p(e),J(ye.$$.fragment,e),zs=p(e),J(ht.$$.fragment,e),ks=p(e),It=T(e,"P",{"data-svelte-h":!0}),f(It)!=="svelte-jssjer"&&(It.innerHTML=jn),Ns=p(e),J(Ct.$$.fragment,e),Gs=p(e),$t=T(e,"P",{"data-svelte-h":!0}),f($t)!=="svelte-1up77xx"&&($t.textContent=hn),Ss=p(e),J(gt.$$.fragment,e),Xs=p(e),J(At.$$.fragment,e),Es=p(e),bt=T(e,"P",{"data-svelte-h":!0}),f(bt)!=="svelte-2f0twl"&&(bt.textContent=In),Qs=p(e),J(_t.$$.fragment,e),Vs=p(e),vt=T(e,"P",{"data-svelte-h":!0}),f(vt)!=="svelte-8l6b91"&&(vt.textContent=Cn),xs=p(e),J(Zt.$$.fragment,e),Hs=p(e),Bt=T(e,"P",{"data-svelte-h":!0}),f(Bt)!=="svelte-1g12cu1"&&(Bt.textContent=$n),Fs=p(e),J(qt.$$.fragment,e),Ys=p(e),Wt=T(e,"P",{"data-svelte-h":!0}),f(Wt)!=="svelte-jftyib"&&(Wt.innerHTML=gn),Ls=p(e),J(Rt.$$.fragment,e),Ds=p(e),J(zt.$$.fragment,e),Ps=p(e),kt=T(e,"P",{"data-svelte-h":!0}),f(kt)!=="svelte-1srdo4a"&&(kt.innerHTML=An),Os=p(e),J(Nt.$$.fragment,e),Ks=p(e),Gt=T(e,"P",{"data-svelte-h":!0}),f(Gt)!=="svelte-ymywwd"&&(Gt.innerHTML=bn),ea=p(e),St=T(e,"P",{"data-svelte-h":!0}),f(St)!=="svelte-1c9q9j4"&&(St.innerHTML=_n),ta=p(e),J(Xt.$$.fragment,e),la=p(e),J(Et.$$.fragment,e),sa=p(e),Qt=T(e,"P",{"data-svelte-h":!0}),f(Qt)!=="svelte-1437twr"&&(Qt.textContent=vn),aa=p(e),J(me.$$.fragment,e),na=p(e),J(Vt.$$.fragment,e),oa=p(e),xt=T(e,"P",{"data-svelte-h":!0}),f(xt)!=="svelte-1791n6i"&&(xt.innerHTML=Zn),ia=p(e),Ht=T(e,"P",{"data-svelte-h":!0}),f(Ht)!=="svelte-ggeloq"&&(Ht.innerHTML=Bn),ra=p(e),J(ce.$$.fragment,e),Ma=p(e),J(Ft.$$.fragment,e),pa=p(e),Yt=T(e,"P",{"data-svelte-h":!0}),f(Yt)!=="svelte-1e3q0we"&&(Yt.innerHTML=qn),ua=p(e),Lt=T(e,"P",{"data-svelte-h":!0}),f(Lt)!=="svelte-1xz3o2z"&&(Lt.textContent=Wn),ya=p(e),V=T(e,"UL",{});var F=Za(V);Tl=T(F,"LI",{"data-svelte-h":!0}),f(Tl)!=="svelte-18grubg"&&(Tl.innerHTML=Rn),Ba=p(F),fl=T(F,"LI",{"data-svelte-h":!0}),f(fl)!=="svelte-q5dr5s"&&(fl.innerHTML=zn),qa=p(F),Dt=T(F,"LI",{});var cl=Za(Dt);dl=T(cl,"P",{"data-svelte-h":!0}),f(dl)!=="svelte-1k6leae"&&(dl.textContent=kn),Wa=p(cl),J(Pt.$$.fragment,cl),cl.forEach(l),Ra=p(F),Jl=T(F,"LI",{"data-svelte-h":!0}),f(Jl)!=="svelte-1imspt9"&&(Jl.innerHTML=Nn),za=p(F),wl=T(F,"LI",{"data-svelte-h":!0}),f(wl)!=="svelte-1nfpn90"&&(wl.innerHTML=Gn),F.forEach(l),ma=p(e),Ot=T(e,"P",{"data-svelte-h":!0}),f(Ot)!=="svelte-oia8x0"&&(Ot.textContent=Sn),ca=p(e),J(Kt.$$.fragment,e),Ta=p(e),el=T(e,"P",{"data-svelte-h":!0}),f(el)!=="svelte-11ycwbg"&&(el.textContent=Xn),fa=p(e),tl=T(e,"P",{"data-svelte-h":!0}),f(tl)!=="svelte-dyag9c"&&(tl.innerHTML=En),da=p(e),ll=T(e,"P",{"data-svelte-h":!0}),f(ll)!=="svelte-1744kiq"&&(ll.innerHTML=Qn),Ja=p(e),J(sl.$$.fragment,e),wa=p(e),al=T(e,"P",{"data-svelte-h":!0}),f(al)!=="svelte-1atsnu2"&&(al.textContent=Vn),Ua=p(e),nl=T(e,"P",{"data-svelte-h":!0}),f(nl)!=="svelte-3m4nno"&&(nl.textContent=xn),ja=p(e),J(ol.$$.fragment,e),ha=p(e),il=T(e,"P",{"data-svelte-h":!0}),f(il)!=="svelte-1gpmvr7"&&(il.innerHTML=Hn),Ia=p(e),J(rl.$$.fragment,e),Ca=p(e),J(Ml.$$.fragment,e),$a=p(e),pl=T(e,"P",{"data-svelte-h":!0}),f(pl)!=="svelte-18m4cm3"&&(pl.innerHTML=Fn),ga=p(e),ul=T(e,"P",{"data-svelte-h":!0}),f(ul)!=="svelte-mkmcno"&&(ul.textContent=Yn),Aa=p(e),yl=T(e,"UL",{"data-svelte-h":!0}),f(yl)!=="svelte-o0yfva"&&(yl.innerHTML=Ln),ba=p(e),J(ml.$$.fragment,e),_a=p(e),jl=T(e,"P",{}),Za(jl).forEach(l),this.h()},h(){ro(t,"name","hf:doc:metadata"),ro(t,"content",si)},m(e,a){P(document.head,t),s(e,y,a),s(e,n,a),s(e,r,a),w(o,e,a),s(e,i,a),s(e,u,a),s(e,I,a),s(e,Z,a),s(e,B,a),s(e,A,a),s(e,q,a),s(e,R,a),s(e,$,a),s(e,b,a),s(e,Y,a),w(x,e,a),s(e,L,a),w(O,e,a),s(e,te,a),s(e,E,a),s(e,le,a),s(e,Q,a),s(e,H,a),w(D,e,a),s(e,_,a),w(z,e,a),s(e,fe,a),w(ee,e,a),s(e,hl,a),s(e,de,a),s(e,Il,a),s(e,Je,a),s(e,Cl,a),s(e,we,a),s(e,$l,a),w(Ue,e,a),s(e,gl,a),s(e,je,a),s(e,Al,a),w(ae,e,a),s(e,bl,a),s(e,he,a),s(e,_l,a),w(ne,e,a),s(e,vl,a),w(Ie,e,a),s(e,Zl,a),s(e,Ce,a),s(e,Bl,a),s(e,$e,a),s(e,ql,a),s(e,ge,a),s(e,Wl,a),w(oe,e,a),s(e,Rl,a),s(e,Ae,a),s(e,zl,a),w(be,e,a),s(e,kl,a),s(e,_e,a),s(e,Nl,a),s(e,ve,a),s(e,Gl,a),w(ie,e,a),s(e,Sl,a),w(re,e,a),s(e,Xl,a),w(Ze,e,a),s(e,El,a),s(e,Be,a),s(e,Ql,a),s(e,qe,a),s(e,Vl,a),s(e,We,a),s(e,xl,a),s(e,Re,a),s(e,Hl,a),w(ze,e,a),s(e,Fl,a),w(ke,e,a),s(e,Yl,a),s(e,Ne,a),s(e,Ll,a),w(Ge,e,a),s(e,Dl,a),s(e,Se,a),s(e,Pl,a),s(e,Xe,a),s(e,Ol,a),w(Ee,e,a),s(e,Kl,a),s(e,Qe,a),s(e,es,a),w(Ve,e,a),s(e,ts,a),w(xe,e,a),s(e,ls,a),s(e,He,a),s(e,ss,a),s(e,Fe,a),s(e,as,a),s(e,Ye,a),s(e,ns,a),s(e,Le,a),s(e,os,a),w(De,e,a),s(e,is,a),w(Pe,e,a),s(e,rs,a),s(e,Oe,a),s(e,Ms,a),s(e,Ke,a),s(e,ps,a),w(et,e,a),s(e,us,a),w(tt,e,a),s(e,ys,a),s(e,lt,a),s(e,ms,a),s(e,st,a),s(e,cs,a),w(at,e,a),s(e,Ts,a),w(nt,e,a),s(e,fs,a),s(e,ot,a),s(e,ds,a),w(Me,e,a),s(e,Js,a),w(it,e,a),s(e,ws,a),s(e,rt,a),s(e,Us,a),s(e,Mt,a),s(e,js,a),w(pe,e,a),s(e,hs,a),w(pt,e,a),s(e,Is,a),s(e,ut,a),s(e,Cs,a),s(e,yt,a),s(e,$s,a),w(mt,e,a),s(e,gs,a),w(ct,e,a),s(e,As,a),s(e,Tt,a),s(e,bs,a),s(e,ft,a),s(e,_s,a),w(ue,e,a),s(e,vs,a),w(dt,e,a),s(e,Zs,a),s(e,Jt,a),s(e,Bs,a),w(wt,e,a),s(e,qs,a),s(e,Ut,a),s(e,Ws,a),s(e,jt,a),s(e,Rs,a),w(ye,e,a),s(e,zs,a),w(ht,e,a),s(e,ks,a),s(e,It,a),s(e,Ns,a),w(Ct,e,a),s(e,Gs,a),s(e,$t,a),s(e,Ss,a),w(gt,e,a),s(e,Xs,a),w(At,e,a),s(e,Es,a),s(e,bt,a),s(e,Qs,a),w(_t,e,a),s(e,Vs,a),s(e,vt,a),s(e,xs,a),w(Zt,e,a),s(e,Hs,a),s(e,Bt,a),s(e,Fs,a),w(qt,e,a),s(e,Ys,a),s(e,Wt,a),s(e,Ls,a),w(Rt,e,a),s(e,Ds,a),w(zt,e,a),s(e,Ps,a),s(e,kt,a),s(e,Os,a),w(Nt,e,a),s(e,Ks,a),s(e,Gt,a),s(e,ea,a),s(e,St,a),s(e,ta,a),w(Xt,e,a),s(e,la,a),w(Et,e,a),s(e,sa,a),s(e,Qt,a),s(e,aa,a),w(me,e,a),s(e,na,a),w(Vt,e,a),s(e,oa,a),s(e,xt,a),s(e,ia,a),s(e,Ht,a),s(e,ra,a),w(ce,e,a),s(e,Ma,a),w(Ft,e,a),s(e,pa,a),s(e,Yt,a),s(e,ua,a),s(e,Lt,a),s(e,ya,a),s(e,V,a),P(V,Tl),P(V,Ba),P(V,fl),P(V,qa),P(V,Dt),P(Dt,dl),P(Dt,Wa),w(Pt,Dt,null),P(V,Ra),P(V,Jl),P(V,za),P(V,wl),s(e,ma,a),s(e,Ot,a),s(e,ca,a),w(Kt,e,a),s(e,Ta,a),s(e,el,a),s(e,fa,a),s(e,tl,a),s(e,da,a),s(e,ll,a),s(e,Ja,a),w(sl,e,a),s(e,wa,a),s(e,al,a),s(e,Ua,a),s(e,nl,a),s(e,ja,a),w(ol,e,a),s(e,ha,a),s(e,il,a),s(e,Ia,a),w(rl,e,a),s(e,Ca,a),w(Ml,e,a),s(e,$a,a),s(e,pl,a),s(e,ga,a),s(e,ul,a),s(e,Aa,a),s(e,yl,a),s(e,ba,a),w(ml,e,a),s(e,_a,a),s(e,jl,a),va=!0},p(e,[a]){const F={};a&2&&(F.$$scope={dirty:a,ctx:e}),x.$set(F);const cl={};a&2&&(cl.$$scope={dirty:a,ctx:e}),O.$set(cl);const Dn={};a&2&&(Dn.$$scope={dirty:a,ctx:e}),z.$set(Dn);const Pn={};a&2&&(Pn.$$scope={dirty:a,ctx:e}),ae.$set(Pn);const On={};a&2&&(On.$$scope={dirty:a,ctx:e}),ne.$set(On);const Kn={};a&2&&(Kn.$$scope={dirty:a,ctx:e}),oe.$set(Kn);const eo={};a&2&&(eo.$$scope={dirty:a,ctx:e}),ie.$set(eo);const to={};a&2&&(to.$$scope={dirty:a,ctx:e}),re.$set(to);const lo={};a&2&&(lo.$$scope={dirty:a,ctx:e}),Me.$set(lo);const so={};a&2&&(so.$$scope={dirty:a,ctx:e}),pe.$set(so);const ao={};a&2&&(ao.$$scope={dirty:a,ctx:e}),ue.$set(ao);const no={};a&2&&(no.$$scope={dirty:a,ctx:e}),ye.$set(no);const oo={};a&2&&(oo.$$scope={dirty:a,ctx:e}),me.$set(oo);const io={};a&2&&(io.$$scope={dirty:a,ctx:e}),ce.$set(io)},i(e){va||(U(o.$$.fragment,e),U(x.$$.fragment,e),U(O.$$.fragment,e),U(D.$$.fragment,e),U(z.$$.fragment,e),U(ee.$$.fragment,e),U(Ue.$$.fragment,e),U(ae.$$.fragment,e),U(ne.$$.fragment,e),U(Ie.$$.fragment,e),U(oe.$$.fragment,e),U(be.$$.fragment,e),U(ie.$$.fragment,e),U(re.$$.fragment,e),U(Ze.$$.fragment,e),U(ze.$$.fragment,e),U(ke.$$.fragment,e),U(Ge.$$.fragment,e),U(Ee.$$.fragment,e),U(Ve.$$.fragment,e),U(xe.$$.fragment,e),U(De.$$.fragment,e),U(Pe.$$.fragment,e),U(et.$$.fragment,e),U(tt.$$.fragment,e),U(at.$$.fragment,e),U(nt.$$.fragment,e),U(Me.$$.fragment,e),U(it.$$.fragment,e),U(pe.$$.fragment,e),U(pt.$$.fragment,e),U(mt.$$.fragment,e),U(ct.$$.fragment,e),U(ue.$$.fragment,e),U(dt.$$.fragment,e),U(wt.$$.fragment,e),U(ye.$$.fragment,e),U(ht.$$.fragment,e),U(Ct.$$.fragment,e),U(gt.$$.fragment,e),U(At.$$.fragment,e),U(_t.$$.fragment,e),U(Zt.$$.fragment,e),U(qt.$$.fragment,e),U(Rt.$$.fragment,e),U(zt.$$.fragment,e),U(Nt.$$.fragment,e),U(Xt.$$.fragment,e),U(Et.$$.fragment,e),U(me.$$.fragment,e),U(Vt.$$.fragment,e),U(ce.$$.fragment,e),U(Ft.$$.fragment,e),U(Pt.$$.fragment,e),U(Kt.$$.fragment,e),U(sl.$$.fragment,e),U(ol.$$.fragment,e),U(rl.$$.fragment,e),U(Ml.$$.fragment,e),U(ml.$$.fragment,e),va=!0)},o(e){j(o.$$.fragment,e),j(x.$$.fragment,e),j(O.$$.fragment,e),j(D.$$.fragment,e),j(z.$$.fragment,e),j(ee.$$.fragment,e),j(Ue.$$.fragment,e),j(ae.$$.fragment,e),j(ne.$$.fragment,e),j(Ie.$$.fragment,e),j(oe.$$.fragment,e),j(be.$$.fragment,e),j(ie.$$.fragment,e),j(re.$$.fragment,e),j(Ze.$$.fragment,e),j(ze.$$.fragment,e),j(ke.$$.fragment,e),j(Ge.$$.fragment,e),j(Ee.$$.fragment,e),j(Ve.$$.fragment,e),j(xe.$$.fragment,e),j(De.$$.fragment,e),j(Pe.$$.fragment,e),j(et.$$.fragment,e),j(tt.$$.fragment,e),j(at.$$.fragment,e),j(nt.$$.fragment,e),j(Me.$$.fragment,e),j(it.$$.fragment,e),j(pe.$$.fragment,e),j(pt.$$.fragment,e),j(mt.$$.fragment,e),j(ct.$$.fragment,e),j(ue.$$.fragment,e),j(dt.$$.fragment,e),j(wt.$$.fragment,e),j(ye.$$.fragment,e),j(ht.$$.fragment,e),j(Ct.$$.fragment,e),j(gt.$$.fragment,e),j(At.$$.fragment,e),j(_t.$$.fragment,e),j(Zt.$$.fragment,e),j(qt.$$.fragment,e),j(Rt.$$.fragment,e),j(zt.$$.fragment,e),j(Nt.$$.fragment,e),j(Xt.$$.fragment,e),j(Et.$$.fragment,e),j(me.$$.fragment,e),j(Vt.$$.fragment,e),j(ce.$$.fragment,e),j(Ft.$$.fragment,e),j(Pt.$$.fragment,e),j(Kt.$$.fragment,e),j(sl.$$.fragment,e),j(ol.$$.fragment,e),j(rl.$$.fragment,e),j(Ml.$$.fragment,e),j(ml.$$.fragment,e),va=!1},d(e){e&&(l(y),l(n),l(r),l(i),l(u),l(I),l(Z),l(B),l(A),l(q),l(R),l($),l(b),l(Y),l(L),l(te),l(E),l(le),l(Q),l(H),l(_),l(fe),l(hl),l(de),l(Il),l(Je),l(Cl),l(we),l($l),l(gl),l(je),l(Al),l(bl),l(he),l(_l),l(vl),l(Zl),l(Ce),l(Bl),l($e),l(ql),l(ge),l(Wl),l(Rl),l(Ae),l(zl),l(kl),l(_e),l(Nl),l(ve),l(Gl),l(Sl),l(Xl),l(El),l(Be),l(Ql),l(qe),l(Vl),l(We),l(xl),l(Re),l(Hl),l(Fl),l(Yl),l(Ne),l(Ll),l(Dl),l(Se),l(Pl),l(Xe),l(Ol),l(Kl),l(Qe),l(es),l(ts),l(ls),l(He),l(ss),l(Fe),l(as),l(Ye),l(ns),l(Le),l(os),l(is),l(rs),l(Oe),l(Ms),l(Ke),l(ps),l(us),l(ys),l(lt),l(ms),l(st),l(cs),l(Ts),l(fs),l(ot),l(ds),l(Js),l(ws),l(rt),l(Us),l(Mt),l(js),l(hs),l(Is),l(ut),l(Cs),l(yt),l($s),l(gs),l(As),l(Tt),l(bs),l(ft),l(_s),l(vs),l(Zs),l(Jt),l(Bs),l(qs),l(Ut),l(Ws),l(jt),l(Rs),l(zs),l(ks),l(It),l(Ns),l(Gs),l($t),l(Ss),l(Xs),l(Es),l(bt),l(Qs),l(Vs),l(vt),l(xs),l(Hs),l(Bt),l(Fs),l(Ys),l(Wt),l(Ls),l(Ds),l(Ps),l(kt),l(Os),l(Ks),l(Gt),l(ea),l(St),l(ta),l(la),l(sa),l(Qt),l(aa),l(na),l(oa),l(xt),l(ia),l(Ht),l(ra),l(Ma),l(pa),l(Yt),l(ua),l(Lt),l(ya),l(V),l(ma),l(Ot),l(ca),l(Ta),l(el),l(fa),l(tl),l(da),l(ll),l(Ja),l(wa),l(al),l(Ua),l(nl),l(ja),l(ha),l(il),l(Ia),l(Ca),l($a),l(pl),l(ga),l(ul),l(Aa),l(yl),l(ba),l(_a),l(jl)),l(t),h(o,e),h(x,e),h(O,e),h(D,e),h(z,e),h(ee,e),h(Ue,e),h(ae,e),h(ne,e),h(Ie,e),h(oe,e),h(be,e),h(ie,e),h(re,e),h(Ze,e),h(ze,e),h(ke,e),h(Ge,e),h(Ee,e),h(Ve,e),h(xe,e),h(De,e),h(Pe,e),h(et,e),h(tt,e),h(at,e),h(nt,e),h(Me,e),h(it,e),h(pe,e),h(pt,e),h(mt,e),h(ct,e),h(ue,e),h(dt,e),h(wt,e),h(ye,e),h(ht,e),h(Ct,e),h(gt,e),h(At,e),h(_t,e),h(Zt,e),h(qt,e),h(Rt,e),h(zt,e),h(Nt,e),h(Xt,e),h(Et,e),h(me,e),h(Vt,e),h(ce,e),h(Ft,e),h(Pt),h(Kt,e),h(sl,e),h(ol,e),h(rl,e),h(Ml,e),h(ml,e)}}}const si='{"title":"DeepSpeed","local":"deepspeed","sections":[{"title":"Choosing a ZeRO stage","local":"choosing-a-zero-stage","sections":[],"depth":2},{"title":"Config file","local":"config-file","sections":[{"title":"DeepSpeed versus Trainer parameters","local":"deepspeed-versus-trainer-parameters","sections":[],"depth":3},{"title":"ZeRO stage","local":"zero-stage","sections":[],"depth":3},{"title":"Initialize large models","local":"initialize-large-models","sections":[],"depth":3},{"title":"NVMe","local":"nvme","sections":[],"depth":3}],"depth":2},{"title":"Training features","local":"training-features","sections":[{"title":"Gradient checkpointing","local":"gradient-checkpointing","sections":[],"depth":3},{"title":"Batch size","local":"batch-size","sections":[],"depth":3},{"title":"Communication data type","local":"communication-data-type","sections":[],"depth":3},{"title":"Gradient accumulation","local":"gradient-accumulation","sections":[],"depth":3},{"title":"Gradient clipping","local":"gradient-clipping","sections":[],"depth":3},{"title":"Mixed precision training","local":"mixed-precision-training","sections":[],"depth":3},{"title":"Optimizer and scheduler","local":"optimizer-and-scheduler","sections":[],"depth":3},{"title":"Universal checkpointing","local":"universal-checkpointing","sections":[],"depth":3}],"depth":2},{"title":"Deploy","local":"deploy","sections":[{"title":"Multi-node","local":"multi-node","sections":[],"depth":3},{"title":"Slurm","local":"slurm","sections":[],"depth":3},{"title":"Jupyter Notebook","local":"jupyter-notebook","sections":[],"depth":3}],"depth":2},{"title":"Save model weights","local":"save-model-weights","sections":[{"title":"fp16","local":"fp16","sections":[],"depth":3},{"title":"fp32","local":"fp32","sections":[],"depth":3}],"depth":2},{"title":"Non-Trainer integration","local":"non-trainer-integration","sections":[],"depth":2},{"title":"Troubleshoot","local":"troubleshoot","sections":[{"title":"Process killed at startup","local":"process-killed-at-startup","sections":[],"depth":3},{"title":"NaN loss","local":"nan-loss","sections":[],"depth":3}],"depth":2},{"title":"Resources","local":"resources","sections":[],"depth":2}],"depth":1}';function ai(v){return po(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ui extends uo{constructor(t){super(),yo(this,t,ai,li,Mo,{})}}export{ui as component};
