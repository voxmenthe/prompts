import{s as rp,o as pp,n as U}from"../chunks/scheduler.18a86fab.js";import{S as mp,i as dp,g as o,s as n,r as d,A as up,h as r,f as l,c as a,j as ap,u,x as p,k as ip,y as fp,a as s,v as f,d as h,t as c,w as M}from"../chunks/index.98837b22.js";import{T as _}from"../chunks/Tip.77304350.js";import{C as $}from"../chunks/CodeBlock.8d0c2e8a.js";import{H as J,E as hp}from"../chunks/getInferenceSnippets.06c2775f.js";import{H as op,a as Li}from"../chunks/HfOption.6641485e.js";function cp(g){let i,y='Try adding new models with a more <a href="./modular_transformers">modular</a> approach first. This makes it significantly easier to contribute a model to Transformers!';return{c(){i=o("p"),i.innerHTML=y},l(m){i=r(m,"P",{"data-svelte-h":!0}),p(i)!=="svelte-1vf3pvi"&&(i.innerHTML=y)},m(m,w){s(m,i,w)},p:U,d(m){m&&l(i)}}}function Mp(g){let i,y='Learn more about our design principles on the <a href="./philosophy">Philosophy</a> doc.';return{c(){i=o("p"),i.innerHTML=y},l(m){i=r(m,"P",{"data-svelte-h":!0}),p(i)!=="svelte-15l6wnx"&&(i.innerHTML=y)},m(m,w){s(m,i,w)},p:U,d(m){m&&l(i)}}}function yp(g){let i,y='Filter by the <a href="https://github.com/huggingface/transformers/labels/New%20model" rel="nofollow">New model</a> label on GitHub to view and add any existing model requests.';return{c(){i=o("p"),i.innerHTML=y},l(m){i=r(m,"P",{"data-svelte-h":!0}),p(i)!=="svelte-w1pu7w"&&(i.innerHTML=y)},m(m,w){s(m,i,w)},p:U,d(m){m&&l(i)}}}function wp(g){let i,y='Each contributor has a unique style and workflow for adding models to Transformers. For an example, take a look at how <a href="https://github.com/huggingface/transformers/pull/29167" rel="nofollow">Gemma</a> was added.';return{c(){i=o("p"),i.innerHTML=y},l(m){i=r(m,"P",{"data-svelte-h":!0}),p(i)!=="svelte-87s97g"&&(i.innerHTML=y)},m(m,w){s(m,i,w)},p:U,d(m){m&&l(i)}}}function Tp(g){let i,y="We don‚Äôt recommend setting up a GPU environment to run the original model because it can be expensive. Instead, work in a CPU environment first to verify the model works in Transformers. Once it does, then you can verify it on a GPU.";return{c(){i=o("p"),i.textContent=y},l(m){i=r(m,"P",{"data-svelte-h":!0}),p(i)!=="svelte-19xgyyj"&&(i.textContent=y)},m(m,w){s(m,i,w)},p:U,d(m){m&&l(i)}}}function bp(g){let i,y='If the model architecture is identical to an existing model, skip ahead to add a <a href="#conversion-script">conversion script</a>, because you can reuse the architecture of the existing model.';return{c(){i=o("p"),i.innerHTML=y},l(m){i=r(m,"P",{"data-svelte-h":!0}),p(i)!=="svelte-6yspk6"&&(i.innerHTML=y)},m(m,w){s(m,i,w)},p:U,d(m){m&&l(i)}}}function gp(g){let i,y='Refer to the ELECTRA <a href="https://gist.github.com/LysandreJik/db4c948f6b4483960de5cbac598ad4ed" rel="nofollow">integration checks</a> for a good example of how to decompose a model into smaller components.';return{c(){i=o("p"),i.innerHTML=y},l(m){i=r(m,"P",{"data-svelte-h":!0}),p(i)!=="svelte-1tk95o9"&&(i.innerHTML=y)},m(m,w){s(m,i,w)},p:U,d(m){m&&l(i)}}}function $p(g){let i,y="This strategy relies on breaking the original model into smaller sub-components, such as when the code can be easily run in eager mode. While more difficult, there are some advantages to this approach.",m,w,T="<li>It is easier later to compare the original model to your implementation. You can automatically verify that each individual component matches its corresponding component in the Transformers‚Äô implementation. This is better than relying on a visual comparison based on print statements.</li> <li>It is easier to port individual components instead of the entire model.</li> <li>It is easier for understanding how a model works by breaking it up into smaller parts.</li> <li>It is easier to prevent regressions at a later stage when you change your code thanks to component-by-component tests.</li>",b,j,v;return j=new _({props:{warning:!1,$$slots:{default:[gp]},$$scope:{ctx:g}}}),{c(){i=o("p"),i.textContent=y,m=n(),w=o("ol"),w.innerHTML=T,b=n(),d(j.$$.fragment)},l(C){i=r(C,"P",{"data-svelte-h":!0}),p(i)!=="svelte-12hhwz6"&&(i.textContent=y),m=a(C),w=r(C,"OL",{"data-svelte-h":!0}),p(w)!=="svelte-1pi7d2z"&&(w.innerHTML=T),b=a(C),u(j.$$.fragment,C)},m(C,k){s(C,i,k),s(C,m,k),s(C,w,k),s(C,b,k),f(j,C,k),v=!0},p(C,k){const V={};k&2&&(V.$$scope={dirty:k,ctx:C}),j.$set(V)},i(C){v||(h(j.$$.fragment,C),v=!0)},o(C){c(j.$$.fragment,C),v=!1},d(C){C&&(l(i),l(m),l(w),l(b)),M(j,C)}}}function jp(g){let i,y="This strategy is viable when the original codebase is too complex, only allows intermediate components to be run in compiled mode, or if it‚Äôs too time-consuming (maybe even impossible) to separate the model into smaller sub-components.",m,w,T='For example, the MeshTensorFlow implementation of <a href="https://github.com/tensorflow/mesh/tree/master/mesh_tensorflow" rel="nofollow">T5</a> is too complex and doesn‚Äôt offer a simple way to decompose the model into its sub-components. In this situation, you‚Äôll have to rely on verifying print statements.';return{c(){i=o("p"),i.textContent=y,m=n(),w=o("p"),w.innerHTML=T},l(b){i=r(b,"P",{"data-svelte-h":!0}),p(i)!=="svelte-1jhtda"&&(i.textContent=y),m=a(b),w=r(b,"P",{"data-svelte-h":!0}),p(w)!=="svelte-1vz7b7r"&&(w.innerHTML=T)},m(b,j){s(b,i,j),s(b,m,j),s(b,w,j)},p:U,d(b){b&&(l(i),l(m),l(w))}}}function Cp(g){let i,y,m,w;return i=new Li({props:{id:"debug-strategy",option:"sub-components",$$slots:{default:[$p]},$$scope:{ctx:g}}}),m=new Li({props:{id:"debug-strategy",option:"model and tokenizer",$$slots:{default:[jp]},$$scope:{ctx:g}}}),{c(){d(i.$$.fragment),y=n(),d(m.$$.fragment)},l(T){u(i.$$.fragment,T),y=a(T),u(m.$$.fragment,T)},m(T,b){f(i,T,b),s(T,y,b),f(m,T,b),w=!0},p(T,b){const j={};b&2&&(j.$$scope={dirty:b,ctx:T}),i.$set(j);const v={};b&2&&(v.$$scope={dirty:b,ctx:T}),m.$set(v)},i(T){w||(h(i.$$.fragment,T),h(m.$$.fragment,T),w=!0)},o(T){c(i.$$.fragment,T),c(m.$$.fragment,T),w=!1},d(T){T&&l(y),M(i,T),M(m,T)}}}function Jp(g){let i,y="Try looking for an existing conversion script to copy, adapt, and reuse for your model!",m,w,T='<li>If you‚Äôre porting a model from TensorFlow to PyTorch, a good starting point may be the BERT <a href="https://github.com/huggingface/transformers/blob/7acfa95afb8194f8f9c1f4d2c6028224dbed35a2/src/transformers/models/bert/modeling_bert.py#L91" rel="nofollow">conversion script</a>.</li> <li>If you‚Äôre porting a model from PyTorch to PyTorch, a good starting point may be the BART <a href="https://github.com/huggingface/transformers/blob/main/src/transformers/models/bart/convert_bart_original_pytorch_checkpoint_to_pytorch.py" rel="nofollow">conversion script</a>.</li>';return{c(){i=o("p"),i.textContent=y,m=n(),w=o("ul"),w.innerHTML=T},l(b){i=r(b,"P",{"data-svelte-h":!0}),p(i)!=="svelte-pc9dd5"&&(i.textContent=y),m=a(b),w=r(b,"UL",{"data-svelte-h":!0}),p(w)!=="svelte-1pqr4gy"&&(w.innerHTML=T)},m(b,j){s(b,i,j),s(b,m,j),s(b,w,j)},p:U,d(b){b&&(l(i),l(m),l(w))}}}function vp(g){let i,y;return i=new $({props:{code:"UlVOX1NMT1clM0QxJTIwcHl0ZXN0JTIwLXN2JTIwdGVzdHMlMkZtb2RlbHMlMkZicmFuZF9uZXdfbGxhbWElMkZ0ZXN0X21vZGVsaW5nX2JyYW5kX25ld19sbGFtYS5weSUzQSUzQUJyYW5kTmV3TGxhbWFNb2RlbEludGVncmF0aW9uVGVzdHM=",highlighted:"RUN_SLOW=1 pytest -sv tests/models/brand_new_llama/test_modeling_brand_new_llama.py::BrandNewLlamaModelIntegrationTests",wrap:!1}}),{c(){d(i.$$.fragment)},l(m){u(i.$$.fragment,m)},m(m,w){f(i,m,w),y=!0},p:U,i(m){y||(h(i.$$.fragment,m),y=!0)},o(m){c(i.$$.fragment,m),y=!1},d(m){M(i,m)}}}function Up(g){let i,y;return i=new $({props:{code:"U0VUJTIwUlVOX1NMT1clM0QxJTIwcHl0ZXN0JTIwLXN2JTIwdGVzdHMlMkZtb2RlbHMlMkZicmFuZF9uZXdfbGxhbWElMkZ0ZXN0X21vZGVsaW5nX2JyYW5kX25ld19sbGFtYS5weSUzQSUzQUJyYW5kTmV3TGxhbWFNb2RlbEludGVncmF0aW9uVGVzdHM=",highlighted:"SET RUN_SLOW=1 pytest -sv tests/models/brand_new_llama/test_modeling_brand_new_llama.py::BrandNewLlamaModelIntegrationTests",wrap:!1}}),{c(){d(i.$$.fragment)},l(m){u(i.$$.fragment,m)},m(m,w){f(i,m,w),y=!0},p:U,i(m){y||(h(i.$$.fragment,m),y=!0)},o(m){c(i.$$.fragment,m),y=!1},d(m){M(i,m)}}}function kp(g){let i,y,m,w;return i=new Li({props:{id:"integration-test",option:"macOS",$$slots:{default:[vp]},$$scope:{ctx:g}}}),m=new Li({props:{id:"integration-test",option:"Windows",$$slots:{default:[Up]},$$scope:{ctx:g}}}),{c(){d(i.$$.fragment),y=n(),d(m.$$.fragment)},l(T){u(i.$$.fragment,T),y=a(T),u(m.$$.fragment,T)},m(T,b){f(i,T,b),s(T,y,b),f(m,T,b),w=!0},p(T,b){const j={};b&2&&(j.$$scope={dirty:b,ctx:T}),i.$set(j);const v={};b&2&&(v.$$scope={dirty:b,ctx:T}),m.$set(v)},i(T){w||(h(i.$$.fragment,T),h(m.$$.fragment,T),w=!0)},o(T){c(i.$$.fragment,T),c(m.$$.fragment,T),w=!1},d(T){T&&l(y),M(i,T),M(m,T)}}}function _p(g){let i,y='We recommend adding a fast tokenizer (<a href="/docs/transformers/v4.56.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast">PreTrainedTokenizerFast</a>) to give users the best performance. Feel free to tag <a href="https://github.com/ArthurZucker" rel="nofollow">@ArthurZucker</a> or <a href="https://github.com/itazap" rel="nofollow">@itazap</a> in your PR for help on how to add <a href="/docs/transformers/v4.56.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast">PreTrainedTokenizerFast</a>.';return{c(){i=o("p"),i.innerHTML=y},l(m){i=r(m,"P",{"data-svelte-h":!0}),p(i)!=="svelte-7rtk5e"&&(i.innerHTML=y)},m(m,w){s(m,i,w)},p:U,d(m){m&&l(i)}}}function Ip(g){let i,y=`Fast image processors use the <a href="https://pytorch.org/vision/stable/index.html" rel="nofollow">torchvision</a> library and can perform image processing on the GPU, significantly improving processing speed.
We recommend adding a fast image processor (<a href="/docs/transformers/v4.56.2/en/main_classes/image_processor#transformers.BaseImageProcessorFast">BaseImageProcessorFast</a>) in addition to the ‚Äúslow‚Äù image processor (<a href="/docs/transformers/v4.56.2/en/main_classes/image_processor#transformers.BaseImageProcessor">BaseImageProcessor</a>) to provide users with the best performance. Feel free to tag <a href="https://github.com/yonigozlan" rel="nofollow">@yonigozlan</a> for help adding a <a href="/docs/transformers/v4.56.2/en/main_classes/image_processor#transformers.BaseImageProcessorFast">BaseImageProcessorFast</a>.`;return{c(){i=o("p"),i.innerHTML=y},l(m){i=r(m,"P",{"data-svelte-h":!0}),p(i)!=="svelte-18mb66f"&&(i.innerHTML=y)},m(m,w){s(m,i,w)},p:U,d(m){m&&l(i)}}}function xp(g){let i,y="In many cases, adding an interactive notebook users can run is a great way to showcase how to use the model for inference or fine-tune it on a downstream task. While not required, including a notebook can drive greater adoption of your model.";return{c(){i=o("p"),i.textContent=y},l(m){i=r(m,"P",{"data-svelte-h":!0}),p(i)!=="svelte-4qm1hn"&&(i.textContent=y)},m(m,w){s(m,i,w)},p:U,d(m){m&&l(i)}}}function Lp(g){let i,y,m,w,T,b,j,v,C,k="Many of the models in Transformers are contributed by developers and researchers. As an open-source first project, we‚Äôre invested in empowering the community to actively and independently add more models.",V,P,Ai="When you add a model to Transformers, you‚Äôll learn:",ns,E,Wi='<li>more about open-source best practices</li> <li>about a models architecture</li> <li>about Transformers‚Äô design principles</li> <li>how to efficiently test large models</li> <li>how to use Python utilities like <a href="https://black.readthedocs.io/en/stable/" rel="nofollow">Black</a> and <a href="https://docs.astral.sh/ruff/" rel="nofollow">Ruff</a> to create clean and readable code</li>',as,Q,Zi="It is a challenging but rewarding process.",is,R,Hi="This guide will walk you through adding an example BrandNewLlama PyTorch model to Transformers. Before you begin, it is a good idea to familiarize yourself with the library.",os,F,rs,Y,Ni="Transformers is an opinionated library with its own unique philosophy and design choices. These choices help us sustainably scale and maintain Transformers.",ps,I,ms,D,zi="Some of these design choices are:",ds,X,Gi="<li>composition &gt; over-abstraction</li> <li>duplicate code isn‚Äôt always bad if it greatly improves readability and accessibility</li> <li>model files are self-contained and all the necessary model code is found in the <code>modeling_mymodel.py</code> file</li>",us,S,Bi="These design choices are important <em>for everyone</em> interacting with the model. It is easier to read, understand, and modify.",fs,q,Vi="This section describes how the model and configuration classes interact and the Transformers code style.",hs,O,cs,K,Pi='All Transformers‚Äô models inherit from a base <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel">PreTrainedModel</a> and <a href="/docs/transformers/v4.56.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a> class. The configuration is the models blueprint.',Ms,ee,Ei='There is never more than two levels of abstraction for any model to keep the code readable. The example model here, BrandNewLlama, inherits from <code>BrandNewLlamaPreTrainedModel</code> and <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel">PreTrainedModel</a>. It is important that a new model only depends on <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel">PreTrainedModel</a> so that it can use the <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> and <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> methods.',ys,te,Qi="Other important functions like the forward method are defined in the <code>modeling.py</code> file.",ws,le,Ri="Specific model heads (for example, sequence classification or language modeling) should call the base model in the forward pass rather than inheriting from it to keep abstraction low.",Ts,se,Fi='New models require a configuration, for example <code>BrandNewLlamaConfig</code>, that is stored as an attribute of <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel">PreTrainedModel</a>.',bs,ne,gs,ae,Yi='<a href="/docs/transformers/v4.56.2/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a> provides the <a href="/docs/transformers/v4.56.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a> and <a href="/docs/transformers/v4.56.2/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> methods.',$s,ie,Di='When you use <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">PreTrainedModel.save_pretrained()</a>, it automatically calls <a href="/docs/transformers/v4.56.2/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">PretrainedConfig.save_pretrained()</a> so that both the model and configuration are saved together.',js,oe,Xi="A model is saved to a <code>model.safetensors</code> file and a configuration is saved to a <code>config.json</code> file.",Cs,re,Js,pe,Si="Transformers prefers a clean and readable code over a more abstracted code style. Some of the code style choices include:",vs,me,qi='<li><p>The code should be accessible to non-English users. Pick descriptive variable names and avoid abbreviations. For example, ‚Äúactivation‚Äù is preferred over ‚Äúact‚Äù. One letter variables names are highly discouraged unless it‚Äôs an index in a for loop.</p></li> <li><p>Explicit code is preferred - even if it‚Äôs longer - over shorter code.</p></li> <li><p>Avoid subclassing <a href="https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html" rel="nofollow">nn.Sequential</a>. Subclass <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" rel="nofollow">nn.Module</a> instead so the code can be quickly debugged with print statements or breakpoints.</p></li> <li><p>Function signatures should be type-annotated. Otherwise, use good variable names so they‚Äôre more understandable.</p></li>',Us,de,ks,ue,Oi='Open a <a href="https://github.com/huggingface/transformers/issues/new?assignees=&amp;labels=New+model&amp;template=new-model-addition.yml" rel="nofollow">New model addition</a> issue to add a specific model.',_s,x,Is,fe,Ki="Now is a good time to get familiar with BrandNewLlama. It is helpful to read a models research paper to understand its technical design and implementation. You don‚Äôt necessarily have to worry too much about the theoretical details. Instead, focus on the practical ones. Use the questions below to guide your reading.",xs,he,eo="<li>What type of model is BrandNewLlama? Is it a encoder, decoder, or encoder-decoder model?</li> <li>What tasks can BrandNewLlama be used for?</li> <li>What makes BrandNewLlama different from other models?</li> <li>What models in Transformers are most similar to BrandNewLlama?</li> <li>What tokenizer does BrandNewLlama use?</li>",Ls,ce,to="In addition to learning more about your model, use the tips below to help you add a model faster.",As,L,Ws,Me,lo='<li>Don‚Äôt reinvent the wheel! Take your time to explore existing models and tokenizers to see what you can copy and reuse. <a href="https://www.gnu.org/software/grep/" rel="nofollow">Grep</a> and <a href="https://github.com/BurntSushi/ripgrep" rel="nofollow">ripgrep</a> are great tools for this.</li> <li>This is more of an engineering than a science challenge. Focus on the more practical (setting up an efficient debugging environment for example) instead of the theorertical aspects of the model.</li> <li>Don‚Äôt be shy to ask for help! We are here to support you. ü§ó</li>',Zs,ye,Hs,we,so='Click on the <strong>Fork</strong> button on the <a href="https://github.com/huggingface/transformers" rel="nofollow">Transformers</a> repository to create your own copy to work on. Clone the repository to your local disk and add the base repository as the remote.',Ns,Te,zs,be,no='Create a virtual environment and perform an <a href="./installation#editable-install">editable install</a> of the library with the ‚Äúdev‚Äù or development dependencies.',Gs,ge,Bs,$e,ao="Due to the number of optional dependencies as Transformers grows, this command may fail. In this case, install the ‚Äúquality‚Äù dependencies. Also make sure you have a deep learning framework installed.",Vs,je,Ps,Ce,io="Return to the parent directory and clone and install the original BrandNewLlama repository.",Es,Je,Qs,ve,oo="Return to your clone of Transformers to begin porting BrandNewLlama.",Rs,Ue,Fs,ke,ro='There are two possible debugging environments for running the original model, a notebook (<a href="https://colab.research.google.com/notebooks/intro.ipynb" rel="nofollow">Google Colab</a> or <a href="https://jupyter.org/" rel="nofollow">Jupyter</a>) or a local Python script.',Ys,A,Ds,_e,po="Notebooks are great for executing code cell-by-cell which can help split logical components from one another. It can also accelerate debugging cycles because intermediate results can be stored. You can also share notebooks when working with other contributors.",Xs,Ie,mo="The downside is that if you aren‚Äôt used to them, it may take some time to get used to.",Ss,W,qs,xe,uo="Run the command below to start and complete the questionnaire with some basic information about the new model. This command jumpstarts the process by automatically generating some model code that you‚Äôll need to adapt.",Os,Le,Ks,Ae,en,We,fo="Before you start adapting the code, create a pull request to track your progress and get feedback from the Transformers team. Title your pull request <strong>[WIP] Add BrandNewLlama</strong> so it‚Äôs clear that this is a work in progress.",tn,Ze,ho="Create a branch with a descriptive name from your main branch.",ln,He,sn,Ne,co="Commit the code, and then fetch and rebase on the main branch.",nn,ze,an,Ge,Mo="Push any changes to your branch and click on <strong>Compare &amp; pull request</strong> to open a pull request on GitHub. Open the pull request as a <em>draft</em> to indicate it‚Äôs a work in progress.",on,Be,rn,Ve,yo="Include relevant Hugging Face team members by adding their GitHub handles in the pull request for questions, feedback, comments, and reviews. Direct team members to specific parts of the code you want by clicking on the <strong>Files changed</strong> tab, and then clicking on <strong>+</strong> to the left of the line number to add a comment. When a question or problem is solved, click on <strong>Resolve</strong> to indicate the issue is resolved. This keeps the conversation organized and clean.",pn,Pe,wo="Remember to periodically commit and push your work, and update your work with the current main branch.",mn,Ee,dn,Qe,un,Re,To="Take some time to work on the original model implementation first to understand how it works.",fn,Fe,bo="This can be difficult if the original model repository is lacking documentation or if the codebase is complex. But you should use this as your motivation to implement the model in Transformers. Your contribution makes it more accessible and user-friendly to everyone!",hn,Ye,go="Orient yourself with the original repository by doing the following.",cn,De,$o='<li>Locate the pretrained weights.</li> <li>Figure out how to the load pretrained weights into the model.</li> <li>Figure out how to run the tokenizer independently of the model.</li> <li>Trace one forward pass to understand which classes and functions are required. These are probably the only classes and functions you‚Äôll have to implement.</li> <li>Locate all the important components (model class, model subclasses, self-attention layer, etc.) of the model.</li> <li>Figure out how to debug the model in the original repository. Add print statements, use interactive debuggers like <a href="https://github.com/gotcha/ipdb" rel="nofollow">ipdb</a>, or a efficient integrated development environment (IDE) like <a href="https://www.jetbrains.com/pycharm/" rel="nofollow">PyCharm</a>.</li>',Mn,Xe,jo="The last point is especially important because you‚Äôll need a thorough understanding of what‚Äôs happening inside the original model before you can reimplement it in Transformers. Feel free to open issues and pull requests in the original repository if you encounter any issues.",yn,Se,Co="A good first step is to load a <em>small</em> pretrained checkpoint and try to reproduce a single forward pass with an example integer vector of inputs. For example, in pseudocode, this could look like the following.",wn,qe,Tn,Oe,bn,Ke,Jo="If you run into issues, you‚Äôll need to choose one of the following debugging strategies depending on the original models codebase.",gn,Z,$n,et,vo="Whichever strategy you choose, it is recommended to debug the initial layers first and the final layers last. Retrieve the output, either with print statements or sub-component functions, of the following layers in this order.",jn,tt,Uo="<li>input ids passed to the model</li> <li>word embeddings</li> <li>input of the first Transformer layer</li> <li>output of the first Transformer layer</li> <li>output of the following n-1 Transformer layers</li> <li>output of the whole model</li>",Cn,lt,ko="The input ids should just be an array of integers like <code>input_ids = [0, 4, 4, 3, 2, 4, 1, 7, 19]</code>.",Jn,st,_o="Layer outputs often consist of multi-dimensional float arrays.",vn,nt,Un,at,Io="Every Transformers model output should have a precision or error tolerance of <em>1e-3</em>. This accounts for any output differences that arise from using a different library framework. Compare the intermediate outputs of the original model with the Transformers implementation to ensure they‚Äôre nearly identical. Having an <em>efficient</em> debugging environment is crucial for this step.",kn,it,xo="Here are some tips for an efficient debugging environment.",_n,ot,Lo='<li><p>To debug intermediate results, it depends on the machine learning framework the original model repository is using. For PyTorch, you should write a script to decompose the original model into smaller sub-components to retrieve the intermediate values. For TensorFlow, you may need to use <a href="https://www.tensorflow.org/api_docs/python/tf/print" rel="nofollow">tf.print</a>. For Flax, make sure the model is <em>not jitted</em> during the forward pass (refer to this GitHub <a href="https://github.com/google/jax/issues/196" rel="nofollow">Issue</a> for more details).</p></li> <li><p>It is faster to debug with a smaller pretrained checkpoint versus a larger checkpoint where the forward pass takes more than 10 seconds. If only large checkpoints are available, create a dummy model with randomly initialized weights and save those weights to compare against the Transformers implementation.</p></li> <li><p>Find the easiest way to call the model‚Äôs forward pass. Ideally, this function (may be called <code>predict</code>, <code>evaluate</code>, <code>forward</code>, or <code>__call__</code>) should only call the forward pass <em>once</em>. It is more difficult to debug a function that calls the forward pass multiple times.</p></li> <li><p>Separate tokenization from the forward pass. Locate where a string input is changed to input ids in the forward pass and start here. You may need to create a small script or modify the original code to directly input the input ids instead of an input string.</p></li> <li><p>Ensure the model is <em>not</em> in training mode. This can produce random outputs due to multiple dropout layers in a model. The forward pass in your debugging environment should be <em>deterministic</em> so that the dropout layers aren‚Äôt used.</p></li>',In,rt,Ao="Once you‚Äôre able to run the original checkpoint, you‚Äôre ready to start adapting the model code for Transformers.",xn,pt,Ln,mt,Wo="The <code>transformers add-new-model-like</code> command should have generated a model and configuration file.",An,dt,Zo="<li><code>src/transformers/models/brand_new_llama/modeling_brand_new_llama.py</code></li> <li><code>src/transformers/models/brand_new_llama/configuration_brand_new_llama.py</code></li>",Wn,ut,Ho="The automatically generated code in the <code>modeling.py</code> file has the same architecture as Llama if you answered it‚Äôs a decoder-only model or it will have the same architecture as BART if you answered it‚Äôs an encoder-decoder model. The generated code is just a starting point. Based on your research on the new model, you‚Äôll need to implement those specific changes by adapting the generated code. This may involve changes to the self-attention layer, the order of the normalization layer, and so on.",Zn,ft,Hn,ht,No="At this point, your code doesn‚Äôt have to be clean or even fully correct, It is more efficient to quickly create a first draft and then iteratively improve on it. The most important thing is that your model can be instantiated from Transformers. The command below creates a model from the configuration with random weights, verifying that the <code>__init__</code> method works.",Nn,ct,zn,Mt,zo="Random initialization occurs in the <code>_init_weights</code> method of <code>BrandNewLlamaPreTrainedModel</code>. All leaf modules are initialized depending on the configuration‚Äôs variables.",Gn,yt,Bn,wt,Go='The initialization scheme can look different if you need to adapt it to your model. For example, <a href="/docs/transformers/v4.56.2/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> initializes <a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html" rel="nofollow">nn.Linear</a> in its last two linear layers.',Vn,Tt,Bo="The <code>_is_hf_initialized</code> flag makes sure the submodule is only initialized once. Setting <code>module.project_q</code> and <code>module.project_hid</code> to <code>True</code> ensures the custom initialization is not overridden later. The <code>_init_weights</code> function won‚Äôt be applied to these modules.",Pn,bt,En,gt,Qn,$t,Vo="The original checkpoint must be converted to a Transformers compatible checkpoint.",Rn,H,Fn,jt,Po="Make sure <strong>all</strong> required weights are initialized and print out all the checkpoint weights that weren‚Äôt used for initialization to make sure the model has been converted correctly.",Yn,Ct,Eo="You may encounter wrong shape statements or name assignments during the conversion. This is most likely because of incorrect parameters in <code>BrandNewLlamaConfig</code>, the wrong architecture, a bug in the <code>init</code> method of your implementation, or you need to transpose one of the checkpoint weights.",Dn,Jt,Qo='Keep iterating on the <a href="#adapt-the-model-code">Adapt the model code</a> section until all the checkpoint weights are correctly loaded. Once you can load a checkpoint in your model, save it to a folder. This should contain a <code>model.safetensors</code> file and a <code>config.json</code> file.',Xn,vt,Sn,Ut,Ro="To help with conversion, the next section briefly describes how PyTorch models stores and defines layer weights and names.",qn,kt,On,_t,Fo="It is helpful to create a basic PyTorch model to understand how layer names are defined and weights are initialized.",Kn,It,ea,xt,Yo="PyTorch layer names are defined by the class attribute name of the layer (<code>dense</code>, <code>intermediate</code>, <code>layer_norm</code>). Create a instance of <code>SimpleModel</code> to fill all the layers with random weights.",ta,Lt,la,At,Do="The weight values of a specific layer are randomly initialized.",sa,Wt,na,Zt,Xo="In the conversion script, the random weights should be replaced with the exact weights from the corresponding layer in the original checkpoint.",aa,Ht,ia,Nt,So="Verify the randomly initialized weights and their corresponding pretrained checkpoint weights have the identical <strong>shape</strong> and <strong>name</strong>. Add assert statements for the shape and print out the checkpoint weight names.",oa,zt,ra,Gt,qo="When the shape or name don‚Äôt match, you may have assigned the incorrect checkpoint weight to a randomly initialized layer. An incorrect shape may be because the <code>BrandNewLlama</code> parameters don‚Äôt exactly match the original models parameters. But it could also be that the PyTorch layer implementation requires the weights to be transposed first.",pa,Bt,ma,Vt,Oo="The forward pass should be implemented next if the model loads correctly. It takes some inputs and returns the model output.",da,Pt,ua,Et,Ko='Don‚Äôt be discouraged if your forward pass isn‚Äôt identical with the output from the original model or if it returns an error. Check that the forward pass doesn‚Äôt throw any errors. This is often because the dimensions are wrong or because the wrong data type is used (<a href="https://pytorch.org/docs/stable/generated/torch.Tensor.long.html" rel="nofollow">torch.long</a> instead of <a href="https://pytorch.org/docs/stable/tensors.html" rel="nofollow">torch.float32</a>).',fa,Qt,er="Your output should have a precision of <em>1e-3</em>. Ensure the output shapes and output values are identical. Common reasons for why the outputs aren‚Äôt identical include:",ha,Rt,tr='<li>Some layers were not added (activation layer or a residual connection).</li> <li>The word embedding matrix is not tied.</li> <li>The wrong positional embeddings are used because the original implementation includes an offset.</li> <li>Dropout is applied during the forward pass. Fix this error by making sure <code>model.training</code> is <code>False</code> and passing <code>self.training</code> to <a href="https://pytorch.org/docs/stable/nn.functional.html?highlight=dropout#torch.nn.functional.dropout" rel="nofollow">torch.nn.functional.dropout</a>.</li>',ca,Ft,lr="Compare the forward pass of the original model and your implementation to check if there are any differences. Ideally, debug and print out the intermediate outputs of both implementations of the forward pass to pinpoint where the original implementation differs from yours.",Ma,Yt,sr="<li>Make sure the hardcoded <code>input_ids</code> in both implementations are identical.</li> <li>Verify the outputs of the first transformation of <code>input_ids</code> (usually the word embeddings) are identical, and work your way through to the last layer.</li>",ya,Dt,nr="Any difference between the two implementations should point to the bug in your implementation.",wa,Xt,ar="One of the best strategies is to add many print statements to the same positions in both implementations, and then successively remove them when they output identical values for the intermediate outputs.",Ta,St,ir="When both implementations produce the same output, verify the outputs are within a precision of <em>1e-3</em>.",ba,qt,ga,Ot,or="This is typically the most difficult part of the process. Congratulations if you‚Äôve made it this far!",$a,Kt,rr="And if you‚Äôre stuck or struggling with this step, don‚Äôt hesitate to ask for help on your pull request.",ja,el,Ca,tl,pr="While the model works, you still need to add tests to ensure it is compatible with Transformers. Tests are important because they help users understand your work by looking at specific tests, and because they prevent your model from breaking in the future if any changes are made.",Ja,ll,mr='<a href="https://cookiecutter.readthedocs.io/en/stable/" rel="nofollow">Cookiecutter</a> should have added a test file for your model. Run the test file below to make sure all common tests pass.',va,sl,Ua,nl,dr="The integration tests should be added first because they serve the same purpose as the debugging scripts you used earlier to implement the new model in Transformers. A template of those model tests, <code>BrandNewLlamaModelIntegrationTests</code>, was added by Cookiecutter and should be filled out. To ensure it passes, run the following command.",ka,N,_a,al,ur="All features unique to BrandNewLlama should be tested in a separate test under <code>BrandNewLlamaModelTester/BrandNewLlamaModelTest</code>. This test is often overlooked, but it is extremely important because:",Ia,il,fr="<li>it helps transfer knowledge you acquired during the process to the community by showing how the models novel features work</li> <li>future contributors can quickly test changes to the model by running these special tests</li>",xa,ol,La,z,Aa,rl,hr="With the model out of the way, time to focus on the tokenizer. The tokenizer should be identical or very similar to an existing tokenizer in Transformers.",Wa,pl,cr="Find and load the original tokenizer file into your implementation. Create a script in the original repository that inputs a string and returns the <code>input_ids</code>. The pseudocode should look similar to the code below.",Za,ml,Ha,dl,Mr="You may need to search the original repository to find the correct tokenizer function or modify the existing tokenizer in your clone of the original repository to only return the <code>input_ids</code>. The script for your tokenizer should look similar to the following.",Na,ul,za,fl,yr="When both implementations have the same <code>input_ids</code>, add a tokenizer test file. This file is analogous to the modeling test files. The tokenizer test files should contain a couple of hardcoded integration tests.",Ga,hl,Ba,G,Va,cl,wr='While this example doesn‚Äôt include an image processor, you may need to implement one if your model requires image inputs. The image processor is responsible for converting images into a format suitable for your model. Before implementing a new one, check whether an existing image processor in the Transformers library can be reused, as many models share similar image processing techniques. Note that you can also use <a href="./modular_transformers">modular</a> for image processors to reuse existing components.',Pa,Ml,Tr='If you do need to implement a new image processor, refer to an existing image processor to understand the expected structure. Slow image processors (<a href="/docs/transformers/v4.56.2/en/main_classes/image_processor#transformers.BaseImageProcessor">BaseImageProcessor</a>) and fast image processors (<a href="/docs/transformers/v4.56.2/en/main_classes/image_processor#transformers.BaseImageProcessorFast">BaseImageProcessorFast</a>) are designed differently, so make sure you follow the correct structure based on the processor type you‚Äôre implementing.',Ea,yl,br="Run the following command (only if you haven‚Äôt already created the fast image processor with the <code>transformers add-new-model-like</code> command) to generate the necessary imports and to create a prefilled template for the fast image processor. Modify the template to fit your model.",Qa,wl,Ra,Tl,gr="This command will generate the necessary imports and provide a pre-filled template for the fast image processor. You can then modify it to fit your model‚Äôs needs.",Fa,bl,$r="Add tests for the image processor in <code>tests/models/your_model_name/test_image_processing_your_model_name.py</code>. These tests should be similar to those for other image processors and should verify that the image processor correctly handles image inputs. If your image processor includes unique features or processing methods, ensure you add specific tests for those as well.",Ya,gl,Da,$l,jr="If your model accepts multiple modalities, like text and images, you need to add a processor. The processor centralizes the preprocessing of different modalities before passing them to the model.",Xa,jl,Cr="The processor should call the appropriate modality-specific processors within its <code>__call__</code> function to handle each type of input correctly. Be sure to check existing processors in the library to understand their expected structure. Transformers uses the following convention in the <code>__call__</code> function signature.",Sa,Cl,qa,Jl,Jr="<code>YourModelProcessorKwargs</code> is a <code>TypedDict</code> that includes all the typical processing arguments and any extra arguments a specific processor may require.",Oa,vl,vr="Add tests for the processor in <code>tests/models/your_model_name/test_processor_your_model_name.py</code>. These tests should be similar to those for other processors and should verify that the processor correctly handles the different modalities.",Ka,Ul,ei,kl,Ur="Now that you have a model and tokenizer, add end-to-end integration tests for the model and tokenizer to <code>tests/models/brand_new_llama/test_modeling_brand_new_llama.py</code>.",ti,_l,kr="The test should provide a meaningful text-to-text example to show the model works as expected. For example, you can include a source-to-target translation pair, an article-to-summary pair, or a question-to-answer pair.",li,Il,_r="If the checkpoint hasn‚Äôt been fine-tuned on a downstream task, then the model tests are sufficient.",si,xl,Ir="Finally, try to make sure your tests can run on a GPU by adding <code>.to(self.device)</code> statements to the models internal tensors. If you don‚Äôt have access to a GPU, we can take care of that for you.",ni,Ll,ai,Al,xr="Your model is only useful if users know how to use it. This is why it‚Äôs important to add documentation and docstrings. Cookiecutter added a template file, <code>docs/source/model_doc/brand_new_llama.md</code>, that you can fill out with information about your model.",ii,Wl,Lr="This is generally a user‚Äôs first interaction with a model, so the documentation should be clear and concise. It is often very useful to add examples of how the model should be used.",oi,Zl,Ar='Make sure docstrings are added to <code>src/transformers/models/brand_new_llama/modeling_brand_new_llama.py</code> and includes all necessary inputs and outputs. Review our <a href="https://github.com/huggingface/transformers/tree/main/docs#writing-documentation---specification" rel="nofollow">guide</a> for writing documentation and docstrings.',ri,Hl,pi,Nl,Wr="Time to tidy things up and make sure the code style is consistent with the rest of the library. Run the following command to automatically fix incorrect styles.",mi,zl,di,Gl,Zr="To verify the code style passes quality checks, run the command below.",ui,Bl,fi,Vl,Hr="There may be other failing tests or checks (missing docstring or incorrect naming) on your pull request due to Transformers strict design tests. We can help you with these issues if you‚Äôre stuck.",hi,Pl,Nr="After ensuring the code runs correctly, you may want to refactor it to make it more readable or cleaner.",ci,El,Mi,Ql,zr='Convert and upload all checkpoints to the <a href="https://hf.co/models" rel="nofollow">Hub</a>. Add a model card to provide more transparency and context about the model. The model card should highlight specific characteristics of a checkpoint, how the model was trained, and code examples of how to use it.',yi,B,wi,Rl,Gr="You should also consult with the Transformers team to decide on an appropriate name for the model, and getting the required access rights to upload the model.",Ti,Fl,Br='Use the <a href="/docs/transformers/v4.56.2/en/main_classes/model#transformers.utils.PushToHubMixin.push_to_hub">push_to_hub()</a> method to upload the model.',bi,Yl,gi,Dl,Vr='Refer to the <a href="./model_sharing">Sharing</a> guide for more information about uploading models to the Hub.',$i,Xl,ji,Sl,Pr="You‚Äôre finally ready to merge your pull request and officially add the model to Transformers! Make sure all the tests are passing and all comments and feedback have been addressed.",Ci,ql,Er="Congratulations on adding a new model to Transformers! ü•≥",Ji,Ol,Qr="This is a very significant contribution. Your work makes Transformers more accessible to developers and researchers around the world. You should be proud of your contribution and share your accomplishment with the community!",vi,Kl,Ui,es,Rr="There are four timelines for model additions depending on the model contributor and community demand for an architecture.",ki,ts,Fr='<li><p><strong>day-0 integration</strong>: If you plan on having a Transformers-first release, this is a great option because we can ensure the documentation is clear and optimize your model as much as possible (quantization, FlashAttention, KV-cache, etc.). We can also help you add the model, provide early reviews and make sure it works as expected.</p> <p>Reach out to <a href="mailto:transformers@huggingface.co">transformers@huggingface.co</a> a few days (preferably weeks) in advance, especially if an architecture is particularly novel, to ensure model integration. We‚Äôll work together on a private fork of Transformers until your checkpoint and release is ready.</p></li> <li><p><strong>same week integration</strong>: Models with significant requests/demand are usually added the same week if the model author doesn‚Äôt reach out.</p> <p>Use the <a href="https://github.com/huggingface/transformers/issues/new?assignees=&amp;labels=New+model&amp;projects=&amp;template=new-model-addition.yml" rel="nofollow">issue tracker</a> to request a specific model to add. The more activity on the issue, the faster and more likely we‚Äôll integrate it.</p></li> <li><p><strong>post-release integration</strong>: Models without popular requests/demand or if we don‚Äôt have the bandwidth to integrate it are added post-release.</p> <p>This is a good opportunity if you‚Äôre interested in contributing a model to Transformers. Take a look at open issues tagged with <a href="https://github.com/huggingface/transformers/issues?q=is%3Aopen+is%3Aissue+label%3A%22New+model%22" rel="nofollow">‚ÄúNew model‚Äù</a>. Feel free to give the most requested models a try first to multiply the impact of your contribution. We‚Äôll be there to help you each step of the way!</p></li> <li><p><strong>Hub-first release</strong>: Transformers <a href="./models#custom-models">remote-code</a> feature allows Transformers-based projects to be shared directly on the Hub. This is a good option if you don‚Äôt have the bandwidth to add a model directly to Transformers.</p> <p>If a model ends up being very popular, then it‚Äôs very likely that we‚Äôll integrate it in Transformers ourselves to enable better support (documentation, maintenance, optimization, etc.) for it. A Hub-first release is the most frictionless way to add a model.</p></li>',_i,ls,Ii,ss,xi;return T=new J({props:{title:"Legacy model contribution",local:"legacy-model-contribution",headingTag:"h1"}}),j=new _({props:{warning:!1,$$slots:{default:[cp]},$$scope:{ctx:g}}}),F=new J({props:{title:"Transformers overview",local:"transformers-overview",headingTag:"h2"}}),I=new _({props:{warning:!1,$$slots:{default:[Mp]},$$scope:{ctx:g}}}),O=new J({props:{title:"Model and configuration",local:"model-and-configuration",headingTag:"h3"}}),ne=new $({props:{code:"bW9kZWwlMjAlM0QlMjBCcmFuZE5ld0xsYW1hTW9kZWwuZnJvbV9wcmV0cmFpbmVkKCUyMnVzZXJuYW1lJTJGYnJhbmRfbmV3X2xsYW1hJTIyKSUwQW1vZGVsLmNvbmZpZw==",highlighted:`model = BrandNewLlamaModel.from_pretrained(<span class="hljs-string">&quot;username/brand_new_llama&quot;</span>)
model.config`,wrap:!1}}),re=new J({props:{title:"Code style",local:"code-style",headingTag:"h3"}}),de=new J({props:{title:"New model addition issue",local:"new-model-addition-issue",headingTag:"h2"}}),x=new _({props:{warning:!1,$$slots:{default:[yp]},$$scope:{ctx:g}}}),L=new _({props:{warning:!1,$$slots:{default:[wp]},$$scope:{ctx:g}}}),ye=new J({props:{title:"Dev environment",local:"dev-environment",headingTag:"h2"}}),Te=new $({props:{code:"Z2l0JTIwY2xvbmUlMjBodHRwcyUzQSUyRiUyRmdpdGh1Yi5jb20lMkYlNUJ5b3VyJTIwR2l0aHViJTIwaGFuZGxlJTVEJTJGdHJhbnNmb3JtZXJzLmdpdCUwQWNkJTIwdHJhbnNmb3JtZXJzJTBBZ2l0JTIwcmVtb3RlJTIwYWRkJTIwdXBzdHJlYW0lMjBodHRwcyUzQSUyRiUyRmdpdGh1Yi5jb20lMkZodWdnaW5nZmFjZSUyRnRyYW5zZm9ybWVycy5naXQ=",highlighted:`git <span class="hljs-built_in">clone</span> https://github.com/[your Github handle]/transformers.git
<span class="hljs-built_in">cd</span> transformers
git remote add upstream https://github.com/huggingface/transformers.git`,wrap:!1}}),ge=new $({props:{code:"cHl0aG9uJTIwLW0lMjB2ZW52JTIwLmVudiUwQXNvdXJjZSUyMC5lbnYlMkZiaW4lMkZhY3RpdmF0ZSUwQXBpcCUyMGluc3RhbGwlMjAtZSUyMCUyMi4lNUJkZXYlNUQlMjI=",highlighted:`python -m venv .<span class="hljs-built_in">env</span>
<span class="hljs-built_in">source</span> .<span class="hljs-built_in">env</span>/bin/activate
pip install -e <span class="hljs-string">&quot;.[dev]&quot;</span>`,wrap:!1}}),je=new $({props:{code:"cGlwJTIwaW5zdGFsbCUyMC1lJTIwJTIyLiU1QnF1YWxpdHklNUQlMjI=",highlighted:'pip install -e <span class="hljs-string">&quot;.[quality]&quot;</span>',wrap:!1}}),Je=new $({props:{code:"Z2l0JTIwY2xvbmUlMjBodHRwcyUzQSUyRiUyRmdpdGh1Yi5jb20lMkZvcmdfdGhhdF9jcmVhdGVkX2JyYW5kX25ld19sbGFtYV9vcmclMkZicmFuZF9uZXdfbGxhbWEuZ2l0JTBBY2QlMjBicmFuZF9uZXdfYmVydCUwQXBpcCUyMGluc3RhbGwlMjAtZSUyMC4=",highlighted:`git <span class="hljs-built_in">clone</span> https://github.com/org_that_created_brand_new_llama_org/brand_new_llama.git
<span class="hljs-built_in">cd</span> brand_new_bert
pip install -e .`,wrap:!1}}),Ue=new $({props:{code:"Y2QlMjB0cmFuc2Zvcm1lcnM=",highlighted:'<span class="hljs-built_in">cd</span> transformers',wrap:!1}}),A=new _({props:{warning:!0,$$slots:{default:[Tp]},$$scope:{ctx:g}}}),W=new _({props:{warning:!1,$$slots:{default:[bp]},$$scope:{ctx:g}}}),Le=new $({props:{code:"dHJhbnNmb3JtZXJzJTIwYWRkLW5ldy1tb2RlbC1saWtl",highlighted:"transformers add-new-model-like",wrap:!1}}),Ae=new J({props:{title:"Create a pull request",local:"create-a-pull-request",headingTag:"h2"}}),He=new $({props:{code:"Z2l0JTIwY2hlY2tvdXQlMjAtYiUyMGFkZF9icmFuZF9uZXdfYmVydA==",highlighted:"git checkout -b add_brand_new_bert",wrap:!1}}),ze=new $({props:{code:"Z2l0JTIwYWRkJTIwLiUwQWdpdCUyMGNvbW1pdCUwQWdpdCUyMGZldGNoJTIwdXBzdHJlYW0lMEFnaXQlMjByZWJhc2UlMjB1cHN0cmVhbSUyRm1haW4=",highlighted:`git add .
git commit
git fetch upstream
git rebase upstream/main`,wrap:!1}}),Be=new $({props:{code:"Z2l0JTIwcHVzaCUyMC11JTIwb3JpZ2luJTIwYS1kZXNjcmlwdGl2ZS1uYW1lLWZvci1teS1jaGFuZ2Vz",highlighted:"git push -u origin a-descriptive-name-for-my-changes",wrap:!1}}),Ee=new $({props:{code:"Z2l0JTIwZmV0Y2glMjB1cHN0cmVhbSUwQWdpdCUyMG1lcmdlJTIwdXBzdHJlYW0lMkZtYWlu",highlighted:`git fetch upstream
git merge upstream/main`,wrap:!1}}),Qe=new J({props:{title:"Original checkpoint",local:"original-checkpoint",headingTag:"h2"}}),qe=new $({props:{code:"bW9kZWwlMjAlM0QlMjBCcmFuZE5ld0xsYW1hTW9kZWwubG9hZF9wcmV0cmFpbmVkX2NoZWNrcG9pbnQoJTIyJTJGcGF0aCUyRnRvJTJGY2hlY2twb2ludCUyRiUyMiklMEFpbnB1dF9pZHMlMjAlM0QlMjAlNUIwJTJDJTIwNCUyQyUyMDUlMkMlMjAyJTJDJTIwMyUyQyUyMDclMkMlMjA5JTVEJTIwJTIwJTIzJTIwdmVjdG9yJTIwb2YlMjBpbnB1dCUyMGlkcyUwQW9yaWdpbmFsX291dHB1dCUyMCUzRCUyMG1vZGVsLmdlbmVyYXRlKGlucHV0X2lkcyk=",highlighted:`model = BrandNewLlamaModel.load_pretrained_checkpoint(<span class="hljs-string">&quot;/path/to/checkpoint/&quot;</span>)
input_ids = [<span class="hljs-number">0</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">7</span>, <span class="hljs-number">9</span>]  <span class="hljs-comment"># vector of input ids</span>
original_output = model.generate(input_ids)`,wrap:!1}}),Oe=new J({props:{title:"Debugging",local:"debugging",headingTag:"h3"}}),Z=new op({props:{id:"debug-strategy",options:["sub-components","model and tokenizer"],$$slots:{default:[Cp]},$$scope:{ctx:g}}}),nt=new $({props:{code:"JTVCJTVCJTBBJTIwJTVCLTAuMTQ2NSUyQyUyMC0wLjY1MDElMkMlMjAlMjAwLjE5OTMlMkMlMjAlMjAuLi4lMkMlMjAlMjAwLjE0NTElMkMlMjAlMjAwLjM0MzAlMkMlMjAlMjAwLjYwMjQlNUQlMkMlMEElMjAlNUItMC40NDE3JTJDJTIwLTAuNTkyMCUyQyUyMCUyMDAuMzQ1MCUyQyUyMCUyMC4uLiUyQyUyMC0wLjMwNjIlMkMlMjAlMjAwLjYxODIlMkMlMjAlMjAwLjcxMzIlNUQlMkMlMEElMjAlNUItMC41MDA5JTJDJTIwLTAuNzEyMiUyQyUyMCUyMDAuNDU0OCUyQyUyMCUyMC4uLiUyQyUyMC0wLjM2NjIlMkMlMjAlMjAwLjYwOTElMkMlMjAlMjAwLjc2NDglNUQlMkMlMEElMjAuLi4lMkMlMEElMjAlNUItMC41NjEzJTJDJTIwLTAuNjMzMiUyQyUyMCUyMDAuNDMyNCUyQyUyMCUyMC4uLiUyQyUyMC0wLjM3OTIlMkMlMjAlMjAwLjczNzIlMkMlMjAlMjAwLjkyODglNUQlMkMlMEElMjAlNUItMC41NDE2JTJDJTIwLTAuNjM0NSUyQyUyMCUyMDAuNDE4MCUyQyUyMCUyMC4uLiUyQyUyMC0wLjM1NjQlMkMlMjAlMjAwLjY5OTIlMkMlMjAlMjAwLjkxOTElNUQlMkMlMEElMjAlNUItMC41MzM0JTJDJTIwLTAuNjQwMyUyQyUyMCUyMDAuNDI3MSUyQyUyMCUyMC4uLiUyQyUyMC0wLjMzMzklMkMlMjAlMjAwLjY1MzMlMkMlMjAlMjAwLjg2OTQlNUQlNUQlNUQlMkM=",highlighted:`[[
 [-<span class="hljs-number">0.1465</span>, -<span class="hljs-number">0.6501</span>,  <span class="hljs-number">0.1993</span>,  ...,  <span class="hljs-number">0.1451</span>,  <span class="hljs-number">0.3430</span>,  <span class="hljs-number">0.6024</span>],
 [-<span class="hljs-number">0.4417</span>, -<span class="hljs-number">0.5920</span>,  <span class="hljs-number">0.3450</span>,  ..., -<span class="hljs-number">0.3062</span>,  <span class="hljs-number">0.6182</span>,  <span class="hljs-number">0.7132</span>],
 [-<span class="hljs-number">0.5009</span>, -<span class="hljs-number">0.7122</span>,  <span class="hljs-number">0.4548</span>,  ..., -<span class="hljs-number">0.3662</span>,  <span class="hljs-number">0.6091</span>,  <span class="hljs-number">0.7648</span>],
 ...,
 [-<span class="hljs-number">0.5613</span>, -<span class="hljs-number">0.6332</span>,  <span class="hljs-number">0.4324</span>,  ..., -<span class="hljs-number">0.3792</span>,  <span class="hljs-number">0.7372</span>,  <span class="hljs-number">0.9288</span>],
 [-<span class="hljs-number">0.5416</span>, -<span class="hljs-number">0.6345</span>,  <span class="hljs-number">0.4180</span>,  ..., -<span class="hljs-number">0.3564</span>,  <span class="hljs-number">0.6992</span>,  <span class="hljs-number">0.9191</span>],
 [-<span class="hljs-number">0.5334</span>, -<span class="hljs-number">0.6403</span>,  <span class="hljs-number">0.4271</span>,  ..., -<span class="hljs-number">0.3339</span>,  <span class="hljs-number">0.6533</span>,  <span class="hljs-number">0.8694</span>]]],`,wrap:!1}}),pt=new J({props:{title:"Adapt the model code",local:"adapt-the-model-code",headingTag:"h2"}}),ft=new J({props:{title:"Model initialization",local:"model-initialization",headingTag:"h3"}}),ct=new $({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEJyYW5kTmV3TGxhbWElMkMlMjBCcmFuZE5ld0xsYW1hQ29uZmlnJTBBbW9kZWwlMjAlM0QlMjBCcmFuZE5ld0xsYW1hKEJyYW5kTmV3TGxhbWFDb25maWcoKSk=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BrandNewLlama, BrandNewLlamaConfig
model = BrandNewLlama(BrandNewLlamaConfig())`,wrap:!1}}),yt=new $({props:{code:"ZGVmJTIwX2luaXRfd2VpZ2h0cyhzZWxmJTJDJTIwbW9kdWxlKSUzQSUwQSUyMCUyMCUyMCUyMCUyMiUyMiUyMkluaXRpYWxpemUlMjB0aGUlMjB3ZWlnaHRzJTIyJTIyJTIyJTBBJTIwJTIwJTIwJTIwaWYlMjBpc2luc3RhbmNlKG1vZHVsZSUyQyUyMG5uLkxpbmVhciklM0ElMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBtb2R1bGUud2VpZ2h0LmRhdGEubm9ybWFsXyhtZWFuJTNEMC4wJTJDJTIwc3RkJTNEc2VsZi5jb25maWcuaW5pdGlhbGl6ZXJfcmFuZ2UpJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwaWYlMjBtb2R1bGUuYmlhcyUyMGlzJTIwbm90JTIwTm9uZSUzQSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMG1vZHVsZS5iaWFzLmRhdGEuemVyb18oKSUwQSUyMCUyMCUyMCUyMGVsaWYlMjBpc2luc3RhbmNlKG1vZHVsZSUyQyUyMG5uLkVtYmVkZGluZyklM0ElMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBtb2R1bGUud2VpZ2h0LmRhdGEubm9ybWFsXyhtZWFuJTNEMC4wJTJDJTIwc3RkJTNEc2VsZi5jb25maWcuaW5pdGlhbGl6ZXJfcmFuZ2UpJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwaWYlMjBtb2R1bGUucGFkZGluZ19pZHglMjBpcyUyMG5vdCUyME5vbmUlM0ElMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBtb2R1bGUud2VpZ2h0LmRhdGElNUJtb2R1bGUucGFkZGluZ19pZHglNUQuemVyb18oKSUwQSUyMCUyMCUyMCUyMGVsaWYlMjBpc2luc3RhbmNlKG1vZHVsZSUyQyUyMG5uLkxheWVyTm9ybSklM0ElMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBtb2R1bGUuYmlhcy5kYXRhLnplcm9fKCklMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBtb2R1bGUud2VpZ2h0LmRhdGEuZmlsbF8oMS4wKQ==",highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_weights</span>(<span class="hljs-params">self, module</span>):
    <span class="hljs-string">&quot;&quot;&quot;Initialize the weights&quot;&quot;&quot;</span>
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(module, nn.Linear):
        module.weight.data.normal_(mean=<span class="hljs-number">0.0</span>, std=self.config.initializer_range)
        <span class="hljs-keyword">if</span> module.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:
            module.bias.data.zero_()
    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(module, nn.Embedding):
        module.weight.data.normal_(mean=<span class="hljs-number">0.0</span>, std=self.config.initializer_range)
        <span class="hljs-keyword">if</span> module.padding_idx <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:
            module.weight.data[module.padding_idx].zero_()
    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(module, nn.LayerNorm):
        module.bias.data.zero_()
        module.weight.data.fill_(<span class="hljs-number">1.0</span>)`,wrap:!1}}),bt=new $({props:{code:"ZGVmJTIwX2luaXRfd2VpZ2h0cyhzZWxmJTJDJTIwbW9kdWxlKSUzQSUwQSUyMCUyMCUyMCUyMCUyMiUyMiUyMkluaXRpYWxpemUlMjB0aGUlMjB3ZWlnaHRzJTIyJTIyJTIyJTBBJTIwJTIwJTIwJTIwaWYlMjBpc2luc3RhbmNlKG1vZHVsZSUyQyUyMFdhdjJWZWMyRm9yUHJlVHJhaW5pbmcpJTNBJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwbW9kdWxlLnByb2plY3RfaGlkLnJlc2V0X3BhcmFtZXRlcnMoKSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMG1vZHVsZS5wcm9qZWN0X3EucmVzZXRfcGFyYW1ldGVycygpJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwbW9kdWxlLnByb2plY3RfaGlkLl9pc19oZl9pbml0aWFsaXplZCUyMCUzRCUyMFRydWUlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBtb2R1bGUucHJvamVjdF9xLl9pc19oZl9pbml0aWFsaXplZCUyMCUzRCUyMFRydWUlMEElMjAlMjAlMjAlMjBlbGlmJTIwaXNpbnN0YW5jZShtb2R1bGUlMkMlMjBubi5MaW5lYXIpJTNBJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwbW9kdWxlLndlaWdodC5kYXRhLm5vcm1hbF8obWVhbiUzRDAuMCUyQyUyMHN0ZCUzRHNlbGYuY29uZmlnLmluaXRpYWxpemVyX3JhbmdlKSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMGlmJTIwbW9kdWxlLmJpYXMlMjBpcyUyMG5vdCUyME5vbmUlM0ElMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBtb2R1bGUuYmlhcy5kYXRhLnplcm9fKCk=",highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_weights</span>(<span class="hljs-params">self, module</span>):
    <span class="hljs-string">&quot;&quot;&quot;Initialize the weights&quot;&quot;&quot;</span>
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(module, Wav2Vec2ForPreTraining):
        module.project_hid.reset_parameters()
        module.project_q.reset_parameters()
        module.project_hid._is_hf_initialized = <span class="hljs-literal">True</span>
        module.project_q._is_hf_initialized = <span class="hljs-literal">True</span>
    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(module, nn.Linear):
        module.weight.data.normal_(mean=<span class="hljs-number">0.0</span>, std=self.config.initializer_range)
        <span class="hljs-keyword">if</span> module.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:
            module.bias.data.zero_()`,wrap:!1}}),gt=new J({props:{title:"Convert checkpoints to Transformers",local:"convert-checkpoints-to-transformers",headingTag:"h3"}}),H=new _({props:{warning:!1,$$slots:{default:[Jp]},$$scope:{ctx:g}}}),vt=new $({props:{code:"bW9kZWwuc2F2ZV9wcmV0cmFpbmVkKCUyMiUyRnBhdGglMkZ0byUyRmNvbnZlcnRlZCUyRmNoZWNrcG9pbnQlMkZmb2xkZXIlMjIp",highlighted:'model.save_pretrained(<span class="hljs-string">&quot;/path/to/converted/checkpoint/folder&quot;</span>)',wrap:!1}}),kt=new J({props:{title:"PyTorch layer weights and names",local:"pytorch-layer-weights-and-names",headingTag:"h4"}}),It=new $({props:{code:"ZnJvbSUyMHRvcmNoJTIwaW1wb3J0JTIwbm4lMEElMEFjbGFzcyUyMFNpbXBsZU1vZGVsKG5uLk1vZHVsZSklM0ElMEElMjAlMjAlMjAlMjBkZWYlMjBfX2luaXRfXyhzZWxmKSUzQSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMHN1cGVyKCkuX19pbml0X18oKSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMHNlbGYuZGVuc2UlMjAlM0QlMjBubi5MaW5lYXIoMTAlMkMlMjAxMCklMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBzZWxmLmludGVybWVkaWF0ZSUyMCUzRCUyMG5uLkxpbmVhcigxMCUyQyUyMDEwKSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMHNlbGYubGF5ZXJfbm9ybSUyMCUzRCUyMG5uLkxheWVyTm9ybSgxMCk=",highlighted:`<span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn

<span class="hljs-keyword">class</span> <span class="hljs-title class_">SimpleModel</span>(nn.Module):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):
        <span class="hljs-built_in">super</span>().__init__()
        self.dense = nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">10</span>)
        self.intermediate = nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">10</span>)
        self.layer_norm = nn.LayerNorm(<span class="hljs-number">10</span>)`,wrap:!1}}),Lt=new $({props:{code:"bW9kZWwlMjAlM0QlMjBTaW1wbGVNb2RlbCgpJTBBcHJpbnQobW9kZWwpJTBBU2ltcGxlTW9kZWwoJTBBJTIwJTIwKGRlbnNlKSUzQSUyMExpbmVhcihpbl9mZWF0dXJlcyUzRDEwJTJDJTIwb3V0X2ZlYXR1cmVzJTNEMTAlMkMlMjBiaWFzJTNEVHJ1ZSklMEElMjAlMjAoaW50ZXJtZWRpYXRlKSUzQSUyMExpbmVhcihpbl9mZWF0dXJlcyUzRDEwJTJDJTIwb3V0X2ZlYXR1cmVzJTNEMTAlMkMlMjBiaWFzJTNEVHJ1ZSklMEElMjAlMjAobGF5ZXJfbm9ybSklM0ElMjBMYXllck5vcm0oKDEwJTJDKSUyQyUyMGVwcyUzRDFlLTA1JTJDJTIwZWxlbWVudHdpc2VfYWZmaW5lJTNEVHJ1ZSklMEEp",highlighted:`model = SimpleModel()
<span class="hljs-built_in">print</span>(model)
SimpleModel(
  (dense): Linear(in_features=<span class="hljs-number">10</span>, out_features=<span class="hljs-number">10</span>, bias=<span class="hljs-literal">True</span>)
  (intermediate): Linear(in_features=<span class="hljs-number">10</span>, out_features=<span class="hljs-number">10</span>, bias=<span class="hljs-literal">True</span>)
  (layer_norm): LayerNorm((<span class="hljs-number">10</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)
)`,wrap:!1}}),Wt=new $({props:{code:"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",highlighted:`<span class="hljs-built_in">print</span>(model.dense.weight.data)
tensor([[-<span class="hljs-number">0.0818</span>,  <span class="hljs-number">0.2207</span>, -<span class="hljs-number">0.0749</span>, -<span class="hljs-number">0.0030</span>,  <span class="hljs-number">0.0045</span>, -<span class="hljs-number">0.1569</span>, -<span class="hljs-number">0.1598</span>,  <span class="hljs-number">0.0212</span>,
         -<span class="hljs-number">0.2077</span>,  <span class="hljs-number">0.2157</span>],
        [ <span class="hljs-number">0.1044</span>,  <span class="hljs-number">0.0201</span>,  <span class="hljs-number">0.0990</span>,  <span class="hljs-number">0.2482</span>,  <span class="hljs-number">0.3116</span>,  <span class="hljs-number">0.2509</span>,  <span class="hljs-number">0.2866</span>, -<span class="hljs-number">0.2190</span>,
          <span class="hljs-number">0.2166</span>, -<span class="hljs-number">0.0212</span>],
        [-<span class="hljs-number">0.2000</span>,  <span class="hljs-number">0.1107</span>, -<span class="hljs-number">0.1999</span>, -<span class="hljs-number">0.3119</span>,  <span class="hljs-number">0.1559</span>,  <span class="hljs-number">0.0993</span>,  <span class="hljs-number">0.1776</span>, -<span class="hljs-number">0.1950</span>,
         -<span class="hljs-number">0.1023</span>, -<span class="hljs-number">0.0447</span>],
        [-<span class="hljs-number">0.0888</span>, -<span class="hljs-number">0.1092</span>,  <span class="hljs-number">0.2281</span>,  <span class="hljs-number">0.0336</span>,  <span class="hljs-number">0.1817</span>, -<span class="hljs-number">0.0115</span>,  <span class="hljs-number">0.2096</span>,  <span class="hljs-number">0.1415</span>,
         -<span class="hljs-number">0.1876</span>, -<span class="hljs-number">0.2467</span>],
        [ <span class="hljs-number">0.2208</span>, -<span class="hljs-number">0.2352</span>, -<span class="hljs-number">0.1426</span>, -<span class="hljs-number">0.2636</span>, -<span class="hljs-number">0.2889</span>, -<span class="hljs-number">0.2061</span>, -<span class="hljs-number">0.2849</span>, -<span class="hljs-number">0.0465</span>,
          <span class="hljs-number">0.2577</span>,  <span class="hljs-number">0.0402</span>],
        [ <span class="hljs-number">0.1502</span>,  <span class="hljs-number">0.2465</span>,  <span class="hljs-number">0.2566</span>,  <span class="hljs-number">0.0693</span>,  <span class="hljs-number">0.2352</span>, -<span class="hljs-number">0.0530</span>,  <span class="hljs-number">0.1859</span>, -<span class="hljs-number">0.0604</span>,
          <span class="hljs-number">0.2132</span>,  <span class="hljs-number">0.1680</span>],
        [ <span class="hljs-number">0.1733</span>, -<span class="hljs-number">0.2407</span>, -<span class="hljs-number">0.1721</span>,  <span class="hljs-number">0.1484</span>,  <span class="hljs-number">0.0358</span>, -<span class="hljs-number">0.0633</span>, -<span class="hljs-number">0.0721</span>, -<span class="hljs-number">0.0090</span>,
          <span class="hljs-number">0.2707</span>, -<span class="hljs-number">0.2509</span>],
        [-<span class="hljs-number">0.1173</span>,  <span class="hljs-number">0.1561</span>,  <span class="hljs-number">0.2945</span>,  <span class="hljs-number">0.0595</span>, -<span class="hljs-number">0.1996</span>,  <span class="hljs-number">0.2988</span>, -<span class="hljs-number">0.0802</span>,  <span class="hljs-number">0.0407</span>,
          <span class="hljs-number">0.1829</span>, -<span class="hljs-number">0.1568</span>],
        [-<span class="hljs-number">0.1164</span>, -<span class="hljs-number">0.2228</span>, -<span class="hljs-number">0.0403</span>,  <span class="hljs-number">0.0428</span>,  <span class="hljs-number">0.1339</span>,  <span class="hljs-number">0.0047</span>,  <span class="hljs-number">0.1967</span>,  <span class="hljs-number">0.2923</span>,
          <span class="hljs-number">0.0333</span>, -<span class="hljs-number">0.0536</span>],
        [-<span class="hljs-number">0.1492</span>, -<span class="hljs-number">0.1616</span>,  <span class="hljs-number">0.1057</span>,  <span class="hljs-number">0.1950</span>, -<span class="hljs-number">0.2807</span>, -<span class="hljs-number">0.2710</span>, -<span class="hljs-number">0.1586</span>,  <span class="hljs-number">0.0739</span>,
          <span class="hljs-number">0.2220</span>,  <span class="hljs-number">0.2358</span>]]).`,wrap:!1}}),Ht=new $({props:{code:"JTIzJTIwcmV0cmlldmUlMjBtYXRjaGluZyUyMGxheWVyJTIwd2VpZ2h0cyUyMHdpdGglMjByZWN1cnNpdmUlMjBhbGdvcml0aG0lMEFsYXllcl9uYW1lJTIwJTNEJTIwJTIyZGVuc2UlMjIlMEFwcmV0cmFpbmVkX3dlaWdodCUyMCUzRCUyMGFycmF5X29mX2RlbnNlX2xheWVyJTBBJTBBbW9kZWxfcG9pbnRlciUyMCUzRCUyMGdldGF0dHIobW9kZWwlMkMlMjAlMjJkZW5zZSUyMiklMEFtb2RlbF9wb2ludGVyLndlaWdodC5kYXRhJTIwJTNEJTIwdG9yY2guZnJvbV9udW1weShwcmV0cmFpbmVkX3dlaWdodCk=",highlighted:`<span class="hljs-comment"># retrieve matching layer weights with recursive algorithm</span>
layer_name = <span class="hljs-string">&quot;dense&quot;</span>
pretrained_weight = array_of_dense_layer

model_pointer = <span class="hljs-built_in">getattr</span>(model, <span class="hljs-string">&quot;dense&quot;</span>)
model_pointer.weight.data = torch.from_numpy(pretrained_weight)`,wrap:!1}}),zt=new $({props:{code:"YXNzZXJ0JTIwKCUwQSUyMCUyMCUyMCUyMG1vZGVsX3BvaW50ZXIud2VpZ2h0LnNoYXBlJTIwJTNEJTNEJTIwcHJldHJhaW5lZF93ZWlnaHQuc2hhcGUlMEEpJTJDJTIwZiUyMlBvaW50ZXIlMjBzaGFwZSUyMG9mJTIwcmFuZG9tJTIwd2VpZ2h0JTIwJTdCbW9kZWxfcG9pbnRlci5zaGFwZSU3RCUyMGFuZCUyMGFycmF5JTIwc2hhcGUlMjBvZiUyMGNoZWNrcG9pbnQlMjB3ZWlnaHQlMjAlN0JwcmV0cmFpbmVkX3dlaWdodC5zaGFwZSU3RCUyMG1pc21hdGNoZWQlMjIlMEElMEFsb2dnZXIuaW5mbyhmJTIySW5pdGlhbGl6ZSUyMFB5VG9yY2glMjB3ZWlnaHQlMjAlN0JsYXllcl9uYW1lJTdEJTIwZnJvbSUyMCU3QnByZXRyYWluZWRfd2VpZ2h0Lm5hbWUlN0QlMjIp",highlighted:`<span class="hljs-keyword">assert</span> (
    model_pointer.weight.shape == pretrained_weight.shape
), <span class="hljs-string">f&quot;Pointer shape of random weight <span class="hljs-subst">{model_pointer.shape}</span> and array shape of checkpoint weight <span class="hljs-subst">{pretrained_weight.shape}</span> mismatched&quot;</span>

logger.info(<span class="hljs-string">f&quot;Initialize PyTorch weight <span class="hljs-subst">{layer_name}</span> from <span class="hljs-subst">{pretrained_weight.name}</span>&quot;</span>)`,wrap:!1}}),Bt=new J({props:{title:"Implement the forward pass",local:"implement-the-forward-pass",headingTag:"h3"}}),Pt=new $({props:{code:"bW9kZWwlMjAlM0QlMjBCcmFuZE5ld0xsYW1hTW9kZWwuZnJvbV9wcmV0cmFpbmVkKCUyMiUyRnBhdGglMkZ0byUyRmNvbnZlcnRlZCUyRmNoZWNrcG9pbnQlMkZmb2xkZXIlMjIpJTBBaW5wdXRfaWRzJTIwJTNEJTIwJTVCMCUyQyUyMDQlMkMlMjA0JTJDJTIwMyUyQyUyMDIlMkMlMjA0JTJDJTIwMSUyQyUyMDclMkMlMjAxOSU1RCUwQW91dHB1dCUyMCUzRCUyMG1vZGVsLmdlbmVyYXRlKGlucHV0X2lkcykubGFzdF9oaWRkZW5fc3RhdGVz",highlighted:`model = BrandNewLlamaModel.from_pretrained(<span class="hljs-string">&quot;/path/to/converted/checkpoint/folder&quot;</span>)
input_ids = [<span class="hljs-number">0</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">1</span>, <span class="hljs-number">7</span>, <span class="hljs-number">19</span>]
output = model.generate(input_ids).last_hidden_states`,wrap:!1}}),qt=new $({props:{code:"dG9yY2guYWxsY2xvc2Uob3JpZ2luYWxfb3V0cHV0JTJDJTIwb3V0cHV0JTJDJTIwYXRvbCUzRDFlLTMp",highlighted:'torch.allclose(original_output, output, atol=<span class="hljs-number">1e-3</span>)',wrap:!1}}),el=new J({props:{title:"Add model tests",local:"add-model-tests",headingTag:"h3"}}),sl=new $({props:{code:"cHl0ZXN0JTIwdGVzdHMlMkZtb2RlbHMlMkZicmFuZF9uZXdfbGxhbWElMkZ0ZXN0X21vZGVsaW5nX2JyYW5kX25ld19sbGFtYS5weQ==",highlighted:"pytest tests/models/brand_new_llama/test_modeling_brand_new_llama.py",wrap:!1}}),N=new op({props:{id:"integration-test",options:["macOS","Windows"],$$slots:{default:[kp]},$$scope:{ctx:g}}}),ol=new J({props:{title:"Implement tokenizer",local:"implement-tokenizer",headingTag:"h2"}}),z=new _({props:{warning:!1,$$slots:{default:[_p]},$$scope:{ctx:g}}}),ml=new $({props:{code:"aW5wdXRfc3RyJTIwJTNEJTIwJTIyVGhpcyUyMGlzJTIwYSUyMGxvbmclMjBleGFtcGxlJTIwaW5wdXQlMjBzdHJpbmclMjBjb250YWluaW5nJTIwc3BlY2lhbCUyMGNoYXJhY3RlcnMlMjAuJTI0JTNGLSUyQyUyMG51bWJlcnMlMjAyODcyJTIwMjM0JTIwMTIlMjBhbmQlMjB3b3Jkcy4lMjIlMEFtb2RlbCUyMCUzRCUyMEJyYW5kTmV3TGxhbWFNb2RlbC5sb2FkX3ByZXRyYWluZWRfY2hlY2twb2ludCglMjIlMkZwYXRoJTJGdG8lMkZjaGVja3BvaW50JTJGJTIyKSUwQWlucHV0X2lkcyUyMCUzRCUyMG1vZGVsLnRva2VuaXplKGlucHV0X3N0cik=",highlighted:`input_str = <span class="hljs-string">&quot;This is a long example input string containing special characters .$?-, numbers 2872 234 12 and words.&quot;</span>
model = BrandNewLlamaModel.load_pretrained_checkpoint(<span class="hljs-string">&quot;/path/to/checkpoint/&quot;</span>)
input_ids = model.tokenize(input_str)`,wrap:!1}}),ul=new $({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEJyYW5kTmV3TGxhbWFUb2tlbml6ZXIlMEElMEFpbnB1dF9zdHIlMjAlM0QlMjAlMjJUaGlzJTIwaXMlMjBhJTIwbG9uZyUyMGV4YW1wbGUlMjBpbnB1dCUyMHN0cmluZyUyMGNvbnRhaW5pbmclMjBzcGVjaWFsJTIwY2hhcmFjdGVycyUyMC4lMjQlM0YtJTJDJTIwbnVtYmVycyUyMDI4NzIlMjAyMzQlMjAxMiUyMGFuZCUyMHdvcmRzLiUyMiUwQXRva2VuaXplciUyMCUzRCUyMEJyYW5kTmV3TGxhbWFUb2tlbml6ZXIuZnJvbV9wcmV0cmFpbmVkKCUyMiUyRnBhdGglMkZ0byUyRnRva2VuaXplciUyRmZvbGRlciUyRiUyMiklMEFpbnB1dF9pZHMlMjAlM0QlMjB0b2tlbml6ZXIoaW5wdXRfc3RyKS5pbnB1dF9pZHM=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BrandNewLlamaTokenizer

input_str = <span class="hljs-string">&quot;This is a long example input string containing special characters .$?-, numbers 2872 234 12 and words.&quot;</span>
tokenizer = BrandNewLlamaTokenizer.from_pretrained(<span class="hljs-string">&quot;/path/to/tokenizer/folder/&quot;</span>)
input_ids = tokenizer(input_str).input_ids`,wrap:!1}}),hl=new J({props:{title:"Implement image processor",local:"implement-image-processor",headingTag:"h2"}}),G=new _({props:{warning:!1,$$slots:{default:[Ip]},$$scope:{ctx:g}}}),wl=new $({props:{code:"dHJhbnNmb3JtZXJzJTIwYWRkLWZhc3QtaW1hZ2UtcHJvY2Vzc29yJTIwLS1tb2RlbC1uYW1lJTIweW91cl9tb2RlbF9uYW1l",highlighted:"transformers add-fast-image-processor --model-name your_model_name",wrap:!1}}),gl=new J({props:{title:"Implement processor",local:"implement-processor",headingTag:"h2"}}),Cl=new $({props:{code:"ZGVmJTIwX19jYWxsX18oJTBBJTIwJTIwJTIwJTIwc2VsZiUyQyUwQSUyMCUyMCUyMCUyMGltYWdlcyUzQSUyMEltYWdlSW5wdXQlMjAlM0QlMjBOb25lJTJDJTBBJTIwJTIwJTIwJTIwdGV4dCUzQSUyMFVuaW9uJTVCVGV4dElucHV0JTJDJTIwUHJlVG9rZW5pemVkSW5wdXQlMkMlMjBsaXN0JTVCVGV4dElucHV0JTVEJTJDJTIwbGlzdCU1QlByZVRva2VuaXplZElucHV0JTVEJTVEJTIwJTNEJTIwTm9uZSUyQyUwQSUyMCUyMCUyMCUyMGF1ZGlvJTNETm9uZSUyQyUwQSUyMCUyMCUyMCUyMHZpZGVvcyUzRE5vbmUlMkMlMEElMjAlMjAlMjAlMjAqKmt3YXJncyUzQSUyMFVucGFjayU1QllvdXJNb2RlbFByb2Nlc3Nvckt3YXJncyU1RCUyQyUwQSklMjAtJTNFJTIwQmF0Y2hGZWF0dXJlJTNBJTBBJTIwJTIwJTIwJTIwLi4u",highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">
    self,
    images: ImageInput = <span class="hljs-literal">None</span>,
    text: <span class="hljs-type">Union</span>[TextInput, PreTokenizedInput, <span class="hljs-built_in">list</span>[TextInput], <span class="hljs-built_in">list</span>[PreTokenizedInput]] = <span class="hljs-literal">None</span>,
    audio=<span class="hljs-literal">None</span>,
    videos=<span class="hljs-literal">None</span>,
    **kwargs: Unpack[YourModelProcessorKwargs],
</span>) -&gt; BatchFeature:
    ...`,wrap:!1}}),Ul=new J({props:{title:"Integration tests",local:"integration-tests",headingTag:"h2"}}),Ll=new J({props:{title:"Add documentation",local:"add-documentation",headingTag:"h2"}}),Hl=new J({props:{title:"Refactor",local:"refactor",headingTag:"h2"}}),zl=new $({props:{code:"bWFrZSUyMHN0eWxl",highlighted:"make style",wrap:!1}}),Bl=new $({props:{code:"bWFrZSUyMHF1YWxpdHk=",highlighted:"make quality",wrap:!1}}),El=new J({props:{title:"Upload to the Hub",local:"upload-to-the-hub",headingTag:"h2"}}),B=new _({props:{warning:!1,$$slots:{default:[xp]},$$scope:{ctx:g}}}),Yl=new $({props:{code:"YnJhbmRfbmV3X2JlcnQucHVzaF90b19odWIoJTIyYnJhbmRfbmV3X2xsYW1hJTIyKQ==",highlighted:'brand_new_bert.push_to_hub(<span class="hljs-string">&quot;brand_new_llama&quot;</span>)',wrap:!1}}),Xl=new J({props:{title:"Merge your model",local:"merge-your-model",headingTag:"h2"}}),Kl=new J({props:{title:"Model addition timeline",local:"model-addition-timeline",headingTag:"h2"}}),ls=new hp({props:{source:"https://github.com/huggingface/transformers/blob/main/docs/source/en/add_new_model.md"}}),{c(){i=o("meta"),y=n(),m=o("p"),w=n(),d(T.$$.fragment),b=n(),d(j.$$.fragment),v=n(),C=o("p"),C.textContent=k,V=n(),P=o("p"),P.textContent=Ai,ns=n(),E=o("ul"),E.innerHTML=Wi,as=n(),Q=o("p"),Q.textContent=Zi,is=n(),R=o("p"),R.textContent=Hi,os=n(),d(F.$$.fragment),rs=n(),Y=o("p"),Y.textContent=Ni,ps=n(),d(I.$$.fragment),ms=n(),D=o("p"),D.textContent=zi,ds=n(),X=o("ul"),X.innerHTML=Gi,us=n(),S=o("p"),S.innerHTML=Bi,fs=n(),q=o("p"),q.textContent=Vi,hs=n(),d(O.$$.fragment),cs=n(),K=o("p"),K.innerHTML=Pi,Ms=n(),ee=o("p"),ee.innerHTML=Ei,ys=n(),te=o("p"),te.innerHTML=Qi,ws=n(),le=o("p"),le.textContent=Ri,Ts=n(),se=o("p"),se.innerHTML=Fi,bs=n(),d(ne.$$.fragment),gs=n(),ae=o("p"),ae.innerHTML=Yi,$s=n(),ie=o("p"),ie.innerHTML=Di,js=n(),oe=o("p"),oe.innerHTML=Xi,Cs=n(),d(re.$$.fragment),Js=n(),pe=o("p"),pe.textContent=Si,vs=n(),me=o("ul"),me.innerHTML=qi,Us=n(),d(de.$$.fragment),ks=n(),ue=o("p"),ue.innerHTML=Oi,_s=n(),d(x.$$.fragment),Is=n(),fe=o("p"),fe.textContent=Ki,xs=n(),he=o("ul"),he.innerHTML=eo,Ls=n(),ce=o("p"),ce.textContent=to,As=n(),d(L.$$.fragment),Ws=n(),Me=o("ul"),Me.innerHTML=lo,Zs=n(),d(ye.$$.fragment),Hs=n(),we=o("p"),we.innerHTML=so,Ns=n(),d(Te.$$.fragment),zs=n(),be=o("p"),be.innerHTML=no,Gs=n(),d(ge.$$.fragment),Bs=n(),$e=o("p"),$e.textContent=ao,Vs=n(),d(je.$$.fragment),Ps=n(),Ce=o("p"),Ce.textContent=io,Es=n(),d(Je.$$.fragment),Qs=n(),ve=o("p"),ve.textContent=oo,Rs=n(),d(Ue.$$.fragment),Fs=n(),ke=o("p"),ke.innerHTML=ro,Ys=n(),d(A.$$.fragment),Ds=n(),_e=o("p"),_e.textContent=po,Xs=n(),Ie=o("p"),Ie.textContent=mo,Ss=n(),d(W.$$.fragment),qs=n(),xe=o("p"),xe.textContent=uo,Os=n(),d(Le.$$.fragment),Ks=n(),d(Ae.$$.fragment),en=n(),We=o("p"),We.innerHTML=fo,tn=n(),Ze=o("p"),Ze.textContent=ho,ln=n(),d(He.$$.fragment),sn=n(),Ne=o("p"),Ne.textContent=co,nn=n(),d(ze.$$.fragment),an=n(),Ge=o("p"),Ge.innerHTML=Mo,on=n(),d(Be.$$.fragment),rn=n(),Ve=o("p"),Ve.innerHTML=yo,pn=n(),Pe=o("p"),Pe.textContent=wo,mn=n(),d(Ee.$$.fragment),dn=n(),d(Qe.$$.fragment),un=n(),Re=o("p"),Re.textContent=To,fn=n(),Fe=o("p"),Fe.textContent=bo,hn=n(),Ye=o("p"),Ye.textContent=go,cn=n(),De=o("ul"),De.innerHTML=$o,Mn=n(),Xe=o("p"),Xe.textContent=jo,yn=n(),Se=o("p"),Se.innerHTML=Co,wn=n(),d(qe.$$.fragment),Tn=n(),d(Oe.$$.fragment),bn=n(),Ke=o("p"),Ke.textContent=Jo,gn=n(),d(Z.$$.fragment),$n=n(),et=o("p"),et.textContent=vo,jn=n(),tt=o("ol"),tt.innerHTML=Uo,Cn=n(),lt=o("p"),lt.innerHTML=ko,Jn=n(),st=o("p"),st.textContent=_o,vn=n(),d(nt.$$.fragment),Un=n(),at=o("p"),at.innerHTML=Io,kn=n(),it=o("p"),it.textContent=xo,_n=n(),ot=o("ul"),ot.innerHTML=Lo,In=n(),rt=o("p"),rt.textContent=Ao,xn=n(),d(pt.$$.fragment),Ln=n(),mt=o("p"),mt.innerHTML=Wo,An=n(),dt=o("ul"),dt.innerHTML=Zo,Wn=n(),ut=o("p"),ut.innerHTML=Ho,Zn=n(),d(ft.$$.fragment),Hn=n(),ht=o("p"),ht.innerHTML=No,Nn=n(),d(ct.$$.fragment),zn=n(),Mt=o("p"),Mt.innerHTML=zo,Gn=n(),d(yt.$$.fragment),Bn=n(),wt=o("p"),wt.innerHTML=Go,Vn=n(),Tt=o("p"),Tt.innerHTML=Bo,Pn=n(),d(bt.$$.fragment),En=n(),d(gt.$$.fragment),Qn=n(),$t=o("p"),$t.textContent=Vo,Rn=n(),d(H.$$.fragment),Fn=n(),jt=o("p"),jt.innerHTML=Po,Yn=n(),Ct=o("p"),Ct.innerHTML=Eo,Dn=n(),Jt=o("p"),Jt.innerHTML=Qo,Xn=n(),d(vt.$$.fragment),Sn=n(),Ut=o("p"),Ut.textContent=Ro,qn=n(),d(kt.$$.fragment),On=n(),_t=o("p"),_t.textContent=Fo,Kn=n(),d(It.$$.fragment),ea=n(),xt=o("p"),xt.innerHTML=Yo,ta=n(),d(Lt.$$.fragment),la=n(),At=o("p"),At.textContent=Do,sa=n(),d(Wt.$$.fragment),na=n(),Zt=o("p"),Zt.textContent=Xo,aa=n(),d(Ht.$$.fragment),ia=n(),Nt=o("p"),Nt.innerHTML=So,oa=n(),d(zt.$$.fragment),ra=n(),Gt=o("p"),Gt.innerHTML=qo,pa=n(),d(Bt.$$.fragment),ma=n(),Vt=o("p"),Vt.textContent=Oo,da=n(),d(Pt.$$.fragment),ua=n(),Et=o("p"),Et.innerHTML=Ko,fa=n(),Qt=o("p"),Qt.innerHTML=er,ha=n(),Rt=o("ul"),Rt.innerHTML=tr,ca=n(),Ft=o("p"),Ft.textContent=lr,Ma=n(),Yt=o("ol"),Yt.innerHTML=sr,ya=n(),Dt=o("p"),Dt.textContent=nr,wa=n(),Xt=o("p"),Xt.textContent=ar,Ta=n(),St=o("p"),St.innerHTML=ir,ba=n(),d(qt.$$.fragment),ga=n(),Ot=o("p"),Ot.textContent=or,$a=n(),Kt=o("p"),Kt.textContent=rr,ja=n(),d(el.$$.fragment),Ca=n(),tl=o("p"),tl.textContent=pr,Ja=n(),ll=o("p"),ll.innerHTML=mr,va=n(),d(sl.$$.fragment),Ua=n(),nl=o("p"),nl.innerHTML=dr,ka=n(),d(N.$$.fragment),_a=n(),al=o("p"),al.innerHTML=ur,Ia=n(),il=o("ul"),il.innerHTML=fr,xa=n(),d(ol.$$.fragment),La=n(),d(z.$$.fragment),Aa=n(),rl=o("p"),rl.textContent=hr,Wa=n(),pl=o("p"),pl.innerHTML=cr,Za=n(),d(ml.$$.fragment),Ha=n(),dl=o("p"),dl.innerHTML=Mr,Na=n(),d(ul.$$.fragment),za=n(),fl=o("p"),fl.innerHTML=yr,Ga=n(),d(hl.$$.fragment),Ba=n(),d(G.$$.fragment),Va=n(),cl=o("p"),cl.innerHTML=wr,Pa=n(),Ml=o("p"),Ml.innerHTML=Tr,Ea=n(),yl=o("p"),yl.innerHTML=br,Qa=n(),d(wl.$$.fragment),Ra=n(),Tl=o("p"),Tl.textContent=gr,Fa=n(),bl=o("p"),bl.innerHTML=$r,Ya=n(),d(gl.$$.fragment),Da=n(),$l=o("p"),$l.textContent=jr,Xa=n(),jl=o("p"),jl.innerHTML=Cr,Sa=n(),d(Cl.$$.fragment),qa=n(),Jl=o("p"),Jl.innerHTML=Jr,Oa=n(),vl=o("p"),vl.innerHTML=vr,Ka=n(),d(Ul.$$.fragment),ei=n(),kl=o("p"),kl.innerHTML=Ur,ti=n(),_l=o("p"),_l.textContent=kr,li=n(),Il=o("p"),Il.textContent=_r,si=n(),xl=o("p"),xl.innerHTML=Ir,ni=n(),d(Ll.$$.fragment),ai=n(),Al=o("p"),Al.innerHTML=xr,ii=n(),Wl=o("p"),Wl.textContent=Lr,oi=n(),Zl=o("p"),Zl.innerHTML=Ar,ri=n(),d(Hl.$$.fragment),pi=n(),Nl=o("p"),Nl.textContent=Wr,mi=n(),d(zl.$$.fragment),di=n(),Gl=o("p"),Gl.textContent=Zr,ui=n(),d(Bl.$$.fragment),fi=n(),Vl=o("p"),Vl.textContent=Hr,hi=n(),Pl=o("p"),Pl.textContent=Nr,ci=n(),d(El.$$.fragment),Mi=n(),Ql=o("p"),Ql.innerHTML=zr,yi=n(),d(B.$$.fragment),wi=n(),Rl=o("p"),Rl.textContent=Gr,Ti=n(),Fl=o("p"),Fl.innerHTML=Br,bi=n(),d(Yl.$$.fragment),gi=n(),Dl=o("p"),Dl.innerHTML=Vr,$i=n(),d(Xl.$$.fragment),ji=n(),Sl=o("p"),Sl.textContent=Pr,Ci=n(),ql=o("p"),ql.textContent=Er,Ji=n(),Ol=o("p"),Ol.textContent=Qr,vi=n(),d(Kl.$$.fragment),Ui=n(),es=o("p"),es.textContent=Rr,ki=n(),ts=o("ul"),ts.innerHTML=Fr,_i=n(),d(ls.$$.fragment),Ii=n(),ss=o("p"),this.h()},l(e){const t=up("svelte-u9bgzb",document.head);i=r(t,"META",{name:!0,content:!0}),t.forEach(l),y=a(e),m=r(e,"P",{}),ap(m).forEach(l),w=a(e),u(T.$$.fragment,e),b=a(e),u(j.$$.fragment,e),v=a(e),C=r(e,"P",{"data-svelte-h":!0}),p(C)!=="svelte-vwc8bz"&&(C.textContent=k),V=a(e),P=r(e,"P",{"data-svelte-h":!0}),p(P)!=="svelte-54s3hx"&&(P.textContent=Ai),ns=a(e),E=r(e,"UL",{"data-svelte-h":!0}),p(E)!=="svelte-1su2pep"&&(E.innerHTML=Wi),as=a(e),Q=r(e,"P",{"data-svelte-h":!0}),p(Q)!=="svelte-19gqvob"&&(Q.textContent=Zi),is=a(e),R=r(e,"P",{"data-svelte-h":!0}),p(R)!=="svelte-1jb46qy"&&(R.textContent=Hi),os=a(e),u(F.$$.fragment,e),rs=a(e),Y=r(e,"P",{"data-svelte-h":!0}),p(Y)!=="svelte-v7op7a"&&(Y.textContent=Ni),ps=a(e),u(I.$$.fragment,e),ms=a(e),D=r(e,"P",{"data-svelte-h":!0}),p(D)!=="svelte-pyhqj0"&&(D.textContent=zi),ds=a(e),X=r(e,"UL",{"data-svelte-h":!0}),p(X)!=="svelte-1inlcmk"&&(X.innerHTML=Gi),us=a(e),S=r(e,"P",{"data-svelte-h":!0}),p(S)!=="svelte-8h2trk"&&(S.innerHTML=Bi),fs=a(e),q=r(e,"P",{"data-svelte-h":!0}),p(q)!=="svelte-phbpho"&&(q.textContent=Vi),hs=a(e),u(O.$$.fragment,e),cs=a(e),K=r(e,"P",{"data-svelte-h":!0}),p(K)!=="svelte-1p4ixnw"&&(K.innerHTML=Pi),Ms=a(e),ee=r(e,"P",{"data-svelte-h":!0}),p(ee)!=="svelte-16w2c02"&&(ee.innerHTML=Ei),ys=a(e),te=r(e,"P",{"data-svelte-h":!0}),p(te)!=="svelte-16tan6r"&&(te.innerHTML=Qi),ws=a(e),le=r(e,"P",{"data-svelte-h":!0}),p(le)!=="svelte-ifrgvs"&&(le.textContent=Ri),Ts=a(e),se=r(e,"P",{"data-svelte-h":!0}),p(se)!=="svelte-1ghogs6"&&(se.innerHTML=Fi),bs=a(e),u(ne.$$.fragment,e),gs=a(e),ae=r(e,"P",{"data-svelte-h":!0}),p(ae)!=="svelte-u15n97"&&(ae.innerHTML=Yi),$s=a(e),ie=r(e,"P",{"data-svelte-h":!0}),p(ie)!=="svelte-pd1xam"&&(ie.innerHTML=Di),js=a(e),oe=r(e,"P",{"data-svelte-h":!0}),p(oe)!=="svelte-1sl970c"&&(oe.innerHTML=Xi),Cs=a(e),u(re.$$.fragment,e),Js=a(e),pe=r(e,"P",{"data-svelte-h":!0}),p(pe)!=="svelte-iqj2v4"&&(pe.textContent=Si),vs=a(e),me=r(e,"UL",{"data-svelte-h":!0}),p(me)!=="svelte-7ttjos"&&(me.innerHTML=qi),Us=a(e),u(de.$$.fragment,e),ks=a(e),ue=r(e,"P",{"data-svelte-h":!0}),p(ue)!=="svelte-1ie5by1"&&(ue.innerHTML=Oi),_s=a(e),u(x.$$.fragment,e),Is=a(e),fe=r(e,"P",{"data-svelte-h":!0}),p(fe)!=="svelte-1f2ecjs"&&(fe.textContent=Ki),xs=a(e),he=r(e,"UL",{"data-svelte-h":!0}),p(he)!=="svelte-petmsi"&&(he.innerHTML=eo),Ls=a(e),ce=r(e,"P",{"data-svelte-h":!0}),p(ce)!=="svelte-1bzv4a2"&&(ce.textContent=to),As=a(e),u(L.$$.fragment,e),Ws=a(e),Me=r(e,"UL",{"data-svelte-h":!0}),p(Me)!=="svelte-fdfcbc"&&(Me.innerHTML=lo),Zs=a(e),u(ye.$$.fragment,e),Hs=a(e),we=r(e,"P",{"data-svelte-h":!0}),p(we)!=="svelte-xccmja"&&(we.innerHTML=so),Ns=a(e),u(Te.$$.fragment,e),zs=a(e),be=r(e,"P",{"data-svelte-h":!0}),p(be)!=="svelte-uhy3bx"&&(be.innerHTML=no),Gs=a(e),u(ge.$$.fragment,e),Bs=a(e),$e=r(e,"P",{"data-svelte-h":!0}),p($e)!=="svelte-1kd1syv"&&($e.textContent=ao),Vs=a(e),u(je.$$.fragment,e),Ps=a(e),Ce=r(e,"P",{"data-svelte-h":!0}),p(Ce)!=="svelte-12p2rz5"&&(Ce.textContent=io),Es=a(e),u(Je.$$.fragment,e),Qs=a(e),ve=r(e,"P",{"data-svelte-h":!0}),p(ve)!=="svelte-1t2s84p"&&(ve.textContent=oo),Rs=a(e),u(Ue.$$.fragment,e),Fs=a(e),ke=r(e,"P",{"data-svelte-h":!0}),p(ke)!=="svelte-1wyg5j5"&&(ke.innerHTML=ro),Ys=a(e),u(A.$$.fragment,e),Ds=a(e),_e=r(e,"P",{"data-svelte-h":!0}),p(_e)!=="svelte-19zu5bh"&&(_e.textContent=po),Xs=a(e),Ie=r(e,"P",{"data-svelte-h":!0}),p(Ie)!=="svelte-dedde1"&&(Ie.textContent=mo),Ss=a(e),u(W.$$.fragment,e),qs=a(e),xe=r(e,"P",{"data-svelte-h":!0}),p(xe)!=="svelte-1340um8"&&(xe.textContent=uo),Os=a(e),u(Le.$$.fragment,e),Ks=a(e),u(Ae.$$.fragment,e),en=a(e),We=r(e,"P",{"data-svelte-h":!0}),p(We)!=="svelte-9w6jnv"&&(We.innerHTML=fo),tn=a(e),Ze=r(e,"P",{"data-svelte-h":!0}),p(Ze)!=="svelte-1y3n9s7"&&(Ze.textContent=ho),ln=a(e),u(He.$$.fragment,e),sn=a(e),Ne=r(e,"P",{"data-svelte-h":!0}),p(Ne)!=="svelte-13fpy6p"&&(Ne.textContent=co),nn=a(e),u(ze.$$.fragment,e),an=a(e),Ge=r(e,"P",{"data-svelte-h":!0}),p(Ge)!=="svelte-13315ec"&&(Ge.innerHTML=Mo),on=a(e),u(Be.$$.fragment,e),rn=a(e),Ve=r(e,"P",{"data-svelte-h":!0}),p(Ve)!=="svelte-1w5c0m4"&&(Ve.innerHTML=yo),pn=a(e),Pe=r(e,"P",{"data-svelte-h":!0}),p(Pe)!=="svelte-g2ec4o"&&(Pe.textContent=wo),mn=a(e),u(Ee.$$.fragment,e),dn=a(e),u(Qe.$$.fragment,e),un=a(e),Re=r(e,"P",{"data-svelte-h":!0}),p(Re)!=="svelte-1we2leg"&&(Re.textContent=To),fn=a(e),Fe=r(e,"P",{"data-svelte-h":!0}),p(Fe)!=="svelte-t6fs80"&&(Fe.textContent=bo),hn=a(e),Ye=r(e,"P",{"data-svelte-h":!0}),p(Ye)!=="svelte-1j9lxpc"&&(Ye.textContent=go),cn=a(e),De=r(e,"UL",{"data-svelte-h":!0}),p(De)!=="svelte-15bc8h3"&&(De.innerHTML=$o),Mn=a(e),Xe=r(e,"P",{"data-svelte-h":!0}),p(Xe)!=="svelte-186njlg"&&(Xe.textContent=jo),yn=a(e),Se=r(e,"P",{"data-svelte-h":!0}),p(Se)!=="svelte-1x2ozq7"&&(Se.innerHTML=Co),wn=a(e),u(qe.$$.fragment,e),Tn=a(e),u(Oe.$$.fragment,e),bn=a(e),Ke=r(e,"P",{"data-svelte-h":!0}),p(Ke)!=="svelte-6pwb24"&&(Ke.textContent=Jo),gn=a(e),u(Z.$$.fragment,e),$n=a(e),et=r(e,"P",{"data-svelte-h":!0}),p(et)!=="svelte-kou5xx"&&(et.textContent=vo),jn=a(e),tt=r(e,"OL",{"data-svelte-h":!0}),p(tt)!=="svelte-1bjux2"&&(tt.innerHTML=Uo),Cn=a(e),lt=r(e,"P",{"data-svelte-h":!0}),p(lt)!=="svelte-nkn0ri"&&(lt.innerHTML=ko),Jn=a(e),st=r(e,"P",{"data-svelte-h":!0}),p(st)!=="svelte-1ai0932"&&(st.textContent=_o),vn=a(e),u(nt.$$.fragment,e),Un=a(e),at=r(e,"P",{"data-svelte-h":!0}),p(at)!=="svelte-14ix5lp"&&(at.innerHTML=Io),kn=a(e),it=r(e,"P",{"data-svelte-h":!0}),p(it)!=="svelte-1gugjqw"&&(it.textContent=xo),_n=a(e),ot=r(e,"UL",{"data-svelte-h":!0}),p(ot)!=="svelte-1nsx9u7"&&(ot.innerHTML=Lo),In=a(e),rt=r(e,"P",{"data-svelte-h":!0}),p(rt)!=="svelte-inp5wx"&&(rt.textContent=Ao),xn=a(e),u(pt.$$.fragment,e),Ln=a(e),mt=r(e,"P",{"data-svelte-h":!0}),p(mt)!=="svelte-6zc4og"&&(mt.innerHTML=Wo),An=a(e),dt=r(e,"UL",{"data-svelte-h":!0}),p(dt)!=="svelte-1xv3kld"&&(dt.innerHTML=Zo),Wn=a(e),ut=r(e,"P",{"data-svelte-h":!0}),p(ut)!=="svelte-16cq26o"&&(ut.innerHTML=Ho),Zn=a(e),u(ft.$$.fragment,e),Hn=a(e),ht=r(e,"P",{"data-svelte-h":!0}),p(ht)!=="svelte-djv6f1"&&(ht.innerHTML=No),Nn=a(e),u(ct.$$.fragment,e),zn=a(e),Mt=r(e,"P",{"data-svelte-h":!0}),p(Mt)!=="svelte-91l1vn"&&(Mt.innerHTML=zo),Gn=a(e),u(yt.$$.fragment,e),Bn=a(e),wt=r(e,"P",{"data-svelte-h":!0}),p(wt)!=="svelte-1347hlh"&&(wt.innerHTML=Go),Vn=a(e),Tt=r(e,"P",{"data-svelte-h":!0}),p(Tt)!=="svelte-1lhu6y1"&&(Tt.innerHTML=Bo),Pn=a(e),u(bt.$$.fragment,e),En=a(e),u(gt.$$.fragment,e),Qn=a(e),$t=r(e,"P",{"data-svelte-h":!0}),p($t)!=="svelte-1kvx6e4"&&($t.textContent=Vo),Rn=a(e),u(H.$$.fragment,e),Fn=a(e),jt=r(e,"P",{"data-svelte-h":!0}),p(jt)!=="svelte-1xtmwxm"&&(jt.innerHTML=Po),Yn=a(e),Ct=r(e,"P",{"data-svelte-h":!0}),p(Ct)!=="svelte-1fh75wx"&&(Ct.innerHTML=Eo),Dn=a(e),Jt=r(e,"P",{"data-svelte-h":!0}),p(Jt)!=="svelte-qx7ezr"&&(Jt.innerHTML=Qo),Xn=a(e),u(vt.$$.fragment,e),Sn=a(e),Ut=r(e,"P",{"data-svelte-h":!0}),p(Ut)!=="svelte-hq4w2t"&&(Ut.textContent=Ro),qn=a(e),u(kt.$$.fragment,e),On=a(e),_t=r(e,"P",{"data-svelte-h":!0}),p(_t)!=="svelte-1esw63a"&&(_t.textContent=Fo),Kn=a(e),u(It.$$.fragment,e),ea=a(e),xt=r(e,"P",{"data-svelte-h":!0}),p(xt)!=="svelte-15hwro6"&&(xt.innerHTML=Yo),ta=a(e),u(Lt.$$.fragment,e),la=a(e),At=r(e,"P",{"data-svelte-h":!0}),p(At)!=="svelte-4s6few"&&(At.textContent=Do),sa=a(e),u(Wt.$$.fragment,e),na=a(e),Zt=r(e,"P",{"data-svelte-h":!0}),p(Zt)!=="svelte-nq8w11"&&(Zt.textContent=Xo),aa=a(e),u(Ht.$$.fragment,e),ia=a(e),Nt=r(e,"P",{"data-svelte-h":!0}),p(Nt)!=="svelte-5dw6mg"&&(Nt.innerHTML=So),oa=a(e),u(zt.$$.fragment,e),ra=a(e),Gt=r(e,"P",{"data-svelte-h":!0}),p(Gt)!=="svelte-1d5wwk0"&&(Gt.innerHTML=qo),pa=a(e),u(Bt.$$.fragment,e),ma=a(e),Vt=r(e,"P",{"data-svelte-h":!0}),p(Vt)!=="svelte-3krmz6"&&(Vt.textContent=Oo),da=a(e),u(Pt.$$.fragment,e),ua=a(e),Et=r(e,"P",{"data-svelte-h":!0}),p(Et)!=="svelte-cearkf"&&(Et.innerHTML=Ko),fa=a(e),Qt=r(e,"P",{"data-svelte-h":!0}),p(Qt)!=="svelte-1wm9vqf"&&(Qt.innerHTML=er),ha=a(e),Rt=r(e,"UL",{"data-svelte-h":!0}),p(Rt)!=="svelte-cpzoqt"&&(Rt.innerHTML=tr),ca=a(e),Ft=r(e,"P",{"data-svelte-h":!0}),p(Ft)!=="svelte-18s62g4"&&(Ft.textContent=lr),Ma=a(e),Yt=r(e,"OL",{"data-svelte-h":!0}),p(Yt)!=="svelte-1jwb28w"&&(Yt.innerHTML=sr),ya=a(e),Dt=r(e,"P",{"data-svelte-h":!0}),p(Dt)!=="svelte-co7qqq"&&(Dt.textContent=nr),wa=a(e),Xt=r(e,"P",{"data-svelte-h":!0}),p(Xt)!=="svelte-1a7i3d3"&&(Xt.textContent=ar),Ta=a(e),St=r(e,"P",{"data-svelte-h":!0}),p(St)!=="svelte-avzzlw"&&(St.innerHTML=ir),ba=a(e),u(qt.$$.fragment,e),ga=a(e),Ot=r(e,"P",{"data-svelte-h":!0}),p(Ot)!=="svelte-tyhory"&&(Ot.textContent=or),$a=a(e),Kt=r(e,"P",{"data-svelte-h":!0}),p(Kt)!=="svelte-1p3qafp"&&(Kt.textContent=rr),ja=a(e),u(el.$$.fragment,e),Ca=a(e),tl=r(e,"P",{"data-svelte-h":!0}),p(tl)!=="svelte-k1wv45"&&(tl.textContent=pr),Ja=a(e),ll=r(e,"P",{"data-svelte-h":!0}),p(ll)!=="svelte-1xkoolp"&&(ll.innerHTML=mr),va=a(e),u(sl.$$.fragment,e),Ua=a(e),nl=r(e,"P",{"data-svelte-h":!0}),p(nl)!=="svelte-lzht9v"&&(nl.innerHTML=dr),ka=a(e),u(N.$$.fragment,e),_a=a(e),al=r(e,"P",{"data-svelte-h":!0}),p(al)!=="svelte-15lyefy"&&(al.innerHTML=ur),Ia=a(e),il=r(e,"UL",{"data-svelte-h":!0}),p(il)!=="svelte-wtsfvq"&&(il.innerHTML=fr),xa=a(e),u(ol.$$.fragment,e),La=a(e),u(z.$$.fragment,e),Aa=a(e),rl=r(e,"P",{"data-svelte-h":!0}),p(rl)!=="svelte-hvob9e"&&(rl.textContent=hr),Wa=a(e),pl=r(e,"P",{"data-svelte-h":!0}),p(pl)!=="svelte-pl50qv"&&(pl.innerHTML=cr),Za=a(e),u(ml.$$.fragment,e),Ha=a(e),dl=r(e,"P",{"data-svelte-h":!0}),p(dl)!=="svelte-1zn9hg"&&(dl.innerHTML=Mr),Na=a(e),u(ul.$$.fragment,e),za=a(e),fl=r(e,"P",{"data-svelte-h":!0}),p(fl)!=="svelte-1144g0m"&&(fl.innerHTML=yr),Ga=a(e),u(hl.$$.fragment,e),Ba=a(e),u(G.$$.fragment,e),Va=a(e),cl=r(e,"P",{"data-svelte-h":!0}),p(cl)!=="svelte-saggkj"&&(cl.innerHTML=wr),Pa=a(e),Ml=r(e,"P",{"data-svelte-h":!0}),p(Ml)!=="svelte-1fdxqip"&&(Ml.innerHTML=Tr),Ea=a(e),yl=r(e,"P",{"data-svelte-h":!0}),p(yl)!=="svelte-m9mfvt"&&(yl.innerHTML=br),Qa=a(e),u(wl.$$.fragment,e),Ra=a(e),Tl=r(e,"P",{"data-svelte-h":!0}),p(Tl)!=="svelte-132cg3u"&&(Tl.textContent=gr),Fa=a(e),bl=r(e,"P",{"data-svelte-h":!0}),p(bl)!=="svelte-zhdd1w"&&(bl.innerHTML=$r),Ya=a(e),u(gl.$$.fragment,e),Da=a(e),$l=r(e,"P",{"data-svelte-h":!0}),p($l)!=="svelte-18ahuk0"&&($l.textContent=jr),Xa=a(e),jl=r(e,"P",{"data-svelte-h":!0}),p(jl)!=="svelte-1nk04r3"&&(jl.innerHTML=Cr),Sa=a(e),u(Cl.$$.fragment,e),qa=a(e),Jl=r(e,"P",{"data-svelte-h":!0}),p(Jl)!=="svelte-a8ijmv"&&(Jl.innerHTML=Jr),Oa=a(e),vl=r(e,"P",{"data-svelte-h":!0}),p(vl)!=="svelte-6201y6"&&(vl.innerHTML=vr),Ka=a(e),u(Ul.$$.fragment,e),ei=a(e),kl=r(e,"P",{"data-svelte-h":!0}),p(kl)!=="svelte-sjhk4c"&&(kl.innerHTML=Ur),ti=a(e),_l=r(e,"P",{"data-svelte-h":!0}),p(_l)!=="svelte-19262vp"&&(_l.textContent=kr),li=a(e),Il=r(e,"P",{"data-svelte-h":!0}),p(Il)!=="svelte-kdwqhn"&&(Il.textContent=_r),si=a(e),xl=r(e,"P",{"data-svelte-h":!0}),p(xl)!=="svelte-fzdwlb"&&(xl.innerHTML=Ir),ni=a(e),u(Ll.$$.fragment,e),ai=a(e),Al=r(e,"P",{"data-svelte-h":!0}),p(Al)!=="svelte-jfubra"&&(Al.innerHTML=xr),ii=a(e),Wl=r(e,"P",{"data-svelte-h":!0}),p(Wl)!=="svelte-a2ts1c"&&(Wl.textContent=Lr),oi=a(e),Zl=r(e,"P",{"data-svelte-h":!0}),p(Zl)!=="svelte-1e4djn7"&&(Zl.innerHTML=Ar),ri=a(e),u(Hl.$$.fragment,e),pi=a(e),Nl=r(e,"P",{"data-svelte-h":!0}),p(Nl)!=="svelte-fzwwhp"&&(Nl.textContent=Wr),mi=a(e),u(zl.$$.fragment,e),di=a(e),Gl=r(e,"P",{"data-svelte-h":!0}),p(Gl)!=="svelte-uqgqza"&&(Gl.textContent=Zr),ui=a(e),u(Bl.$$.fragment,e),fi=a(e),Vl=r(e,"P",{"data-svelte-h":!0}),p(Vl)!=="svelte-12tjtsr"&&(Vl.textContent=Hr),hi=a(e),Pl=r(e,"P",{"data-svelte-h":!0}),p(Pl)!=="svelte-1ccpdqs"&&(Pl.textContent=Nr),ci=a(e),u(El.$$.fragment,e),Mi=a(e),Ql=r(e,"P",{"data-svelte-h":!0}),p(Ql)!=="svelte-1g4ptn2"&&(Ql.innerHTML=zr),yi=a(e),u(B.$$.fragment,e),wi=a(e),Rl=r(e,"P",{"data-svelte-h":!0}),p(Rl)!=="svelte-1t4pd0l"&&(Rl.textContent=Gr),Ti=a(e),Fl=r(e,"P",{"data-svelte-h":!0}),p(Fl)!=="svelte-qo3sas"&&(Fl.innerHTML=Br),bi=a(e),u(Yl.$$.fragment,e),gi=a(e),Dl=r(e,"P",{"data-svelte-h":!0}),p(Dl)!=="svelte-1e9q1k1"&&(Dl.innerHTML=Vr),$i=a(e),u(Xl.$$.fragment,e),ji=a(e),Sl=r(e,"P",{"data-svelte-h":!0}),p(Sl)!=="svelte-1hif0p"&&(Sl.textContent=Pr),Ci=a(e),ql=r(e,"P",{"data-svelte-h":!0}),p(ql)!=="svelte-id2k40"&&(ql.textContent=Er),Ji=a(e),Ol=r(e,"P",{"data-svelte-h":!0}),p(Ol)!=="svelte-197xklk"&&(Ol.textContent=Qr),vi=a(e),u(Kl.$$.fragment,e),Ui=a(e),es=r(e,"P",{"data-svelte-h":!0}),p(es)!=="svelte-om5qbx"&&(es.textContent=Rr),ki=a(e),ts=r(e,"UL",{"data-svelte-h":!0}),p(ts)!=="svelte-kmys7o"&&(ts.innerHTML=Fr),_i=a(e),u(ls.$$.fragment,e),Ii=a(e),ss=r(e,"P",{}),ap(ss).forEach(l),this.h()},h(){ip(i,"name","hf:doc:metadata"),ip(i,"content",Ap)},m(e,t){fp(document.head,i),s(e,y,t),s(e,m,t),s(e,w,t),f(T,e,t),s(e,b,t),f(j,e,t),s(e,v,t),s(e,C,t),s(e,V,t),s(e,P,t),s(e,ns,t),s(e,E,t),s(e,as,t),s(e,Q,t),s(e,is,t),s(e,R,t),s(e,os,t),f(F,e,t),s(e,rs,t),s(e,Y,t),s(e,ps,t),f(I,e,t),s(e,ms,t),s(e,D,t),s(e,ds,t),s(e,X,t),s(e,us,t),s(e,S,t),s(e,fs,t),s(e,q,t),s(e,hs,t),f(O,e,t),s(e,cs,t),s(e,K,t),s(e,Ms,t),s(e,ee,t),s(e,ys,t),s(e,te,t),s(e,ws,t),s(e,le,t),s(e,Ts,t),s(e,se,t),s(e,bs,t),f(ne,e,t),s(e,gs,t),s(e,ae,t),s(e,$s,t),s(e,ie,t),s(e,js,t),s(e,oe,t),s(e,Cs,t),f(re,e,t),s(e,Js,t),s(e,pe,t),s(e,vs,t),s(e,me,t),s(e,Us,t),f(de,e,t),s(e,ks,t),s(e,ue,t),s(e,_s,t),f(x,e,t),s(e,Is,t),s(e,fe,t),s(e,xs,t),s(e,he,t),s(e,Ls,t),s(e,ce,t),s(e,As,t),f(L,e,t),s(e,Ws,t),s(e,Me,t),s(e,Zs,t),f(ye,e,t),s(e,Hs,t),s(e,we,t),s(e,Ns,t),f(Te,e,t),s(e,zs,t),s(e,be,t),s(e,Gs,t),f(ge,e,t),s(e,Bs,t),s(e,$e,t),s(e,Vs,t),f(je,e,t),s(e,Ps,t),s(e,Ce,t),s(e,Es,t),f(Je,e,t),s(e,Qs,t),s(e,ve,t),s(e,Rs,t),f(Ue,e,t),s(e,Fs,t),s(e,ke,t),s(e,Ys,t),f(A,e,t),s(e,Ds,t),s(e,_e,t),s(e,Xs,t),s(e,Ie,t),s(e,Ss,t),f(W,e,t),s(e,qs,t),s(e,xe,t),s(e,Os,t),f(Le,e,t),s(e,Ks,t),f(Ae,e,t),s(e,en,t),s(e,We,t),s(e,tn,t),s(e,Ze,t),s(e,ln,t),f(He,e,t),s(e,sn,t),s(e,Ne,t),s(e,nn,t),f(ze,e,t),s(e,an,t),s(e,Ge,t),s(e,on,t),f(Be,e,t),s(e,rn,t),s(e,Ve,t),s(e,pn,t),s(e,Pe,t),s(e,mn,t),f(Ee,e,t),s(e,dn,t),f(Qe,e,t),s(e,un,t),s(e,Re,t),s(e,fn,t),s(e,Fe,t),s(e,hn,t),s(e,Ye,t),s(e,cn,t),s(e,De,t),s(e,Mn,t),s(e,Xe,t),s(e,yn,t),s(e,Se,t),s(e,wn,t),f(qe,e,t),s(e,Tn,t),f(Oe,e,t),s(e,bn,t),s(e,Ke,t),s(e,gn,t),f(Z,e,t),s(e,$n,t),s(e,et,t),s(e,jn,t),s(e,tt,t),s(e,Cn,t),s(e,lt,t),s(e,Jn,t),s(e,st,t),s(e,vn,t),f(nt,e,t),s(e,Un,t),s(e,at,t),s(e,kn,t),s(e,it,t),s(e,_n,t),s(e,ot,t),s(e,In,t),s(e,rt,t),s(e,xn,t),f(pt,e,t),s(e,Ln,t),s(e,mt,t),s(e,An,t),s(e,dt,t),s(e,Wn,t),s(e,ut,t),s(e,Zn,t),f(ft,e,t),s(e,Hn,t),s(e,ht,t),s(e,Nn,t),f(ct,e,t),s(e,zn,t),s(e,Mt,t),s(e,Gn,t),f(yt,e,t),s(e,Bn,t),s(e,wt,t),s(e,Vn,t),s(e,Tt,t),s(e,Pn,t),f(bt,e,t),s(e,En,t),f(gt,e,t),s(e,Qn,t),s(e,$t,t),s(e,Rn,t),f(H,e,t),s(e,Fn,t),s(e,jt,t),s(e,Yn,t),s(e,Ct,t),s(e,Dn,t),s(e,Jt,t),s(e,Xn,t),f(vt,e,t),s(e,Sn,t),s(e,Ut,t),s(e,qn,t),f(kt,e,t),s(e,On,t),s(e,_t,t),s(e,Kn,t),f(It,e,t),s(e,ea,t),s(e,xt,t),s(e,ta,t),f(Lt,e,t),s(e,la,t),s(e,At,t),s(e,sa,t),f(Wt,e,t),s(e,na,t),s(e,Zt,t),s(e,aa,t),f(Ht,e,t),s(e,ia,t),s(e,Nt,t),s(e,oa,t),f(zt,e,t),s(e,ra,t),s(e,Gt,t),s(e,pa,t),f(Bt,e,t),s(e,ma,t),s(e,Vt,t),s(e,da,t),f(Pt,e,t),s(e,ua,t),s(e,Et,t),s(e,fa,t),s(e,Qt,t),s(e,ha,t),s(e,Rt,t),s(e,ca,t),s(e,Ft,t),s(e,Ma,t),s(e,Yt,t),s(e,ya,t),s(e,Dt,t),s(e,wa,t),s(e,Xt,t),s(e,Ta,t),s(e,St,t),s(e,ba,t),f(qt,e,t),s(e,ga,t),s(e,Ot,t),s(e,$a,t),s(e,Kt,t),s(e,ja,t),f(el,e,t),s(e,Ca,t),s(e,tl,t),s(e,Ja,t),s(e,ll,t),s(e,va,t),f(sl,e,t),s(e,Ua,t),s(e,nl,t),s(e,ka,t),f(N,e,t),s(e,_a,t),s(e,al,t),s(e,Ia,t),s(e,il,t),s(e,xa,t),f(ol,e,t),s(e,La,t),f(z,e,t),s(e,Aa,t),s(e,rl,t),s(e,Wa,t),s(e,pl,t),s(e,Za,t),f(ml,e,t),s(e,Ha,t),s(e,dl,t),s(e,Na,t),f(ul,e,t),s(e,za,t),s(e,fl,t),s(e,Ga,t),f(hl,e,t),s(e,Ba,t),f(G,e,t),s(e,Va,t),s(e,cl,t),s(e,Pa,t),s(e,Ml,t),s(e,Ea,t),s(e,yl,t),s(e,Qa,t),f(wl,e,t),s(e,Ra,t),s(e,Tl,t),s(e,Fa,t),s(e,bl,t),s(e,Ya,t),f(gl,e,t),s(e,Da,t),s(e,$l,t),s(e,Xa,t),s(e,jl,t),s(e,Sa,t),f(Cl,e,t),s(e,qa,t),s(e,Jl,t),s(e,Oa,t),s(e,vl,t),s(e,Ka,t),f(Ul,e,t),s(e,ei,t),s(e,kl,t),s(e,ti,t),s(e,_l,t),s(e,li,t),s(e,Il,t),s(e,si,t),s(e,xl,t),s(e,ni,t),f(Ll,e,t),s(e,ai,t),s(e,Al,t),s(e,ii,t),s(e,Wl,t),s(e,oi,t),s(e,Zl,t),s(e,ri,t),f(Hl,e,t),s(e,pi,t),s(e,Nl,t),s(e,mi,t),f(zl,e,t),s(e,di,t),s(e,Gl,t),s(e,ui,t),f(Bl,e,t),s(e,fi,t),s(e,Vl,t),s(e,hi,t),s(e,Pl,t),s(e,ci,t),f(El,e,t),s(e,Mi,t),s(e,Ql,t),s(e,yi,t),f(B,e,t),s(e,wi,t),s(e,Rl,t),s(e,Ti,t),s(e,Fl,t),s(e,bi,t),f(Yl,e,t),s(e,gi,t),s(e,Dl,t),s(e,$i,t),f(Xl,e,t),s(e,ji,t),s(e,Sl,t),s(e,Ci,t),s(e,ql,t),s(e,Ji,t),s(e,Ol,t),s(e,vi,t),f(Kl,e,t),s(e,Ui,t),s(e,es,t),s(e,ki,t),s(e,ts,t),s(e,_i,t),f(ls,e,t),s(e,Ii,t),s(e,ss,t),xi=!0},p(e,[t]){const Yr={};t&2&&(Yr.$$scope={dirty:t,ctx:e}),j.$set(Yr);const Dr={};t&2&&(Dr.$$scope={dirty:t,ctx:e}),I.$set(Dr);const Xr={};t&2&&(Xr.$$scope={dirty:t,ctx:e}),x.$set(Xr);const Sr={};t&2&&(Sr.$$scope={dirty:t,ctx:e}),L.$set(Sr);const qr={};t&2&&(qr.$$scope={dirty:t,ctx:e}),A.$set(qr);const Or={};t&2&&(Or.$$scope={dirty:t,ctx:e}),W.$set(Or);const Kr={};t&2&&(Kr.$$scope={dirty:t,ctx:e}),Z.$set(Kr);const ep={};t&2&&(ep.$$scope={dirty:t,ctx:e}),H.$set(ep);const tp={};t&2&&(tp.$$scope={dirty:t,ctx:e}),N.$set(tp);const lp={};t&2&&(lp.$$scope={dirty:t,ctx:e}),z.$set(lp);const sp={};t&2&&(sp.$$scope={dirty:t,ctx:e}),G.$set(sp);const np={};t&2&&(np.$$scope={dirty:t,ctx:e}),B.$set(np)},i(e){xi||(h(T.$$.fragment,e),h(j.$$.fragment,e),h(F.$$.fragment,e),h(I.$$.fragment,e),h(O.$$.fragment,e),h(ne.$$.fragment,e),h(re.$$.fragment,e),h(de.$$.fragment,e),h(x.$$.fragment,e),h(L.$$.fragment,e),h(ye.$$.fragment,e),h(Te.$$.fragment,e),h(ge.$$.fragment,e),h(je.$$.fragment,e),h(Je.$$.fragment,e),h(Ue.$$.fragment,e),h(A.$$.fragment,e),h(W.$$.fragment,e),h(Le.$$.fragment,e),h(Ae.$$.fragment,e),h(He.$$.fragment,e),h(ze.$$.fragment,e),h(Be.$$.fragment,e),h(Ee.$$.fragment,e),h(Qe.$$.fragment,e),h(qe.$$.fragment,e),h(Oe.$$.fragment,e),h(Z.$$.fragment,e),h(nt.$$.fragment,e),h(pt.$$.fragment,e),h(ft.$$.fragment,e),h(ct.$$.fragment,e),h(yt.$$.fragment,e),h(bt.$$.fragment,e),h(gt.$$.fragment,e),h(H.$$.fragment,e),h(vt.$$.fragment,e),h(kt.$$.fragment,e),h(It.$$.fragment,e),h(Lt.$$.fragment,e),h(Wt.$$.fragment,e),h(Ht.$$.fragment,e),h(zt.$$.fragment,e),h(Bt.$$.fragment,e),h(Pt.$$.fragment,e),h(qt.$$.fragment,e),h(el.$$.fragment,e),h(sl.$$.fragment,e),h(N.$$.fragment,e),h(ol.$$.fragment,e),h(z.$$.fragment,e),h(ml.$$.fragment,e),h(ul.$$.fragment,e),h(hl.$$.fragment,e),h(G.$$.fragment,e),h(wl.$$.fragment,e),h(gl.$$.fragment,e),h(Cl.$$.fragment,e),h(Ul.$$.fragment,e),h(Ll.$$.fragment,e),h(Hl.$$.fragment,e),h(zl.$$.fragment,e),h(Bl.$$.fragment,e),h(El.$$.fragment,e),h(B.$$.fragment,e),h(Yl.$$.fragment,e),h(Xl.$$.fragment,e),h(Kl.$$.fragment,e),h(ls.$$.fragment,e),xi=!0)},o(e){c(T.$$.fragment,e),c(j.$$.fragment,e),c(F.$$.fragment,e),c(I.$$.fragment,e),c(O.$$.fragment,e),c(ne.$$.fragment,e),c(re.$$.fragment,e),c(de.$$.fragment,e),c(x.$$.fragment,e),c(L.$$.fragment,e),c(ye.$$.fragment,e),c(Te.$$.fragment,e),c(ge.$$.fragment,e),c(je.$$.fragment,e),c(Je.$$.fragment,e),c(Ue.$$.fragment,e),c(A.$$.fragment,e),c(W.$$.fragment,e),c(Le.$$.fragment,e),c(Ae.$$.fragment,e),c(He.$$.fragment,e),c(ze.$$.fragment,e),c(Be.$$.fragment,e),c(Ee.$$.fragment,e),c(Qe.$$.fragment,e),c(qe.$$.fragment,e),c(Oe.$$.fragment,e),c(Z.$$.fragment,e),c(nt.$$.fragment,e),c(pt.$$.fragment,e),c(ft.$$.fragment,e),c(ct.$$.fragment,e),c(yt.$$.fragment,e),c(bt.$$.fragment,e),c(gt.$$.fragment,e),c(H.$$.fragment,e),c(vt.$$.fragment,e),c(kt.$$.fragment,e),c(It.$$.fragment,e),c(Lt.$$.fragment,e),c(Wt.$$.fragment,e),c(Ht.$$.fragment,e),c(zt.$$.fragment,e),c(Bt.$$.fragment,e),c(Pt.$$.fragment,e),c(qt.$$.fragment,e),c(el.$$.fragment,e),c(sl.$$.fragment,e),c(N.$$.fragment,e),c(ol.$$.fragment,e),c(z.$$.fragment,e),c(ml.$$.fragment,e),c(ul.$$.fragment,e),c(hl.$$.fragment,e),c(G.$$.fragment,e),c(wl.$$.fragment,e),c(gl.$$.fragment,e),c(Cl.$$.fragment,e),c(Ul.$$.fragment,e),c(Ll.$$.fragment,e),c(Hl.$$.fragment,e),c(zl.$$.fragment,e),c(Bl.$$.fragment,e),c(El.$$.fragment,e),c(B.$$.fragment,e),c(Yl.$$.fragment,e),c(Xl.$$.fragment,e),c(Kl.$$.fragment,e),c(ls.$$.fragment,e),xi=!1},d(e){e&&(l(y),l(m),l(w),l(b),l(v),l(C),l(V),l(P),l(ns),l(E),l(as),l(Q),l(is),l(R),l(os),l(rs),l(Y),l(ps),l(ms),l(D),l(ds),l(X),l(us),l(S),l(fs),l(q),l(hs),l(cs),l(K),l(Ms),l(ee),l(ys),l(te),l(ws),l(le),l(Ts),l(se),l(bs),l(gs),l(ae),l($s),l(ie),l(js),l(oe),l(Cs),l(Js),l(pe),l(vs),l(me),l(Us),l(ks),l(ue),l(_s),l(Is),l(fe),l(xs),l(he),l(Ls),l(ce),l(As),l(Ws),l(Me),l(Zs),l(Hs),l(we),l(Ns),l(zs),l(be),l(Gs),l(Bs),l($e),l(Vs),l(Ps),l(Ce),l(Es),l(Qs),l(ve),l(Rs),l(Fs),l(ke),l(Ys),l(Ds),l(_e),l(Xs),l(Ie),l(Ss),l(qs),l(xe),l(Os),l(Ks),l(en),l(We),l(tn),l(Ze),l(ln),l(sn),l(Ne),l(nn),l(an),l(Ge),l(on),l(rn),l(Ve),l(pn),l(Pe),l(mn),l(dn),l(un),l(Re),l(fn),l(Fe),l(hn),l(Ye),l(cn),l(De),l(Mn),l(Xe),l(yn),l(Se),l(wn),l(Tn),l(bn),l(Ke),l(gn),l($n),l(et),l(jn),l(tt),l(Cn),l(lt),l(Jn),l(st),l(vn),l(Un),l(at),l(kn),l(it),l(_n),l(ot),l(In),l(rt),l(xn),l(Ln),l(mt),l(An),l(dt),l(Wn),l(ut),l(Zn),l(Hn),l(ht),l(Nn),l(zn),l(Mt),l(Gn),l(Bn),l(wt),l(Vn),l(Tt),l(Pn),l(En),l(Qn),l($t),l(Rn),l(Fn),l(jt),l(Yn),l(Ct),l(Dn),l(Jt),l(Xn),l(Sn),l(Ut),l(qn),l(On),l(_t),l(Kn),l(ea),l(xt),l(ta),l(la),l(At),l(sa),l(na),l(Zt),l(aa),l(ia),l(Nt),l(oa),l(ra),l(Gt),l(pa),l(ma),l(Vt),l(da),l(ua),l(Et),l(fa),l(Qt),l(ha),l(Rt),l(ca),l(Ft),l(Ma),l(Yt),l(ya),l(Dt),l(wa),l(Xt),l(Ta),l(St),l(ba),l(ga),l(Ot),l($a),l(Kt),l(ja),l(Ca),l(tl),l(Ja),l(ll),l(va),l(Ua),l(nl),l(ka),l(_a),l(al),l(Ia),l(il),l(xa),l(La),l(Aa),l(rl),l(Wa),l(pl),l(Za),l(Ha),l(dl),l(Na),l(za),l(fl),l(Ga),l(Ba),l(Va),l(cl),l(Pa),l(Ml),l(Ea),l(yl),l(Qa),l(Ra),l(Tl),l(Fa),l(bl),l(Ya),l(Da),l($l),l(Xa),l(jl),l(Sa),l(qa),l(Jl),l(Oa),l(vl),l(Ka),l(ei),l(kl),l(ti),l(_l),l(li),l(Il),l(si),l(xl),l(ni),l(ai),l(Al),l(ii),l(Wl),l(oi),l(Zl),l(ri),l(pi),l(Nl),l(mi),l(di),l(Gl),l(ui),l(fi),l(Vl),l(hi),l(Pl),l(ci),l(Mi),l(Ql),l(yi),l(wi),l(Rl),l(Ti),l(Fl),l(bi),l(gi),l(Dl),l($i),l(ji),l(Sl),l(Ci),l(ql),l(Ji),l(Ol),l(vi),l(Ui),l(es),l(ki),l(ts),l(_i),l(Ii),l(ss)),l(i),M(T,e),M(j,e),M(F,e),M(I,e),M(O,e),M(ne,e),M(re,e),M(de,e),M(x,e),M(L,e),M(ye,e),M(Te,e),M(ge,e),M(je,e),M(Je,e),M(Ue,e),M(A,e),M(W,e),M(Le,e),M(Ae,e),M(He,e),M(ze,e),M(Be,e),M(Ee,e),M(Qe,e),M(qe,e),M(Oe,e),M(Z,e),M(nt,e),M(pt,e),M(ft,e),M(ct,e),M(yt,e),M(bt,e),M(gt,e),M(H,e),M(vt,e),M(kt,e),M(It,e),M(Lt,e),M(Wt,e),M(Ht,e),M(zt,e),M(Bt,e),M(Pt,e),M(qt,e),M(el,e),M(sl,e),M(N,e),M(ol,e),M(z,e),M(ml,e),M(ul,e),M(hl,e),M(G,e),M(wl,e),M(gl,e),M(Cl,e),M(Ul,e),M(Ll,e),M(Hl,e),M(zl,e),M(Bl,e),M(El,e),M(B,e),M(Yl,e),M(Xl,e),M(Kl,e),M(ls,e)}}}const Ap='{"title":"Legacy model contribution","local":"legacy-model-contribution","sections":[{"title":"Transformers overview","local":"transformers-overview","sections":[{"title":"Model and configuration","local":"model-and-configuration","sections":[],"depth":3},{"title":"Code style","local":"code-style","sections":[],"depth":3}],"depth":2},{"title":"New model addition issue","local":"new-model-addition-issue","sections":[],"depth":2},{"title":"Dev environment","local":"dev-environment","sections":[],"depth":2},{"title":"Create a pull request","local":"create-a-pull-request","sections":[],"depth":2},{"title":"Original checkpoint","local":"original-checkpoint","sections":[{"title":"Debugging","local":"debugging","sections":[],"depth":3}],"depth":2},{"title":"Adapt the model code","local":"adapt-the-model-code","sections":[{"title":"Model initialization","local":"model-initialization","sections":[],"depth":3},{"title":"Convert checkpoints to Transformers","local":"convert-checkpoints-to-transformers","sections":[{"title":"PyTorch layer weights and names","local":"pytorch-layer-weights-and-names","sections":[],"depth":4}],"depth":3},{"title":"Implement the forward pass","local":"implement-the-forward-pass","sections":[],"depth":3},{"title":"Add model tests","local":"add-model-tests","sections":[],"depth":3}],"depth":2},{"title":"Implement tokenizer","local":"implement-tokenizer","sections":[],"depth":2},{"title":"Implement image processor","local":"implement-image-processor","sections":[],"depth":2},{"title":"Implement processor","local":"implement-processor","sections":[],"depth":2},{"title":"Integration tests","local":"integration-tests","sections":[],"depth":2},{"title":"Add documentation","local":"add-documentation","sections":[],"depth":2},{"title":"Refactor","local":"refactor","sections":[],"depth":2},{"title":"Upload to the Hub","local":"upload-to-the-hub","sections":[],"depth":2},{"title":"Merge your model","local":"merge-your-model","sections":[],"depth":2},{"title":"Model addition timeline","local":"model-addition-timeline","sections":[],"depth":2}],"depth":1}';function Wp(g){return pp(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Vp extends mp{constructor(i){super(),dp(this,i,Wp,Lp,rp,{})}}export{Vp as component};
