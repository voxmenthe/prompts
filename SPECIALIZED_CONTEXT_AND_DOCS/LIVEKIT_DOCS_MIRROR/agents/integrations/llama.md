LiveKit Docs › Partner spotlight › Llama

---

# Llama and LiveKit

> Build voice AI on open source models from Meta AI.

## Overview

[Llama](https://www.llama.com/) is a family of open source LLMs developed by [Meta AI](https://www.meta.ai/). These models are widely deployed by a large number of cloud inference providers, and also support your own local or private deployments.

## Providers

LiveKit Agents has out-of-the-box support for all of these Llama inference providers:

- **[Cerebras](https://docs.livekit.io/agents/integrations/llm/cerebras.md)**: Fast text-only inference for the latest Llama models.

- **[Groq](https://docs.livekit.io/agents/integrations/llm/groq.md)**: Fast inference for the latest Llama models.

- **[Fireworks](https://docs.livekit.io/agents/integrations/llm/fireworks.md)**: Inference, fine-tuning, and multimodal support for the latest Llama models.

- **[Perplexity](https://docs.livekit.io/agents/integrations/llm/perplexity.md)**: The Sonar family of models are based on Llama 3.1, fine-tuned for search.

- **[Telnyx](https://docs.livekit.io/agents/integrations/llm/telnyx.md)**: Hosted inference for the latest Llama models.

- **[Together AI](https://docs.livekit.io/agents/integrations/llm/together.md)**: Inference, fine-tuning, and multimodal support for the latest Llama models.

- **[Ollama](https://docs.livekit.io/agents/integrations/llm/ollama.md)**: Run Llama and other open source models locally.

---


For the latest version of this document, see [https://docs.livekit.io/agents/integrations/llama.md](https://docs.livekit.io/agents/integrations/llama.md).

To explore all LiveKit documentation, see [llms.txt](https://docs.livekit.io/llms.txt).